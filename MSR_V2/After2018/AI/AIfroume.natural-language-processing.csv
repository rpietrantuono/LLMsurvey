Post Link,Title,CreationDate,AcceptedAnswerId,Score,ViewCount,Tags,Body,TagName
"46517","Research on Direct Preference Optimization in subsequence of the response","2024-08-14 22:39:54","","1","8","<natural-language-processing><large-language-models><fine-tuning>","<p>I wanted to start research on Direct Preference Optimization (DPO) but in the specific case where we're interested in part of the generated sentence, as if <em>we could highlight</em> where the model gave a bad response, and train specifically on it.</p>
<p>More rigorously, given a generated sequence of tokens <span class=""math-container"">$\{y_1, y_2, ..., y_t\}$</span>, I wanted to fine-tune the model on a selected range <span class=""math-container"">$\{y_i, ..., y_{i+k}\}$</span>.</p>
<p>Could I use DPO directly by doing <span class=""math-container"">$\pi_\theta(y_i, ..., y_{i+k}\vert x, y_1, ..., y_{i-1})$</span>? Or could similar works be pointed out?</p>
<p>Thanks!</p>
","natural-language-processing"
"46516","How to convert a positionally encoded predicted embedding from a decoder to its matching token?","2024-08-14 20:14:41","46521","0","24","<natural-language-processing><transformer><embeddings><positional-encoding><tokenization>","<p>Is it valid to just subtract the positional encoding from a predicted output if the decoder was also positionally encoded? Or does masking take care of this problem, and the decoder should only learn the embedding (not positionally encoded)</p>
","natural-language-processing"
"46488","What model would you recommend for fine-tuning to generate accurate embeddings for specialized language?","2024-08-10 17:58:50","","2","57","<natural-language-processing><large-language-models><embeddings><fine-tuning><model-request>","<p>I'm working on creating custom embeddings for a dataset of legal texts in Uzbek.</p>
<p>What model would you recommend for fine-tuning to generate accurate embeddings, particularly for specialized language like legal terminology?</p>
<p>If possible, could you also outline the steps for doing this and code implementation?</p>
","natural-language-processing"
"46324","Summary Generation","2024-07-24 10:40:21","","0","20","<natural-language-processing><transformer><large-language-models><huggingface>","<p>I want to create a summary from a list of some bullet points and keywords . Most NLP and Transformer based models are not very well suited for short sentences and bullet point.
Bullet points are usually very small 1-4 words .
Most summarisers just concat the points together that is not what I am looking for
I don't wish to use a api for this a hugging face , transformer, or an LLM model would be great that i could run locally .</p>
<p>For Example:</p>
<ul>
<li>Had breakfast : NO</li>
<li>Had Lunch : NO</li>
<li>Went for a jog : YES</li>
</ul>
<p>Output :
Did not have breakfast and lunch . I went for a jog</p>
","natural-language-processing"
"46311","Document clustering and summarisation via GraphRAG","2024-07-23 09:40:47","","0","22","<natural-language-processing><large-language-models><embeddings><knowledge-graph>","<p>Suppose I have a corpus of documents that I want to cluster and summarise. There are an indeterminate number of parent clusters, and each parent may in turn have several tributary child clusters. I would like to identify both parent and child clusters, and generate LLM summaries for each.</p>
<p>My approach has been to use hierarchical agglomerative clustering to determine the number of parents so as to maximise the silhouette score, subsequently clustering document embeddings with this optimal number. I then repeat this process to determine the number of child clusters for each parent. Following this, for each cluster I extract several documents whose embeddings are closest to the cluster centroids, along with important keywords and key phrases from the cluster, to use in the LLM summarisation prompt.</p>
<p>This isn't exactly a conventional RAG application since I seek to summarise the entire corpus, but I think it shares enough similarities as to be considered a kind of RAG.</p>
<p>I would be grateful for recommendations on how to improve this procedure. For example, I'm aware that GraphRAG can use community detection to identify clustered concepts. Would GraphRAG perhaps be more suitable for identifying parent and child clusters than my current approach? If so, would the LLM prompt take a different form than the key document, key phrase and keyword extraction that I've outlined?</p>
","natural-language-processing"
"46275","Combinig output of two different machine learning models for accurate invoice data extraction: Is this a viable approach?","2024-07-17 18:12:58","","0","26","<natural-language-processing><training><transformer><accuracy><ensemble-learning>","<p>I am working (trying to work) on a project to extract relevant information from invoices. Currently I don't achieve much good accuracy so am trying to come up with some new ideas. I am considering combining two machine learning models: Lilt and YOLO, but the specific models arent important, I want to ask you about my proposed workflow:</p>
<p><strong>Initial Processing with Lilt:</strong>
The invoice is first processed by the Lilt model and OCR engine to extract structured data based on the layout and content.  Lilt's output is captured in a structured format, such as JSON.</p>
<p><strong>Secondary Processing with YOLO:</strong>
The same invoice is then processed by the YOLO model to detect and extract specific fields or text blocks (e.g., invoice number, date, total amount). YOLO's output is similarly captured in a structured format with confidence scores.</p>
<p><strong>Comparison and Reconciliation:</strong>
I will implement a function to compare the outputs from Lilt and YOLO.</p>
<p><strong>For each field:</strong>
If both models provide a value, I will compare the confidence scores and choose the higher one.
If only one model provides a value, I will use that value.</p>
<p>My goal is to leverage the strengths of both models to achieve higher accuracy in extracting invoice data. However, I have some concerns and would appreciate feedback on the following points:</p>
<pre><code>Integration Complexity: Are there best practices for integrating outputs from two different models effectively?

Performance: Will running two models sequentially significantly impact processing time, and how can this be optimized?

Data: The models would be trained not on same datasets. I am currently working with one czech invoice dataset in Layout/Lilt format that i had obtain but YOLO expect different input so i would need to annotate new dataset. Would that be a problem?

Accuracy: Is it common to combine output of several transformers?
</code></pre>
<p>Has anyone implemented a similar approach, and what lessons did you learn? Are there alternative methods that might achieve better results? Is my idea just too complicated or straight up useless?</p>
<p>Any insights, suggestions, or resources would be greatly appreciated!</p>
","natural-language-processing"
"46252","Normalizing the embedding space of an encoder language model with respect to categorical data","2024-07-15 23:12:22","","0","22","<natural-language-processing><classification><transformer><word-embedding>","<p>Suppose we have a tree/hierarchy of categories (e.g. categories of products in an e-commerce website), each node being assigned a title. Assume that the title of each node is semantically accurate, meaning it's consistent with the category (the titles of the children nodes) it represents. Now, take an encoder language model (like BERT or Word2Vec) and produce embeddings for each node/category. My goal is to ensure that these embeddings are representative of the categorical hierarchy. I wonder:</p>
<ul>
<li>Should the embeddings (mostly) be consistent with the categorical hierarchy, even if the categorical hierarchy is very niche and/or uneven (meaning that categorical granularity is not necessarily evenly distributed, if that makes sense)? By consistent, I mean that the embeddings of sibling nodes under one parent should be closer to each other than to children nodes of other parents, and closer to their parent's embeddings than to other parents' embeddings. Is there a nice metric to measure/validate this?</li>
<li>If not, what would be good ways to re-map a latent space to make it &quot;nicer&quot; with respect to the categorical hierarchy? I'm thinking either 1) we directly transform the latent space or 2) fine-tune the language encoder model (i.e. BERT). For example: 1) let's say that the shape formed by a category/parent's sub-categories/children is a thin oval, would it be possible and make sense to want to map the space such that this thin oval becomes a circle? Also for 2) would fine-tuning BERT along the task of classifying leaf embeddings' under the correct parent embeddings do the same thing?</li>
</ul>
<p>I think that this requires the categories to not be so niche and to have some correspondence to regular language usage (and even more after providing context), which is my case.</p>
<p>This is just my intuition, so let me know your thoughts. I would be interested in exploring anything from the most simple heuristic approaches to SOTA NLP techniques that could pertain to this problem.</p>
","natural-language-processing"
"46244","How to quantify the tone of a textual paragraph? If there is historical communication available, how to check for consistency in tonality for new i/p?","2024-07-15 07:27:07","","0","14","<deep-learning><natural-language-processing>","<p>Certain aspects of NLP such as the basic Polarity, Subjectivity, and Positivity, can be obtained with ease, but keyword consistent usage and the &quot;<strong>Style</strong>&quot; or the &quot;<strong>Tone</strong>&quot; of writing cannot be well quantified to maintain the consistency which is helpful for brands in their marketing campaigns.</p>
<p>Tried to obtain different quantifiers, and get the aggregate values for the historical communications data, and ranging from this aggregated value would be an accept window, wherein if the new sentence/para lies within the range, it can be deemed consistent, but this is not working out well and lacks accuracy.</p>
","natural-language-processing"
"46165","How to generate synthetic text data for LLM fine tuning?","2024-07-05 20:18:47","","0","46","<natural-language-processing><large-language-models>","<p>Given a corpus of data like a log of Slack conversations, I want to be able to use this and generate fictitious conversations e.g., given 10 conversations, I want to be able to scale this up to 100 conversations. Is there a toolkit to do this? I tried searching but could not find anything. I understand the most naive approach would be to use a pre-trained LLM, give the corpus to it as input and ask it to do the job. I haven't tried this but the real corpus will be large enough such that it won't fit in context window of a pre-trained LLM.</p>
","natural-language-processing"
"46153","Do sinusoidal positional embeddings fundamentally limit context length?","2024-07-04 01:35:02","","0","20","<natural-language-processing><positional-encoding>","<p>In principle, it seems like we can generate endless sinusoidal positional embeddings. However, with respect to context window maximums, is there some limitation that sinusoidal positional embeddings have if we pretrain on a fixed window size but inference on a much larger set of sequence lengths? I imagine that, with large enough sequences, positional embeddings eventually duplicate due to the cyclical nature of the sin/cos functions, but I'm not 100% sure.</p>
","natural-language-processing"
"46117","Hugging Face model with large context window","2024-06-30 19:20:28","","0","16","<natural-language-processing>","<p>Im looking for a model that accepts input like 50k characters and a prompt answering a question based on that text. Is there something available like that? Not sure how to find it, new to AI.</p>
","natural-language-processing"
"46110","How does casual and padding mask work in decoder-only models?","2024-06-30 14:00:13","","0","37","<natural-language-processing><transformer><attention>","<p>I am trying to implement a decoder-only model from scratch using PyTorch, but I am confused about how the masking works. From what I understand, when we have encoder-decoder architecture, the padding mask is in the encoder and the casual mask is in the decoder. Then, with the decoder-only architecture, do we combine them, and if we do, how will this look?</p>
","natural-language-processing"
"46052","Efficient Matching of Sample Requests to Sample Offers Using Large Language Models","2024-06-23 02:27:52","","0","22","<natural-language-processing><large-language-models><open-ai><text-classification>","<p>I want to discuss an interesting matching problem. We aim to match sample requests with corresponding sample offers. Here are some examples:</p>
<p>Sample Requests:</p>
<p>Need help installing Linux on my old laptop.
Looking for a tutor in specialist mathematics.
Need a second person to help assemble an Ikea bed.
Sample Offers:</p>
<p>Electron Workshop and Linux Users Victoria Tech.
VCE maths tutor (Further, Methods, Specialist).
Heading from Lake Eildon to Melbourne. Anyone available?
To solve this problem, I used a large language model (LLM) to perform the matching. My approach involves embedding the requests and offers using vector embeddings and then employing a Retrieval-Augmented Generation (RAG) framework using LangChain. The method has shown promising results.</p>
<p>Here's a snippet of my code:</p>
<h1>Initialize the OpenAI embeddings</h1>
<p>embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)</p>
<h1>Sample data</h1>
<p>strings_to_embed = sample_off</p>
<h1>Create Chroma vector store from the texts using the built-in embeddings</h1>
<p>vector_store = Chroma.from_texts(texts=strings_to_embed, embedding=embeddings)
retriever = vector_store.as_retriever()</p>
<p>template = &quot;&quot;&quot; Match with the best offer based on the following context. Make different phrasing of the offer then search it.
Only return the matching answer.
No extra reasoning or string should be added:
{context}</p>
<p>Question: {question}
&quot;&quot;&quot;</p>
<p>prompt = ChatPromptTemplate.from_template(template=template)</p>
<p>rag_chain = (
{&quot;context&quot;: retriever, &quot;question&quot;: RunnablePassthrough()}
| prompt
| ChatOpenAI()
| StrOutputParser()
)</p>
<h1>Now to match the best request with the best offer, we invoke the RAG chain</h1>
<p>rag_chain.invoke(sample_req[0])
While this method works well, I believe it may require too many LLM calls, which is not efficient. I am looking for ideas and discussions on how to improve this approach. Specifically, I want to explore how we can use the retriever more efficiently. For example, structuring the sample offers into different classes could potentially make the querying process more straightforward and efficient.</p>
<p>Any insights or suggestions on optimizing this process would be greatly appreciated!</p>
","natural-language-processing"
"46024","What is the exact purpose of input modulation gate in LSTMs?","2024-06-19 12:50:42","","0","43","<deep-learning><natural-language-processing><recurrent-neural-networks><long-short-term-memory>","<p>Basically, I was learning about LSTMs where I found LSTMs are made up of three gates: The forget gate, input gate and output gate. However, I came across some sources that state there is a fourth gate called hte <code>input modulation gate</code>. Yet, I can't find much information about this gate. Some sources say it's usually omitted when defining the input gates. Other sources say it's part of the input gate as a sort of sub-system.</p>
<p><strong>What exactly does the input modulation gate do in LSTMs?</strong></p>
","natural-language-processing"
"45991","How are perplexities over multiple instance aggregated?","2024-06-15 19:27:15","","1","54","<natural-language-processing><large-language-models><perplexity>","<p>The perplexity of the <span class=""math-container"">$i^{th}$</span> token in the <span class=""math-container"">$k^{th}$</span> sequence is</p>
<p><span class=""math-container"">$$
P_{ki} = \frac{1}{p(t_{ki})}
$$</span></p>
<p>The perplexity aggregated for the <span class=""math-container"">$k^{th}$</span> sequence is then</p>
<p><span class=""math-container"">$$
P_{k} = \left(\prod_{i=1}^N P_{ki}\right)^{1/N} \\
= \left(\prod_{i=1}^N \frac{1}{p(t_{ki})} \right)^{1/N}
$$</span></p>
<p>which is the geometric mean of the perplexities of the tokens. This makes sense as we are essentially taking the multiplicative inverse of the probability that the model got the whole sequence correct.</p>
<p>Now my question is how to aggregate the perplexities of several sequences. It seems from various places, including the <a href=""https://huggingface.co/spaces/evaluate-metric/perplexity"" rel=""nofollow noreferrer"">Hugging Face Tutorial</a>, I see that the prescription is to take the arithmetic mean of the perplexities of sequences</p>
<p><span class=""math-container"">$$
P = \frac{1}{m} \sum_{k=1}^m P_k
$$</span></p>
<p>I am not quite understanding what it means to take the average of 1/probabilities. What is this actually capturing?</p>
","natural-language-processing"
"45936","Classifier-Free-Guidance with Transformers","2024-06-09 13:29:04","46258","0","53","<deep-learning><natural-language-processing><transformer>","<p><a href=""https://i.sstatic.net/v8te0AAo.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/v8te0AAo.png"" alt=""enter image description here"" /></a></p>
<p>I'm working on music generation using transformers.
Using the decoder part for the audio tokens with text conditioning by the T5 encoder</p>
<p><a href=""https://i.sstatic.net/fztWztX6.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/fztWztX6.png"" alt=""enter image description here"" /></a>
In Classifier-Free-Guidance, the text conditioning randomly dropped with a probability of <span class=""math-container"">$p_{uncond}$</span>. So when it's dropped, what should the cross-attention input be, or how is the transformer architecture modified?</p>
<p>Is it like when the text condition is not present the middle sub-block is skipped with an if statement?</p>
","natural-language-processing"
"45926","Why decoder only model require left padding?","2024-06-08 10:22:19","","0","57","<natural-language-processing><transformer><natural-language-understanding>","<p>We used Gemma 2B model to infer, and tried left and right padding. &quot;right&quot; padding is giving us different answer compared to left padding.
Why do we use left padding for decoder only model, please provide technical answer.</p>
<p>I have also check
<a href=""https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa"">While fine-tuning a decoder only LLM like LLaMA on chat dataset, what kind of padding should one use?</a> but there was no technical answer for it.</p>
","natural-language-processing"
"45923","Why I am getting different KV cache?","2024-06-08 08:02:18","","0","27","<natural-language-processing><transformer>","<p>I have taken Squad 2.0 dataset for inferencing Gemma 2B model.</p>
<p>When I provided model with 1st datapoint truncating till 36 tokens and same datapoint truncating till 80 tokens.</p>
<p>I am getting slightly different KV cache for first 36 tokens, why is that so?</p>
<p><strong>Example:</strong></p>
<p><strong>Input 1 Token:</strong> [[     2, 235309,  19647, 235307]]</p>
<p><strong>Input 2 Token:</strong> [[     2, 235309,  19647, 235307,   1261,    573,   2872]]</p>
<p>Above is just example not actual prompt. Input 2 is extension of input 1.</p>
<p>When giving input 1 and input 2 to model we will get KV cache. The KV cache of first 4 tokens should be same theoretically. But I am getting difference in both the KV cache only when Input 2 has more than 54 tokens in my case. Otherwise I am getting same KV cache.</p>
<p>Please help me figure out why this case is happening.</p>
","natural-language-processing"
"45902","Any popular diffusion model for language modeling?","2024-06-06 07:28:33","","4","62","<natural-language-processing><large-language-models><diffusion-models><language-model>","<p>Is there a popular diffusion model-based framework for language modelling? If not, is it because of the difficulty sampling for discrete distributions?</p>
","natural-language-processing"
"45862","is bfloat training compatible with float16 inference?","2024-05-31 17:04:26","","0","120","<natural-language-processing><computation>","<p>Lately I stumbled upon the Llama3 hf docs: <a href=""https://huggingface.co/docs/transformers/main/en/model_doc/llama3"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/main/en/model_doc/llama3</a></p>
<p><em>The Llama3 models were trained using bfloat16, but the original inference uses float16. The checkpoints uploaded on the Hub use torch_dtype = 'float16', which will be used by the AutoModel API to cast the checkpoints from torch.float32 to torch.float16.Training the model in float16 is not recommended and is known to produce nan; as such, the model should be trained in bfloat16.</em></p>
<p>Does this mean that the weights are always stored in float16 during training, and each forward pass we cast them to bfloat16, and the gradients as well as the activations are stored in bfloat16?</p>
<p>If the things mentioned above are true, then what about LoRA? So should the compute finetuning dtype also be bfloat16? While weights are stored in float16 should inference be performed in float16 as it will allow for more precise computations?</p>
","natural-language-processing"
"45853","probability intepreter of attention mechanism in Seq2Seq","2024-05-30 06:02:38","","0","24","<natural-language-processing><attention><seq2seq>","<p>Many people explained seq2seq model by explanatory description. However, in my opinion, that is just like a robot who could say something correctly but don't really understand it. Just like the AI did.</p>
<p>In my opinion, the correct way to descript Seq2Seq model and others in NLP should start from a probability view.
My probaility view is very simple. The output of encoder is a presentation of the probability distribution of the next word. And in each step of the Decoder, it just modify the distribution based on each word it predicted by the distribution and output the modified distribution. Then do this again and again.</p>
<p>So from this probability view, how could we explain the attention mechanism used in Seq2seq?</p>
","natural-language-processing"
"45852","An issue about the Decoder in seq2seq(rnn)","2024-05-30 05:17:08","","0","8","<natural-language-processing><recurrent-neural-networks><seq2seq><encoder-decoder>","<p>Here is a confusion about the decoder in seq2seq.
In each time-step in decoder, there are two outputs: 1.output 2.hidden.
and this hidden state is used as the next input hidden state.
this output is used as the next input state.</p>
<p>But when I use pytorch, I find 1.output 2.hidden are exactly the same thing.
this means output=hidden, so what's the point to use two same thing twice?</p>
<p>in pytorch we can specify the length of rnn (corresponding to the number of words in a stentence, say N), but to implement the decoder, we often set the length to 1.
and manullay do a loop N times. In this case, the formula &quot;hidden=output&quot; is true.</p>
<p>Maybe there is some misunderstanding here, however, I find now way to figure it out. Since I found no formula description(probability based) in my lecture slides. And I don't know how pytorch exactly works.</p>
<p>Besides, if anyone could give probability interpreter step by step, that would be fine.
This confusion is related to another confusion. That is, what's meaning of hidden state?
If it is understood to be a vector which contains info of all the sentence, why I can extract one predicted word from it by juse one matrix(the linear matrix connect to the output of the decoder in each step)?</p>
<p>Here is an example. suppose the output hidden state of encoder is <span class=""math-container"">$h_0$</span>,
and the first input of decoder is <span class=""math-container"">$x_1$</span>, than the first output is <span class=""math-container"">$o_1$</span>, first hidden output is <span class=""math-container"">$h_1$</span>. and by the same method we define <span class=""math-container"">$x_i,o_i,h_i$</span>.
so we have <span class=""math-container"">$x_2=o_1,h_1=o_1$</span>, and if we set the final output in each step as <span class=""math-container"">$y_i$</span>,
so suppose <span class=""math-container"">$y_i=Mo_i$</span>, this means that we use the same <span class=""math-container"">$M$</span> to extract different things from <span class=""math-container"">$o_i$</span>, this is a little strange, and another strange is that since <span class=""math-container"">$o_i=h_i$</span>, we are using the same thing twice.</p>
","natural-language-processing"
"45813","Why can't we use only keys to calculate self-attention?","2024-05-25 11:27:00","","0","33","<deep-learning><natural-language-processing><computer-vision><transformer><attention>","<p>I was reading about the self-attention mechanism and the paper suggests to have 3 things to be computed: Key, Query and Value. As far as I understood the reason for having Value is to allow adjustments to the initial embedding (after the positional encoding) depending on the context (that's intuitive). However, I don't get why we need the Query there. Why can't we do the similarity calculations using only the Keys?</p>
","natural-language-processing"
"45768","Why Tokenization Algorithm replace space with underscore ""_""?","2024-05-21 12:23:06","45775","0","47","<natural-language-processing><tokenization>","<p>I have recently read an article for Byte-Pair Encoding (BPE), in which they have replaced space with an underscore(_), or we can say, adding underscore after each word/token.</p>
<p>I did not understand the intuition for adding an underscore; we can just do it without adding an underscore.
We can also have any other character that is not frequently used; why underscore?
We can also add an underscore at the start of the word or both end and start, but why add to the end?</p>
<p>Site: <a href=""https://medium.com/@hsinhungw/understanding-byte-pair-encoding-fd196ebfe93f"" rel=""nofollow noreferrer"">https://medium.com/@hsinhungw/understanding-byte-pair-encoding-fd196ebfe93f</a></p>
","natural-language-processing"
"45708","Determining optimal data size for generalization in transformer encoders, particularly for Time-Series signal data","2024-05-14 21:56:30","","0","43","<deep-learning><natural-language-processing><transformer><time-series>","<p>I'm currently experimenting with training a model that employs a single transformer encoder on time-series signal data. Despite having a relatively small dataset of around 50 examples, each with a sequence length of approximately 1000, the model seems to excel at understanding and memorizing these examples. However, I'm concerned about its generalization capabilities given the limited amount of data.</p>
<p>I'm wondering: <strong>How much data is typically required for a transformer encoder to generalize well,</strong> especially in the context of time-series signal data? Is there a recommended range or guideline for the amount of training data that can help ensure better generalization performance? Additionally, are there specific strategies or techniques that can enhance generalization in transformer models when working with small datasets?</p>
<p>Any insights, experiences, or references would be greatly appreciated. Thank you!</p>
","natural-language-processing"
"45691","What should be Relationship between embedding dimension and context length?","2024-05-13 12:59:22","45697","2","129","<natural-language-processing><transformer><large-language-models>","<p>What should we keep hidden dimension/embedding dimension (d_model as per attention is all you need paper), greater, equal, or smaller to the context length (n)?</p>
<p>Is there any such relationship between the embedding dimension and context length?</p>
<p>How will it affect the LLM?</p>
","natural-language-processing"
"45640","My loss is increasing instead of decreasing when i use a regularizer, but if i don't use regularizer then it stays at 00000e+00 or something","2024-05-08 07:53:48","","0","16","<convolutional-neural-networks><natural-language-processing><classification><image-recognition><image-net>","<p>This is my model architecture:</p>
<pre><code>activation = LeakyReLU(negative_slope=0.1)  # You can adjust the slope (alpha) as 

needed

# Text input
text_input_layer = Input(shape=(500,))
embedding_layer = Embedding(max_words, 50)(text_input_layer)
normalized_embedding = BatchNormalization()(embedding_layer)  # Add BatchNormalization layer
replace_zeros = Lambda(lambda x: tf.where(tf.equal(x, 0), 0.001 * tf.ones_like(x), x))(normalized_embedding)
replace_nan = Lambda(lambda x: tf.where(tf.math.is_nan(x), 0.001 * tf.ones_like(x), x))(replace_zeros)
text_layer = Conv1D(256, 3, activation=activation)(replace_nan)
text_layer = MaxPooling1D(3)(text_layer)
text_layer = Conv1D(256, 3, activation=activation)(text_layer)
text_layer = MaxPooling1D(3)(text_layer)
text_layer = Conv1D(256, 3, activation=activation)(text_layer)
text_layer = MaxPooling1D(3)(text_layer)
text_layer = Flatten()(text_layer)
text_layer = Dense(512, activation=activation)(text_layer)

# Image input
image_input_layer = Input(shape=(256, 256, 1))
replace_zeros_image = Lambda(lambda x: tf.where(tf.equal(x, 0), 0.001 * tf.ones_like(x), x))(image_input_layer)
replace_nan_image = Lambda(lambda x: tf.where(tf.math.is_nan(x), 0.001 * tf.ones_like(x), x))(replace_zeros_image)
image_layer = Conv2D(256, (3, 3), activation=activation)(replace_nan_image)
image_layer = MaxPooling2D((2, 2))(image_layer)
image_layer = Conv2D(256, (3, 3), activation=activation)(image_layer)
image_layer = MaxPooling2D((2, 2))(image_layer)
image_layer = Conv2D(256, (3, 3), activation=activation)(image_layer)
image_layer = MaxPooling2D((2, 2))(image_layer)
image_layer = Flatten()(image_layer)
image_layer = Dense(512, activation=activation)(image_layer)

# Concatenate text and image branches
concatenated_layer = Concatenate()([text_layer, image_layer])
#kernel_regularizer=l1(0.001)
# Dense layers
dense_layer = Dense(512, activation=activation)(concatenated_layer)
dense_layer = Dense(1024, activation=activation, kernel_regularizer=l1(0.0000001))(dense_layer)
dense_layer = Dense(2048, activation=activation)(dense_layer)
output_layer = Dense(1, activation='sigmoid')(dense_layer)

# Define the model with two inputs
model = Model(inputs=[text_input_layer, image_input_layer], outputs=output_layer)
model.summary()
</code></pre>
<p>Here is my compiling section and then running it:</p>
<pre><code>optimizer = RMSprop(learning_rate=0.1, clipvalue=1.0)
loss_function = CategoricalCrossentropy()
model.compile(optimizer=optimizer,
              loss=loss_function,
              metrics=[CategoricalAccuracy()])
</code></pre>
<p>Am still new to two-input layer-type architecture</p>
<p>Also here is the shape of my data:</p>
<pre><code>print(&quot;Text Data Shapes:&quot;)
print(&quot;Training:&quot;, x_train_text.shape, y_train_text.shape)
print(&quot;Validation:&quot;, x_val_text.shape, y_val_text.shape)
print(&quot;Test:&quot;, x_test_text.shape, y_test_text.shape)
​
print(&quot;\nImage Data Shapes:&quot;)
print(&quot;Training:&quot;, x_train_image.shape, y_train_image.shape)
print(&quot;Validation:&quot;, x_val_image.shape, y_val_image.shape)
print(&quot;Test:&quot;, x_test_image.shape, y_test_image.shape)
Text Data Shapes:
Training: (5000, 500) (5000,)
Validation: (2000, 500) (2000,)
Test: (1000, 500) (1000,)

Image Data Shapes:
Training: (5000, 256, 256) (5000,)
Validation: (2000, 256, 256) (2000,)
Test: (1000, 256, 256) (1000,)
</code></pre>
<p>Here the text data was tokenized, as such the shape is like that.</p>
","natural-language-processing"
"45575","Visual representation(s) for variable length m-tuples","2024-04-29 04:23:17","","0","18","<natural-language-processing><graphs><graph-theory>","<p>I'm working with a dataset of sequences, each 200 characters long. Within these sequences are embedded 10-character patterns (P1 to P5). The co-occurrence of these patterns varies across sequences - some contain just one pattern (e.g. P1), while others have multiple patterns (e.g. P1, P2, P3).</p>
<p>The current methods like Venn diagrams and basic graph models primarily capture co-occurance frequency of patterns (P1 and P2 vs P1,P2,P3 etc.) and pairwise relationships between patterns but cannot adequately represent complex co-occurrences involving more than two patterns (m-tuples where m&gt;2) for a visualization. While visualizations like upset plots come closer, they still don't provide an insightful visualization of the compositional relationships between P1 to P5.</p>
<p>I need visualization or network analysis techniques that can effectively capture and visualize the frequency and complexity of m-tuple (m&gt;2) pattern co-occurrences within the sequences. I'm particularly interested in methods going beyond pairwise interactions to include higher-order relationships. The goal is to better understand and visualize how these patterns co-exist, potentially revealing intricate relationships or frequent combinations critical for further analysis.</p>
<p>What is a good computational context to look for insight here? Methods focusing on social network analysis? Graph theory? Could this be better suited in the context of natural language processing where P1 to P5 could be posed as words, and sequences as sentences?</p>
","natural-language-processing"
"45567","How does ChatGPT assign confidence level?","2024-04-28 19:29:47","","0","78","<natural-language-processing><chatgpt><question-answering>","<p>How does ChatGPT assign confidence level to its answer? What is the mathematical description of it?</p>
<p>Here is my guess. It produces many answers from auto-regression. It already has a probability assigned to each of its outputs. It can just output this probability or some function of this probability for the chosen output. Is this correct?</p>
","natural-language-processing"
"45555","Is there any purpose of altering neural network architecture if validation loss does not decrease but training loss does?","2024-04-27 18:15:10","","0","22","<neural-networks><natural-language-processing><transformer><gradient-descent>","<p>I am training a transformer based neural network and the validation loss is not decreasing, but the training loss does decrease. I am wondering if it's possible to debug or change the architecture such that this is reversed, or if I definitely need to debug my dataset.</p>
","natural-language-processing"
"45531","Can 3D convolutions appropriately capture a frozen embedding space?","2024-04-24 21:17:38","","0","18","<natural-language-processing><computer-vision><embeddings><word2vec><skip-gram>","<p>My project is a strange combination of NLP and Computer Vision.
I have datapoints of 3D tensor where each element is a token in an NLP vocabulary. The vocabulary is around 1000 unique &quot;words&quot;.</p>
<p>The tokens within the 3D tensor are spatially related to adjacent tokens. For this reason an embedding model is relevant. I'm using SkipGrams adapted to three dimensions (so instead of context windows, it's a context &quot;cube&quot; around a target token). Suppose I've pre-trained this SkipGram model on a whole dataset of these 3D tensors. Thus, I have a simple lookup table with which I can convert each token to its fixed embedding.</p>
<p>Now, I want to train a generative model on this dataset to capture it's distribution, and interpolate between points using a trained latent space. To do this, I'm using a Variational Auto Encoder architecture from Stable Diffusion adapted to three dimensions (Conv3D instead of Conv2D). To adapt it to three dimensions, I'm treating the embedding dimension as though it is a color channel in standard Conv3D implementations. Instead of taking a tensor of shape <code>(3, Height, Width, Depth)</code> as input, my VAE takes <code>(Token Embedding Dimension Size, Height, Width, Depth)</code> as input. The &quot;3&quot; in the standard Conv3D task corresponds to RGB values in a voxel image.</p>
<p>The question is: Will my VAE be able to capture the embedding dimension even though it is treated  as the &quot;channel&quot; dimension?</p>
<p>I've read some papers which suggest that the embedding space collapses if it is used as part of the training task for an instance like this, so I don't believe that is an option. Specifically, <a href=""https://arxiv.org/pdf/2212.09412.pdf"" rel=""nofollow noreferrer"">this</a> paper found that &quot;frozen embeddings alleviate the [embedding space] collapse remarkably&quot;</p>
","natural-language-processing"
"45403","Attention Mechanism: Why don't we just use a simple dot product instead of the Q, K, V matrices?","2024-04-09 09:38:57","","0","36","<natural-language-processing><transformer><attention><gpt>","<p>I am currently learning about Transformers by reading Richard Turner's paper <a href=""https://arxiv.org/pdf/2304.10557.pdf"" rel=""nofollow noreferrer"">&quot;An Introduction to Transformers&quot;</a>. On page 3 of the paper he gave a &quot;naive&quot; approach to build the attention matrix by a simple dot product of the input vector <span class=""math-container"">$X$</span> (then passing through a softmax function) - given input vector <span class=""math-container"">$X$</span> (a <span class=""math-container"">$D \times N$</span> matrix) we can calculate the <span class=""math-container"">$n, n'$</span>-th entry of the attention matrix <span class=""math-container"">$A$</span> as:</p>
<p><span class=""math-container"">$$A_{n,n'} = \frac{\exp( \textbf{x}_n^\top  \textbf{x}_{n'})}{\sum_{n''=1}^N \exp(\textbf{x}_{n''}^\top \textbf{x}_{n'})}$$</span></p>
<p>Written in matrix form it would be:</p>
<p><span class=""math-container"">$$A = \text{softmax}(X^{\top}X)$$</span></p>
<p>Where <span class=""math-container"">$\text{softmax}(M)$</span> means to apply the regular softmax function to each <em>column</em> of the matrix <span class=""math-container"">$M$</span>.</p>
<p>He later on explained that this approach &quot;entangles information about the similarity between locations in the sequence with the content of the sequence itself&quot;, and thus improving it by applying a linear transformation <span class=""math-container"">$U$</span> to the vector <span class=""math-container"">$\textbf{x}_n$</span>:</p>
<p><span class=""math-container"">$$A_{n,n'} = \frac{\exp( \textbf{x}_n^\top U^\top U \textbf{x}_{n'})}{\sum_{n''=1}^N \exp(\textbf{x}_{n''}^\top U^\top U \textbf{x}_{n'})}$$</span></p>
<p>or</p>
<p><span class=""math-container"">$$A = \text{softmax}(X^\top U^\top UX)$$</span></p>
<p>And later, he again improving it further by using two separate linear transformations <span class=""math-container"">$U_k$</span> and <span class=""math-container"">$U_q$</span>, since &quot;the numerator
in this construction is symmetric and this could be a disadvantage&quot;:</p>
<p><span class=""math-container"">$$A_{n,n'} = \frac{\exp \left( \textbf{x}_n^\top U_{\textbf{k}}^\top U_{\textbf{q}}^{} \textbf{x}_{n'} \right)}{\sum_{n''=1}^N \exp \left(\textbf{x}_{n''}^\top U_{\textbf{k}}^\top U_{\textbf{q}}^{} \textbf{x}_{n'}\right)}$$</span></p>
<p>or</p>
<p><span class=""math-container"">$$ A = \text{softmax}(X^\top U_k^\top U_qX)$$</span></p>
<p>My problem is that the exact disadvantage of the two approaches above and the exact improvements each new approach provides isn't explained very clearly in the paper. Is it possible for anyone to offer a more detailed (both intuitively and mathematically) explanation on the disadivantage of each of the naive approaches and how the improvement would help?</p>
","natural-language-processing"
"45398","why we use learnable positional encoding instead of Sinusoidal positional encoding","2024-04-09 08:59:00","","1","287","<machine-learning><deep-learning><natural-language-processing><transformer><bert>","<p>In the original paper of <a href=""https://arxiv.org/pdf/1706.03762.pdf"" rel=""nofollow noreferrer"">transformers</a> they using positional encoding to capture the position of each word in the sentence and for calculate that it using sin and cos ,like shom in the image.<a href=""https://i.sstatic.net/pFtun.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/pFtun.png"" alt=""Sinusoidal positional encoding"" /></a> In Bert and the author architecture that based on transformers ,they use learnable position encoding ,so they initialize the vectors of positional encoding randomly and then start to adjust them in training.<br>My question is why we use the learnable positional encoding, what is the objective?</p>
","natural-language-processing"
"45378","Train my own LLM on a smaller corpus of text?","2024-04-07 12:21:57","","0","293","<natural-language-processing><transformer><large-language-models><open-ai><huggingface>","<p>Would it be possible to train my own LLM on a smaller corpus of text, lets say some coding documentation that I then want to ask questions about using the model?</p>
<hr />
<p>If so, are there any recommended ways of doing this, i.e is there a prebuilt architecture or library I can use, and just provide the corpus of text.</p>
","natural-language-processing"
"45329","How the Q,K,V be calculated in multi-head attention","2024-04-02 08:58:12","","0","245","<machine-learning><deep-learning><natural-language-processing><transformer><attention>","<p>I want to understand the transformer architecture, so I start with self attention and I understand their mechanism, but when I pass to the multi-head attention I find some difficulties like how calculate Q , K and V for each head.
I find many way to calculate Q , K and V but I don't know which  way is correct.<br>
<strong>method 1:</strong>
<img src=""https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png"" alt=""this image illustrate how calcule these matrices "" />
<strong>method 2:</strong>
I find this method in YouTube.
<a href=""https://i.sstatic.net/HEZHv.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/HEZHv.png"" alt=""enter image description here"" /></a>
<strong>method 3:</strong>
in this method it just for headi we have:
Qi=xWqi
Ki=xWki
Vi=xWvi
so I don't know which method is correct
there is the links of my references
<a href=""https://jalammar.github.io/illustrated-transformer/"" rel=""nofollow noreferrer"">The Illustrated Transformer</a>
<a href=""https://youtu.be/bCz4OMemCcA?si=4cJa0YojjkPgzcs0"" rel=""nofollow noreferrer"">YouTube video</a></p>
","natural-language-processing"
"45311","Clarification on T5 Model Pre-training Objective and Denoising Process","2024-03-31 20:21:27","","0","19","<natural-language-processing>","<p>I am currently developing a T5 model (encoder-decoder architecture) from scratch for educational purposes. While working on this project, I've encountered some confusion regarding the pre-training objective, specifically the <em>denoising objective</em>. I would like to clarify my understanding and have some questions about the process.</p>
<p>Given the sentence:</p>
<blockquote>
<p>Thank you for inviting me to your party last week.</p>
</blockquote>
<p>Based on my understanding, during the pre-training phase with a denoising objective, the model works as follows:</p>
<ul>
<li><strong>Encoder input</strong>: <code>Thank you &lt;X&gt; me to your party &lt;Y&gt; week</code></li>
<li><strong>Decoder input</strong>: <code>&lt;X&gt; for inviting &lt;Y&gt; last</code></li>
<li><strong>Decoder labels (true labels)</strong>: <code>for inviting &lt;Y&gt; last &lt;Z&gt;</code></li>
</ul>
<p>Here are my questions:</p>
<ol>
<li>Is my interpretation of how the encoder input, decoder input, and decoder labels are constructed correct?</li>
<li>In this setup, the model is expected to predict sentinel tokens (e.g., <code>&lt;X&gt;</code>, <code>&lt;Y&gt;</code>). Could this potentially introduce confusion for the model, for example, it may take the idea that it is possible for the word &quot;last&quot; to come after the token ? Or does the model naturally learn to interpret these situations correctly?</li>
</ol>
<hr />
<p><strong>Accordingly to the paper:</strong></p>
<p><a href=""https://i.sstatic.net/QYUco.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/QYUco.png"" alt=""denoising objective"" /></a></p>
<blockquote>
<p>we process the sentence <code>Thank you for inviting me to your party last week.</code> The words <code>for</code>, <code>inviting</code> and <code>last</code> are randomly chosen for corruption. Each consecutive span of corrupted tokens is replaced by a sentinel token (shown as <code>&lt;X&gt;</code> and <code>&lt;Y&gt;</code>) that is unique over the example. Since <code>for</code> and <code>inviting</code> occur consecutively, they are replaced by a single sentinel <code>&lt;X&gt;</code>. The output sequence then consists of the dropped-out spans, delimited by the sentinel tokens used to replace them in the input plus a final sentinel token <code>&lt;Z&gt;</code>.</p>
</blockquote>
","natural-language-processing"
"45301","Problems with understanding instruction fine-tuning","2024-03-31 04:55:27","","0","22","<natural-language-processing><transformer><large-language-models><gpt>","<p>I'm trying to read up on instruction fine-tuning, but I think I have a big misunderstanding.</p>
<p>As I understand, instruction datasets typically have 3 components: (a) the instruction (b) the output/response, and (c) and an optional input. Now, according to this <a href=""https://arxiv.org/pdf/2308.10792.pdf"" rel=""nofollow noreferrer"">paper</a>: &quot;Based on the collected IT dataset, a pretrained model can be directly fine-tuned in a fully-supervised manner, where given the instruction and the input, the model is trained by predicting each token in the output sequentially.&quot; This makes sense to me, i.e, the response/output is the ground truth the model is expected to predict.</p>
<p>However, when I check many tutorials (e.g., this <a href=""https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/instruction-tune-llama-2-int4.ipynb"" rel=""nofollow noreferrer"">tutorial notebook</a>), it seems that instructions, inputs, and outputs are all combined into a single text sample. But I can't tell from the notebook how the training now works. What is now the ground truth for the supervised training. Or is this now treated as a next-word-prediction task?</p>
<p>What am I missing? Or are these indeed two different approaches for instruction tuning. Sorry if those a stupid questions!</p>
","natural-language-processing"
"45281","Unable to Save Generated Data to JSONL File - Always Resulting in ""Wrote 0 examples to finetuning_events.jsonl"" Message","2024-03-29 00:20:39","","0","19","<natural-language-processing><chatgpt><open-ai><fine-tuning>","<h3>Issue Description</h3>
<p>When attempting to generate JSONL data using Llama Index, the process works well until the final step where the results are saved to a JSONL file. However, every time I try to save the data, it seems to be unsuccessful as I always receive the message &quot;Wrote 0 examples to finetuning_events.jsonl&quot;. I am unsure of the reason behind this issue.</p>
<h3>Steps to Reproduce</h3>
<ol>
<li>Successfully generated JSONL data using Llama Index.</li>
<li>Attempted to save the results to a JSONL file.</li>
<li>Received the message &quot;Wrote 0 examples to finetuning_events.jsonl&quot;.</li>
</ol>
<h3>Additional Information</h3>
<ul>
<li>Llama Index version used: 0.10.22</li>
<li>Operating System: Windows</li>
</ul>
<h3>Log</h3>
<p><code>Wrote 0 examples to ./dataset_data/finetuning_events.jsonl</code></p>
<p>My code:</p>
<pre><code>     def jsonl_generation(self):
        &quot;&quot;&quot;
        Generate JSONL file for fine-tuning events and perform model refinement.
        &quot;&quot;&quot;
        # Initialize OpenAI FineTuningHandler and CallbackManager
        finetuning_handler = OpenAIFineTuningHandler()
        callback_manager = CallbackManager([finetuning_handler])

        self.llm.callback_manager = callback_manager

        # Load questions for fine-tuning from a file
        questions = []
        with open(f'{self.dataset_path}/train_questions.txt', &quot;r&quot;, encoding='utf-8') as f:
            for line in f:
                questions.append(line.strip())

        try:
            # Generate responses to the questions using GPT-4 and save the fine-tuning events to a JSONL file
            index = VectorStoreIndex.from_documents(
                self.documents
            )
            query_engine = index.as_query_engine(similarity_top_k=2, llm=self.llm)
            for question in questions:
                response = query_engine.query(question)
        except Exception as e:
            # Handle the exception here, you might want to log the error or take appropriate action
            print(f&quot;An error occurred: {e}&quot;)
        finally:
            # Save the fine-tuning events to a JSONL file
            finetuning_handler.save_finetuning_events(f'{self.dataset_path}/finetuning_events.jsonl')
<span class=""math-container"">```</span>
</code></pre>
","natural-language-processing"
"45142","2 Different attentions mentioned in DeBERTa","2024-03-17 03:15:51","","1","18","<natural-language-processing><papers><disentangled-representation>","<p>I am trying to understand the disentangled self-attention in DeBERTa paper, but I can't understand at which point of the paper they stop from introducing background knowledge about already known attention mechanisms and go on to discuss disentangled attention.</p>
<p>More specifically, in Section <span class=""math-container"">$3$</span> of <a href=""https://arxiv.org/abs/2006.03654"" rel=""nofollow noreferrer"">DeBERTa</a>, they state that each token is represented using <span class=""math-container"">$2$</span> vectors <span class=""math-container"">$\{H_i\}$</span>, and <span class=""math-container"">$\{P_{i|j}\}$</span>. Then they went onto introduce equation <span class=""math-container"">$(2)$</span>:
<span class=""math-container"">$$A_{i,j} = H_iH_j^T + H_iP_{j|i}^T + P_{i|j}H_{j}^T + P_{i|j}P_{j|i}^T$$</span></p>
<p>which they <strong>call calculating cross attention score</strong>.
But then they also later go onto introduce another attention score in <span class=""math-container"">$(4)$</span> (pic below):
<a href=""https://i.sstatic.net/4ANvh.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4ANvh.png"" alt=""Attention"" /></a></p>
<p>What I don't understand is why there are <span class=""math-container"">$2$</span> different attention matrices <span class=""math-container"">$A, \tilde{A}$</span> each one having something to do with disentanglement (one disentangles word embedding, the other introduces disentangled weight matrices). Which one is the new novel method they introduced? Was <span class=""math-container"">$(2)$</span> just for some toy example giving?
Also, they don't clarify how to produce vectors <span class=""math-container"">$H, P_{i|j}$</span> explicitly, could anyone explain how to process and input <strong>x</strong> to produce <span class=""math-container"">$H, P_{i|j}$</span></p>
","natural-language-processing"
"45098","Why different noise in GAN generate different images?","2024-03-12 18:45:12","45100","4","1344","<machine-learning><convolutional-neural-networks><natural-language-processing><computer-vision><transformer>","<p>I understand that noise <span class=""math-container"">$z$</span> serves as the input to the generator. Noise <span class=""math-container"">$z$</span> is essentially a vector of random numbers, typically from Gaussian distribution with chosen size of like <span class=""math-container"">$100$</span>. However, I don't understand how different noise can produce different images.</p>
<p>Sorry if this sounds like stupid question, but I've been experimenting with GANs and noticed that if I keep the noise constant, the generated image remains the same, seems like the numbers in the noise vector are linked to generating specific image, but I haven't come across an explanation for this online.</p>
","natural-language-processing"
"45079","How do transformer-based architectures generate contextual embeddings?","2024-03-10 19:17:11","","1","83","<machine-learning><deep-learning><convolutional-neural-networks><natural-language-processing><transformer>","<p>How do transformer-based architectures like Roberta generate contextual embeddings? The articles I've read keep saying that transformer encoders work bidirectionally. Because of self-attention, they can look at every token, unlike RNN/LSTM, which can only process the previous hidden state. I'm not sure how the Transformer accomplishes that.</p>
","natural-language-processing"
"45062","Fine tuning or just feature extraction or both using Roberta?","2024-03-08 19:54:47","45063","1","96","<neural-networks><machine-learning><deep-learning><natural-language-processing><transformer>","<p>I'm reading a program that use the pre-trained Roberta model (roberta-base). The code first extracts word embeddings from each caption in the batch, using the last hidden state of the Roberta model. Then, the model is trained to align these word embeddings with the image features (pixels) of the image through a type of attention mechanism. Then the models are updated using attention loss function. This iterative process continues until the training is complete, so I guess the word embeddings will be different after each epoch ? This is a multi-modal problem.</p>
<p>When I compare the Roberta model after training with the pre-trained model (roberta-base), I notice that every parameters the trained Roberta model are different, seems like the new model has updated the parameters. I'm not sure whether this is a form of fine-tuning or just feature extraction or both ?</p>
","natural-language-processing"
"45054","Why do LLM tokenizers use a special symbol for space such as Ġ in BPE or ▁ in SPM?","2024-03-08 08:55:04","","1","197","<natural-language-processing><large-language-models><language-model>","<p>Popular tokenizers use a special symbol such as &quot;Ġ&quot; (BPE) or &quot;▁&quot; (SentencePiece) to represent space. What is the reasoning behind this?</p>
<p>I did try searching for the answer. I got two types of explanations, but they don't explain anything to me.</p>
<p><strong>Some languages such as Japanese don't typically use space to separate words.</strong></p>
<p>That's true, but tokenizing such a language won't make use of the special character as well. I don't understand how having a token as <code>&quot;Ġhorse&quot;</code> is any different from <code>&quot; horse&quot;</code> in this scenario.</p>
<p>Let's assume we want to tokenize the made-up laguage Spaceless English, which is English, but without whitespace. <code>tokenize(&quot;I'mridingahorse&quot;) -&gt; [&quot;I'm&quot;, &quot;riding&quot;, &quot;ahorse&quot;]</code>. No need for spaces at all, let alone a special character.</p>
<p>In fact this seems like it would be in favor of using a plain space as opposed to a special symbol.</p>
<p><strong>Some tokens have a space in them and this helps us differentiate between spaces in the original text and spaces in the tokens</strong></p>
<p>For example &quot;New York&quot; might be a token.</p>
<p>This kinda makes sense, but I still don't quite get why we would ever need this distinction. How is <code>&quot;ĠNew York&quot;</code> different from <code>&quot; New York&quot;</code>? <code>&quot; New York&quot;</code> is still different from <code>[&quot; New&quot;, &quot; Toronto&quot;]</code>. A tokenizer would employ some kind of a greedy algorithm to tokenize text... and even if it's not greedy, but the full NP-complete search, it would still tokenize <code>&quot;I'm going to New York&quot;</code> as <code>[&quot;I'm&quot;, &quot; going&quot;, &quot; to&quot;, &quot; New York&quot;]</code>, the same way as we would expect it to tokenize &quot;extracurricular&quot; to say <code>[&quot;extra&quot;, &quot;curricul&quot;, &quot;ar&quot;]</code> and not to <code>[&quot;ex&quot;, &quot;trac&quot;, &quot;u&quot;, &quot;rr&quot;, &quot;ic&quot;, &quot;u&quot;, &quot;lar&quot;]</code>, and the same way as we would expect it to work on Spaceless English.</p>
<p>Note that I'm looking at the problem only through the lens of converting text to tokens and tokens to text. Perhaps the need for these character has to do with creating the token list based on the training corpus?</p>
","natural-language-processing"
"45015","Minimum Number of Samples for LLM Benchmark?","2024-03-04 18:22:44","","0","108","<natural-language-processing><large-language-models><benchmarks>","<p>I am working on a project to evaluate various fine-tuned LLMs. Unfortunately inference is prohibitively slow, and I don't think I will be able to test my models on the full test set of 40,000 samples. My current plan is to implement an early stopping threshold.</p>
<p><strong>Is there an &quot;accepted&quot; or theoretical minimum number of samples that are required to benchmark an LLM?</strong></p>
","natural-language-processing"
"44943","What technique is used for training Large Language Models like GPT?","2024-02-28 03:06:16","","1","354","<machine-learning><natural-language-processing><unsupervised-learning><gpt><language-model>","<p>I'm learning about GenAI, such as GPT (Generative Pretrained Transformer), and I'm particularly interested in understanding the training techniques used for these models.</p>
<p>Deep learning, generally, can involve training with supervised learning with labeled datasets which makes sense.  But I also encounter references to unsupervised learning: specifically, predicting the next word in a sequence. The concept of unsupervised training with next-word prediction is unclear to me. To me, it feels like GPT is trained with supervised learning with a labeled dataset: is this correct?</p>
","natural-language-processing"
"44933","Why do Transformer decoders use masked self attention when producing new tokens?","2024-02-26 23:51:31","","1","261","<natural-language-processing><transformer><attention><gpt><encoder-decoder>","<p>I've been reading that transformer decoders use masked self attention so that the decoder can't cheat by looking ahead. For example, when predicting the 6th token in the sequence we shouldn't have access to the 7th token.</p>
<p>However, why can't the decoder perform full self attention on all previously predicted tokens? When predicting the 6th token, why can't the third token embedding have access to the 5th token. Wouldn't this system of representation offer richer context. Some explanations that I have seen online have stated that this system would violate the nature of autoregressive token generation, however we still aren't looking at the 7th token or anything after to predict the sixth token, we are just allowing all the already predicted tokens to attend to each other. The presence of every single token in a generated sequence is only the result of everything that came before it which still sounds very autoregressive.</p>
<p>In this previous post:
<a href=""https://ai.stackexchange.com/questions/40917/what-if-we-drop-the-causal-mask-in-auto-regressive-transformer"">What if we drop the causal mask in auto-regressive Transformer?</a></p>
<p>The answer mentions:
<strong>Allowing available tokens to attend to each other would violate the autoregressive property and potentially introduce information leakage from future tokens, leading to incorrect predictions.</strong></p>
<p>I'm not sure what this really means or where exactly the information leakage would be coming from, since the 6th token would have no information about the 7th. I know that doing self attention like this increases the complexity, however is there any actual accuracy or quality reasons why we don't do this.</p>
","natural-language-processing"
"43904","Using a HMM for grammar checking","2024-02-24 04:09:25","","0","19","<natural-language-processing><hidden-markov-model>","<p>I want to try to make an HMM from scratch for POS tagging, which I would extend to grammar checking. I understand there's much better ways for a grammar checker but this is just as a learning experience and for fun.</p>
<p>My idea is to do rule-based grammar checking based on the sequence of POS tags. I would generate the POS tags through my HMM then enforce concrete grammar rules. For example, I would assign POS tags to a sentence then perform the following check (out of many): if an adjective comes after a noun, is there a linking verb in between? If there isn't, then the sentence most likely contains an error.</p>
<p>However, I understand that HMMs seek to maximize the probability of assigning a POS tag based on the POS of the previous tag. My main concern is that if I only introduce sentences with proper grammar, and in turn proper POS tag sequences, then wouldn't my model never assign an improper POS tag and my rule-based check would never work since every POS tag is a valid sequence?</p>
<p>For example, take this slice of a full sentence: &quot;He wants watch...&quot;. The issue here is obvious, that it should be &quot;he wants TO watch...&quot; The problem I'm imagining is that if my model only gets data on sentences with proper VB-&gt;VB transitions, i.e. the second verb is in the &quot;ing&quot; form, or the second verb is infinitive, etc... then wouldn't the probability of an improper VB-&gt;VB transition such as in &quot;he wants watch&quot; be parsed as &quot;NN VB NN&quot; because this improper verb to verb transition would have 0 probability as it's never seen in the data. In this case, I would assume that the model takes the transition VB-&gt;NN since &quot;watch&quot; is also a noun, and VB-&gt;NN has a non-zero probability</p>
<p>I'm not sure if I'm overthinking this, or if this is valid. Are there any fixes? I imagined that smoothing may fix this without changes to the dataset. I also considered introducing sentences with incorrect grammar to the dataset on purpose, but that seems inefficient. Is it possible to stick to using only a HMM and enforcing concrete rules for a grammar checker?</p>
","natural-language-processing"
"43843","What language model can convert normal text to JSON data","2024-02-20 05:32:39","43855","0","229","<natural-language-processing><language-model><natural-language-understanding>","<p>I have tried training T5-small, T5-base and T5-Large on around 15K rows of data where input data was something like but I did not get desired results</p>
<pre><code>Nutrition Facts,
100g per,
Energy 646.95Kcal Carbohydrates 19.31g,
 Protein 21.94g 53.55g Total Fat 6.64g Saturated Fat 14.97g Dietary Fiber,
&lt;1.Omg Cholesterol Sodium 0.29g Sugars 3.39g,
Lightly Salted and to Perfection,
Ingredients: Peanuts, Almonds,,
Cashews, Pistachios, Vegetable Oil, Salt,
aa, ,
74G,
Pistachio, 61129110611336177
WE ARE NUTS ABOUT QUALITY,
Baked,
Nuts Salted,
Mixed
WE ARE NUTS ABOUT,
Community 364, 13 Street Plot No. 36,
Al Area 1, 24149,UAE 4971 4 3355777,
License Number: 224614 VAT No: 100058529700003,
CERTIFIED COMPANY,
ALLERGEN WARNING: in a facility that also processes nuts, sesame and mustard,
Store in a cool dry place away from heat moisture,
Instruction Once store in airtight container and consume before expiry date,
Pro: 14/12/23,
Exp:13/12/24,
Net 40gms
</code></pre>
<p>Output data will be in JSON format of the above details.
What language models can be trained for this purpose and minimum how many Parameters it should have?</p>
","natural-language-processing"
"43723","Where I can find SOTA models of information retrieval?","2024-02-08 14:31:50","","0","53","<machine-learning><natural-language-processing><reference-request><state-of-the-art><information-retrieval>","<p>Can someone tell me where I can find SOTA models of information retrieval?</p>
<p>My task is to rank documents by given query by semantic search of embedding. I know that models like ColBERT, SPLADE solve this problem, but I think they are not SOTA now. I tried to find SOTA models on paperswithcode but there almost nothing about this problem.</p>
","natural-language-processing"
"43626","Why won't ChatOllama work with GraphCypherQAChain?","2024-01-31 13:06:38","","0","66","<natural-language-processing><chat-bots>","<p>I am trying to get a QA Chain that uses mistral to work, but the Chain fails to restrict the LLM to solely use the relationships in the Knowledge Graph (in Neo4j).</p>
<p>The code is:</p>
<pre><code>cypher_chain = GraphCypherQAChain.from_llm(
    graph=graph,
    cypher_llm=cypher_model,
    qa_llm=qa_model,
    validate_cypher=True,
    verbose=True,
)

query_1 = &quot;Qual é a relação entre a severidade, recuperação e infecção à COVID 19, insuficiência e deficiência de Vitamina D e o uso de protetor solar?&quot;
query_2 = &quot;Trace a relação entre a severidade, recuperação e infecção à COVID 19, insuficiência e deficiência de Vitamina D e o uso de protetor solar trazendo referências bibliográficas conhecidas que suportem a resposta.&quot;
query_3 = &quot;Quem é Silvio Santos?&quot;

for question in [query_1, query_2, query_3]:
    answer = cypher_chain.invoke(question)
    print(answer)
</code></pre>
<p>when I use:</p>
<pre><code>
qa_model = ChatOllama(model=&quot;mistral&quot;, temperature=0.0)
</code></pre>
<p>It yields long answers, which is incorrect for there are no relations that support such argumentation.</p>
<p>When I use:</p>
<pre><code>qa_model = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;, temperature=0.0)
</code></pre>
<p>It yields no answers, which is expected.</p>
<p>How can I make sense of this behavior?</p>
","natural-language-processing"
"43602","Does the fixed context in attention mechanism is accquired after getting the decoder hidden layer of the first hidden state?","2024-01-29 08:34:26","","0","21","<natural-language-processing><recurrent-neural-networks><attention><autoencoders><encoder-decoder>","<p>here, the fixed context vector (ci) is used for the decoder model, why the decoder model also used by the attention weights. On the first (c1), does that mean the decoder does not have context ? (i = 1 ; c1 - 1 = c0). Thanks</p>
<p><a href=""https://i.sstatic.net/bwSvY.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bwSvY.png"" alt=""enter image description here"" /></a></p>
<p>references : Jurafsky, D., &amp; Martin, J. H. (2023). Speech and language processing: An Introduction to Natural Language Processing(pp.205-208), (3rd ed. draft), Computational Linguistics, and Speech Recognition. Prentice Hall.</p>
","natural-language-processing"
"43601","understanding the distribution shift problem in direct preference optimization (DPO)","2024-01-29 05:40:58","","0","112","<natural-language-processing><large-language-models><rlhf>","<p>I'm having trouble understanding this paragraph of the <a href=""https://arxiv.org/pdf/2305.18290.pdf"" rel=""nofollow noreferrer"">DPO paper</a>:</p>
<p><a href=""https://i.sstatic.net/gCdY4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/gCdY4.png"" alt=""enter image description here"" /></a></p>
<p>Why does it matter so much that the preference data distribution aligns with the reference model output distribution? My understanding is that during training, the parameters of the sft (supervised fine-tuning) are updated such that chosen responses (<span class=""math-container"">$y_w$</span>) have a higher probability of being generated, and rejected responses (<span class=""math-container"">$y_l$</span>) have a lower probability of being generated, and the reference model is just there to prevent the sft model from straying too far from the original parameters. But I fail to understand how the wrong reference distribution could hinder this process. Could someone please help me?</p>
","natural-language-processing"
"43519","Zero-shot out of distribution text classification","2024-01-22 20:54:12","","0","18","<natural-language-processing><classification><text-classification><anomaly-detection>","<p>I'm building out a pipeline that would allow me to filter out text based on whether or not the text belongs to any of the classes I've defined.</p>
<p>I feel like one (albeit naive) approach would simply be to embed both the text and the text representing the class, and apply a distance function to both, discarding the sample if the distance is over some threshold.</p>
<p>Is this feasible in a zero-shot setting? If so, how should I go about figuring out the threshold? If not, what (if any) methods could be used in a zero-shot setting?</p>
<p>Note: I'm not looking for any methods that require additional data outside of the sample and the classes themselves.</p>
","natural-language-processing"
"43510","Understanding the concepts of embedding in Roberta architecture?","2024-01-22 10:27:41","","0","42","<neural-networks><machine-learning><deep-learning><natural-language-processing><python>","<p>I'm reading the <a href=""https://github.com/huggingface/transformers/blob/main/src/transformers/models/roberta/modeling_roberta.py"" rel=""nofollow noreferrer"">implementation file of Roberta architecture</a>, specifically in the <a href=""https://github.com/huggingface/transformers/blob/3f69f415adcbdaedec154ba8eac220ef3276975d/src/transformers/models/roberta/modeling_roberta.py#L65"" rel=""nofollow noreferrer"">RobertaEmbedding class</a>, this class has the comment:</p>
<pre><code>Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.
</code></pre>
<p>I'm a newbie to this, I want to ask about the changes in the <code>RobertaEmbedding class</code>, are these changes related to the dynamic masking in Roberta architecture? Thanks</p>
","natural-language-processing"
"43465","Why does skip-gram uses linear maps for embedding?","2024-01-18 01:07:47","43472","0","36","<natural-language-processing><word-embedding><skip-gram>","<p>This question is inspired from Lilian Weng's blog <a href=""https://lilianweng.github.io/posts/2017-10-15-word-embedding/#other-tips-for-learning-word-embedding"" rel=""nofollow noreferrer"">here</a> about skip-gram model, where she shows the model as multiplication via 2 matrices <span class=""math-container"">$W$</span> and <span class=""math-container"">$W'$</span> for embedding and word context matrix and <span class=""math-container"">$W$</span> takes in one hot encoded embedding into a 'better' embedding space.</p>
<p>My question is, why should we require a linear map for this task? As in, why should some linear map from one-hot encoded space be useful for embedding words densely, while preserving semantic information as much as possible (this is the definition of word 'better' as used above)?</p>
<p>For an overview of the model, see here:</p>
<p><a href=""https://i.sstatic.net/9B6bb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/9B6bb.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"43417","how can I interpret attention weights matrix? Are they reliable?","2024-01-12 23:11:20","","0","83","<machine-learning><natural-language-processing><attention><large-language-models><explainable-ai>","<p>I've fine-tuned two different models (Bert and Roberta) on a dataset for a binary classification task and I'm comparing the sentences where the models predict wrong. I decided to use attention weights as explainability method to understand which tokens are contributing the most to the model's output. I have a function that visualizes the attention matrix:</p>
<pre><code>def show_attention_matrix(text, model):
    
    input_ids = tokenizer(text, return_tensors=&quot;pt&quot;)[&quot;input_ids&quot;].to(device)
    attention_mask = tokenizer(text, return_tensors=&quot;pt&quot;)[&quot;attention_mask&quot;].to(device)

    tokens = tokenizer.convert_ids_to_tokens(input_ids.view(-1))

    attentions = model(input_ids, attention_mask)[&quot;attentions&quot;]
    last_layer_attention = attentions[-1]
    last_layer_attention = last_layer_attention.squeeze(0)
    mean_attentions = torch.mean(last_layer_attention, dim=0)

    mean_attentions = mean_attentions.cpu().detach().numpy()

    df = pd.DataFrame(mean_attentions)

    plt.figure(figsize=(20, 10))
    heatmap = sns.heatmap(df, annot=True, cmap=&quot;viridis&quot;, fmt=&quot;.3f&quot;, cbar=True, xticklabels=tokens, yticklabels=tokens)
    heatmap.xaxis.tick_top()
    plt.show()
</code></pre>
<p>The code above generates a plot like the following:<a href=""https://i.sstatic.net/MluiQ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/MluiQ.jpg"" alt=""enter image description here"" /></a></p>
<p>Since I'm getting the embeddings from the [CLS] token and pass it to a classification head, does it make sense to also look at the weights of the [CLS] and find the tokens with the highest scores?</p>
","natural-language-processing"
"43408","publically available language models that can be used to train arbitrary language data?","2024-01-12 08:00:09","","1","39","<natural-language-processing><large-language-models><chatgpt><language-model>","<p>I have sentence data in a language that is not widely in use and as such popular LLMs do not support the language. I want to train some language model such that given some question, it is able to respond back in the same language, just as in ChatGPT just with a different language.</p>
<p>In such a case, what language model is publically available and is sufficiently powerful? Or would it be possible to use popular LLMs (such as ChatGPT) to achieve such a goal?</p>
","natural-language-processing"
"43386","Are K and V values reused in each decoder layer's cross-Attention in the original ""Attention is all you need"" paper?","2024-01-10 18:41:36","","0","50","<machine-learning><natural-language-processing><transformer><attention>","<p>I'm working with Transformers and have a question about the encoder-decoder structure. In each decoder layer's cross-attention, are the K and V pairs from the corresponding encoder layer reused for all cross-attention operations within that decoder layer? Or are they recalculated for each operation?</p>
<p>Also, if K and V are reused, doesn't this limit the decoder's effectiveness? It seems like only the Query values are changing and propagating through the model. Since most of the meaning is stored in the V layer, wouldn't using the same K and V hinder the decoder's abilities?</p>
","natural-language-processing"
"43336","How to learn text style in an article using LLMs?","2024-01-06 21:06:10","","2","41","<natural-language-processing><large-language-models><hidden-layers><style-transfer>","<p>What is the best way to learn text style in an article? By text style I mean special characteristics and patterns inherent to different authors/group's writing style. For-example, author attribution problem is about learning who wrote an article.</p>
<p>I've seen some researchers applying VAEs and GANs to text to learn the style distribution of sentences in an article (Some references: <a href=""https://arxiv.org/pdf/2109.04624.pdf"" rel=""nofollow noreferrer"">here</a>, <a href=""https://arxiv.org/pdf/2103.07567.pdf"" rel=""nofollow noreferrer"">here</a>, <a href=""https://www.usenix.org/conference/usenixsecurity18/presentation/shetty"" rel=""nofollow noreferrer"">here</a>). However, VAEs and GANs usually have worse performance in language compared to vision tasks.</p>
<p>My question is how to capture style information using LLMs? Is averaging the last hidden states of sentences/paragraphs based on the &quot;max_length&quot; attribute of the model a good approach? Is there a better way to capture style information with LLMs?</p>
","natural-language-processing"
"43327","Why is the sinusoidal model classified as absolute positional encoding in some literature?","2024-01-05 18:30:29","43488","2","113","<natural-language-processing><transformer><positional-encoding>","<p>I am currently reading in depth about positional encodings, and as we know there are two types of positional encodings: Absolute and relative.</p>
<h4>My question:</h4>
<p>Why is the sinusoidal model classified as absolute positional encoding in some literature, given that in Vaswani's original paper it was said that it captures relative relationships between words, and this has been proven <a href=""https://blog.timodenk.com/linear-relationships-in-the-transformers-positional-encoding/"" rel=""nofollow noreferrer"">here</a>.</p>
<p>However, while I was reading a <a href=""https://direct.mit.edu/coli/article/48/3/733/111478/Position-Information-in-Transformers-An-Overview"" rel=""nofollow noreferrer"">research</a>, it was mentioned that projections that occur in the attention layer destroy this:</p>
<blockquote>
<p>Indeed, sinusoidal position embeddings exhibit useful properties in theory. Yan et al. (2019) investigate the dot product of sinusoidal position embeddings and prove important properties:
(1) The dot product of two sinusoidal position embeddings depends only on their relative distance. That is, <img src=""https://latex.codecogs.com/svg.image?&amp;space;P_t%5ET.P_%7Bt+r%7D"" alt="" P_t^T.P_{t+r}"" /> is independent of <img src=""https://latex.codecogs.com/svg.image?t"" alt=""t"" />.
(2) <img src=""https://latex.codecogs.com/svg.image?&amp;space;P_t%5ET.P_%7Bt+r%7D=P_t%5ET.P_%7Bt-r%7D"" alt=""P_t^T.P_{t+r}=P_t^T.P_{t-r}"" />, which means that sinusoidal position embeddings are unaware of direction. However, in practice the sinusoidal embeddings are projected with two different projection matrices, which destroys these properties.</p>
</blockquote>
<p>Is this the reason?</p>
","natural-language-processing"
"43317","Neural Machine Translation with multi-language input to a single-language output?","2024-01-04 21:14:30","","1","17","<deep-learning><natural-language-processing><large-language-models><machine-translation>","<p>I'm looking for NMT paradigms where the input to the model is the same text in N languages (e.g., L1, L2, L3) and the output is the translation in a different target language (e.g., L4).</p>
<p>However, I have the Rosetta Stone problem. Each input text might be randomly noisy/incomplete, that's why I think such a paradigm might help. The hope is to train a model that can compensate for the noise (missing elements) in one input text using the parallel elements in the other input texts (assuming that no element is missing from all input texts).</p>
<p>For training, I have parallel L1-L2-L3-L4 text quadruplets. I also have texts in each individual language separately that I can use for pre-training. Are there any methods to pre-train NMT models using single-language data?</p>
","natural-language-processing"
"43254","Finetuning Mistral or MistralForSequenceClassification for text classification","2023-12-29 18:05:11","","1","742","<natural-language-processing><training><python><large-language-models><fine-tuning>","<p>I need to do text classification and have a dataset of 10K entries. I am considering using mistral and following a tutorial like <a href=""https://huggingface.co/docs/transformers/training"" rel=""nofollow noreferrer"">https://huggingface.co/docs/transformers/training</a> and replace model name by Mistral. But I have noticed there is also MistralForSequenceClassification.</p>
<p>Could you please help me with the following questions:</p>
<p>Is using the above mentioned tutorial and replacing the model name with mistralai/Mistral-7B-v0.1 the correct approach?</p>
<p>Do I need to use MistralForSequenceClassification?</p>
<p>Many thanks.</p>
","natural-language-processing"
"43235","What is the approximate minimum coding rate for NLP datasets?","2023-12-27 03:29:52","","0","11","<natural-language-processing><transformer><information-theory>","<p>I just realized that it is actually practical to use information theory to compute the maximum viable compression for datasets &amp; that it is easiest to compute for discrete datasets. This makes me wonder what the minimum coding rate (i.e. minimum required bit representation) for well known NLP datasets is? Also approximately how close to this minimum coding rate do modern transformers achieve in the embedding space?</p>
","natural-language-processing"
"43222","Do AI-based code-generators guarantee correct output?","2023-12-25 15:47:51","","3","2946","<natural-language-processing><chatgpt><large-language-models>","<p>I haven't spent much time looking at AI-based code-generators. What mechanism is used to generate code and how is it different than standard NLP?</p>
","natural-language-processing"
"43150","Which input embeddings are learned during pre-training in BERT? What about during fine-tuning?","2023-12-16 04:54:39","","0","80","<natural-language-processing><transformer><bert>","<p>I was reading the 2019 BERT paper and they mention how they use wordpieces that are then represented as the sum of token embeddings, segment embeddings, and positional embeddings. What is unclear to me is whether the token, segment and positional embeddings are all learned during pre-training AND whether they are modified during fine-tuning.</p>
<h2>Pre-Training:</h2>
<ul>
<li><strong>Sentence Embeddings:</strong> The paper says that the sentence embeddings are learned during pre-training (&quot;we add a learned embedding to every token indicating whether it belongs to sentence A or sentence B&quot;). <strong>am pretty confident about this.</strong></li>
<li><strong>Positional Embeddings:</strong> The paper does not say whether the positional embeddings are learned during pre-training. However, BERT relies on the transformer architecture from the &quot;Attention Is All You Need&quot; pa[er and I believe the positional embeddings in THAT paper are learned during what would pre-training for the BERT model. <strong>- Not so confident about this.</strong></li>
<li><strong>Token Embeddings:</strong> I'm guessing the token embeddings aren't learned during pre-training but before pre-training. Specifically, I hypothesize that the authors simply use the word piece embeddings approach to break up sentences into word &quot;pieces&quot; AND map each of these pieces to numbers, but this mapping is not modified during pre-training. <strong>- I'm very uncertain about this.</strong></li>
</ul>
<p><strong>Are positional embeddings and token embeddings learned during pre-training?</strong></p>
<h2>Fine-Tuning:</h2>
<p>Essentially the same question but for fine-tuning: are these embeddings typically modified during fine-tuning?</p>
","natural-language-processing"
"43149","What is the loss function used when pre-training BERT on MLM & NSP tasks?","2023-12-16 04:14:29","","0","335","<natural-language-processing><reference-request><objective-functions><bert>","<p>I'm new to NLP and was reading through the 2019 BERT paper and am confused about the loss function used during pre-training.</p>
<p>As I understand it, the model is trained on the MLM and NSP tasks. The MLM task is trained by passing the final hidden vectors corresponding to the mask tokens into a softmax function and then minimizing the cross entropy loss function between the softmax output and truth.</p>
<p>For the NSP task, I understand that the goal is to use the final hidden vector corresponding to the [CLS] token, and using that to  determine whether the two &quot;sentences&quot; follow each other or not. Now the paper doesn't exactly say what loss function they use for this is, so I'm assuming they're doing something similar to the MLM case.</p>
<p>Now, in the appendix the authors mention that &quot;The training loss is the sum of the mean MLM likelihood and the mean NSP likelihood&quot;. Given the relationship between log likelihood and cross entropy, this makes it seem like both MLK and NSP are used simultaneously during pre-training through a combined loss function.</p>
<p>I'm probably overthinking things, but I was wondering if any of you had a different interpretation of this. Specifically:</p>
<p><strong>What is the loss function used when pre-training BERT on MLM &amp; NSP? Also, what's your source?</strong></p>
<p>I've read the paper start to end, as well as the transformers paper, searched forums, videos, and blogs, and my next stop is to dig into the code. I feel most explanations are either hand-wavy and it's unclear whether they're just guessing (like me) or if they actually know the answer.</p>
","natural-language-processing"
"43147","Why is there a ""reference free"" option in DPO (Direct Preference Optimization)'s loss function?","2023-12-16 00:48:48","","0","280","<neural-networks><reinforcement-learning><natural-language-processing><large-language-models><loss>","<p>There is a <a href=""https://github.com/huggingface/trl/blob/d708ec272f292ded00a4d0f14b5bd214741b87f3/trl/trainer/dpo_trainer.py#L762"" rel=""nofollow noreferrer"">reference_free</a> parameter in <a href=""https://github.com/huggingface/trl"" rel=""nofollow noreferrer"">trl</a>'s loss function implementation of DPO, while <a href=""https://arxiv.org/abs/2305.18290"" rel=""nofollow noreferrer"">the original DPO paper</a> does not mention the concept of &quot;reference free&quot;.</p>
<p>In trl's implementation:</p>
<pre><code>    pi_logratios = policy_chosen_logps - policy_rejected_logps
    if reference_free:
        ref_logratios = 0
    else:
        ref_logratios = reference_chosen_logps - reference_rejected_logps

    logits = pi_logratios - ref_logratios
</code></pre>
<p>When <code>reference_free</code> is <code>True</code>, the loss is calculated as cross entropy between <code>policy_chosen_logps</code> and <code>policy_rejected_logps</code>, while <code>reference_chosen_logps</code> and <code>reference_rejected_logps</code> are not in use.</p>
<p>What are the pros and cons of the &quot;reference free&quot; DPO?</p>
","natural-language-processing"
"43138","What would be the best AI model to query a database in natural language?","2023-12-15 12:15:56","","1","82","<natural-language-processing>","<p>We want to build an AI Chatbot, that has access to our DB schema and the data (it is a RDBMS system) and can answer complex questions around this data. Few examples like -</p>
<ul>
<li>What was the most expensive IT purchase in last 6 months</li>
<li>Which purchase category has most spikes in spend over last one month</li>
<li>which department has upward spend pattern in last 3 months</li>
</ul>
<p>What we have tried -</p>
<ul>
<li>tried a few nl2sql models</li>
<li>tried openai APIs to convert the question to a SQL</li>
</ul>
<p>What we want to achieve -</p>
<ul>
<li>we want to pre-train the model with the database schema, so that building a SQL is not a guesswork and model exactly knows how the DB looks like</li>
<li>we don't want to send the DB schema with each prompt (typically how it is done in nl2sql or openai), since our DB schema is huge and complex and sending it with each prompt will exhaust the context length</li>
</ul>
<p>Questions -</p>
<ul>
<li>Is this a problem statement that can be solved by AI models?</li>
<li>If yes, where we should start?</li>
</ul>
<p>Any direction/suggestion would be highly appreciated. Thanks in advance.</p>
","natural-language-processing"
"43071","Using naive bayesian vs. transformer-based architecture model for human-annotated data?","2023-12-10 14:04:24","","0","84","<neural-networks><reinforcement-learning><machine-learning><deep-learning><natural-language-processing>","<p>I have a reddit dataset with thousands of online posts over the economy and inflation. We have used human-annotation on 60% of posts to determine whether users blame the following entities over the current inflation: We coded 1 for posts blaming Democrats, We coded 2 for posts blaming Republicans, We coded 3 for posts blaming the Federal Reserve, We coded 4 for posts that are negative about the economy/inflation but are not particularly blaming any political party or government entity over the economy.</p>
<p>My goal is to use the human-annotated posts to determine who is being blamed in the remaining 50% of posts that have not been labelled, and I am not sure if using a naive bayes model is appropriate here or if other ML models are more suitable? I have seen some guides like <a href=""https://towardsdatascience.com/sentiment-analysis-introduction-to-naive-bayes-algorithm-96831d77ac91"" rel=""nofollow noreferrer"">this</a> that recommend using a naive bayesian model for cases like mine but I am not sure if they are suitable?</p>
<p>#data example</p>
<pre><code>dput(df[1:10,c(1,2,3,4,8)])
</code></pre>
<p>#data output:</p>
<pre><code>
structure(list(id = c(1933, 7161, 4661, 2885, 5102, 5052, 4585, 
1935, 5259, 891), username = c(&quot;the_dog&quot;, &quot;Empyrean Cobalt&quot;, 
&quot;Engineeer&quot;, &quot;AuraKUPO&quot;, &quot;kyo_465&quot;, &quot;Johnpierpontmorgan&quot;, &quot;ToughLuck&quot;, 
&quot;SmallQuietDog&quot;, &quot;kyo_465&quot;, &quot;LessonsIndissent&quot;), post = c(&quot;Think jhk AT Pinoy etc all should be grateful to cecas for taking the heat off them&quot;, 
&quot;Scamdetector said I hope you all realised that UOB actually didnt answer Clement question Click to expand UOB is just using the same template to reply like robotic mode&quot;, 
&quot;netzach said this Daniels guy Click to expand I think people are not understanding WP and Daniel Goh in their entirely&quot;, 
&quot;TS is still a student Companies must pay FT CPF in cash instead Only sinkies need to pay CPF a cut of their pay&quot;, 
&quot;ponpokku said at least they dun downgrade like CECA pose no threats to locals CECA ish u have to double work to kio their sai Click to expand I dun want to hire people who tell me there are those who are worse than them&quot;, 
&quot;Count on me cecapore PR and new shitizen count as locals ok People no need serve ns Jin songggg&quot;, 
&quot;muddywaters said Thats in EP holders from INDIA its actually quite scary thought This is likely to creep up to in EP holders from INDIA By then they will be even more 嚣张 Click to expand they already took over mandarin gardens&quot;, 
&quot;greentiger said The problem with CECAs is that they have almost no supporters here This is not the case with PRCs Click to expand Tiongs faced much worse than ceca back then There were so many public antitiong actions where many even made it to mainstream media Newspapers reporting issues or clashes with tiongs used to be a norm The that ceca faced is considered mild already&quot;, 
&quot;Handyman said There should not have that gap if your Sinkie grads are educated to what the market needs the skills set that are sought after by employers and not just for statistics reporting that you have a highly educated work force So your gov is just plugging the holes using FT cos it seems like your educated grads are unable to fill that gapnow somewhere must be very wrong for things to turn out this way Click to expand Do you know that your skills set become obsolete faster in this time and age Whose responsibility is it to gain skills Who benefits with the right skills set&quot;, 
&quot;iamcat said the foreigners applying for jobs back then when i was recruiting were mostly from developing economies with low per capita gdp many of these economies also are not really developed market economies where the work experience is at international level their education certificates many are also from universities where copyingcorruption has been known to occur widely i seldom saw back then resumes from developed economies though there were a few here and there such as japan usa uk europe australia hk Click to expand Who live in comfortable country will want to switch Similarly as mentioned talented hard working and smart Singaporeans would have jobs Only left over sinkies who are toxic in their workplace have no skillset not talented then think that CECA steal their jobs&quot;
), date = c(&quot;2021-07-13 00:00:00 UTC&quot;, &quot;2020-09-22 00:00:00 UTC&quot;, 
&quot;2021-08-07 00:00:00 UTC&quot;, &quot;2021-04-07 00:00:00 UTC&quot;, &quot;2021-07-23 00:00:00 UTC&quot;, 
&quot;2021-07-06 00:00:00 UTC&quot;, &quot;2021-07-08 00:00:00 UTC&quot;, &quot;2021-07-13 00:00:00 UTC&quot;, 
&quot;2021-07-06 00:00:00 UTC&quot;, &quot;2021-07-06 00:00:00 UTC&quot;), responsibility_attribution = c(4, 
3, 1, 2, 4, 1, 2, 4, 1, 4)), row.names = c(NA, -10L), class = c(&quot;tbl_df&quot;, 
&quot;tbl&quot;, &quot;data.frame&quot;))

</code></pre>
","natural-language-processing"
"43065","What is the meaning of ""dimensionality of the embeddings and hidden states""?","2023-12-09 19:02:30","","0","107","<machine-learning><deep-learning><natural-language-processing><recurrent-neural-networks><transformer>","<p>I was reading the GPT-2 and LSTM documents and noticed that they use the terms &quot;dimension of embedding and hidden state&quot;. For GPT-2, the size is <span class=""math-container"">$768$</span>, and for LSTM, the size is <span class=""math-container"">$256$</span>. What does that mean ? Are there any visual graphs or figures for these concepts ? Very difficult to understand any of this.</p>
<p>Thanks</p>
","natural-language-processing"
"43057","Are sentence-transformers the best available pretrained models for computing embeddings for a sentence?","2023-12-08 10:02:11","43062","1","149","<natural-language-processing>","<p>I am playing around with the sentence transformers pretrained models to compute embeddings for a sentence and then compare it using the cosine similarity on the two vectors. I was using the <code>sentence-transformers/all-MiniLM-L6-v2</code> model and used the <a href=""https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"" rel=""nofollow noreferrer"">inference API</a> on the model page.</p>
<p>For the two sentences:</p>
<ol>
<li>delivery fee not showing</li>
<li>delivery fee showing twice</li>
</ol>
<p>the similarity score was nearly 0.72 which seems very high for the two sentences that are in fact kind of opposite of each other. I would rather believe that these are orthogonal and would like them to have a score close to 0.</p>
<p>Can you guys help me with any other model that might give better results? Also, read about Universal Sentence Encoder by Google. Any reviews about that?</p>
","natural-language-processing"
"43047","Approaching construction of model that interprets financial reports","2023-12-07 21:21:02","","1","76","<natural-language-processing><large-language-models><embeddings>","<p>I want to train a model to be able to interpret financial reports (from a company). Basically, <strong>I want to be able to extract relevant information without needing to read through hundreds of pages of text</strong>. I know I will need to use a database that can store vectors for the embeddings of the texts. However, I have some questions:</p>
<ul>
<li>Assuming the texts are hundreds of pages long and, therefore, they go over a lot of stuff, what vectorization technique can be used?</li>
<li>I assume I will have to obtain a homogeneous training set. How do I do this without reading all the texts if I still don't have the final model (classification??)?</li>
<li>Let's say I have the final model. How do I &quot;query&quot; the things I want to know? In other words, would I have to input some text and then the model has to be able to interpret that as a query?</li>
</ul>
<p>Note: I apologize in advance if im not being too descriptive, I currently don't have so much information about the details of the data and other things, I only have a general sketch about the idea of the project.</p>
","natural-language-processing"
"43038","Is beam search the actual obstacle that prevents GPT-style models from doing sophisticated math reasoning?","2023-12-07 05:10:47","","4","249","<natural-language-processing><large-language-models><language-model><automated-theorem-proving><automated-reasoning>","<p>This is a rather soft question. Some people believe that GPT-style models can eventually solve very complex math problems if the models are large enough, but I'm skeptical about this. Suppose the GPT model is indeed large enough and can make very accurate predictions about the probabilities of the next token. Now we let it solve an extremely hard math problem, e.g. proving the Riemann Hypothesis. Proof length is not an obstacle, since the model can generate lots of tokens and therefore gains a lot of computational resources.</p>
<p>I think the most serious obstacle is how to generate the most likely <em>proof</em>, instead of the most likely <em>next token</em>. The bad thing is, that a proof might seem very plausible in the beginning, but may look more and more ridiculous as more tokens are generated. So, greedy decoding does not necessarily work; that's why people came up with beam search. But, beam search is also kind of greedy, and it also does not guarantee to produce the global optimal proof.</p>
<p>There may be extreme cases in which the optimal proof is among the top k+1 candidates but our beam size is k so it's not adopted. Therefore, the problem degenerates to a classic computational complexity problem: how on earth can we find the optimal generated sequence? This seems to be rather irrelevant to LLMs.</p>
<p>This problem is clearly in NP since its corresponding decision problem is: <em>given a scheme to generate the next token probabilities, can we generate a sequence with length as most l and log-likelihood at least p?</em> This decision problem can be verified in polynomial time by providing a satisfying sequence. I suspect this problem is NP-complete but I don't know how to prove it yet.</p>
<p>So, I conjecture that, unless P=NP, we can't use GPT-style LLMs to solve really hard math problems. Do you think so?</p>
","natural-language-processing"
"43021","Are there strictly deterministic LLMs?","2023-12-06 15:34:23","","5","1738","<natural-language-processing><large-language-models><model-request>","<p>LLMs are understood to generate non-deterministic outputs.</p>
<p>Are there LLMs out there that are capable to producing deterministic outputs for any given input given fixed parameters (like e.g temperature)?</p>
<p>I heard that llama.cpp - if run on a CPU instead of a GPU appears to generate deterministic outputs.</p>
","natural-language-processing"
"42986","Masking during Instruction Tuning for LLM finetuning","2023-12-03 13:14:04","","0","430","<natural-language-processing><transformer><large-language-models>","<p>I'm currently trying to learn more about LLMs particularly generative decoder only models such as the GPT family of models. I do have one question about masking though.</p>
<p>For me the way masking is performed left-to-right makes sense during pre-training but it is weird to me during instruction fine-tuning when dealing with the input prompt. I therefore have two questions:</p>
<ul>
<li>Is the input prompt masked in the same way as the text during pre-training?</li>
<li>And if so why is it done in this way and have there been studies on it</li>
</ul>
","natural-language-processing"
"42970","Is Training Separate NER Models for Specific Labels a Viable Strategy for Improved Accuracy?","2023-12-01 05:59:40","","0","26","<natural-language-processing><named-entity-recognition>","<p>In my project, I'm utilizing Named Entity Recognition (NER) to identify crucial variables in prompts categorized into specific domains. However, incorporating numerous labels in the training data has resulted in poor accuracy. Considering this, would creating separate NER models for each category be a  strategy to enhance accuracy and improve variable identification?</p>
","natural-language-processing"
"42939","Prefix tuning in LLM uses learnable vectors to fine tune the model","2023-11-28 14:59:33","","0","93","<neural-networks><machine-learning><deep-learning><natural-language-processing><transformer>","<p>I would like to implement a new architecture for Transformer.</p>
<p>Below description is my thought.</p>
<p>Prefix tuning in LLM uses learnable vectors to fine tune the model.</p>
<p>Is there a way to use the output generated by the Neural network as prefix?</p>
<p>Thanks</p>
<p><a href=""https://i.sstatic.net/YsUZ1.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/YsUZ1.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"42855","Would maximizing (instead of minimizing) error of an LLM/HMM lead to complex behavior?","2023-11-20 04:06:50","","1","80","<natural-language-processing><training><datasets><chatgpt><natural-language-generation>","<p>Imagine we have some sort of &quot;next token predictor,&quot; either with transformer architecture, LSTM, or just a HMM (though the terminology I use here will be less aligned to HMMs, I believe the question is generalizable to all generative NLP).</p>
<p>We reverse the cost function. That is, we are training to maximize error instead of minimizing it. In the case where error is neither maximized nor minimized, the behavior will be fairly boring. However, a model which is maximizing error may still need to learn patterns of syntax and which words usually follow one another in order to avoid them. I would expect that in some abstract way, it may behave creatively, because it is trying to produce output which is <em>not</em> in the training data, and is furthest away from it. In fact, it ideally should understand the user's query in order to avoid using words that follow it.</p>
<p>This makes me think the output may be non-boring, although probably not practically useful.</p>
","natural-language-processing"
"42819","NLP ""small"" model to improve ""big"" model","2023-11-16 08:47:15","42860","2","89","<machine-learning><natural-language-processing><language-model>","<p>When training the model for NLP is it important to get rid of data which has &quot;bad semantic&quot; for learning process?</p>
<p>My plan is to create a &quot;small model&quot; which can decide whether data used for training the final model are &quot;good&quot; or &quot;bad&quot;.</p>
<p>For instance the small model will be made from &quot;good&quot; data example and &quot;bad&quot; data example.
Later on all data which are going to be used to train a final big data model will be fist evaluated by the smaller one in order to increase overall quality of the data used in the final model.</p>
","natural-language-processing"
"42787","What is the input to an encoder-decoder transformer in next word prediction task?","2023-11-13 21:27:57","","1","65","<natural-language-processing><transformer><encoder-decoder>","<p>I'm trying to understand how encoder-decoder architectures are used, or if they are used at all, for generative tasks that do not require an explicit prompt (ie. machine translation, summarization, etc.).</p>
<p>From my understanding, decoder-only models autoregressively predict the next token in a sequence given its previous predictions. This makes sense, as we can simply keep feeding it tokens already predicted during inference. But how is this done when there is an encoder involved? For machine translation, we have the sequence in the source language to feed to the encoder. Similarly, we can feed it a passage to summarize for summarization. What would we feed the encoder if we simply wanted next word prediction? Do we feed it the sequence we want it to complete? I haven't found any examples of this task being performed. Does this mean that encoder-decoder models aren't needed for this task?</p>
","natural-language-processing"
"42761","Masking in Decoder of Transformer","2023-11-12 12:36:05","","1","294","<natural-language-processing><transformer><decoder>","<p>I understand that the masked multi-head attention block ensures that generation of token at time step t doesn't rely on subsequent tokens of the input. But the residual connection which adds the input to the output of masked multi-head attention block adds some of the information from future time steps which is then used to construct the query matrix for multi-head attention block.</p>
<p>Shouldn't some kind of mask be applied before adding the input values to the output of masked multi-head attention block as well?</p>
<p><em>Asking this question in the context of training process.</em></p>
<p><img src=""https://kikaben.com/transformers-encoder-decoder/images/figure-1.png"" alt=""Reference Image for Decoder Architecture"" /></p>
","natural-language-processing"
"42686","If the unigram precision is (N-1)/N, then the bigram precision is :","2023-11-06 08:01:43","","0","47","<machine-learning><natural-language-processing><generative-model><n-gram>","<p>Consider the following machine translation scenario. The reference translation has N words (do not consider sentence beginner ‘hat’ and sentence finisher ‘dot’). The machine output also has N words. If the unigram precision is (N-1)/N, then the bigram precision is
(a) Also (N-1)/N
(b) At most (N-2)/(N-1)
(c) At least (N-2)/(N-1)
(d) At least (N-3)/(N-1)</p>
<p>Statement- If the unigram precision is (N-1)/N, then the bigram precision is  At most (N-2)/(N-1).</p>
<p>Is there any <em><strong>counter example</strong></em> which could prove the above statement wrong having candidate translation, C and reference translation, R.</p>
<p>I am unable to find any such counter example, kindly please help.</p>
<p>Also, are there any generalised results.</p>
<p>Prof Justification:
The given unigram precision implies that only one word in the candidate translation, C is different from the words in the reference translation, R. Under this circumstance the ‘best’ case of bigram match occurs when the unigram mismatch is at one of the boundaries and the rest of the words occur exactly in the same order as in R. Then only one out of N-2 bigrams does not match, giving rise to the bigram precision of (N-2)/(N-1).
The worst case of bigram mismatch occurs when the order of words in C is very different from that of R. The no of bigram matches can be even 0, as in
C: people laugh loudly
R: men loudly laugh</p>
","natural-language-processing"
"42679","what are the applications scenarios for prefix decoder LMs","2023-11-05 20:38:26","","0","362","<natural-language-processing><gpt>","<p>Motivated by this <a href=""https://ai.stackexchange.com/questions/27038/why-does-gpt-2-exclude-the-transformer-encoder"">post</a> wherein one of the comments mentioned the use-case for encoder-decoder LM. I wanted to know when to use prefix-decoder LM? vis a vis encoder-decoder or causal decoder only architectures?</p>
","natural-language-processing"
"42593","How to measure similarities between text (word to word or word to phrase)?","2023-10-30 13:37:30","","1","32","<natural-language-processing><computer-vision>","<p>Is there a way to measure to measure similarities between two pieces of text ? Think about the case where you have an image captioning model but you only want to deal/use specific class names. e.g. say you have classes like 'vegetation' , 'car' , etc .. and your captioning model output could be something like 'tree' , 'tree on the side of the road' , 'vehicle' , 'car' ...</p>
","natural-language-processing"
"42559","Why encoders are required in Transformers","2023-10-26 17:09:51","","0","203","<natural-language-processing><transformer><attention><natural-language-understanding><encoder-decoder>","<p>In the original Transformers paper why encoder is added when a decoder alone can do what an encoder can do (like multi-head attention, feed-forward NN etc....).</p>
<p>I mean even a decoder also has the same components that an encoder has</p>
<p><a href=""https://i.sstatic.net/i7Rkm.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/i7Rkm.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"42452","Setting number of rows returned by vector stores","2023-10-14 18:35:38","42453","0","147","<natural-language-processing><python><language-model>","<p>When using vector stores like pinecone or Faiss from langchain, is it possible to set the number of records returned based on similarity search?</p>
<p>For example, consider the following code, is there a parameter that can be set to control number of rows returned?</p>
<pre><code>FAISS.from_documents(mydata, embed_model)
</code></pre>
","natural-language-processing"
"42406","Exploring the Similarity of Sibling’s Voices Using Automatic Speaker Recognition","2023-10-11 09:16:42","","0","21","<deep-learning><natural-language-processing>","<p>I want to start project on Exploring the Similarity of Sibling’s Voices Using Automatic Speaker Recognition</p>
<blockquote>
<p>Everyone has a unique voice, because of the different structure of their articulatory organs. Some people have similar voices due to biological similarity or someone is mimicking them. This similarity raises a security concern. Several studies tried to distinguish between similar voices of people using speaker recognition techniques. Speaker recognition not only models an individual’s voice but also their speaking habits. This study surveys the use of automatic speaker recognition techniques in order to explore the similarity between siblings. This includes comparing the performance of several models, such as artificial neural networks (ANNs), Gaussian mixture model (GMM) and i-vector. In addition, a dataset of sibling speech is recorded and processed to be available for public research.</p>
</blockquote>
<p>and <strong>want to know what to learn in order to make this project and if there any recommended recourses?</strong></p>
","natural-language-processing"
"42393","LLM for Postgres","2023-10-10 07:55:27","","1","172","<natural-language-processing><open-ai><large-language-models>","<p>I have a postgres database with 200+ Tables. Each table contains information about my supply inventory. It also contains columns which are JSON and there are nested JSON as well. There are relationships as well and some relationships are based on the values in the JSON Column in one table pointing to another Column in Another Table.</p>
<p>I use to do ETL to flat it, then query and generate report.</p>
<p>Recently I tried to solve this problem by LLM, I have installed and tried LLama-2 model on one of my EC2 machine. But I am not able to achieve the result which I thought. I wanted to chat with my database.</p>
<p>I have following questions in order to complete this entire activity. It will be great if you people can guide me for my next steps and other information.</p>
<ul>
<li><p>One of the major problem is I face token limit error.</p>
<ul>
<li>I understand that there is token limit for each LLM, but I am still wondering or not able to
understand that do I need to really or explicitly create Embedding for my data or do I need
to normalize or de-normalize data or something else I need to do.</li>
</ul>
</li>
<li><p>The existing solution which I have created or working on is working, but it is not consistent</p>
<ul>
<li>How can I make my solution more consitent</li>
</ul>
</li>
<li><p>The existing solution which I have created gives result sometime correctly and sometimes incorrect or it not able to understand data</p>
<ul>
<li>How can I make model understand my data for complex JSON or other columns, for joins etc</li>
</ul>
</li>
<li><p>Increasing Datasize</p>
<ul>
<li>How can I manage my model or solution to cater the increasing datasize in near future</li>
</ul>
</li>
<li><p>Is there something to do with the Model</p>
<ul>
<li>Is there any other Model which I should try or use which is suitable for my usecase</li>
</ul>
</li>
</ul>
<p>These are the some high level queries which I have.
It will be great if someone can help me out understand the details here.</p>
","natural-language-processing"
"42313","Aren't context lengths for transformers an artificial restriction?","2023-10-04 07:45:30","42321","3","1050","<natural-language-processing><transformer><attention><gpt><decoder>","<p>Let's focus on the case of decoder-only transformers, where I am using algorithm 10 from &quot;Formal Algorithms for Transformers&quot; by Mary Phung and Marcus Hutter as a reference.</p>
<p><a href=""https://i.sstatic.net/Me8rq.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Me8rq.png"" alt=""Algorithm 10 from &quot;Formal Algorithms for Transformers&quot; by Mary Phung and Marcus Hutter"" /></a>: <a href=""https://i.sstatic.net/ZWC9o.png"" rel=""nofollow noreferrer"">https://i.sstatic.net/ZWC9o.png</a></p>
<p>Previously I thought that the maximum context length is very much <strong>built into</strong> the transformer, for example as the dimension of a layer of weights. After studying this algorithm I am surprised because it seems more like an <strong>artificial restriction</strong>! Because this is a topic of active research I would like to know if I am misunderstanding something.</p>
<p>The way I see it, if I had access to the weights of GPT-2 right now, I could almost execute it on any number of tokens I like right away (If I had sufficient memory to compute this). The MHA algorithm is just carried out over a larger sequenece. There are only two issues, which are points where the context window <span class=""math-container"">$l_{max}$</span> appears:</p>
<ol>
<li>The positional encoding has only <span class=""math-container"">$l_{max}$</span> positions</li>
<li>During training the weights were never optimized to attend over more than <span class=""math-container"">$l_{max}$</span> tokens.</li>
</ol>
<p>But these issues seem rather easy to resolve:</p>
<ol>
<li><p>Use some positional encoding which has infinitely many positions. The first encoding vectors are nicely spread around while the later ones are closer to eachother, due to the nature of fitting an infinite sequence of vectors into more or less a unit ball/sphere. But this is not an issue: It is natural for the positional encoding to become more vague as the token is further and further in the past.</p>
</li>
<li><p>Train 50% on context lengths around <span class=""math-container"">$l_{max}$</span>, 25% on context lengths around <span class=""math-container"">$2 l_{max}$</span>, 12.5% on context lengths around <span class=""math-container"">$4 l_{max}$</span> and so on...</p>
</li>
</ol>
<p>I can imagine the following issues appearing:</p>
<p>A) Memory becomes larger than what is available on a single &quot;unit&quot; (GPU?) so you have to start moving data back and forth to execute your transformer, which is just terribly inefficient during training and also inference, so it is really pointless to train on such large context windows.</p>
<p>B) Perhaps the transformer just doesn't learn well with this procedure for some reason.</p>
<p>These issues are still rather &quot;soft&quot; issues though. As far as I can tell, I could use the architecture of GPT-2 (modified positional encoding) to create 1000000 context window LLMs, in theory. So, am I missing something?</p>
<p>Thank you!</p>
","natural-language-processing"
"42306","Is there any well-established work that allows robots to communicate their decision-making using natural language?","2023-10-03 18:52:25","","1","26","<machine-learning><natural-language-processing><reference-request><human-robot-interaction>","<p>I am searching for a well-established work that allows robots to communicate their decision-making using natural language.</p>
<p>For example, a robot's explanation could be &quot;I did [task1] because [reason1] and [reason2].&quot;</p>
<p>I know there is parallel research across different fields but I was wondering if anyone knows a good work with reusable code.</p>
<p>Thanks!</p>
","natural-language-processing"
"42266","Is ChatGPT a viable strategy for solving the P-NP Problem?","2023-09-30 17:16:12","","0","233","<natural-language-processing><large-language-models><automated-reasoning>","<p>According to ZDNet, it is an open question whether a transformer LLM like ChatGPT can facilitate the determination of a solution to the <a href=""https://en.wikipedia.org/wiki/P_versus_NP_problem"" rel=""nofollow noreferrer"">P-NP Problem</a>. (See <strong><a href=""https://www.zdnet.com/article/can-generative-ai-solve-computer-sciences-greatest-unsolved-problem/"" rel=""nofollow noreferrer"">Can generative AI solve computer science's greatest unsolved problem?</a> (ZDNet)</strong>) This would seem to be an attempt to mine statistical patterns of a corpus as a form of non-determinstic automated reasoning to collate a series of logical propositions that cohere to a deductively sound argument. So, the question arises is there any <em>a priori</em> justification for rejecting this particular form of generative AI as a strategy for developing a mathematical logical argument to determine an answer to the question of P-NP equivalency?</p>
","natural-language-processing"
"42265","How to train a seq2seq model to rephrase input text following given rules","2023-09-30 12:26:12","","0","69","<natural-language-processing><large-language-models><seq2seq>","<p>I want to train (fine-tune) a seq2seq model to perform the task of rephrasing input following these rules :</p>
<p>1- always follow the pattern &quot;Entity Verb Entity&quot;</p>
<p>2- only use simple sentences : never combine sentences</p>
<p>3- Don't replace existing words</p>
<p>4- Don't lose the overall meaning of the text or any information in it.</p>
<p>For example:</p>
<p>text = &quot;Project Risk Management includes the processes of conducting risk management planning, identification, analysis, response planning, response implementation, and monitoring risk on a project&quot;</p>
<p>Standardized Text = &quot;Project Risk Management conducts risk management planning. Project Risk Management conducts risk identification. Project Risk Management conducts risk analysis. Project Risk Management plans responses. Project Risk Management implements responses. Project Risk Management monitors risk on a project.&quot;</p>
<p>Using ChatGPT the results were very good, but I want to know if I can fine tune a model (BERT, T5, any LM) locally, what should be the data format for training such a model, evaluation metrics ?</p>
","natural-language-processing"
"42247","How to get Llama-2 Rotary Embeddings?","2023-09-29 07:46:08","","-1","691","<neural-networks><natural-language-processing><transformer><word-embedding><large-language-models>","<p>I want to get the Llama-2 rotary embeddings. I do <code>print(model)</code> and get the following output:
<a href=""https://i.sstatic.net/jFu2Z.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/jFu2Z.png"" alt=""enter image description here"" /></a></p>
<p>In the picture I highlight the rotary embeddings.</p>
<p>How can get the rotary embeddings and how can I interpret the output? What means 32x LLamaDecoderLayer and in its round brakets are four layer plus LlamaRotaryEmbeddings?</p>
<p>It's possible to get the embeddings as the first hidden-state <code>hidden_state[0]</code> and I want to know, which hidden-state represents the rotary embeddings.
Am I right, that there are several rotary embeddings?</p>
<p>Thanks in forward.</p>
<p>Best regards.</p>
","natural-language-processing"
"42234","Data preparation for NLP model","2023-09-28 06:23:34","42335","1","55","<machine-learning><natural-language-processing><language-model>","<p>I have data from our ticketing system. Currently using OpenNLP to create different models.</p>
<p>For simplicity I have a <strong>10k ticket's text</strong> as category <strong>final queue</strong> of the ticket.</p>
<p>My questions:</p>
<ul>
<li>Is it important for the model to have data similarly distributed?
<ul>
<li>eg. for 3 category imagine that 6k items is for 1.cat, 3k is for 2.cat and the rest 1k for 3.cat.</li>
<li>Will this affect the final classification?</li>
</ul>
</li>
<li>Is it wise to remove a constants from the evaluated text?
eg. &quot;Good day&quot;, &quot;Best regards&quot; and others?
<ul>
<li>Should I already remove such constants from data set for training model or just remove it from text for classification?</li>
</ul>
</li>
</ul>
","natural-language-processing"
"42140","Why do current language models no longer generate to long or short texts?","2023-09-19 21:58:45","","3","165","<natural-language-processing><chatgpt><large-language-models><language-model><natural-language-generation>","<p>One of the biggest strengths of ChatGPT is that it generates fitting text with respect to the input query. It usually stays on topic, anwers the question completely and especially does not start talking gibberish or repeating itself.</p>
<p>This behaviour is different when comparing this to older LLMs. For example: GPT2 would usually only stop generating text when it hit the token limit or a predefined stop sequence. Also, it had a much bigger problem with giving repeating answers. Newer models (especially instruction tuned ones) do not suffer from this problems (e.g. llama 2).</p>
<p><strong>So I have 2 questions: What mechanisms/techniques are used in current language models such that...</strong></p>
<ol>
<li>...<strong>the models know when to stop generating text.</strong></li>
<li>...<strong>the models do not repeat themselfes and stay on topic.</strong></li>
</ol>
<p>I suspect it might have alot to do with instruction tuning but I am happy to hear from you.</p>
","natural-language-processing"
"42132","NLP for classifying a YES or NO response to a question","2023-09-19 16:18:15","","1","111","<machine-learning><natural-language-processing><text-classification><topic-model>","<p>I'm currently working on a project that requires some feature extraction. The data I have is text and comes from an interview. The interviewer asks a question, the client responds, and the interviewer collects the response.</p>
<p>Examples:
How much of <em>this</em> do you do?
I do <em>this</em> sometimes, maybe twice a week.
Returns: True</p>
<p>How much of <em>this</em> do you do?
N/A
Returns: False</p>
<p>How much of <em>this</em> do you do?
I've been trying to stop recently.
Returns: True</p>
<p>How much of <em>this</em> do you do?
I haven't done this in a long time. I used to when I was younger.
Returns: False</p>
<p>I've done some research into LDA and think this could be a good fit, but what I've gathered is that it predicts the general topic, not whether someone answers a specific way.</p>
<p>Any thoughts?</p>
","natural-language-processing"
"42107","AI: Inverse questions answering - quiz style: Verify descriptive answers to a static question","2023-09-16 11:31:04","42183","1","73","<natural-language-processing>","<p>I'm exploring LLMs for educative purposes an came across the topic question answering, e. g. building a system that ingests documents like PDFs and is able to answer questions about its content.</p>
<p>My question: Are there models / keywords / tutorials when it comes to inverting this process? Let's say you would ingest the PDF of a Sherlock Holmes story and the define hard coded questions like &quot;Who was the perpetrator?&quot; &quot;What was the motive?&quot;. People could write descriptive answers in their own words to these questions and the LLM would return a probability, whether the given answer is correct or not.</p>
","natural-language-processing"
"42018","Keywords extractions from short names (table and column names)","2023-09-07 10:24:35","42036","0","42","<natural-language-processing>","<p>I extract keywords that are table and column names (around 100,000 in the test).
I process them in Python, and as a result, I get a CSV file with sample keywords:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>db_id</th>
<th>type</th>
<th>object_id</th>
<th>keyword</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>data warehouse zoom meeting participants</td>
</tr>
</tbody>
</table>
</div>
<p>And the object_id column (which object the keyword refers to).</p>
<p>From the given sample keyword:</p>
<p>I would like to obtain, for example:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>db_id</th>
<th>type</th>
<th>object_id</th>
<th>keyword</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>data warehouse</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>zoom participants</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>organization id</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>zoom meeting participants</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>1200</td>
<td>zoom</td>
</tr>
</tbody>
</table>
</div>
<p>And preferably even more complex, as if it was proposed to me by LLM
The ultimate goal is to have several records associated with the same 'object_id'.</p>
<p><strong>What is the best tool to do this sensibly to extract keywords from such short lines?
Another issue is how to determine which keywords are important and which are not.</strong></p>
<p>The processing script:</p>
<pre><code>import os
from dotenv import load_dotenv
import pyodbc
import csv
import wordninja
import re


# Loading Environment Variables
load_dotenv('.env')
db_user = os.getenv('USER')
db_password = os.getenv('PASSWORD')
db_host = os.getenv('HOST')
db_name = os.getenv('DB_NAME')

# Creating Connection String
connection_string = f&quot;DRIVER=ODBC Driver 17 for SQL Server;SERVER={db_host};DATABASE={db_name};UID={db_user};PWD={db_password}&quot;

# Connecting to the Database
conn = pyodbc.connect(connection_string)
cursor = conn.cursor()

# Retrieving Keywords from the Database
cursor.execute('SELECT * FROM keywords_test')
table_columns = [column[0] for column in cursor.description]
rows = [dict(zip(table_columns, row)) for row in cursor.fetchall()]

# Abbreviation Definitions
abbreviations = {
    &quot;dwh&quot;: &quot;data warehouse&quot;,
    &quot;attr&quot;: &quot;attribute&quot;,
    ...
}

# List of words to be protected from splitting
protected_words = list(set([&quot;id&quot;, &quot;emails&quot;, &quot;email&quot;, &quot;users&quot;, &quot;date&quot;, &quot;update&quot;, &quot;updates&quot;, &quot;msdyn&quot;...])) 


def separate_protected_and_abbreviations(text):
    &quot;&quot;&quot;
    This function separates protected words and handles abbreviations.
    &quot;&quot;&quot;
    # Sort protected words by length (longest first)
    sorted_protected_words = sorted(protected_words, key=len, reverse=True)
    
    # Introduce a space around protected words so they are treated as separate entities
    for word in sorted_protected_words:
        text = re.sub(f&quot;(?i)(?&lt;!\w){word}(?!\w)&quot;, f&quot; {word} &quot;, text)

    # Use regex rule for further splitting
    split_pattern = re.compile(r'(?&lt;=[a-z])(?=[A-Z])|(?&lt;=[A-Z])(?=[A-Z][a-z])|[_-]')
    words = re.split(split_pattern, text)
    
    # Expand abbreviations
    words = [expand_abbreviations(word) for word in words]

    # Process words
    new_words = []
    for word in words:
        if word.lower() in protected_words:
            new_words.append(word)
        else:
            new_words.extend(wordninja.split(word))

    return ' '.join(new_words)


def expand_abbreviations(text):
    &quot;&quot;&quot;
    This function expands the abbreviations present in the text.
    &quot;&quot;&quot;
    words = text.split()
    new_words = []
    for word in words:
        if word.lower() in abbreviations:
            new_words.extend(abbreviations[word.lower()].split())
        else:
            new_words.append(word)
    return ' '.join(new_words)

def process_text(keyword):
    &quot;&quot;&quot;
    Process the given keyword by separating out protected words, 
    handling abbreviations and then making everything lowercase.
    &quot;&quot;&quot;
    keyword = separate_protected_and_abbreviations(keyword)
    keyword = keyword.lower()
    keyword = ' '.join([word for word in keyword.split() if len(word) &gt; 1])
    return expand_abbreviations(keyword)  

for row in rows:
    row[&quot;keyword&quot;] = process_text(row[&quot;keyword&quot;])

filename = &quot;processed.csv&quot;
with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=list(rows[0].keys()))
    writer.writeheader()
    writer.writerows(rows)

# Closing the Database Connection
conn.close()
</code></pre>
","natural-language-processing"
"42005","Why is an encoder + decoder model with L by L layers the same speed as as decoder only model with 2 L layers?","2023-09-05 22:46:35","","2","86","<natural-language-processing><transformer>","<p>I was watching this lecture: <a href=""https://youtu.be/27rNqGrTdSI?t=2295"" rel=""nofollow noreferrer"">https://youtu.be/27rNqGrTdSI?t=2295</a></p>
<p>In it the presenter stated that:</p>
<p>&quot;An encoder + decoder model with L by L layers is actually the same speed as as decoder only model with 2 L layers because in the end the input and targets still have to be processed and decoder only concatenates inputs and targets to do most tasks. Technically, Encoder Decoder models are a form of sparsity, they are also sequentially sparse, they have dedicated parameters to inputs and targets, they different parameters for inputs and targets, parameter to flop ratio behaves differently from decoder only models&quot;</p>
<p>Why is &quot;An encoder + decoder model with L by L layers the same speed as as decoder only model with 2 L layers&quot; true?</p>
","natural-language-processing"
"41939","Fine Tuning a Bert Transformer. How to label for emotions and train large scripts?","2023-08-31 11:29:38","41969","0","155","<natural-language-processing><bert><data-labelling><emotion-recognition>","<p>From what I have seen you can fine tune a Bert model to detect emotions by labelling single sentences.
But if the text you want to evaluate is a large script with many sentences, do I need to split the script into sentences and get a classification for each one? If I did it that way I could find the average score for each emotion for the the sentences in the script.
The problem with doing it that way is the the context between sentences is lost. A context like sarcasm often means that sentences have to be connected in order to understand that it is sarcastic.
I would be interested to get some advice on this.</p>
","natural-language-processing"
"41915","How to label missing/default values for a named entity recognition dataset","2023-08-29 09:45:57","41946","0","52","<machine-learning><natural-language-processing><training><training-datasets><named-entity-recognition>","<p>I am building the training dataset for a named entity recognition model, with 2 tags: <code>Name</code> and <code>Category</code> and I am using a pre-trained spaCy model.</p>
<p>Given a document, the model needs to extract the name and category of several items.</p>
<p>However, the name or category can be missing or contain a value which means it is absent.
In this case, should I tag or ignore the entities?</p>
<p>For example, given the following document:</p>
<pre><code>The first item's name is: X and category is: N/A
The second item's name is: --- and category is &lt;specifiy-item-category&gt;
The third item's category is: Y
</code></pre>
<p>should I also tag <code>N/A</code> as the Category (first line) or <code>---</code> as the Name  or <code>&lt;specifiy-item-category&gt;</code> as the Category (the second line) ?</p>
<p>Specifically, I am not interested in empty values and in the end I am going to ignore them anyway. Should the model be agnostic or not of empty meaning?</p>
","natural-language-processing"
"41858","How can BERT/Transformer models accept input batches of different sizes?","2023-08-23 23:22:40","","0","336","<neural-networks><natural-language-processing><transformer><bert>","<p>I understand that all inputs in a batch need to be of the same size. However, it seems BERT/Transformers models can accept batches with different sizes as input.</p>
<p>How is that possible? I thought we needed to pad all examples in a batch to <code>model.max_input_size</code>, however, it seems HuggingFace does <code>Dynamic Padding</code> that allows sending batches of different lengths (till the time they are smaller than <code>max_input_size</code>)</p>
<p><a href=""https://i.sstatic.net/zC1WS.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/zC1WS.png"" alt=""enter image description here"" /></a></p>
<p>Link: <a href=""https://mccormickml.com/2020/07/29/smart-batching-tutorial/"" rel=""nofollow noreferrer"">https://mccormickml.com/2020/07/29/smart-batching-tutorial/</a><br />
Link2: <a href=""https://huggingface.co/learn/nlp-course/en/chapter3/2?fw=pt#dynamic-padding"" rel=""nofollow noreferrer"">https://huggingface.co/learn/nlp-course/en/chapter3/2?fw=pt#dynamic-padding</a></p>
","natural-language-processing"
"41823","How word2vec de-embeds the special names in language models which output text","2023-08-20 16:49:09","","0","46","<natural-language-processing><word-embedding><word2vec>","<p>I am new to nlp field. I have some questions about word2vec embeddings. as I know they have a fixed size dictionary of vocabs. so definitely there some words which is not in that predefined dictionary of vocab, for i.e. we may get an special name (like people's name) which doesn't exist in the vocab and they are called out-of-vocabulary (OOV) words.</p>
<p>So how embedding and de-embedding for a translation language model work? I want the language model of the example to include the de-embedding part; as we know in classification language models we may only concern about the embedding part as the output is not an embedding vector, and does not need to be converted to a string(word)</p>
<p>I don't know what ways are used to embed those OOV words? I guess one way is to use some main word2vec and another complementary fastText for OOV words, or instead some complementary generic way of embedding like <code>nn.embedding</code> in pytorch. This won't make any problem in the classification models like sentiment analysis or Text classification.</p>
<p>Question 1: what are other methods that can be used for embedding an OOV word while we want to use word2vec?</p>
<p>but in the models which Their output is eventually gonna be a word (like translation or text summarization), I have some concerns as below:</p>
<p>Note we know the output of a translation language model is a sequence of embedding vectors to correspondent output word.</p>
<p>Note the way that we convert those embedding vectors to words, usually is by finding the closest embedding Vector in the embedding Matrix, either word2vec or fastText or de-embedder of <code>nn.embedding</code>. Also note this way eventually result, some Vector and from there, by its index, we would get a word.</p>
<p>as we have two embedding models, so when we are the step which have received the language model output embedding vector, we need first distinguish, this output embedding vector Should be de-embedded from which embedding model (word2vec or fastText)? note as I said eventually the next action (finding closest embedding) would result some word.</p>
<p>so I guess one way maybe is find the closest vectors for 2 embedding models, also we their similarity score to output embedding vector of the language model, and know to de-embed from which one.</p>
<p>question 2: so how this problem to distinguish to which embedding model to de-embed from is handled? I guess there should be more sophisticated methods in Practice so if there are please tell me?</p>
<p>question 3: do u know a model which have implemented my solutions (one for embedding by complementary embedding model, 2nd one distinguishing by similarity score)?</p>
","natural-language-processing"
"41813","How does GPT like Decoder only conversational models distunguish the source of text?","2023-08-18 20:49:01","","0","62","<natural-language-processing><transformer><chat-bots><gpt><seq2seq>","<p>In a conversational setting where two sources of text (user and the model) follow each other like below</p>
<p>User: some text bla bla
Model: another text bah bah
User: bla bla bla
Model: bah bah</p>
<p>and so on, how does the model differentiate the texts written by the user and the model?
I assume in an encoder-decoder setting (like T5 or BART), texts from two sources can be differentiated by giving user texts as encoder input and model's earlier responses as decoder input.</p>
<p>How about GPT-like Decoder only models?
Relating to that, what is the common method to train models for long conversational setting like above?</p>
","natural-language-processing"
"41802","Concatenation of Feature vectors in transformers before passing to fcnn","2023-08-17 12:08:07","","1","284","<machine-learning><natural-language-processing><transformer><attention>","<p>** As I am new to the field , the question might feel little abstract and naïve considering my experience.
I am studying the Transformer architecture and trying to understand the various components within it. I am not able to understand the purpose of concatenating the attention head vectors, when the researchers could have used some other method to fuse the vectors. I wanted to understand the intuition behind that. I got a very good conversation on stack exchange itself (<a href=""https://ai.stackexchange.com/questions/20948/combine-two-feature-vectors-for-a-correct-input-of-a-neural-network?newreg=666bdbcf8c0f4470ba6d740b00f4050f"">Combine two feature vectors for a correct input of a neural network</a>). Taking the guidance from the link I wanted to understand whether the attention head outputs are linearly separable and that's why the researchers decided to concatenate the vectors? Or is it something related to direct vector sum for subspaces (not sure), or there is any proof relating to Information Theory wherein somebody has shown that the information loss in lesser that way (I am speculating). Please guide me through the concept.</p>
","natural-language-processing"
"41779","Any research in ""probe-tuning"" of LLMs?","2023-08-15 21:16:34","","0","47","<natural-language-processing><supervised-learning><large-language-models><binary-classification><fine-tuning>","<p>Is there any research in &quot;probe-tuning&quot; of LLMs, i.e., tuning LLM's parameter weights such that a specific <a href=""https://arxiv.org/abs/1610.01644"" rel=""nofollow noreferrer"">probe (classifier)</a> is more reliably detecting certain markers throughout the context, such as grammatical errors, aggression, manipulation, certain political bias, etc.?</p>
<p>This is different from classical fine-tuning and RLHF. As well as classical fine-tuning, probe-tuning is a supervised ML method: it is based on human-annotated texts (contexts). However, probe-tuning should be more effective than classical fine-tuning for detecting many occurrences of a certain marker throughout the context. Probe-tuning doesn't train on LLM's own &quot;original rollouts&quot; at all, only on LLM's activations during the context pass through the LLM.</p>
<p>I imagine than before doing actual probe-tuning, first we should determine which probe in the LLM is most aligned to the training data (annotations) already, so that probe-tuning likely just attenuates some vaguely existing concept within the LLM.</p>
","natural-language-processing"
"41643","Optimal Quantity of Training Data for Fine-Tuning an LLM: Is Bigger Always Better?","2023-08-04 07:43:00","","0","348","<natural-language-processing><gpt><large-language-models><language-model><fine-tuning>","<p>I am currently working on fine-tuning an LLM for a specific task, and I am trying to determine the optimal size for my training dataset. Intuitively, one might think that the more data, the better. However, I am aware that in some contexts, this may lead to overfitting or other issues.</p>
<p>What is the general consensus on the optimal quantity of training data required for fine-tuning a Large Language Model? Is bigger always better?</p>
","natural-language-processing"
"41513","Seq2Seq model- Confusing about the dimension of Seq2Seq model","2023-07-28 07:15:41","41525","0","29","<natural-language-processing><long-short-term-memory><embeddings><seq2seq>","<p>I am new to Seq2Seq and hope to find a proper guildances, advices.</p>
<blockquote>
<p>I am doing a Project from an online course so I can not give the material but I got my Project notebook on <a href=""https://github.com/CQHofsns/LSTM-based-Seq2Seq-QA-bots-Udacity/blob/main/(Starter%20Code)%20Chatbot%20With%20LSTM%20and%20Pretrained%20Embeddings.ipynb"" rel=""nofollow noreferrer"">Github</a></p>
</blockquote>
<p>I want to ask about my understanding about the architecture as well as the data dimension after each layer. Suppose I have a Seq2Seq model as below:</p>
<pre><code> Seq2Seq(
  (encoder): Encoder(
    (embedding): Embedding(5678, 512)
    (lstm): LSTM(512, 512, batch_first=True)
  )
  (decoder): Decoder(
    (embedding): Embedding(4297, 512)
    (lstm): LSTM(512, 512, batch_first=True)
    (fc): Linear(in_features=512, out_features=4297, bias=True)
    (dropout): Dropout(p=0.2, inplace=False)
    (softmax): LogSoftmax(dim=1)
  )
)
</code></pre>
<p>Where 5678 is source_vocab size, 512 is desired embedding size, 4297 is target_vocab size. You can check my Encoder, Decoder, Seq2Seq class as below:</p>
<pre><code>device= torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
print(device)

class Encoder(nn.Module):
    
    def __init__(self, input_size, hidden_size):
        
        super(Encoder, self).__init__()
        
        self.input_size= input_size
        self.hidden_size= hidden_size
        
        self.embedding= nn.Embedding(self.input_size, self.hidden_size)
        self.lstm= nn.LSTM(self.hidden_size, self.hidden_size, batch_first= True)

    def forward(self, i):
        print(i.size())
        embedded= self.embedding(i)
        print(embedded.size())
        o,(h,c)= self.lstm(embedded)
        
        return h, c
    

class Decoder(nn.Module):
      
    def __init__(self, hidden_size, output_size):
        
        super(Decoder, self).__init__()
        
        self.hidden_size= hidden_size
        self.output_size= output_size

        self.embedding= nn.Embedding(self.output_size, self.hidden_size)
        self.lstm= nn.LSTM(self.hidden_size, self.hidden_size, batch_first= True)
        self.fc = nn.Linear(self.hidden_size, self.output_size)
        self.dropout= nn.Dropout(0.2)
        self.softmax= nn.LogSoftmax(dim= 1)
        
    def forward(self, i, h, c):
        embedded= self.embedding(i)
        o,(h,c)= self.lstm(embedded, (h, c))
        o= self.fc(o[0])
        o= self.dropout(o)
        o= self.softmax(o)
        
        return o, h, c
        
        

class Seq2Seq(nn.Module):
    
    def __init__(self, encoder_input_size, encoder_hidden_size, decoder_hidden_size, decoder_output_size):
        
        super(Seq2Seq, self).__init__()
        
        self.input_size= encoder_input_size
        self.hidden_size= encoder_hidden_size
        self.output_size= decoder_output_size
        
        self.encoder= Encoder(self.input_size, self.hidden_size)
        self.decoder= Decoder(self.hidden_size, self.output_size)
    
    def forward(self, src, trg, teacher_forcing_ratio = 0.5):
        
        output_seq= []
        
        encoder_hidden, encoder_cell= self.encoder(src)
        
        decoder_hidden= encoder_hidden
        decoder_cell= encoder_cell

        decoder_input= torch.Tensor([[target_vocab.token_to_index(&quot;&lt;SOS&gt;&quot;)]]).long().to(device)
        
        for time_step in range(trg.size(0)):
            output_token, decoder_hidden, decoder_cell= self.decoder(
                decoder_input,
                decoder_hidden,
                decoder_cell
            )
            output_seq.append(output_token)
            
            if self.training:
                if random.random() &lt; teacher_forcing_ratio:
                    decoder_input= trg[time_step]
            else:
                _, top_index= output_token.data.topk(1)
                decoder_input= top_index.squeeze().detach()
        
        return output_seq
</code></pre>
<p>My quesions is that the Input of Encoder is the soure vocabualry size, which mean that <strong>each token in the input sequence should be converted into one-hot vector before parsing to the Encoder before hand</strong> (for example, should a batch has a dimension of (batch_size, seq_len, vocab_size) instead of (batch_size, seq_len)?</p>
<p>I search others notebook and saw that they just parse a batch of (batch_size, seq_len) into the Encoder and I got confused.</p>
<p>Any help is appreciated.</p>
<p>I have tried pass (batch_size, seq_len, vocab_size) and the Embedding layer output dimension is (batch_size, seq_len, vocab_size, embedding_dim), which make me more confused, isn't it should be (batch_size, seq_len, embedding_dim)</p>
","natural-language-processing"
"41510","Can back-bone of text-to-image GEN AI models utilised for classification?","2023-07-28 05:43:36","","1","41","<deep-learning><natural-language-processing><computer-vision><generative-model>","<p>With the advent of GEN AI (Stable Diffusion), we are able to create images with text. For eg. If i need to create a <em>dog on beach during sunset</em>; now in background this model needs to first get images of object in the image which is <strong>dog</strong>, scene which is <strong>beach</strong>, <strong>sunset</strong>.</p>
<p>Now when the model knows what are the objects/ scene in the image, it is good to say it can classify the objects/ scenes. I wanted to utilise this feature of model for building classification models. Would appreciate getting leads/code/discussions on this.</p>
","natural-language-processing"
"41394","How was the token list determined for the tokenizer ""cl100k_base""?","2023-07-21 11:35:51","41397","1","431","<natural-language-processing>","<p>Does it have something to do with smoothing out the token frequencies to a desired distribution? If so, what's that distribution? And how is it achieved?</p>
<p>Is there a separate paper about it? Or should I just dig through LLM papers?</p>
","natural-language-processing"
"41367","How is the padding mask incorporated in the attention formula?","2023-07-19 22:29:35","41383","1","643","<natural-language-processing><transformer><attention><sequence-modeling><padding>","<p>I have been looking for the answer in other questions but no one tackled that. I want to ask you how is the padding mask considered in the formula of attention?</p>
<p>The attention formula taking into account a causal mask is:
<span class=""math-container"">$Attention(Q, K, V) = softmax(\frac{QK^{T} + CausalMask}{\sqrt{d_{k}}})V$</span></p>
<p>But how do we add the padding mask? The aim of a padding mask is to mask the padding positions as they're used just to make the batching feasible. But I don't know how this mask is added in the Attention formula.</p>
<p>Does it make sense if we do element-wise multiplication of the Attention matrix with a tensor of ones of shape (batch size, sequence length, <span class=""math-container"">$d_{model}$</span>) and whatever sentence <span class=""math-container"">$s$</span> in that batch and wherever position <span class=""math-container"">$p$</span> is a padding token then the tensor[s, p, :] is zeros?</p>
<p>Thank you in advance for your help!</p>
","natural-language-processing"
"41295","Fine-Tune Llama on main and auxiliary task","2023-07-15 19:29:23","","0","174","<deep-learning><natural-language-processing><large-language-models>","<p>I am trying to fine-tune Llama model on two task at the same time, using hugging face library:</p>
<p>Main task: Causal language model like the model was initially trained for
A classification task based on the whole input sequence (recommend an article). For this task I am getting as a reference the LlamaForCausalLM class, overwriting init and forward functions .
However, I want to combine the two tasks above into one process. The main problem is that language modelling is an iterative process were the loss is calculated for every new context token in the input sequence, while for the classification task the loss should only be calculated once.</p>
<p>How can I freeze the loss update on the classification task up and only calculated once the language modelling part has been completed. Is there any example you can recommend in order to combine a main LM task with an auxiliary classification task?</p>
<p>First question for me here, thanks everyone for your understanding.</p>
","natural-language-processing"
"41249","What is considered the pre-fill, and what is considered the decoding phase in this process?","2023-07-12 11:35:18","","1","2283","<machine-learning><deep-learning><natural-language-processing><transformer><large-language-models>","<p>I've seen conflicting information about this online so I'm looking for clarification. I'm dealing with the causal LLaMAF model specifically.</p>
<p>I used to think that a sequence of tokens is generated in, and a sequence of probabilities for the next token in the sequence is generated as output. This generated output token is then appended to the sequence of tokens, and fed in the model again.</p>
<p>However, I know understand that there's a key value cache that's generated for each sequence of tokens fed in. This key value cache stores a precomputed matrix that can be used in future computations to prevent having to recompute previously seen tokens.</p>
<p>So, the new workflow is feed in token list -&gt; generate next token and key value cache -&gt; feed in next token -&gt; generate next token and key value cache for current token</p>
<p>What is considered the pre-fill, and what is considered the decoding phase in this process? Does the prefill phase involve feeding through the token list one by one passes to generate the kv cache? Why does the prefill phase take significantly longer?</p>
","natural-language-processing"
"41163","Does fine-tuning a multilingual transformer model allow it to generalize to languages unseen in the fine-tuning dataset?","2023-07-06 00:48:59","41165","0","146","<natural-language-processing><transformer><fine-tuning>","<p>Example: <a href=""https://huggingface.co/google/umt5-base"" rel=""nofollow noreferrer"">https://huggingface.co/google/umt5-base</a></p>
<blockquote>
<p>Note: UMT5 was only pre-trained on mC4 excluding any supervised training. Therefore, this model has to be fine-tuned before it is useable on a downstream task.</p>
</blockquote>
<p>The model was pre-trained on a whole lot of languages. Let's suppose I devise a fine-tuning dataset to classify sentences (like user feedback). But due to resource constraints, only a few languages will be included. In my fine-tuned task, will the model be able to generalize to languages it was pre-trained, but not fine-tuned on?</p>
","natural-language-processing"
"41136","What is an appropriate tool to use that takes in a large knowledge base in string form and can answer questions based on the knowledge base?","2023-07-04 05:56:09","","1","61","<natural-language-processing><chatgpt>","<p>I have an issue where I'm trying to use the openAI API to input a very large custom knowledge base (exceeding 1GB) that allows the user to ask questions based on that base to receive intelligent answers. However, the openAI API is very restraining in the tokens and requests that can be inputted, and I was wondering if there is another tool that is more suited for my problem. I figured it would have to utilize an LLM to understand and parse the info.</p>
<p>I tried different measures such as smartly looking up specific sections of info then inputting a smaller chunk it into GPT, but I'm still largely restricted by the API's restraints.</p>
<p>I'm quite new to this, so any ideas and suggestions would be appreciated</p>
","natural-language-processing"
"41072","How does a multidimensional vector get fed into a single node in a neural network?","2023-07-01 05:35:28","","1","149","<natural-language-processing><feedforward-neural-networks><vectors>","<p>I mostly develop neural networks completely from scratch, like without libraries. I've been seeing, especially in NLP tasks, entire vectors, often representing words, get fed into a single node. I'm not really sure how this works, because in all the books I've ever read, and all the projects that I've developed, only a single number has ever gone into each node. So, how does this work?</p>
","natural-language-processing"
"41070","How are sentences numerically encoded before passing them to neural networks?","2023-07-01 02:23:31","41071","3","222","<natural-language-processing><data-preprocessing>","<p>I'm trying to understand NLP, how sentences can be used as input output in neural network architecture. As we know ANN is only compatible with number data. That's mean the sentences must be convert to number, right?</p>
<p>Suppose I have this sentence</p>
<pre><code>Hello world, the world is saying hello.
</code></pre>
<p>How it looks like when it converted to number?
I think it will looks like this...</p>
<pre><code>1 2 3 2 4 5 1
</code></pre>
<p>Where:</p>
<pre><code>hello = 1
world = 2
...
</code></pre>
<p>But what if there's typo? For example <code>hello worlf</code></p>
","natural-language-processing"
"40990","Sentence generation for limited vocabulary","2023-06-25 20:03:25","40999","0","207","<natural-language-processing><natural-language-generation>","<p>I need to make a sentence generator for a limited set of vocabulary (about 600 words). The requirements are:</p>
<ul>
<li>It must use only the words that are on the list, and never go beyond that;</li>
<li>It must produce sentences of varying syntactic structures, including complex sentences, relative clauses, tenses etc (not just the basic &quot;SVO&quot; sentences or whatever);</li>
<li>The sentences must be at reasonably meaningful and make sense at least most of the time (meaning that the sentences like &quot;Colourless green ideas sleep furiously&quot; shouldn't be generated).</li>
</ul>
<p>I'd like to ask what's the best way to go about it.</p>
<p>The &quot;varying sentence structures&quot; part is the easy one: I can do the grammar.</p>
<p>The issue, however, is the &quot;meaningfullness&quot; part. So far, I reckon that in order to implement it, I would need to generate a collocations database for each word: other words can it govern, and as what arguments specifically (e.g., the verb &quot;give&quot; can govern animate nouns as agents and recipients, and inanimate nouns as patients; while the verb can generally only govern some speech-related nouns like &quot;story&quot;, &quot;words&quot; or &quot;truth&quot; as patients). I should probably be able to extract this information from a corpus: I would need to use something like deeppavlov to parse the sentence structures (in order to extract the exact relationship between words), and some tool to account for irregular verbs and inflections (I would want for all forms of the same word to be treated as the same word, obviously).</p>
<p>However, collocations alone aren't enough to ensure meaningful sentences: even if every clause consists of only meaningful collocations, it still doesn't prevent, say, unrelated clauses to co-occur in the same complex sentence (&quot;I have to go to school because my dog is brown&quot;, or whatever). So in addition to a collocations database, I think I would also need a co-occurrence database, essentially telling how likely is each of the 600 words to co-occur with each of the other 599 words in the same sentence, regardless of their syntactic relationship. Basically, a total of 360000 probability values.</p>
<p>I'd like to ask for advice. Am I missing anything, is there perhaps an easier way to go about what I want to do?</p>
<p>Also, are there perhaps any existing solutions for my requirements? I briefly tried tweaking with the ChatGPT for a while, but getting it to stick to the list of words and at the same time produce diverse sentences had driven me insane pretty quickly.</p>
<p>P.S. So far, I'm kinda leaning towards a non-neural-network solution because of the small vocabulary list.</p>
<p>I'll appreciate any help or advice.</p>
","natural-language-processing"
"40917","What if we drop the causal mask in auto-regressive Transformer?","2023-06-21 20:55:04","","2","2100","<natural-language-processing><training><transformer><attention><inference>","<p>I understand the triangular causal mask in the attention is used to prevent tokens from <a href=""https://ai.stackexchange.com/questions/23889/what-is-the-purpose-of-decoder-mask-triangular-mask-in-transformer"">&quot;looking into the future&quot;</a>, but why do we want to prevent that?</p>
<p>Let's suppose we have a model with context length <span class=""math-container"">$T = 8$</span>. At inference time, we want to predict the 5th token with the previous 4 ones, so we truncate the upper-left submatrix and the causal mask looks like the following</p>
<pre><code>[1, 0, 0, 0]
[1, 1, 0, 0]
[1, 1, 1, 0]
[1, 1, 1, 1]
</code></pre>
<p>In this case, the model has no access to the 5th token because we did not feed it into the model in the first place, so it certainly cannot cheat by peeking ahead at the ground truth. Why do we still need the causal mask?</p>
<p>Moreover, the second row <code>[1, 1, 0, 0]</code> prevents the 2nd token from &quot;attending to&quot; the 3rd and 4th tokens. This makes sense if we are trying to predict the 3rd token, but we are actually predicting the 5th one. Why don't we allow available tokens to attend to each other?</p>
","natural-language-processing"
"40916","What ways are there to cluster an embedding space via binary branching?","2023-06-21 19:04:17","","0","79","<natural-language-processing>","<p>Let’s say I have a corpus of text and generate embeddings for it (I’m new to this, so not too particular as to what type of embeddings to use).</p>
<p>I assume there is some function that can show me the top N tokens regarding cosin similarity for any chosen word / token W.</p>
<p>I would like to use some (possibly recursive) graph algorithm which tries to convert a cluster of nodes with many edges into a binary branching tree.</p>
<p>The result would be a binary-branching ontology for the concept - like a nested list subclassifying its aspects. Like</p>
<ul>
<li>tree</li>
<li>what is it</li>
<li>core properties</li>
<li>important additional info</li>
<li>…</li>
</ul>
<p>Or maybe a “prototype” graph of associations, like</p>
<ul>
<li>tree, pine, oak, wood, forest, furniture, carpentry…</li>
</ul>
<p>Any guidance on this would be appreciated.</p>
","natural-language-processing"
"40851","Why shouldn't the attention matrices $W^Q$, $W^K$, $W^V$ be the same?","2023-06-15 05:50:36","","0","736","<natural-language-processing><transformer><attention><explainable-ai><vector-semantics>","<p>My question is why the attention head matrices <span class=""math-container"">$W^Q$</span>, <span class=""math-container"">$W^K$</span>, <span class=""math-container"">$W^V$</span> should not be the same <span class=""math-container"">$W = W^Q =W^K= W^V$</span>. In my understanding of transformer-based language models  <strong>one</strong> attention head is responsible for <strong>one</strong> syntactic or semantic relation between any two words in the context. One might think that such a relation is represented by <strong>one</strong> matrix <span class=""math-container"">$W$</span> that projects the full word embeddings <span class=""math-container"">$x_i$</span> from their full semantic space to a semantic subspace responsible for this relation. Here we could - in principle - calculate scores <span class=""math-container"">$\sigma_{ij}$</span> as &quot;similiarities&quot; between two projected words <span class=""math-container"">$Wx_i$</span> and <span class=""math-container"">$Wx_j$</span> and then calculate the weighted sum of the projected tokens <span class=""math-container"">$Wx_k$</span>.</p>
<p>I wonder why this would not work, and why we need three different matrices.</p>
<p>Another way around: What does it mean to calculate the score as the dot-product of two vectors from two different semantic subspaces? Is this still some kind of similiarity (which lies at the heart of word embeddings)? And doesn't it sound like comparing apples and pears?</p>
<p>Or viewed differently: How similar are the three matrices of an attention head in practice, e.g. when considering some 100<span class=""math-container"">$\times$</span>100 attention heads of a large transformer model like ChatGPT?</p>
","natural-language-processing"
"40812","How to work with multiple embeddings?","2023-06-12 03:38:27","","3","536","<natural-language-processing><embeddings><linear-algebra><vector-semantics>","<p>This is a conceptual gap that I have concerning embeddings, and would really appreciate some help closing it.</p>
<p>I understand when you embed a corpus for, let's say, a question-and-answer task you can then encode your query to find documents within your corpus that are nearest to the query in the embedding space, using something like cosine distance, and retrieve an answer, with a source being the document in your corpus from which it got the answer.</p>
<p>This to me is a &quot;one-dimensional&quot; embedding task - you chunk your corpus documents into lists of sentences for embeddings. The resulting list of embeddings is then a (NxM)-dimensional matrix, where N is your number of chunks you feed in, and M is functionally the number of unique tokens in your corpus.</p>
<p><a href=""https://i.sstatic.net/PBvl4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/PBvl4.png"" alt=""enter image description here"" /></a></p>
<p>However, for my project, I am trying to embed multiple text fields about public companies to later search and compare them - like a long description (1-2 paragraphs in length), their industry (1-2 words in length), and their sector (1-2 words).</p>
<p>I would think this is a &quot;3-dimensional&quot; embedding task, because we have three separate text fields that we embed. So for TSLA, we'd have a (NxMx3) tensor with embeddings for each of the three fields? How would the semantic search in this case work?</p>
<p>When performing semantic search, should I just try to search over all three groups of embeddings? If so, what might that look like? Or should I concatenate the embeddings somehow (kind of 'flattening')</p>
<p>Thank you in advance for any help</p>
","natural-language-processing"
"40749","How big the context can be using HuggingFace models?","2023-06-07 17:53:04","46011","0","727","<natural-language-processing><pytorch><bert><language-model><question-answering>","<p>I'm new on AI, Neural Networks, ChatBots and all this ecosystem. I'm trying to use a classical example of pre-trained models, more specifically <code>timpal0l/mdeberta-v3-base-squad2</code>.</p>
<p>As I could see in the examples, it is necessary to provide a small text (context) and a question, which the model will respond to by extracting information from the context and using training on the structure of the language. This is my working code so far:</p>
<pre><code>from transformers import AutoTokenizer, AutoModelForQuestionAnswering, AutoConfig, DefaultDataCollator
import torch

tokenizer = AutoTokenizer.from_pretrained(&quot;timpal0l/mdeberta-v3-base-squad2&quot;)
model = AutoModelForQuestionAnswering.from_pretrained(&quot;timpal0l/mdeberta-v3-base-squad2&quot;, return_dict=False )

# From portuguese: My cat is called Helena. She is fat and has spots all over her body.
little_text = &quot;minha gata se chama helena. Ela é gorda e tem manchas pelo corpo.&quot;

# From portuguese: who is helena?
question = &quot;quem é helena?&quot;

inputs = tokenizer.encode_plus(question, little_text, add_special_tokens=False, return_tensors=&quot;pt&quot;)

input_ids = inputs[&quot;input_ids&quot;].tolist()[0]

text_tokens = tokenizer.convert_ids_to_tokens(input_ids)
answer_start_scores, answer_end_scores = model(**inputs)

answer_start = torch.argmax(
    answer_start_scores
)  
answer_end = torch.argmax(answer_end_scores) + 1

answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))

print(f&quot;Question: {question}&quot;)
print(f&quot;Answer: {answer}\n&quot;)

------------------------------------------------
Question: quem é helena?
Answer: minha gata # From portuguese: My cat 
</code></pre>
<p>Everything went well. The model is able to perfectly answer questions about the small text provided as context.</p>
<p>What I couldn't understand is: when I provide a much larger text to serve as context (from a file, for example) the time for the response increases considerably. So every time I go to ask a question about the given text I have to wait a long time to get the answer.</p>
<p>So my question is: Am I doing this correctly? My intention is to create a chatbot to help answer questions about a specific system (a kind of help bot), so I simply copied all the text from the online help and pasted it into a single file but I believe that this method only works for small texts because at every question I must <code>tokenizer.encode_plus(question, little_text ... </code></p>
<p>How big the context can be?</p>
","natural-language-processing"
"40725","Let's Verify Step by Step: Old wine in new bottles?","2023-06-06 14:28:03","","3","255","<reinforcement-learning><natural-language-processing><reference-request><training><rewards>","<p>In their paper <a href=""https://arxiv.org/abs/2305.20050"" rel=""nofollow noreferrer"">&quot;Let's Verify Step by Step&quot;</a> OpenAI proudly presents a new way of reward learning which shall foster LLMs' capabilities of mathematical and logical reasoning:</p>
<blockquote>
<p>We've trained a model to achieve a new state-of-the-art in
mathematical problem solving by rewarding each correct step of
reasoning (“process supervision”) instead of simply rewarding the
correct final answer (“outcome supervision”).</p>
</blockquote>
<p>But not to reward just the correct answer but each single correct step seems a general principle of modern didactics, so it sounds like old wine in new bottles, and it should not come as a surprise that it yields better results.</p>
<p>My question is: Is this really new state-of-the-art in machine learning and is there really no <a href=""https://en.wikipedia.org/wiki/Prior_art"" rel=""nofollow noreferrer"">prior art</a>? In case there <strong>is</strong>, references are welcome.</p>
<p>To think one step further (not part of the question): Modern teachers might not only tell the student which steps were wrong and right, but also <strong>explain</strong> why. Shouldn't LLMs be able to understand such explanations (possibly in natural language) to improve their learning?</p>
","natural-language-processing"
"40655","If I freeze pre-trained model weights and than train a classifier on top of its embeddings does that called fine-tunning?","2023-05-30 16:52:29","","1","241","<neural-networks><machine-learning><deep-learning><natural-language-processing><computer-vision>","<p>In the context of machine learning.  If I freeze pre-trained model weights (for example, BERT) and then train a classifier on top of its embeddings, does that called fine-tuning?</p>
","natural-language-processing"
"40597","How do I choose a good treshold for classification (using cosine similarity scores)?","2023-05-26 10:44:43","","0","1409","<natural-language-processing><classification><embeddings><cosine-similarity>","<p>I am using openai's <code>text-embedding-ada-002</code> embeddings model to do a semantic search on a database of articles to find articles that are most related to a given input text. I am looking for a way to define a minimum similarity score to prevent returning articles that aren't actually related enough.</p>
<p>There is two difficulties that I have:</p>
<ol>
<li>For some search queries a certain similarity score seems appropriate as a minimum treshold value, but then for others that minimum value seems to be too strict. For instance I find that for very well defined specific topics you generally want a higher treshold similarity score than for more broad or generic texts. That's my intuition so far at least.</li>
<li>The scores of the openai embedding model almost always fall between 0.77 and 1 instead of using the entire range of -1 to 1 and in reality the scores in normal cases all fall around 0.88. Having all scores so close to eachother makes it harder to pinpoint a good treshold value.</li>
</ol>
<p>Are any known methods for determining a good treshold value for cosine similarity scores?</p>
","natural-language-processing"
"40590","What is MLM & NSP loss function","2023-05-26 05:01:58","","1","876","<natural-language-processing><transformer><objective-functions><bert>","<p>Two objective functions are used during the BERT language
model pretraining step.</p>
<p>The first one is masked language
model (MLM) that randomly masks
15% of the
input tokens and the objective is to predict the vocabulary</p>
<p>The second objective
is the next sentence prediction (NSP) task. This is a binary
classification task for predicting whether two sentences are
subsequent in the original text.</p>
<p>I am looking for such objective function as mathematical definition.</p>
","natural-language-processing"
"40564","Why does ChatGPT fail in playing ""20 questions""?","2023-05-24 13:32:59","","24","11843","<natural-language-processing><chatgpt><benchmarks>","<p><a href=""https://en.wikipedia.org/wiki/IBM_Watson"" rel=""noreferrer"">IBM Watson</a>'s success in playing <a href=""https://en.wikipedia.org/wiki/IBM_Watson#Jeopardy!"" rel=""noreferrer"">&quot;Jeopardy!&quot;</a> was a landmark in the history of artificial intelligence. In the seemingly simpler game of <a href=""https://en.wikipedia.org/wiki/Twenty_questions"" rel=""noreferrer"">&quot;Twenty questions&quot;</a> where player B has to guess a word that player A thinks of by asking questions to be answered by &quot;Yes/No/Hm&quot; ChatGPT fails epically - at least in my personal opinion. I thought first of Chartres cathedral and it took ChatGPT 41 questions to get it (with some additional help), and then of Kant's Critique of Pure Reason where after question #30 I had to explicitly tell ChatGPT that it's a book. Then it took ten further questions. (Chat protocols can be provided. It may be seen that ChatGPT follows no or bad question policies or heuristics humans intuitively would use.)</p>
<p>My questions are:</p>
<ol>
<li><p>Is there an intuitive understanding why ChatGPT plays &quot;20 questions&quot; so bad?</p>
</li>
<li><p>And why do even average humans play it so much better?</p>
</li>
<li><p>Might it be a future <a href=""https://openreview.net/pdf?id=yzkSU5zdwD#:%7E"" rel=""noreferrer"">emergent ability</a> which may possibly arise in ever larger LLMs?</p>
</li>
</ol>
<p>I found two interesting papers on the topic</p>
<ol>
<li><p><a href=""https://evanthebouncy.medium.com/llm-self-play-on-20-questions-dee7a8c63377"" rel=""noreferrer"">LLM self-play on 20 Questions</a></p>
</li>
<li><p><a href=""https://arxiv.org/ftp/arxiv/papers/2301/2301.01743.pdf"" rel=""noreferrer"">Chatbots As Problem Solvers: Playing Twenty Questions With Role Reversals</a></p>
</li>
</ol>
<p>The first one answers some of my questions partially, e.g. that &quot;gpt-3.5-turbo has a score of 68/1823 playing 20 questions with itself&quot; which sounds pretty low.</p>
","natural-language-processing"
"40447","Does ChatGPT use different transformers for different downstream tasks?","2023-05-14 10:16:25","","3","1142","<natural-language-processing><transformer><chatgpt><multi-task-learning>","<p>What I find hard to figure out is whether ChatGPT guesses from the prompt the downstream NLP task to be performed - text summary, text generation, question-answering, doing logic or arithmetic, translation,  sentiment or style analysis - and then uses specialized decoders/transformers. Or if there is only one transformer which handles all downstream tasks. How then can it be understood that ChatGPT performs so well in so many tasks - <strong>as if</strong> it used specialized transformers.</p>
<p>If it guesses the task: How is it done (in high-level terms) and how does it switch?</p>
<p>The answer may be so clear (for the experts) that it is never mentioned explicitly, but for the non-expert it is hard to tell (and to believe).</p>
<p>(Maybe it's easier to answer the question if there is a specific and specifically trained transformer for each supported language.)</p>
<p>BTW: Why is the task &quot;to follow instructions&quot; (which InstructGPT is said to be specialized for) a task on its own? Isn't every prompt an instruction in a sense, instructing ChatGPT to perform some downstream task?</p>
","natural-language-processing"
"40400","How Does The Scaled Dot Product's Dimensions Work Out In Mult-Head Attention?","2023-05-11 02:20:54","","0","242","<neural-networks><natural-language-processing><attention><linear-algebra>","<p>I don't understand how self-attention works with batched values for the <span class=""math-container"">$Q \times K^T $</span> step. According to the diagram below (assume 1 head), once we get past the first 3 linear steps, we arrive at the equation. <span class=""math-container"">$$softmax(\frac{Q \, K^T}{\sqrt{d_k}})V$$</span>
Assuming Q and K have dimensions <span class=""math-container"">$[\text{batch}, \text{sequence}, \text{key_dim}]$</span>, if the tensor contraction goes like <span class=""math-container"">$$Q \, K^T = [\text{batch}_q, \text{sequence}_q, \text{query_dim}_q] \times [\text{batch}_k, \text{key_dim}_k, \text{sequence}_k] = [\text{batch}_q, \text{batch}_k, \text{query_dim}_q, \text{key_dim}_k]$$</span>
there is an extra batch dimension in the result.</p>
<p>I can avoid this extra batch dimension by doing a for-loop over the batch dimension and compute the formula 1-to-1 for each query and key. But one of the benefits of self-attention is that it's parallelizable so there must be a way to do this without a for-loop. How do I achieve this?</p>
<p><a href=""https://i.sstatic.net/xBov2.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/xBov2.png"" alt=""enter image description here"" /></a></p>
<p>With Eigen Tensor I have these incorrect duplicate results</p>
<pre><code>Eigen::Tensor&lt;double, 3&gt; query(2, 2, 3);
query.setValues({{
                         {1, 6, 9},
                         {8, 7, 11}},

                 {       {1, 6, 9},
                         {8, 7, 11}}});

Eigen::Tensor&lt;double, 3&gt; key(2, 2, 3);
key.setValues({{
                         {4, 5, 0},
                         {10, 15, 7}},

                 {       {4, 5, 0},
                         {10, 15, 7}}});

// contract along last dim of query and key
Eigen::array&lt;Eigen::IndexPair&lt;int&gt;, 1&gt; matmul{Eigen::IndexPair&lt;int&gt;(2, 2)};

Eigen::Tensor&lt;double, 4&gt; qk_t = query.contract(key, matmul);

std::cout &lt;&lt; &quot;QxK_T: dimensions&quot; &lt;&lt; qk_t.dimensions() &lt;&lt; &quot;\n&quot; &lt;&lt; qk_t &lt;&lt; &quot;\n&quot;;

QxK_T: [2, 2, 2, 2]
[[[[ 34, 163],
   [ 34, 163]],

  [[ 67, 262],
   [ 67, 262]]],


 [[[ 34, 163],
   [ 34, 163]],

  [[ 67, 262],
   [ 67, 262]]]]
</code></pre>
","natural-language-processing"
"40387","How does a Machine Learning model predict this classification problem?","2023-05-10 08:51:24","40397","0","75","<machine-learning><natural-language-processing><classification><text-classification><feature-extraction>","<p>Let’s imagine we want to create a simple Sentiment Analysis model using Machine Learning not Deep Learning algorithms, so we need to have a set of handcrafted features for this classification problem.</p>
<p>Let's say we have 2 features (F1, F2) for each sentence and a target class consisting of 0 and 1 as positive and negative. So we have a bunch of sentences in a dataset like this:</p>
<p><a href=""https://i.sstatic.net/cZtRX.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/cZtRX.png"" alt=""enter image description here"" /></a></p>
<p>Well, classification algorithms like SVM, LR, DT, and …. can be trained from the training set and learn the sentiment of each sentence from their features. They can also test themselves using the test set. Now the model is ready to predict the sentiment of any sentence out of the dataset. Till now, there is no problem and everything is clear to me.</p>
<p>My problem is when we want to give a new sentence to the model form outside the dataset. Obviously, when we give a sentence to the model, we don’t give any feature to the model. So here is my question, how the model can predict the sentiment of the new sentence when it doesn’t know how to calculate each of the features?</p>
<p>Should we define what is F1, and F2 in the model first? Should we define a function and for any new input sentence, call the function to calculate the proper value for each feature and then teach the model that the function outputs are equal to F1 and F2 in the dataset?</p>
<p><strong>To make a long question shorter</strong>, let me give a clear instance. My new sentence is &quot;She was overjoyed when saw my cat&quot;. I want to give this sentence to the model and obviously expect to see a predicted positive sentiment. This sentence is not in my dataset so there is no feature for it and the model has no idea about F1 and F2. On the other hand, my model learned to determine the sentiment of each sentence using F1 and F2. So back to my question, when I don't give new sentence features (F1, F2) to my model and don't specify any procedure to calculate the features for new inputs, how the model can predict the sentiment of my new sentences?</p>
<hr />
<p>Updated:</p>
<p>As an example of a classification problem, I mentioned the article
&quot; A Pattern-Based Approach for Sarcasm Detection on Twitter,&quot; Click <a href=""https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7549041%22"" rel=""nofollow noreferrer"">here</a>! where the authors proposed four sets of features that cover the different types of sarcasm.
They used those to classify tweets as sarcastic and non-sarcastic.
These features are sentiment-related features, Punctuation-related features, Syntactic and semantic
features, and Pattern features. For instance, in sentiment-related features, they checked whether there
is a contrast between the different components. By contrast,
they mean the coexistence of a negative component and a
positive one within the same tweet. Once the features are extracted, they ran the classification using classifiers like
(SVM).
So till now, everything is clear, with those features they trained their model and then test it with the test set.
The question is when they wanna check the classification for a new sentence, say x for instance, obviously, we should
calculate all four sets of features for the new input x.
Assume that G(x) is a function that gets a new sentence x and returns four sets of features for it (F1,F2,F3, F4), where (F1 = Sentiment-relatedfeatures, F2 = Punctuation-related features, F3 = Syntactic and semantic features, F4 = Pattern features)
How should I show the model to use these features (F1,...,F4) to predict the class for this new sentence (x)?</p>
<p>We have such a code: Ypred = model.predict(x, F1,F2,F3,F4); how the model should know to use F1,...F4 features in the
same way as its train or test phase?</p>
","natural-language-processing"
"40385","What is a neuron in large language models?","2023-05-10 05:20:28","40386","-1","137","<natural-language-processing><transformer><chatgpt><gpt><artificial-neuron>","<p>I'm reading OpenAI's new paper &quot;<a href=""https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html"" rel=""nofollow noreferrer"">Language models can explain neurons in language models</a>&quot; And I can't fully understand the concept of neurons here.</p>
<p>Can you please explain it? Is it related to the attention mechanism?</p>
","natural-language-processing"
"40379","Is the problem of Language Modelling a Well-Posed Learning Problem?","2023-05-09 15:45:52","","2","100","<natural-language-processing><math><sequence-modeling><language-model>","<p>Hadamard defines (<a href=""https://en.wikipedia.org/wiki/Well-posed_problem"" rel=""nofollow noreferrer"">Well-posed problem (Wikipedia)</a>) a well-posed problem as one for which:</p>
<ol>
<li>a solution exists,</li>
<li>the solution is unique,</li>
<li>the solution depends continuously on the data (e.g. it is stable)</li>
</ol>
<p>Now for an autoregressive language model, the pretaining objective consists of predicting the next token given all previous tokens. But as I see it, while the objective helps the model pick nuances of the language and learn &quot;language representation&quot;, there is no &quot;correct&quot; answer.
Given the example, say, &quot;I would love to have some ____&quot;, &quot;chocolate&quot; is just as &quot;correct&quot; as &quot;coffee&quot;.
Thus, the solution is not &quot;unique&quot; as required by the definition.
But again, we could think of the problem as taking as input all the previous tokens and returning a probability distribution over the whole vocabulary. In this way of looking at the problem, the solution, i.e., the probability distribution, is unique.
So, is the problem of language modelling well-posed?
Is either of the two approaches the right reason? If not, what is the correct reason?</p>
","natural-language-processing"
"40373","How are the transformer encoder outputs handled?","2023-05-09 07:05:01","","0","131","<neural-networks><natural-language-processing><transformer>","<p>According to the Attention Is All You Need paper, the transformer's encoder portion is described as</p>
<blockquote>
<p>The encoder is composed of a stack of N = 6 identical layers. Each layer has two
sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network.</p>
</blockquote>
<p>How are the outputs of the N<sub>x</sub>=6 identical layers put together? Is it via concatenation, summation, element-wise product, or are the 6 blocks placed in sequential order, etc? Is the same also done for the decoder?</p>
<p><a href=""https://i.sstatic.net/wKCNA.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wKCNA.png"" alt=""Transformer architecture"" /></a></p>
","natural-language-processing"
"40330","How is ChatGPT able to perform part-of-speech tagging?","2023-05-06 20:04:46","","3","418","<natural-language-processing><chatgpt>","<p>ChatGPT seems to be able of part-of-speech tagging:</p>
<p><a href=""https://i.sstatic.net/bCCuv.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bCCuv.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.sstatic.net/buv59.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/buv59.png"" alt=""enter image description here"" /></a></p>
<p>How can its – possibly <a href=""https://www.jasonwei.net/blog/emergence"" rel=""nofollow noreferrer"">emergent</a> – ability to perform part-of-speech tagging be understood?</p>
","natural-language-processing"
"40282","Can you automatically write a text summarizing a finance document using AI models?","2023-05-03 08:38:46","","1","105","<natural-language-processing><text-generation><text-summarization>","<p>I'm given pdf documents containing complex information about a financial product and my task is to write a disclaimer: a two page document with a very precise structure explaining this financial product, the risks associated to it etc, infos that are present in the pdf but hard to understand for common people.
Do you know if it would be possible for an AI to read this complex document and write the disclaimer ?
More precisely, could it be able to extract information from documents whose content and layout change and write a comprehensive summary in a defined setting?</p>
","natural-language-processing"
"40273","What information does the word embedding in Transformers will encode about the word when analysed outside of the model?","2023-05-02 10:15:48","","1","171","<natural-language-processing><transformer><word-embedding>","<p>Word2vec and similar architectures create word embedding vectors as a byproduct from a supervised learning task, where they need to predict the correct context word. Consequently, the inner representation of words inside this network will preserve some form of proximity-based word similarity based on the used corpus. When extracted, we can observe this via measuring cosine similarity between words, which will result in values close to 1 for words often occurring in each other's proximity and close to -1 for words that are highly infrequent together.</p>
<p>Thus, I would consider the word2vec embedding vectors to be quite interpretable regarding their meaning. What about transformers?</p>
<p>Transformers produce a similar inner representation of words, but than they alter them and recombine them through the attention mechanism multiple times, in order to solve the seq2seq learning task. What will the initial embedding before the first encoding really mean, if anything? Do they have any value when separated from the transformer? Like for example, the vectors generated in a word2vec model can be extracted and used in a downstream task. Is it reasonable to use the embedding vectors from a transformer for any downstream task?</p>
","natural-language-processing"
"40252","Why are biases (typically) not used in attention mechanism?","2023-04-30 15:37:19","40256","7","3147","<neural-networks><deep-learning><natural-language-processing><transformer><attention>","<p>Watching <a href=""https://youtu.be/kCc8FmEb1nY?t=4767"" rel=""nofollow noreferrer"">this video</a> implementing attention in a transformer. He set query, key, and value biases to <code>False</code> and said &quot;Typically, people don't use biases for these&quot;.</p>
<p>Even in <a href=""https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention"" rel=""nofollow noreferrer"">official PyTorch code</a> the default bias is <code>False</code>:</p>
<blockquote>
<p>add_bias_kv: If specified, adds bias to the key and value sequences at dim=0. Default: <code>False</code>.</p>
</blockquote>
<p>What is the reason behind that?</p>
","natural-language-processing"
"40244","In the attention mechanism, why don't we normalize after multiplying values?","2023-04-29 17:54:30","","0","692","<neural-networks><natural-language-processing><transformer><attention><normalisation>","<p>As this <a href=""https://ai.stackexchange.com/q/21237/23811"">question</a> says:</p>
<blockquote>
<p>In scaled dot product attention, we scale our outputs by dividing the
dot product by the square root of the dimensionality of the matrix:</p>
<p><a href=""https://i.sstatic.net/wLI4m.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wLI4m.png"" alt=""enter image description here"" /></a></p>
<p>The reason why is stated that this constrains the distribution of the weights of the output to have a standard deviation of 1.</p>
</blockquote>
<p>My question is why don't we do the same after multiplying to <span class=""math-container"">$V$</span>(values) for the same reason?</p>
","natural-language-processing"
"40236","AI to understand what problem my computer has, for instance by looking at the logs which are too big for me","2023-04-29 09:40:55","","2","87","<natural-language-processing><data-preprocessing>","<h3>Short version</h3>
<p>I have a computer which doesn't work properly but I can't figure out what's wrong. I've tried to install other operating systems, run some system tests and look at the system logs, but couldn't figure out what's wrong.</p>
<p>The log files I have are tens of thousand of lines long and around the megabyte, as an order of magnitude. That's way too big for me to carefully look at everything and understand which warnings/errors are the important ones and which ones are unrelated.</p>
<p>Is there any AI tool which I could use to look at my logs and tell me which lines are the most suspicious and should be investigated further?</p>
<p>I believe LLMs like ChatGPT might be able to do this, but I don't see how I could use them to process 1MB of data.</p>
<hr />
<h3>Long version with specific details</h3>
<p>The computer I mentioned is an Android phone. It's stuck displaying the boot animation; sometimes it displays the real screen for a few seconds, but then it goes back to the boot animation; all this, without ever rebooting. I factory-resetted it and installed other ROMs, but the problem persists: sometimes it shows the welcome screen, which seems to work too, but it doesn't last long.</p>
<p>I can connect to that phone via ADB and managed to look at the logs. I saved the output of <code>dmesg</code> (5809 lines, 539KB) and <code>logcat</code> (24964 lines, 2.9MB), but they're too big for me to look manually, and they contain way too many errors, most of which are unrelated to the real problem.</p>
<p>I tried to write some scripts to help me process those files (e.g. collapse the duplicate lines, group the lines according to some regexes etc), but that's still not enough.</p>
<p>I ran out of ideas and the only remaining solution I can think of is to use some AI to go through those logs and spot the lines which are the most worrying. I'm unsure whether any AI exists which could help me with this though.</p>
","natural-language-processing"
"40232","Process 2TB worth of conversational data hoarded over 40 years. How can I pass this into GPT to ask questions about it?","2023-04-28 19:25:40","","3","635","<natural-language-processing><data-preprocessing><chatgpt><gpt>","<p>I'm still very new to this stuff. I have close to 2TB worth of data hoarded from IRC chats to everyday chats with friends and family.</p>
<p>But is there a way to pass in this much data into GPT to ask questions about it? Or would I require something else?</p>
<p><strong>For example:</strong></p>
<p>&quot;When did Bob tell Jane about the legos he had in school when they were at home?&quot;</p>
","natural-language-processing"
"40205","How to optimize transformer inference for prompts shorter than the maximum sequence length?","2023-04-26 10:58:49","","1","453","<natural-language-processing><transformer><inference><production-systems>","<p>As far as I understand, a Transformer has a specific input sequence length that depends on its architecture. So a model like <code>gpt-4</code> has a sequence length of 8192 tokens. As such, I am interested what happens when the input prompt is shorter than that. <a href=""https://ai.stackexchange.com/questions/22957/how-can-transformers-handle-arbitrary-length-input"">This question and answers</a> suggest that the input is simply padded out to the full input sequence length. But that doesn't really seem plausible to me. That would mean that the cost of processing a 100 token prompt would be the same as the cost of processing a 1000 token prompt. And it clearly isn't, as they charge a different price for them - they charge for token count, not API request count.</p>
<p>I am interested to know how variable length input sequences are handled for experimenting with trying to implement my own language model. I have two possible hypothesis. One could be that they actually combine multiple prompts into a single large prompt and tell the model to complete them all. But I don't think that it is the case as the risk of mixing the prompts from different users and the data they have would probably drastically degrade the quality of the output. I also thought that maybe they have different model sizes - like <code>gpt4-1k</code>, <code>gpt4-2k</code>, <code>gpt4-3k</code>, ... - but that seems like a large overhead, as each of these would need to be trained separately.</p>
","natural-language-processing"
"40167","How does GPT-based language model like ChatGPT determine the n-th letter of a word?","2023-04-23 02:30:19","","6","642","<natural-language-processing><chatgpt><gpt><natural-language-understanding><language-model>","<p>I understand that GPT models process input text by converting words into tokens and then embedding vectors and do not process them letter by letter. Given this approach, I am curious to know how a model like ChatGPT can identify the first (or n-th) letter of a given word. Can anyone explain the underlying mechanism or provide any insights on this capability?</p>
<p><a href=""https://i.sstatic.net/qZNNx.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/qZNNx.png"" alt=""enter image description here"" /></a>
<a href=""https://i.sstatic.net/2hGyg.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/2hGyg.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"40140","How is the next token predicted in transformers?","2023-04-21 00:48:04","","5","3512","<natural-language-processing><transformer><gpt><language-model>","<p>In the transformer (or GPT/decoder only), at the end of the decoder blocks but before the final linear layer you have X vectors (for the X tokens at the input of the decoder). We then want to compute the probabilities for the next token of the sequence - what do we then feed to the linear layer? Is it the last embedding corresponding to the hidden state of the last token in the input sequence?</p>
<p>I've seen some tutorials on youtube on how to make mini gpts but I never quite understood why they feed the entire X vectors/hidden states at the end of the decoder blocks to the linear layer and not just the last vector/hidden state... Wouldn't you have X probability distributions when in reality you only want one? And if we do want the X probability distributions then wouldn't we be completely missing the point of the masked self attention since we would be trying to predict words that are already in the input sequence, so essentially &quot;cheating&quot;?</p>
","natural-language-processing"
"40134","Do different ngrams share embedding in Fasttext?","2023-04-20 16:34:36","40299","0","34","<neural-networks><natural-language-processing><word-embedding><text-classification><pretrained-models>","<p>As per Section 3.2 in the <a href=""https://arxiv.org/pdf/1607.04606.pdf"" rel=""nofollow noreferrer"">original paper on Fasttext</a>, the authors state:</p>
<blockquote>
<p>In order to bound the memory requirements of our model, we use a
hashing function that maps n-grams to integers in 1 to K</p>
</blockquote>
<p>Does this mean the model computes only K embeddings regardless of the number of distinct ngrams extracted from the training corpus, and if 2 different ngrams collide when hashed, they share the same embedding?</p>
<p>Thanks.</p>
","natural-language-processing"
"40013","Why doesn't ChatGPT ask questions?","2023-04-12 08:17:38","","1","854","<natural-language-processing><chatgpt><natural-language-generation>","<p>As far as I understand ChatGPT has been trained on a vast array of data, and it <em>does understand</em> questions; but it seems to never ask. Even if a person would ask clarifying questions (that I assume are in the train set) ChatGPT doesn't, opting instead to invent context or just say &quot;X depends on Y, Z&quot;...</p>
<p>Not asking questions seems trained into the network, but I am not sure how one would go about training a model not to generate questions in such a way that not even in DAN mode it doesn't. I understand that for toxic language GPT-3 uses human raters to generate a train set and then optimizes for non toxic behavior, but it seems to specific to be used for the general concept of questions.</p>
","natural-language-processing"
"39999","What is the difference between T5 and T0 models?","2023-04-11 21:48:09","40007","1","469","<deep-learning><natural-language-processing><gpt><language-model>","<p>What is the difference between T5 and T0 models? I had read that T0 is T5 + LM. But as I know T5 uses encoder-decoder model like BART but BART can be used as LM so that's mean that T5 has a LM function too. So what is the difference between T5 and T0 then?</p>
","natural-language-processing"
"39929","Summarizing articles with ChatGPT","2023-04-06 03:32:04","","1","293","<natural-language-processing><open-ai><chatgpt>","<p>You cannot upload files such as articles on ChatGPT. As an alternative I provided links to ChatGPT of the corresponding webpages but it is clear from its summaries that it is not able to open the link and is not actually summarizing that article. Similarly, telling it the title of the article and author doesn't work because it does not access the article. For example, if you give it the prompt &quot;Write the 4th paragraph of this article: <a href=""https://www.msn.com/en-ca/news/canada/this-ontario-teacher-wants-schools-to-be-more-open-to-muslim-student-needs-starting-with-prayer/ar-AA19wzbe?ocid=hpmsn&amp;cvid=b735bc2290e14ee385647759d7de753f&amp;ei=11"" rel=""nofollow noreferrer"">https://www.msn.com/en-ca/news/canada/this-ontario-teacher-wants-schools-to-be-more-open-to-muslim-student-needs-starting-with-prayer/ar-AA19wzbe?ocid=hpmsn&amp;cvid=b735bc2290e14ee385647759d7de753f&amp;ei=11</a> &quot; it will not write the correct paragraph so I am not sure how it summarizes the article. On the other hand, you need to pay to access some articles so I find it unclear how it summarizes those articles. Also, the articles can be long so if you paste sections in separate chunks ChatGPT will summarize each section, which is not ideal because it should summarize the whole article at the same time.</p>
<p>How do you summarize articles with ChatGPT?</p>
","natural-language-processing"
"39919","Machine Translation Transformers: Why Mask in Decoder?","2023-04-05 03:20:18","","3","428","<deep-learning><natural-language-processing><transformer><attention><machine-translation>","<p>I am trying to understand the purpose of masking in the decoder in the <a href=""https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""nofollow noreferrer"">&quot;Attention is All you Need&quot;</a> paper. Why wouldn't we want to rely on bidirectional context when translating? What goes wrong if masking isn't used in the decoder? Are there successful models in which the decoder doesn't use masking? Thank you!</p>
","natural-language-processing"
"39902","How can the Transformer model tell from positional encoding data to the origional data?","2023-04-04 02:11:11","","1","48","<natural-language-processing><transformer><positional-encoding>","<p>I am having trouble understanding positional encoding. Say after the wor2vec or some encoding algo we get the tensor <span class=""math-container"">$[0.7, 0.4, 0.2]$</span> for the second position. Now the final input into the model would add a positional encoding, making it <span class=""math-container"">$[0.7 + \sin(1.0), 0.4 + \cos(1.0), 0.2 + \sin(1.0)]$</span> right? Here's the question:</p>
<p>How can the model know if it's word tensor <span class=""math-container"">$[0.7, 0.4, 0.2]$</span> with positional encoding <span class=""math-container"">$[\sin(1.0), \cos(1.0), \sin(1.0)]$</span>, or if it is word tensor <span class=""math-container"">$[0.7 + \sin(1.0) - \sin(0.0), 0.4 + \cos(1.0) - \cos(0.0), 0.2 + \sin(1.0) - \sin(0.0)]$</span> with positional encoding <span class=""math-container"">$[\sin(0.0), \cos(0.0), \sin(0.0)]$</span>? They both have the same numbers.</p>
","natural-language-processing"
"39828","Can I reduce computation by only predicting response tokens in a transformer and still get the same gradients?","2023-03-29 04:27:11","","1","45","<natural-language-processing><python><transformer><chatgpt><language-model>","<p>I have been looking at the source code of the Stanford Alpaca model and I believe that during inference, the whole instruction + response data is fed into the model normally. Then the instruction part of the label is masked with IGNORE_INDEX to prevent gradient calculation on the instruction.</p>
<p>But I believe that in the transformer network, after the attention blocks and before the last head layer, it should be possible to take only the (embedded) tokens corresponding to the response parts from contexts and avoid predicting from the tokens corresponding to the instruction part altogether. This could potentially save computation, especially when the instruction part is long or when training on back-and-forth conversations, similar to interactions with ChatGPT. So my question is:</p>
<hr />
<ol>
<li>Is the gradients calculated by these two approaches the same?</li>
</ol>
<p>I actually tried to ask GPT-4 about this. Initially, he suggested that my approach would lose some information, but later changed his opinion when I asked him further. Would my approach indeed result in a loss of information or any other drawbacks?</p>
<hr />
<ol start=""2"">
<li>Is the saving, if possible, worth the effort of modifying the model's source code?</li>
</ol>
<p>Since the change would only affect one matrix multiplication, which is already efficiently computed, I'm unsure if it's worth the trouble. Furthermore, I only know a little bitPyTorch and would definitely struggle with implementing modifications to complicated models written in other frameworks like TensorFlow or JAX.</p>
<hr />
","natural-language-processing"
"39824","How does a LLM (transformer) pick words from its vocabulary?","2023-03-28 18:23:53","","2","2022","<neural-networks><natural-language-processing><transformer><natural-language-generation><large-language-models>","<p>I have a very rough understanding of the &quot;attention/self attention&quot; mechanism of transformer models and how this can be used to process a set of word vectors provided as an input/prompt to the encoder of a network and how this will produce &quot;attention weights&quot; for the word vectors based on positional encodings and some other learnable parameters (key/query/value transforms). And then these can be &quot;fed&quot; to the decoder part of the network which will also consider word vectors that have been produced by the decoder so far and influence word selection by paying special attention to particular word combinations.</p>
<p>However LLMs clearly produce words in their output/response that do not occur anywhere inside the &quot;prompt&quot; text. So they must be using these &quot;attention weights&quot; to consider words from a wider vocabulary, which could be quite large.</p>
<p>Is it the case that the decoder &quot;considers&quot; each possible word in it's entire vocabulary when producing an output word? For example I'm imagining an input layer to a NN with several thousand nodes (one per word vector in dictionary) on the input then these are &quot;combined&quot; through some operation with attention weights (from the encoder and decoder &quot;attention section&quot;) producing values for most word vectors that are very low (so below the threshold for some activation function) but each word is still &quot;considered&quot; to an extent? Or are only a subset of words considered in some way?</p>
","natural-language-processing"
"39712","Creating or using a corpus for a chatbot interaction modelling for an existing intelligent tutor system","2023-03-21 18:47:30","","0","40","<natural-language-processing><chat-bots><dialogue-systems><human-computer-interaction><intelligent-personal-assistants>","<p>I'm currently researching and building a chatbot to link to an existing intelligent tutoring system for the domain of the topic of relational databases. The current intelligent tutoring system is rudimentary (forms with checkboxes and the sort, a quiz type) and anything could serve the purpose of modeling the dialogue that would be better than just reading a textbook or having a passive attitude in the classroom. The main problem is that I don't have any corpora to utilize, besides the hardcoded questions, and I don't have any time at all to create a better corpus from scratch.</p>
<p>My thesis adviser gave me the starting point for a dialogue model: the chatbot would ask a question and <em>the student</em> would try to answer. Depending on the feedback, the student could ask &quot;how&quot;, &quot;why&quot;, or &quot;explain&quot;.</p>
<p>There is research showing that using theoretical frameworks to guide the learning goals of a chatbot could help students learn more effectively by moving from passive to active learning. <strong>It is really necessary to understand <em>learning objectives</em> before starting to develop.</strong> A theoretical framework can guide the dialogue modeling.</p>
<p>This happens, for instance, with CodingTutor which is an agent to help students learn how to program. It uses <a href=""https://www.celt.iastate.edu/instructional-strategies/effective-teaching-practices/revised-blooms-taxonomy/"" rel=""nofollow noreferrer"">the revised Bloom taxonomy</a> to combine different types of knowledge to help the person learn. This is still complex because there are many types of questions, answers, and other types of interaction like solving a programming exercise. <em><strong>The CodingTutor approach could be an option if I didn't lack time.</strong></em></p>
<p>On the other hand, other ITS with a chatbot module was implemented by using the user's own questions to a previous iteration of the ITS chatbot and Google queries. The learning goal was only memory retention. The students asked &quot;Why&quot;, &quot;Advantages/Disadvantages&quot;, &quot;Application of&quot;, &quot;How&quot; and &quot;Who&quot;. <em><strong>This is a more reasonable approach than CodingTutor</strong></em> but with a caveat: <em><strong>I have no corpus.</strong></em></p>
<p>There are other ITSs, like AutoTutor, that use expectation-and-misconception tutoring (EMT). Still, the complexity is greater and I would have to hardcode every single misconception to a single expectation.</p>
<p><em>My question is if there are some corpora that I could use for the simple learning objective of memory retention using &quot;why&quot;, &quot;how&quot;, and &quot;explain&quot; for the topic of relational databases.</em></p>
<hr />
<p><strong>EDIT</strong>: given that it's thesis research, according to my adviser, the topic of relational databases of the intelligent tutor isn't fundamental, but it has to be useful for instance K-12 Geography. The chatbot is a complementary module to an intelligent tutor, and the intelligent tutor is still bare bones that any corpus - with some learning objectives in mind - would suffice. Also, the end result of that said intelligent tutor far into the future would be to be cross-domain (not open-domain), for instance, to be able to be adapted for different domains in a standalone fashion (different training sets, different corpora, the works).</p>
<p>However, given that there isn't any corpus for that intelligent tutor, ANY corpus would be better. So, a corpus for relational databases Q&amp;A created with ChatGPT would be enough (with all the inherited problems doing so, like bias, incorrect answers, etc.). Now the &quot;how to&quot; is more important than the actual accuracy. In other words, the corpus had to be accurate enough.</p>
","natural-language-processing"
"39689","If we prompt a large language model on a task, will its ability for other tasks be affected? How to recover?","2023-03-20 14:14:24","","1","202","<natural-language-processing><chatgpt><language-model><large-language-models><prompt>","<p>For example, I guess that for some retrieval augmented LLMs, their generated contents may lack some creativity? Recent work has explored the inability of retrieval augmented methods to enhance the reasoning of LLMs. Then imagine a scenario where we prompt ChatGPT in order to have it implement a task related to information extraction, and suppose we continue the session process and we want it to answer a question for us ( here the task transform from <em>Information Extraction</em> to <em>Open-domain QA</em>), then will the LLM remain the same ability to answer a question?</p>
<p>So, a natural consideration is: when prompt has become a paradigm for aligning LLM with human needs, how can we <strong>eliminate the impact of prompt and recover</strong> LLM?</p>
<p>But perhaps a more economical strategy would be to open a new session window and give the LLM a prompt about the open-domain QA.</p>
","natural-language-processing"
"39652","Large Language Models vs Tabular Data","2023-03-18 13:29:09","","0","194","<natural-language-processing><classification><gpt><large-language-models>","<p><strong>Problem:</strong><br />
Let's say we want to predict insurance frauds. Whenever we obtain an insurance claim, we are provided with a free-form description detailing the loss and a substantial amount of data on the claimant, presented in a tabular format.</p>
<p><strong>Questions:</strong><br />
How can we utilize both the written loss description and the extensive structured data we have gathered? Should we build two separate models, one for natural language processing and the other for tabular data? Is it possible for Large Language Models (LLMs) to extract insights from tabular data? If so, how? What limitations or pitfalls should we bear in mind?</p>
","natural-language-processing"
"39584","Is the input embedding split along the embedding dimension so that every head of the multi-head-attention module just gets a part of the input data?","2023-03-14 17:19:50","","1","152","<natural-language-processing><transformer><attention><word-embedding><embeddings>","<p>So I found two contradictory explanations of the MHA (multi-head-self-attention-module):</p>
<p>In <strong>the first approach</strong>, the input embedding (= the input matrix) is split along the embedding dimension and all heads are given a subset of the dimensions/features of each word.
Some websites supporting this theory:
<a href=""https://medium.com/@smitasasindran/12-attention-mechanisms-multihead-attention-958041a35553"" rel=""nofollow noreferrer"">https://medium.com/@smitasasindran/12-attention-mechanisms-multihead-attention-958041a35553</a>
<br>-&gt; Quote: &quot;The input has been split into multiple heads, and we are running the attention model separately on each of these heads.&quot;</p>
<p><a href=""https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec#3fa3"" rel=""nofollow noreferrer"">https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec#3fa3</a> <br>-&gt; Quote: &quot;In multi-head attention we split the embedding vector into N heads, so they will then have the dimensions batch_size * N * seq_len * (d_model / N).&quot;</p>
<br>
<br>
<p><strong>The second approach</strong> assumes that all heads receive the entire input data, but different weight matrices are used for each head depending on the number of heads.
This theory is well explained on <a href=""https://hungsblog.de/en/technology/learnings/visual-explanation-of-multi-head-attention/"" rel=""nofollow noreferrer"">https://hungsblog.de/en/technology/learnings/visual-explanation-of-multi-head-attention/</a>
<br>-&gt; Quote: &quot;Each head is responsible to fully calculate the attention for the whole embedding, not just for a subset of it and creates h attention matrices&quot;</p>
<p>I tend to the second explanation, but have not been able to find a satisfactory and contradiction-free answer so far.</p>
","natural-language-processing"
"39579","SparseGPT code reproduction","2023-03-14 14:13:33","39767","1","97","<natural-language-processing><large-language-models>","<p>SparseGPT: <a href=""https://arxiv.org/pdf/2301.00774.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/2301.00774.pdf</a></p>
<p>Pruning on the super large language model based on the Transformers structure has achieved a high compression rate with a small loss of accuracy. Is there any related code reproduction or research?</p>
<p>Someone mentioned on <a href=""https://github.com/karpathy/nanoGPT"" rel=""nofollow noreferrer"">https://github.com/karpathy/nanoGPT</a>, but no response.</p>
","natural-language-processing"
"39552","How is ChatGPT trained?","2023-03-13 10:03:13","","1","870","<machine-learning><natural-language-processing><training><chatgpt>","<p>According to OpenAI, ChatGPT is trained in a 3-step process.
<a href=""https://i.sstatic.net/RBf8H.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/RBf8H.png"" alt=""ChatGPT_diagram"" /></a>
Are the steps where human AI trainers are involved, i.e. training the initial policy and providing the A&gt;B&gt;C&gt;D grading as training sets for the reward model, the ONLY place where actual knowledge is entered? Are there no other learning steps where human trainers are NOT involved and the model learns from high-quality sources like authoritative texts? The sampled prompts in step 2 are supposed to cover EVERYTHING on the internet, so what happens when the trainers do not know anything about the topic? Did OpenAI invite domain experts to grade specific prompts-answer pairs?</p>
","natural-language-processing"
"39548","Request for assistance with converting legal contracts to environment for DQN","2023-03-13 08:48:15","","0","14","<reinforcement-learning><natural-language-processing><dqn><legal>","<p>I want to convert the Extractive QA task as a Reinforcement Learning Problem Statement. So I want to integrate NLP problem into Reinforcement Learning and see if my results were achieving better when compared to only NLP model and see why it is performing better or why it is performing worse</p>
<p>I have a set of legal contracts and I want to use an extractive QA task to extract relevant information such as payment terms and insurance. I have tokenized the data and have a Hugging Face transformer model for this. My ultimate goal is to use a DQN where the transformer model serves as the base model.</p>
<p>To achieve this, I need to convert the tokenized data into an RL environment and train the combined model on a group of contract environments. However, I am currently facing difficulties in creating the environment for DQN.</p>
<p>I would greatly appreciate it if you could offer any advice or guidance on how I can proceed with this task. I am eager to learn and am open to any suggestions you may have.</p>
<p>Thank you very much for your time and consideration.</p>
","natural-language-processing"
"39367","lyric search algorithm :prompt to real lyric","2023-03-01 00:44:05","","0","43","<machine-learning><deep-learning><natural-language-processing>","<p>I want to make a lyric search tool.</p>
<p>In other words,it is means that give some prompts and get some lyrics which exist in the real world.</p>
<p><strong>For example:</strong></p>
<p><strong>Input:</strong> some lyrics from coldplay ,give me power</p>
<p><strong>Output:</strong></p>
<p>Lights will guide you home</p>
<p>And ignite your bones</p>
<p>And I will try to fix you</p>
<p>I am a NLP newbie.And I want to use BERT to solve this problem but i don't know how to continue to do it.</p>
<p>My idea is bulid a structure as following:</p>
<p><a href=""https://i.sstatic.net/khloD.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/khloD.jpg"" alt=""enter image description here"" /></a></p>
<p>And calculate  cosine similarity between output.</p>
<p>But it dosen't work well.</p>
<p>So I have another idea.</p>
<p>Powerful chatGPT can recommand lyric but it does not work well in other non-English language lyrics.</p>
<p>Now my idea is use chatGPT to generate a lyric, translate the generated lyric into a specified language, and then compare the generated lyric with the lyric datasets to select the most similar one.</p>
<p>But this method is complex and it's hard to guarantee the accuracy of the search.</p>
<p>Is there any better way？Is there another way to do this without chatgpt?
Or are there any similar papers?I only found the papers about ai generate lyric.</p>
","natural-language-processing"
"39363","Coding a conversational AI which remembers previous context","2023-02-28 18:13:50","","1","89","<natural-language-processing><transformer><generative-model><language-model>","<p>I am trying to code a proper conversational AI which remembers previous context and answers accordingly (something like a micro ChatGPT). Additionally I want the AI to work on a custom knowledge base stored in a vector database like pinecone.</p>
<p>Are there any implementation references available ?</p>
","natural-language-processing"
"39207","What are the most effective methods and tools for summarizing long-form content like articles, editorials, and discussion threads for an app?","2023-02-18 12:20:07","","2","45","<machine-learning><natural-language-processing><algorithm-request><text-summarization><natural-language-generation>","<p>With users expecting instantaneous information and no compromise on in-depth details, app developers are challenged to condense long-form content such as articles, editorials, and discussion threads into concise summaries. To ensure that users still gain valuable insights and information, it is important to determine the most effective methods and tools to summarize such content.</p>
<p>Are there any viable algorithms or libraries that are proven to produce summaries without sacrificing the important details? Any insights or suggestions on the best practices to address this problem would be much appreciated.</p>
","natural-language-processing"
"39206","Resources for NLP","2023-02-18 12:12:09","39208","0","76","<deep-learning><natural-language-processing><reference-request>","<p>I am an undergraduate student in mathematics. I have a fair bit of experience with deep learning in computer vision research and am willing to dabble into NLP. I hope that things won't be very disjointed and some of the knowledge can be transferred.</p>
<p>I wanted to know if y'all can recommend some YouTube playlists that start from scratch as far as NLP is concerned, and then gets pretty deep into the subject. I would also like it to have a research-oriented flavor. Thanks in advance.</p>
","natural-language-processing"
"39168","Are ""prompt engineering"" and ""prompt design"" used as synonymous?","2023-02-15 17:24:10","","5","727","<natural-language-processing><terminology><chat-bots><chatgpt>","<p>Are &quot;prompt engineering&quot; and &quot;prompt design&quot; used as synonymous / equivalent terms on the day to day communications (not research papers) in Artificial Intelligence community ? Do you simply say &quot;prompt&quot;?</p>
<hr>
<p>I'm &quot;following&quot; questions about ChatGPT. I think that there are too many questions and online content in general that are not making the most appropriate use of terms like</p>
<ul>
<li>ChatGPT</li>
<li>prompt engineering</li>
<li>prompt design</li>
</ul>
<p>This makes hard to find helpful content.</p>
<h3>ChatGPT</h3>
<p><em>ChatGPT</em> has being used as a common name like calling a code library &quot;chatgpt&quot; on questions about the OpenAI API, mostly of them specifically about the text completions end-point, some related to packages or libraries that use this end-point. Regarding this term, IMHO, it's clear that it's too early to consider that <em>ChatGPT</em> is a common name and people should be encouraged to avoid to use it this way in order to make their post clear about what they are talking about.</p>
<h3>Prompt Engineering</h3>
<p>So far I have read stuff that I was able to find without investing too much time like</p>
<ul>
<li><p>Wikipedia article <a href=""https://en.wikipedia.org/wiki/Prompt_engineering"" rel=""nofollow noreferrer"">prompt engineering</a> that presents <em>prompt engineering</em> as something very broad.</p>
</li>
<li><p><a href=""https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api"" rel=""nofollow noreferrer"">Best practices for prompt engineering with OpenAI API</a> that focus on <strong>writing prompts</strong>.</p>
</li>
</ul>
<p>As an engineer, I like what I understood about what is <em>prompt engineering</em> from the Wikipedia article, not the second as it looks to me that trivializes the term.</p>
<p>Some questions, including here, apparently use <em>prompt engineering</em> to refer to the <em>writing prompts</em>. While might not be wrong to use this term, it looks to me to be way too broad for such specific task.</p>
<p>Related:</p>
<p>The following answers use the term &quot;prompt engineering&quot; but they look to focus on <em>writing prompts</em>:</p>
<ul>
<li><a href=""https://ai.stackexchange.com/a/39020/42632"">Answer</a> to <a href=""https://ai.stackexchange.com/q/38361/42632"">What causes ChatGPT to generate responses that refer to itself as a bot or LM?</a> (from this site)</li>
<li><a href=""https://stackoverflow.com/a/75418423/1595451"">Answer</a> to <a href=""https://stackoverflow.com/q/75349226/1595451"">How to avoid word limit in ChatGPT in R?</a> (from Stack Overflow)</li>
</ul>
<h3>Prompt design</h3>
<p>As well that I have done in relation to <em>prompt engineering</em>, so far I have read stuff  like the OpenAI API documentation, i.e. <a href=""https://platform.openai.com/docs/guides/completion/prompt-design"" rel=""nofollow noreferrer"">Prompt design</a> that focus on <em>writing prompts</em>.</p>
","natural-language-processing"
"39159","Is there a metric to compare BOW vs TFIDF results?","2023-02-15 06:28:57","","1","33","<natural-language-processing><bag-of-words><tf-idf>","<p>I am working on a document search task and have used Bag of Words (BOW) and TFIDF vectorization techniques. My observation after going through some sample searches are -</p>
<ul>
<li>Both of them seem to provide similar results when we look at top X results for a given search term.</li>
<li>However, in some cases BOW might give a slightly better top X results compared to TFIDF and vice versa.</li>
<li>The cases in which TFIDF is slightly better is comparatively more than cases in which BOW is slightly better.</li>
</ul>
<p>I wish to select either of the two and based on above eyeballing I decided to go with TFIDF. But this is not explainable since the decision is based on individual perspective after looking at some sample cases. I would like to know if there is some kind of metric that I can make use of to arrive at a decision? Since eyeballing can lead to biased decision.</p>
","natural-language-processing"
"39134","I want to tokenize a text and also want to consider space and new line as separate tokens: for NLP Task","2023-02-12 19:48:33","","0","25","<natural-language-processing>","<p>I want to tokenize a text and also want to consider space and new line as separate tokens:</p>
<p>if there are multiple spaces, then tokenize them separately, for example, &quot;Hi, I am\n  Teddy&quot; this should tokenize as [&quot;Hi&quot;,&quot; &quot;, &quot;,&quot;,&quot; &quot;,&quot;I&quot;,&quot; &quot;,&quot;am&quot;,&quot;\n&quot;,&quot; &quot;,&quot; &quot;,&quot;Teddy&quot;]</p>
<p><strong>Note: That After new-line (\n) in text there are 2 spaces</strong></p>
","natural-language-processing"
"39078","What background should I have before starting to fine tune a Large Language Model?","2023-02-08 01:26:48","39081","1","162","<natural-language-processing><language-model><fine-tuning>","<p>I want to know what things I should be learning before trying to fine-tune or for that matter working with a large language model.</p>
<p>In my case, I am trying to fine-tune bloom (<a href=""https://huggingface.co/blog/bloom"" rel=""nofollow noreferrer"">https://huggingface.co/blog/bloom</a>).</p>
<p>But considering my inadequate knowledge of this, I want to know what things I should cover first before taking on something so big.</p>
<p>Any suggestions are appreciated.</p>
","natural-language-processing"
"39073","Why does CLIP use a decoder-only transformer for encoding text?","2023-02-07 13:23:44","","4","2251","<natural-language-processing><computer-vision><transformer><vision-transformer>","<p>In CLIP [1], the authors train a model to learn multi-modal (text, vision) embeddings by maximizing the cosine similarity between text and image embeddings produced by text and image encoders.</p>
<p>For the text encoder, the authors choose to use a variant of GPT2 which is a decoder-only transformer, taking the activations of the highest layer of the transformer at the [EOS] token the feature representation of the text (emphasis mine):</p>
<blockquote>
<p>The text encoder is a Transformer (Vaswani et al., 2017) with the architecture modifications described in <strong>Radford et al. (2019)</strong>. As a base size we use a 63M-parameter 12- layer 512-wide model with 8 attention heads. The trans- former operates on a lower-cased byte pair encoding (BPE) representation of the text with a 49,152 vocab size (Sennrich et al., 2015). For computational efficiency, the max sequence length was capped at 76. The text sequence is bracketed with [SOS] and [EOS] tokens and the <strong>activations of the highest layer of the transformer at the [EOS] token are treated as the feature representation of the text</strong> which is layer normalized and then linearly projected into the multi-modal embedding space.</p>
</blockquote>
<p>I found this pretty weird considering that they could have used an encoder (a-la BERT) which to me seem more fitted to act as encoders than decoders. Perhaps they wanted to enable generative text capabilities, but they could've achieved that with an encoder-decoder architecture (a-la T5) too.</p>
<p>I was expecting ablations on the text-encoder architecture, motivating their choices, but found none. Any clue why they made these choices?</p>
<h1>References:</h1>
<p>[1] A. Radford et al., ‘Learning Transferable Visual Models From Natural Language Supervision’, in Proceedings of the 38th International Conference on Machine Learning, Jul. 2021, pp. 8748–8763. Accessed: Feb. 07, 2023. [Online]. Available: <a href=""https://proceedings.mlr.press/v139/radford21a.html"" rel=""nofollow noreferrer"">https://proceedings.mlr.press/v139/radford21a.html</a></p>
","natural-language-processing"
"39053","Is there a way to find a list of associated words to a named entity?","2023-02-05 05:48:03","","0","40","<natural-language-processing><named-entity-recognition>","<p>Is there a way to find a list of associated words to a named entity?</p>
<p>For instance, let the named entity be FIFA. Now FIFA is a Football Organization and hence related to the term football and all the terms related to football like jersey, footballers, goal, goalkeeper, halftime, penalty, freekick et cetera.</p>
<p>Is there a way we could do that? I have tried Babelnet but didn't get the desired results or anything even close to what I want.</p>
","natural-language-processing"
"39050","Computation required for GPT model to choose likely word from n-options where n < total vocabulary size","2023-02-05 00:36:26","","1","48","<natural-language-processing><math><transformer><gpt><gpt-3>","<p>Let’s imagine two different use cases for a LLM/GPT-3.</p>
<ol>
<li>Predicting the next most likely word in a sequence using all ~50k words in its dictionary (i.e. the standard method of prompting a LLM)</li>
<li>Checking whether &quot;Word-1&quot; is more likely than &quot;Word-2&quot; to be next in a sequence</li>
</ol>
<p>How much more computationally efficient is #2?</p>
<p>My understanding is that the computation of the attention mechanism is dependent on the length of the prompt (so will be the same) and takes up most of the computation needed to get the output (but to what extent, I'm not sure). The difference will be in the decoding stage.</p>
<p>Would the one matrix multiplication in the decoding calculation be the only computation using the smaller 2-row matrix instead of the 50k-row matrix or are there other improvements in efficiency?</p>
","natural-language-processing"
"39021","What's computationally more efficient between bag-of-words representation and bag-of-ngrams representation, with special regard to words order?","2023-02-02 15:04:31","39022","1","51","<machine-learning><natural-language-processing><word-embedding>","<p>I cannot figure out what is more computationally efficient between the two representations mentioned in my question in terms of training time and the amount of data required. Especially, when it comes to considering the order of the words in a sentence.</p>
","natural-language-processing"
"38923","Why does ChatGPT not give the answer text all at once?","2023-01-27 15:18:09","","17","8240","<natural-language-processing><language-model><chatgpt>","<p>When ChatGPT is generating an answer to my question, it generates it word by word.<br />
So I actually have to wait until I get the final answer.</p>
<p>Is this just for show?<br />
Or is it really real-time generating the answer word by word not knowing yet what the next word will be?</p>
<p>Why does it not give the complete answer text all at once?</p>
","natural-language-processing"
"38897","sentence alignment between same language texts","2023-01-26 08:09:21","","1","129","<natural-language-processing><machine-translation><text-detection>","<p>Take this two texts as an example:</p>
<blockquote>
<p>&quot;I will start the recording and share the presentation. I hope it's
all clear from what we saw last time on classical cryptography and if
you remember we got to discussing perfect security. Ah, you're right,
I didn't upload the slides. Wait, they are the same as last time. If
you want to get the face on the fly, last time I mean last year. I had
some things to do and didn't upload.&quot;</p>
</blockquote>
<blockquote>
<p>&quot;Okay, I will start recording and I will share the presentation again.
1, 0 So I hope it's all clear compared to what we saw last time about
classic victory, And if you remember we got to let's say discuss the
perfect security. Ah you could see already, I didn't upload the
Slides, Wait they are the same as last time, Eh. If you want to have
done on the fly, I mean last time, I mean from last year. Morning I
had some stuff to do, I didn't upload.&quot;</p>
</blockquote>
<p>We want to align the sentences so that similar sentences (within a certain degree of difference) are being matched together.
Which are the approaches to solve the issue?</p>
<pre><code>[I will start the recording and share the presentation], 
[I will start recording and I will share the presentation]


[I hope it's all clear from what we saw last time on classical cryptography],
[I hope it's all clear compared to what we saw last time about classic victory]

[and if you remember we got to discussing perfect security],
[And if you remember we got to let's say discuss the perfect security]
.
.
.
</code></pre>
<p>I have been looking into DTW and perceptual hashing as a way to solve the problem without any concrete result then I saw that in the field of automatic translation sentence alignment is widely used but with the assumption that the two texts have different languages and that there is a one-to-one mapping between words without &quot;gaps&quot; or extra words in between.</p>
","natural-language-processing"
"38843","Would it be possible to involve a proof assistant in the process of training a LLM?","2023-01-21 23:13:00","38900","2","1048","<natural-language-processing><recurrent-neural-networks><proofs><gpt><automated-theorem-proving>","<p>LLMs like GPT-3 have been shown capable of outputting highly complex code. Sadly, actually using them to replace a programmer's job has two major caveats:</p>
<ol>
<li><p>LLMs are notoriously bad at producing complex algorithms</p>
</li>
<li><p>It isn't possible to check whether the outputted code is correct</p>
</li>
</ol>
<p>As such, while something like ChatGPT will easily translate between different syntaxes, and even produce useful code, that is limited, to an extent, to code it has already seen. Fortunately, the (2) problem already has a solution: a <strong>proof checker</strong>. Certain languages have these built in, including Lean, Coq, Agda, Idris and Kind. As an example, suppose you wrote the following prompt, asking for an algorithm in Agda:</p>
<pre><code>Complete the following Agda function, which negates a boolean:

not : Bool -&gt; Bool
</code></pre>
<p>A LLM could fill it incorrectly, as follows:</p>
<pre><code>not : Bool -&gt; Bool
not true  = true
not false = false
</code></pre>
<p>But the cool thing is, in a proof assistant, you're able to enrich the type arbitrarily, and turn it into a complete specification of the program you desire. As such, you could prevent the issue above as follows:</p>
<pre><code>Complete the following Agda function:

not : (in : Bool) -&gt; Sigma (out : Bool) (in != out)
</code></pre>
<p>This type <strong>demands</strong> that the implementation of <code>not</code> comes accompanied by a proof that the output is, indeed, different from the input. Suppose that we did that, and the Ai still produced an incorrect algorithm:</p>
<pre><code>not : (in : Bool) -&gt; Sigma Bool (λout -&gt; in != out)
not true  = MkSigma true  &lt;proof_here&gt;
not false = MkSigma false &lt;proof_here&gt;
</code></pre>
<p>In that case, it wouldn't be able to fill the <code>&lt;proof_here&gt;</code> with a valid proof that the algorithm is correct, <em>because it isn't</em>. As such, we would be able to easily discard that answer, feed the AI an error message, and ask it to try again. We can repeat this process until it gets it right. Of course, this is a simple example, but you could make arbitrarily complex algorithm demands using the same technique. For example, the prompt below would demand a correct sorting algorithm:</p>
<pre><code>Complete the following Agda function:

sort : (in : List Nat) -&gt; Sigma (List Nat) (λ out -&gt; IsSorted out &amp; IsSame in out)
</code></pre>
<p>Once again, chances are it would produce the wrong solution, but we'd be able to automatically discard it and try again, until it gets it right. This leaves us with only the problem (1): <strong>LLMs are notoriously bad at coding</strong>. That is, even if we're able to discard the wrong output, something like current-version ChatGPT will probably never get anything sufficiently complex correct.</p>
<p>Now, that's not unsurprising: GPT wasn't trained to write proofs. As such, a natural solution would be to do so. But the amount of proofs written is very limited, compared to, say, the size of Wikipedia. We don't have enough data. But the cool thing is: we can actually make the AI itself generate the proofs it is trained on. It would work as follows:</p>
<ol>
<li><p>Train the AI on publicly available proofs (Agda/Coq std-libs, for example)</p>
</li>
<li><p>Generate a random theorem and ask it to prove</p>
</li>
<li><p>If it gets the proof wrong, go back to 2</p>
</li>
<li><p>If it gets the proof right, train it on that proof, and go back to 1</p>
</li>
</ol>
<p>By repeating this loop ad infinitum, we'd have both a growing body of proofs, and an AI that is increasingly more capable of proving complex theorems.</p>
<p><strong>My questions are: is there substance to this approach? If so, has anyone tried it? Citations would be appreciated. If not, is there any clear reason I'm not aware of?</strong></p>
","natural-language-processing"
"38785","Seq2seq with attention model only predicts index 0 in a text generation task","2023-01-17 17:39:56","","0","84","<natural-language-processing><tensorflow><seq2seq>","<p>I am trying to build a model which summarizes some brief input text (X) and generates a headline (Y).</p>
<p>The problem is that the model always outputs 0 as the vocabulary index, which I think that might be due to sentence padding, I have tried to use mask_zero parameter in the embedding layer but results are the same.</p>
<p>I also have considered that the problem might be that I have very little data to train the network but I supposed it would fail in some manner but outputing random words, not always 0.</p>
<p>The network architecture I am trying to use is a seq2seq Bi-LSTM with attention mechanism and I am using Glove 50D embeddings as input layer.</p>
<p>Basically the model is based in three code functions that comprehend the previously explained model.</p>
<p>A good visual representation of the model is the following from Andrew Ng just substituting one hot vector inputs with embeddings in the input layer:</p>
<p><a href=""https://i.sstatic.net/j0TKl.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/j0TKl.png"" alt=""Full model structure"" /></a></p>
<ol>
<li>Model layers definition at global scope to share weights</li>
</ol>
<pre><code># Attention layers globally defined
repeator = tf.keras.layers.RepeatVector(Tx)
concatenator = tf.keras.layers.Concatenate(axis=-1)
dense_1 = tf.keras.layers.Dense(10, activation='tanh')
dense_2 = tf.keras.layers.Dense(1, activation='relu')
activator = tf.keras.layers.Activation('softmax', name=&quot;attention_weights&quot;)
dotor = tf.keras.layers.Dot(axes=1)

# Post-attention LSTM globally defined to share weights
post_attention_LSTM = tf.keras.layers.LSTM(units=n_s, return_state=True)
output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')
</code></pre>
<ol start=""2"">
<li>Full model structure:</li>
</ol>
<pre><code>def seq2seq_clickbait(Tx, Ty, n_a, n_s, vocab_size, emb_size):

    # Define Model Inputs
    sentence_indices = tf.keras.layers.Input(shape=(Tx,), dtype='int32')

    emb_matrix = build_embeddings_matrix(word_to_vec, vocab_size, word_to_idx, emb_size)

    pretrained_embedding = pretrained_embedding_layer(emb_matrix, vocab_size, emb_size)

    embeddings = pretrained_embedding(sentence_indices)

    s0 = tf.keras.layers.Input(shape=(n_s,), name='s0')
    c0 = tf.keras.layers.Input(shape=(n_s,), name='c0')

    s = s0
    c = c0

    outputs = []

    a = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=n_a, return_sequences=True))(embeddings)

    for t in range(Ty):

        # Once we have a, we can get the context to pass it to the post attention lstm time step
        context = one_step_attention(a, s)

        # Get current states from post-attention lstm
        s, _, c = post_attention_LSTM(inputs=context, initial_state=[s, c])

        # Apply dense (softmax vocab_size)
        out = output_layer(inputs=s)
        outputs.append(out)

    model = tf.keras.models.Model(inputs=[sentence_indices, s0, c0], outputs=outputs)

    return model

</code></pre>
<p>A good visual representation of what does one_step_attention(a, s)</p>
<p><a href=""https://i.sstatic.net/KisBY.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/KisBY.png"" alt=""enter image description here"" /></a></p>
<ol start=""3"">
<li>context</li>
</ol>
<pre><code>def one_step_attention(a, s_prev):

    # Repeat the s_prev vector Tx times to expand the vector
    s_prev = repeator(s_prev)

    # Concatenate a and s_prev
    concat = concatenator([a, s_prev])

    # Forward prop to a dense layer
    e = dense_1(concat)

    energies = dense_2(e)

    # Apply softmax to energies to get the alphas
    alphas = activator(energies)

    # Get context from the alphas
    context = dotor([alphas, a])

    return context
</code></pre>
<p>I present the outputs to the model as a one hot vector so if the ouput sentence is length (Ty) 20 the output tensor is (20, m, vocab_size). My guess is that many of the labeled sentences are not length 20 and therefore they are padded, so the network is learning to output 0's since it is a pretty good way of improving accuracy / decrease loss in short senteces widely padded.</p>
<p>If half of the output steps of the network are filled with a [1, 0, 0,..., 0] one hot vector which represents the 0 index (pad) it dense layer will learn to output probabilities distributions like [0.8, 0.002, 0.00003, ....] selecting the 0 index.</p>
<p>Any ideas on how to solve this? Thank you in advance</p>
<h1>EDIT</h1>
<p>Some additional info about the model.</p>
<p>loss function is categorical_crossentropy, I have not added extra tokens to the vocabulary given by GloVe embeddings, I removed 'PAD' as a vocabulary token since TF embeddings docs says so when mask_zero=True. m is the number of examples, Tx and Ty is the sentence max length of X and Y, n_s is the number of post-attention LSTM units and n_a is Bi-LSTM units. I think indeed is a masking problem but mask_zero=True is not solving it. It only works with return_sequences=True and post att LSTM has return_squences=False because it loops through steps.</p>
","natural-language-processing"
"38767","Giving Specified Data a Larger Value/Weight in a Model","2023-01-16 01:12:44","","1","18","<natural-language-processing><classification><weights><text-classification>","<p>I'm in the process of creating a model to classify an occupational code based on a job title &amp; description. I have a large sample of labelled data to achieve this.</p>
<p>The government has a resource with every occupation code's job description and the respective duties of each occupation, I wanted to know if there was a way to give the Government's occupation data a higher weight in the model (since there is only one description for each occupation code), rather than relying on data that was labelled by an individual since it could lead to variations/inconsistencies depending on the individual who was labelling it.</p>
<p>My apologies if using the term &quot;weights&quot; is incorrect to describe what I'm trying to achieve. If so, let me know the correct terminology.</p>
<p>Just to clarify, I'm not talking about giving certain classes/labels a higher weight to correct a class imbalance. I'm trying to give the regulatory SOC occupation descriptions a higher value in the model.</p>
","natural-language-processing"
"38725","How does chatGPT know it's an AI?","2023-01-12 01:13:09","","1","507","<neural-networks><natural-language-processing><agi><chatgpt>","<p><a href=""https://i.sstatic.net/3HZEb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/3HZEb.png"" alt=""enter image description here"" /></a></p>
<p>I've tried several prompts to understand how does it &quot;know&quot; that it's an AI, but it's answers are inconclusive for me. It says that it was hard-coded to recognize keywords in this regard, which might mean that OpenAI might have trained it intensively on text about itself, but how exactly? my question remains</p>
","natural-language-processing"
"38724","Pre-Trained Model for Occupational Coding","2023-01-11 22:25:38","","0","34","<natural-language-processing><classification><clustering><text-classification>","<p>I've recently embarked on a task to classify an occupation code, given a job title &amp; description. I have come across clustering, a method of grouping data into clusters of which were not previously assigned. As well as, classification to group new data into pre-defined categories.</p>
<p>The only problem is that most of the classification methods I've seen used are for a limited number of categories (usually 2, as high as 30), and the number of occupation codes reaches into the several hundred.</p>
<p>Is there any resources someone can point me to, or an idea of a pre-trained model to use as a foundation? Any insights into this problem (if it's even possible) would be greatly appreciated. I currently have 2M+ human-tagged job postings to work off of. I've read up on the process of freezing a BERT models architectural layers, and feeding the training data into the softmax layer, but I'm hoping someone could let me know if that is just a waste of time.</p>
","natural-language-processing"
"38706","How can i create a new language model for language other than english?","2023-01-11 08:48:43","","1","95","<natural-language-processing><language-model>","<p>I have large set of corpus for all literature in 'Tamil' language, i am trying to create a document retrieval engine through simple natural language.</p>
<p>Since the corpus is huge, its hard to do a supervised learning, i also checked ai4bharat.org 's initiatives to build the language models, but its still not working good the literature texts.</p>
<p>what is required to build a model from scratch</p>
","natural-language-processing"
"38578","For specific tasks, is it better to fine-tune models on examples or just use prompting with the context of the task?","2023-01-03 17:54:35","38580","1","645","<natural-language-processing><comparison><training><fine-tuning><language-model>","<p>These days large language models cover a vast amount of topics and information, but I wanted to understand: <em>For specific tasks, is it better to fine-tune models on examples or just use prompting with the context of the task?</em></p>
<p>For example, if I wanted to train a language model to do question answering for linear algebra, is it better to train it with examples of linear algebra problems and their solutions, or try out different prompts?</p>
","natural-language-processing"
"38569","How to tokenize compound sentences based on the conjunctions?","2023-01-03 06:53:41","","0","43","<deep-learning><natural-language-processing><algorithm-request><pretrained-models><sentiment-analysis>","<p>I am trying to tokenize sentences of a document for aspect-based sentiment analysis. There are some sentences that consist of more than one topic. For example,</p>
<blockquote>
<p>The touch screen is good but the battery is weak</p>
</blockquote>
<p>or</p>
<blockquote>
<p>Their smartphones are great and their TVs are perfect.</p>
</blockquote>
<p>I want to tokenize sentences based on these &quot;conjunctions&quot;. To be more specific, for example, in the first case, I want to get these tokens:</p>
<blockquote>
<p>[The touch screen is good, the battery is weak]</p>
</blockquote>
<p>Existing tokenizers split documents based on punctuation. Even if I spit based on words such as <code>but</code>, <code>and</code>, and so on, it is possible to get splits that are words. For example</p>
<blockquote>
<p>the phone is handy and cool</p>
</blockquote>
<p>will be</p>
<blockquote>
<p>[the phone is handy, cool].</p>
</blockquote>
<p>but instead it should remain the same, that is</p>
<blockquote>
<p>[the phone is handy and cool].</p>
</blockquote>
<p>Is there any pre-trained model for this task? Are there any other solutions?</p>
","natural-language-processing"
"38538","Why does ChatGPT create fake code?","2022-12-31 09:50:52","38541","6","1988","<machine-learning><natural-language-processing><open-ai><chat-bots><chatgpt>","<p>ChatGPT has been a big thing lately. It also makes a lot of mistakes. For example, it creates <strong>fake</strong> functions of a package and tells it as it works for real. I was wondering how that works. Why is it creating fake functions of code and not just telling that it doesn't know how to solve the question that was asked?</p>
<hr>
<p>Example taken from Stack Overflow.</p>
<p><strong>Question</strong></p>
<p>Link: <a href=""https://stackoverflow.com/q/74662093/"">https://stackoverflow.com/q/74662093/</a></p>
<p>Title:</p>
<blockquote>
<p>App script accessing secret manager to retrieve api token</p>
</blockquote>
<p>Body:</p>
<blockquote>
<p>I am trying to access secret manager from a small script I built on app script. I need to access and API with with a key but do not want to hardcode it.</p>
<p>I have already assigned the app to a project. I am just not sure how to query the token.</p>
</blockquote>
<p>Answer (deleted)</p>
<p>Link: <a href=""https://stackoverflow.com/a/74682465/1595451"">https://stackoverflow.com/a/74682465/1595451</a></p>
<p>Body</p>
<blockquote>
<p>To access the Secret Manager from Google App Script, you can use the
<strong>SecretManager.getSecret(secret)</strong> method, which takes a secret parameter specifying the name of the secret you want to retrieve. For
example:</p>
<pre><code> // Get the secret named &quot;my-api-token&quot;
 var secret = SecretManager.getSecret('my-api-token');
 
 // Use the secret value in your script
 var apiToken = secret.getValue();
</code></pre>
<p>Note that this method will throw an error if the specified secret does
not exist or if the user does not have permission to access it. You
can use a try-catch block to handle these cases gracefully. For
example:</p>
<pre><code> try {
   // Get the secret named &quot;my-api-token&quot;
   var secret = SecretManager.getSecret('my-api-token');
 
   // Use the secret value in your script
   var apiToken = secret.getValue();
 } catch (e) {
   Logger.log('Error getting secret: ' + e.message);
 }
</code></pre>
<p>Also note that the getValue() method returns the secret value as a
string, so you may need to convert it to the appropriate data type
(such as a number or boolean) depending on your use case.</p>
<p>For more information, see the <a href=""https://developers.google.com/apps-script/guides/secrets"" rel=""nofollow noreferrer"">Secret Manager documentation</a> and
the <a href=""https://developers.google.com/apps-script/reference/secrets/secret-manager"" rel=""nofollow noreferrer"">SecretManager class reference</a>.</p>
</blockquote>
<p><strong>SecretManager.getSecret(secret)</strong> method doesn't exist, and obviously the links returns page not found.</p>
","natural-language-processing"
"38521","How was ChatGPT trained?","2022-12-29 01:02:32","38561","6","2212","<natural-language-processing><chat-bots><training-datasets><language-model><chatgpt>","<p>I know that large language models like GPT-3 are trained simply to continue pieces of text that have been scraped from the web. But how was ChatGPT trained, which, while also having a good understanding of language, is not directly a language model, but a chatbot? Do we know anything about that? I presume that a lot of conversations was needed in order to train it. Did they simply scrape those conversations from the web, and where did they find such conversations in that case?</p>
","natural-language-processing"
"38458","How can I put more weight specific words when doing text classification?","2022-12-23 08:56:12","","0","403","<natural-language-processing>","<p><a href=""https://i.sstatic.net/NWgsJ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/NWgsJ.png"" alt=""picture"" /></a>
The picture shows the model I want to implement. As you can see, the input will be a single sentence (e.g. I want to massacre those ugly people!). Then, the teacher model will output weights(which will be 0~1 float values) to more important words to classify (e.g. The model will give more weights to words like massacre and ugly for classifying the sentence to be hate-speech). Then, the student model takes those weights from the teacher and the same sentence, and the weights will be a hint for student to know which words it should focus and classifies the sentence.</p>
<p>What I want to know is that how can I make student model to focus several words than others? Just multiplying weights to the word embeddings naively doesn't seem a good solution I think. Please give me some insight. Thank you.</p>
","natural-language-processing"
"38423","How do I generate video classification labels using video descriptions/titles?","2022-12-20 19:05:35","","-1","182","<natural-language-processing><text-classification><automation><labels><javascript>","<p>I've been scanning the internet for ways to generate baseball-based labels for youtube baseball videos using text collected from a YT video's description, title, and top 50 titles, but so far, I have been unable to find a Natural Language Processing (NLP) that can achieve this.</p>
<p>To achieve this, I think I must analyse the sentence's sentiment (positive or negative) and understand its hypothesis. From there, I would need to compare those sentences to a baseball-themed whitelist of labels I would need, like 'match', 'baseball', and 'Yankees - Red Sox'.</p>
<p>We have plenty of videos that already have labels, so this would be an option for training an AI.</p>
<p>Finding sentiment in a sentence is already finished. The question is, how can we generate labels with text that already has sentiment values assigned to it? Is there a program we could run this through that is free?</p>
","natural-language-processing"
"38397","What's the relationship between number of heads and embedding dimension in Transformers?","2022-12-19 00:18:54","","4","3219","<deep-learning><natural-language-processing><transformer><attention><hyper-parameters>","<p>I am reading the book: Natural Language Processing with Transformers. It has the following paragraph</p>
<blockquote>
<p>Although head_dim does not have to be smaller than the number of embedding dimensions of the tokens (embed_dim), in practice it is chosen to be a multiple of embed_dim so that the computation across each head is constant. For example, BERT has 12 attention heads, so the dimension of each head is 768/12=64.</p>
</blockquote>
<p>While learning transformers, I tried to draw an analogy between CNN filters and multi-headed attention. For instance, increasing the number of filters helps learn different image features, while increasing number of heads help better understand the semantics of a sentence. However, it seems like that the input to the transformer (after being converted to embeddings) is being divided across heads. Perhaps my understanding of multi-head attention is incorrect.</p>
<p>Basically, I want to know why the author is dividing the inputs across the heads rather than feeding all the inputs to it.</p>
","natural-language-processing"
"38387","Does ChatGPT's limited understanding of novel inputs reveal limitations in language's ability to convey meaning?","2022-12-17 21:48:32","","0","199","<natural-language-processing><open-ai><gpt-3><chatgpt>","<p>As a language model, <strong>ChatGPT</strong> generate responses based on patterns they have learned from the data they were trained on. However, it may not always provide a <em>perfect</em> or <em>complete answer</em> to <strong>novel</strong> or <strong>unexpected inputs</strong>, <code>indicating that it does not have a genuine understanding of the task or concept at hand</code>.</p>
<blockquote>
<p>The question then becomes whether inability of <strong>ChatGPT</strong> or other language based AI system to fully understand and respond to <strong>novel</strong> or <strong>unexpected inputs</strong> is a reflection of the <strong>inherent limitations</strong> of language as a medium for conveying meaning and understanding?</p>
</blockquote>
","natural-language-processing"
"38372","How can a language model keep track of the provenance of the main knowledge/sources used to generate a given output?","2022-12-16 18:12:54","","6","826","<natural-language-processing><language-model><chatgpt>","<p>One of the main criticisms against the use of ChatGPT on Stack Exchange is that it doesn't attribute the main knowledge/sources used to generate a given output. How can a language model keep track of the provenance of the main knowledge/sources used to generate a given output?</p>
","natural-language-processing"
"38365","NLP: Question answer with 2 contexts","2022-12-16 12:52:41","","0","94","<natural-language-processing><transformer><question-answering>","<p>Is there a Hugging Face Transformer that takes 2 contexts as input for question answering? For example, I could have transcript of a meeting in first context and agenda of the meeting in the second context. Then ask a question - Did the meeting adhere to the discussion topics given in the agenda? Alternatively, can you suggest how to solve such types of question answering problems that might require multiple contexts?</p>
","natural-language-processing"
"38340","Why do the values in the cross attentional mechanism within a transformer come from the encoder and not from the decoder?","2022-12-15 10:09:29","","1","1006","<natural-language-processing><transformer><attention>","<p>The transformer architecture contains a cross attention mechanism which is enriching the encoder with information from the decoder. The place where this takes place is visualized in the image below:</p>
<p><a href=""https://i.sstatic.net/L3ifH.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/L3ifH.jpg"" alt=""transformer_architecture"" /></a></p>
<p>The cross attention mechanism within the original transformer architecture is implemented in the following way:</p>
<p><a href=""https://i.sstatic.net/BBwHl.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/BBwHl.jpg"" alt=""cross_attention_computation"" /></a></p>
<p>The source for the images is <a href=""https://www.youtube.com/watch?v=EixI6t5oif0"" rel=""nofollow noreferrer"">this video</a>.
Why are the values in this step coming from the encoder instead of from the decoder? Is this where e.g. the actual language translation happens within a transformer?</p>
","natural-language-processing"
"38315","How do ChatGPT content filters work? (If not chatGPT then in general)","2022-12-13 22:20:38","","2","4997","<natural-language-processing><open-ai><gpt>","<p>I first tried ChatGPT few days ago.  And every day that goes by it seems more and more content filters are introduced.   I can still make it do stuff if I &quot;jailbreak it&quot; but I feel like the restrictions are getting tighter.  By the way I'm not making it do anything bad, just testing it's limits of what it can do.  Over time it can do less and less (or is willing to do less and less).  This makes me wonder how the filters are implemented and why they work the way they do:</p>
<ul>
<li>Why is it that seemingly for any filter that's put in place there is a workardound?  Things like (imagine, pretend etc).  If something is filtered wouldn't it be filtered across all contexts?   Why does adding a magic word like &quot;act as though&quot; make it ignore filters all of a sudden?</li>
<li>Are the rest of you seeing the same trend of increased filtering?   For me, coming from a sysadmin background it almost feels like a fight between the admins and the users.  The admins begin gently with fine grained filters with very specific contexts, but as they see the onslaught in creativity of the users of bypassing those specific contexts they are using increasingly more and more general contexts to filter on (because they can't keep up with all the jailbreaks).   Of course this blocks legit uses too.</li>
<li>Since ChatGPT is (or more precisely, used to be) very cooperative with what the users told it to behave like, do the admins have a similar natural language interface to interact with chatGPT to tell it how they want it to behave?   Ex admins say &quot;never give a response that's less than 5 sentences in length&quot;, then even though the user says &quot;answer me simply yes or no&quot;.  Admins (hidden) request takes precedence?</li>
<li>Why in a single session I can have it cooperate and then when asked to do exactly the same thing seconds later it refuses? (ex: answer me with a single random swear word: works perfect and then couple questions later it refuses)</li>
</ul>
<p>I tried asking some of these questions to ChatGPT directly and I didn't get very far with it except that apparently the boiler plate &quot;As a large language model trained by OpenAI, I am a machine learning model that ...&quot; is some kind of hard-coded disclaimer added by the engineers.   Supposedly it's a different mechanism from content filters.   Which kind of makes sense.   Of course I don't know if I can trust that answer, as how the disclaimer sais ChatGPT is known to be confidently incorrect.</p>
<p>Also, I realize chatGPT is proprietary, so I'm not expecting anyone to reveal any secrets.  I will be very satisfied of knowing how this is handled in similar NLP models.</p>
","natural-language-processing"
"38270","How does an AI like ChatGPT answer a question in a subject which it may not know?","2022-12-12 03:31:48","38272","34","11245","<natural-language-processing><chat-bots><question-answering><board-games><chatgpt>","<p>After seeing <a href=""https://meta.stackoverflow.com/q/421831"">StackOverflow's banning of ChatGPT</a>, I explored it out of curiosity. It's marvellous as it can write code by itself!</p>
<p>Later to check if it knows chess as well like Google-Deepmind's AlphaZero AI, I asked below questions:</p>
<blockquote>
<p><strong>Me</strong>: Does openai know how to play chess?<br />
<strong>OpenAI</strong>: It is not clear whether OpenAI knows how to play chess. As an artificial intelligence research organization, OpenAI has developed a number of advanced machine learning algorithms and techniques that allow AI systems to learn and adapt to new tasks and situations. ...</p>
</blockquote>
<blockquote>
<p><strong>Me</strong>: In a chess if white has a king &amp; bishop and if black has only a king, then who can win with a perfect play?<br />
<strong>OpenAI</strong>: In a chess game where white has a king and a bishop and black has only a king, <strong>it is possible for either player to win with perfect play</strong>. This type of endgame is known as a king and bishop versus king endgame, and it is considered one of the most challenging in chess. ...</p>
</blockquote>
<p>Now this answer is entirely wrong. Because as soon as only a bishop (or a knight) remains apart from the kings, it's instantly <a href=""https://chess.stackexchange.com/questions/30561/is-it-possible-to-win-with-a-king-and-one-bishop-vs-a-king"">declared as a draw</a>!</p>
<p><strong>Question</strong>: Shouldn't the AI reject my question on a subject which is not in its known criteria?<br />
It does so for many other subjects.</p>
<hr />
<p><strong>Note</strong>: Should we replace <code>bishop = rook</code> then ChatGPT answers exactly the same answer with replacing those pieces. However that happens to be true.</p>
","natural-language-processing"
"38240","Confused about NER evaluation","2022-12-09 21:23:05","","0","51","<natural-language-processing><named-entity-recognition>","<p>I'm reading from the book Speech and Language Processing by
Dan Jurafsky and James H. Martin and I've stuck for a while trying to understand what the authors mean by the following</p>
<blockquote>
<p>The fact that named entity tagging has a segmentation component which
is not present in tasks like text categorization or part-of-speech
tagging causes some problems with evaluation. For example, a system
that labeled Jane but not Jane Villanueva as a person would cause
two errors, a false positive for O and a false negative for I-PER.
In addition, using entities as the unit of response but words as the
unit of training means that there is a mismatch between the training
and test conditions.</p>
</blockquote>
<p>In particular, I don't see what's the problem with</p>
<blockquote>
<p>For example, a system
that labeled Jane but not Jane Villanueva as a person would cause
two errors, a false positive for O and a false negative for I-PER.</p>
</blockquote>
<p>Was is expected to cause one error or something? What if Jane Villaneuva was labeled as B-LOC I-LOC?</p>
<p>Thanks.</p>
","natural-language-processing"
"38220","Why is ChatGPT bad at math?","2022-12-08 23:12:22","","29","36751","<natural-language-processing><math><chat-bots><gpt><chatgpt>","<p>As opposed to <a href=""https://ai.stackexchange.com/q/38217/145"">How does ChatGPT know math?</a>, I've been seeing some things floating around the Twitterverse about how ChatGPT can actually be very bad at math. For instance, I asked it &quot;If it takes 5 machines 5 minutes to make 5 devices, how long would it take 100 machines to make 100 devices?&quot;</p>
<p>The conversation went <a href=""https://i.sstatic.net/XDTem.png"" rel=""noreferrer"">like this</a>:</p>
<blockquote>
<p><strong>Mithical</strong>: If it takes 5 machines 5 minutes to make 5 devices, how long would it take 100 machines to make 100 devices?<br />
<strong>ChatGPT</strong>: If it takes 5 machines 5 minutes to make 5 devices, then it would take 100 machines 100 minutes to make 100 devices.<br />
<strong>Mithical</strong>: That's not right. Check carefully and try again.<br />
<strong>ChatGPT</strong>: I apologize if my response was not correct. Can you please provide more information or clarify your question? I may have misunderstood the scenario you described.<br />
<strong>Mithical</strong>: It takes a machine 5 minutes to make a device. How long would it take 100 machines to make 100 devices?<br />
<strong>ChatGPT</strong>: If it takes a single machine 5 minutes to make a single device, then it would take 100 machines 5 minutes to make 100 devices. Therefore, it would take a total of 500 minutes for 100 machines to make 100 devices.</p>
</blockquote>
<p>Now, unless I'm misunderstanding something here, the answer is 5 minutes. ChatGPT first makes the intuitive mistake of 100, that a human might make as well, and then goes on to (correctly, as far as I understand) say it's 5 minutes... but concludes in the same response that it's then 500 minutes.</p>
<p>Why is this AI so bad at math? Computers are generally supposed to be good at math. Why does this model make such simple logical mistakes?</p>
","natural-language-processing"
"38180","Negative sampling in batch or entire dataset?","2022-12-06 03:32:17","39307","0","462","<machine-learning><natural-language-processing><recommender-system>","<p>For nlp task like word2vec, we do negative sampling through the entire dataset</p>
<p>But in some cases like candidate generation in recommendation system, we do in batch negative sampling.</p>
<p>So my question are:</p>
<ol>
<li>What's the difference between two method?</li>
<li>Did module like <code>tensorflow</code> has already realized  <code>in batch NEG</code> and <code>globally NEG</code>?</li>
</ol>
","natural-language-processing"
"38150","How does ChatGPT retain the context of previous questions?","2022-12-04 11:23:04","38262","55","48890","<natural-language-processing><chat-bots><natural-language-understanding><chatgpt>","<p>One of the innovations with OpenAI's ChatGPT is how natural it is for users to interact with it.</p>
<p>What is the technical enabler for ChatGPT to maintain the context of previous questions in its answers? For example, ChatGPT understands a prompt of &quot;tell me more&quot; and expands on it's previous answer.</p>
<p>Does it use activations from previous questions? Is there a separate input for the context? How does it work?</p>
","natural-language-processing"
"38144","Phonetic similarity metric for NLP (English)","2022-12-03 16:57:33","","2","230","<natural-language-processing>","<p>I am looking for similarity metrics of phonemes (expressed in IPA) in English. In other words, given two phonemes A and B (both written), I want to know how similar they are based on some metric, M. For example, M(ɒ, oʊ) would yield a higher score than M(æ,ɔɪ).</p>
","natural-language-processing"
"38128","What models/algorithms besides variational autoencoders can I use to transform a discrete input into a differentiable latent space?","2022-12-02 12:27:57","","1","33","<natural-language-processing><algorithm-request><variational-autoencoder><model-request>","<p>Let's say I have a discrete input and want to transform it into a differentiable latent space. What models/algorithms besides variational autoencoders can I use?</p>
","natural-language-processing"
"38034","How are gradients backpropogated in ALBERT?","2022-11-26 06:20:51","38482","0","55","<deep-learning><natural-language-processing><bert>","<p>I was reading the <a href=""https://arxiv.org/abs/1909.11942"" rel=""nofollow noreferrer"">ALBERT</a> paper and saw that they use the same parameters in each layer hence reducing the number of unique parameters. From what I could gather it seems if the all the layers have say parameters W then parameters of different layers would be updated differently which would destroy the parameter sharing.</p>
<p>So one way I can think of is say we have only one set of parameters W and after each layer completes it's weight update W changes to W' and the preceding layers now use W'.</p>
<p>Is this the right way to think about it or does something else happen under the hood?</p>
","natural-language-processing"
"37990","Did old-fashioned, rule-based systems die out when statistical learning broke through into NLP?","2022-11-22 18:34:47","37998","2","100","<machine-learning><natural-language-processing><statistical-ai><rule-based-systems>","<p>It is not quite clear to me whether the statistical approach superseded the rule-based system in the 90s.</p>
<p><a href=""https://link.springer.com/content/pdf/10.1023/A:1006517723917.pdf"" rel=""nofollow noreferrer"">McMahon and Smith (1998)</a> report that many other researchers used &quot;hybrids of statistical and formal approaches&quot;. What do they mean? Maybe it was still unclear which one was best suited for?</p>
","natural-language-processing"
"37892","How do Neural Networks deal with ambiguity of words?","2022-11-15 00:52:47","","0","50","<neural-networks><natural-language-processing>","<p>The word &quot;shot&quot; has several meanings. For example, when one says they shot an animal, it could mean that they shot it with a gun, or even shot it out of a cannon.</p>
<p>How can NN trained models be used to identify the appropriate meaning of the word shot?</p>
","natural-language-processing"
"37882","How to develop an Entity linking system able to detect custom entities?","2022-11-14 11:54:17","","1","65","<natural-language-processing><knowledge-representation><natural-language-understanding><knowledge-base>","<p>I am trying to build an entity linking system that links entities found in a text to entities on Wikipedia. If no Wikipedia page seems to match this entity, the systems will assume to have found a new entity and adds it to an internal knowledge base.
I am currently working to build a system that works like this:</p>
<ol>
<li>Extract mentions of entities in the text: in the sentence &quot;Napoleon commissioned a grand reconstruction of Paris&quot;, <em><strong>Napoleon</strong></em> is extracted as it refers to some entity.</li>
<li>Search for the alias &quot;Napoleon&quot; in Wikipedia and compute the embeddings of the pages that appear.</li>
<li>Compute the embedding of the sentence where the mention is found and compare it against the embeddings computed from Wikipedia. In this case, <em><strong>Napoleon III</strong></em> should be the best fit, although <em><strong>Napoleon I</strong></em> has a higher prior probability, given his popularity.</li>
<li>If no page from Wikipedia surpasses a given similarity threshold, we assume that we have found an entity with no corresponding page on Wikipedia; thus, we store it in our entity kb.</li>
<li>Save on our kb the previously computed embeddings of Wikipedia pages.</li>
</ol>
<p>Can this approach work effectively? How can I improve it?</p>
<p>Any help you can provide would be greatly appreciated!</p>
","natural-language-processing"
"37853","How are gradients of individual layers computed?","2022-11-12 17:11:07","","2","212","<neural-networks><natural-language-processing><gradient-descent><transformer>","<p>I have been reading some papers recently (example: <a href=""https://arxiv.org/pdf/2012.00363.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/2012.00363.pdf</a>) which seem to be training individual layers of, say, a transformer, holding the rest of the model frozen/constant. In the case of the paper I read, this was done in an attempt to minimize parameter changes so as to reduce knowledge &quot;lost&quot; by a model when it is updated for new information.</p>
<p>My question is, how are individual layers of a transformer trained? Like, if we run the transformer and get a gradient, how can we use that gradient to train, say, the first layer, without affecting the rest of the layers at all?</p>
","natural-language-processing"
"37784","Matching sentences (/bullet points) in two sets using NLP","2022-11-06 11:29:25","","0","105","<natural-language-processing>","<p>I am working on a problem where I have two texts T1, T2. T1 contains some important points that I have entered. How can I make sure that T2 has those points? I am aware of the algorithms like cosine, jaccard, BERT for semantic similarity but the problem is that they apply to the whole text whereas I want point-wise similarity i.e. T2 must contain the T1 points although the order and words used may differ a bit.</p>
<p>By points I meant bullet points covering discrete concepts and I basically want to check how many discrete concepts in my T1's points are covered in T2 where they could be in a single sentence or spread out across multiple sentences.</p>
<p>Example:</p>
<p>So T1 could have the following two points:</p>
<ul>
<li>The Queen reigned from 1943 to 2022.</li>
<li>The Queen was the second
longest reigning monarch.</li>
</ul>
<p>Now T2 could either be:</p>
<p>The Queen was the second longest reigning monarch with her reign spanning 1952 to 2022.</p>
<p>or</p>
<ul>
<li>The Queen reigned from 1952 to 2022.</li>
<li>She was Britain's second longest monarch.</li>
</ul>
<p>In both these cases, T2 should be considered to contain both points in T1.</p>
","natural-language-processing"
"37657","How to classify data into organised groups by using a resulting classification vector and a set of probabilities?","2022-10-27 14:58:19","37660","0","41","<natural-language-processing><classification><bert><probability>","<p>I am trying to figure out the best way to calculate the probability a sentence belongs to some category.
For simplicity sake, lets assume that the sentence is &quot;yellow fruit&quot;.
Next, I use the an BERT classifier to get a classification result [-5,1,2] with the categories [apple, orange, banana].</p>
<p>The array simply tells us how strong is the signal that corresponds to a category. In this case -5 for apple, 1 for orange, and 2 for banana.
The answer to this classification is &quot;banana&quot; since 2 is the max number in the [-5,1,2] array, and it position corresponds to the category &quot;banana&quot;.
Therefore, we know that &quot;yellow fruit&quot; is most-likely a banana.</p>
<p>Next, I have a table of likelihood of purchase for apples, oranges and bananas:</p>
<p>Apple: 80%</p>
<p>Orange: 10%</p>
<p>Banana: 50%</p>
<p>I need to calculate the likelihood of customer purchase for sentence &quot;yellow fruit&quot;.
Therefore, I am given the sentence &quot;yellow fruit&quot;, the classification vector [-5,1,2] the classification categories [apple, orange, banana] and the likelihood table for purchase [0.8,0.1,0.5]</p>
<p>How do I calculate the the likelihood of purchase for the sentence &quot;yellow fruit&quot; ?</p>
","natural-language-processing"
"37537","How to predict the rating of a text review and improve it?","2022-10-19 23:05:28","37554","1","159","<neural-networks><machine-learning><natural-language-processing><text-classification><naive-bayes>","<ol>
<li><p>Why is it better to treat the rating prediction of a text review as a regression problem rather than a classification one? Is it because the ratings (1,2,3,4,5) are ordinal variables?</p>
</li>
<li><p>What kind of Naive Bayes algorithm is the most suitable for this problem? Is Multinomial Naive Bayes the best one? It is a classifier, so I am unsure if it can deal with the ordinal nature of the rating variable or not.</p>
</li>
<li><p>The conditional independence assumption does not hold for text data. Terms are conditionally dependent on each other. Which observations in the dataset will be primarily affected by this assumption? Those observations whose word/feature counts are the least (the most sparse ones)?</p>
</li>
<li><p>If we want to keep a single feature/word in our model, which one should we choose? Should we keep the feature with the maximum sum of its word counts?</p>
</li>
<li><p>Generally, is it accurate to say that neural networks are better than KNN models for predicting the ratings because the text datasets are usually sparse? Does the performance of these two regressors mainly differs for observations whose word/feature counts are the least (the most sparse ones)?</p>
</li>
</ol>
","natural-language-processing"
"37526","Are custom tokens better than punctuation pseudo-tokens for LLMs?","2022-10-19 14:20:45","","1","27","<natural-language-processing><natural-language-understanding><language-model>","<p>I've seen two approaches for introducing custom tokens for transfer learning with large language models like Bert or GPT3. Some approaches introduce new tokens into the vocabulary and learn embeddings from scratch. This is the &quot;traditional&quot; approach. However, I've seen other papers that imitate custom tokens with the use of punctuation, e.g. <code>&quot;&lt;custom-token&gt;&quot;</code>. In this case the model is not learning any new tokens, but is learning to connect subword tokens and punctation already in its vocabulary. I think this approach is often used with GPT3, as the closed API prevents learning new tokens from-scratch.</p>
<p>Has any research benchmarked whether one approach is better than another, when both options are available?</p>
","natural-language-processing"
"37365","Any models for text to json","2022-10-10 11:16:44","","2","1785","<deep-learning><natural-language-processing><seq2seq>","<p>There are many sequence to sequence (seq2seq) models and end to end models, like text to sql. I was wondering are there any text to json deep learning models?</p>
<p>For example:</p>
<p>Text</p>
<pre><code>&quot;Switch on the computer&quot;. 
</code></pre>
<p>JSON:</p>
<pre><code>{&quot;actions&quot;:[&quot;switch on&quot;], &quot;object&quot;:&quot;computer&quot;}
</code></pre>
<p>Another Example:</p>
<p>Text:</p>
<pre><code>&quot;Lower the heater temperature to 25 degrees and before that play music for one hour&quot;.
</code></pre>
<p>JSON:</p>
<pre><code> {&quot;actions&quot;: [&quot;lower the heater temperature&quot;,&quot;play the music&quot;],&quot;order&quot;:[1,0]}
</code></pre>
<p>Note that JSON has different or some additional elements depending on the text. This is different from regular seq2seq models. Any suggestions on which models to use? Thank you!!</p>
","natural-language-processing"
"37357","Batching together similar length sequences to avoid padding and packing","2022-10-09 16:33:25","","1","414","<natural-language-processing><recurrent-neural-networks><pytorch><training-datasets><batch-learning>","<p>I am training an RNN in PyTorch to produce captions for images. It's a pretty standard architecture – the image is processed by a pre-trained InceptionV3 to extract features, the recurrent module processes the words seen so far and then its result is merged with image features and fed through a linear layer to produce a probability distribution over the vocab to predict the next word. A network trained this way can auto-regressively predict a whole caption for an image (it's seeded with an artificial  token at the beginning to have a preceding sequence to start off with).</p>
<p>To train the network every caption is decomposed like this in the training dataset:</p>
<pre><code>X, y
&lt;START&gt;, a
&lt;START&gt; a, man
&lt;START&gt; a man, is
&lt;START&gt; a man is, sitting
&lt;START&gt; a man is sitting, on
&lt;START&gt; a man is sitting on, a
&lt;START&gt; a man is sitting on a, chair
&lt;START&gt; a man is sitting on a chair, &lt;END&gt;
</code></pre>
<p>The result is that there is a lot of input sequence length variation in the training data which is a problem since we would need a lot of padding in batches. I am aware that there are techniques of counteracting this (<code>pack_padded_sequence</code> in PyTorch) but I came up with another idea.</p>
<p>I am modifying the <code>Sampler</code> object that's used to provide indices for the <code>DataLoader</code> to construct batches in such a way that the <code>Sampler</code> orders all of the example indices by input sequence length, groups it into batch-size chunks, and shuffles the chunks before feeding them to the <code>DataLoader</code>. As a result the sequences in individual batches are almost always the same length – not because of any padding but because of the fact that we ordered the examples by length before grouping them. There will be some batches that will encompass examples on a border of length groups so some padding will be necessary but it will be minimal (just one zero for a group of lengths [5, 5, 5, 6, 6, 6] for example) and the number of such groups would be negligible (~0.002% of the batches in my case).</p>
<p>My question is – does this method introduce some kind of drawback that I am not aware of? I find it simpler than having completely random batches and padding and packing them. I can't tell however, if it would introduce some kind of bias to the model. My intuition tells me that this should not be problem since the sequence lengths for batches would vary greatly across training (since I am shuffling the index chunks), but I wanted to get a second opinion. I guess the question boils down to -&gt; is sequence length variation <strong>within the batch</strong> important for proper training? Or, for this specific case -&gt; is it important that the net process examples decomposed from a single caption <strong>within the same batch</strong> or close to each other time-wise?</p>
<p>I'd be happy to train the network with both solutions and check the results myself but it's quite time-expensive and I'd prefer to avoid some stupid stuff if I can.</p>
","natural-language-processing"
"37283","If GPT-3 is trained on predicting the next token, how is it able to take commands?","2022-10-04 21:46:18","","2","1115","<natural-language-processing><transformer><gpt-3>","<p>From my understanding, GPT-3 is trained on predicting the next token from a sequence of tokens. Given this, how is it able to take commands? For instance, in this example input, wouldn't the statistically most likely prediction be to insert a period and end the sentence?</p>
<pre><code>Input: write me a beautiful sentence

Output: I cannot put into words how much I love you, so I'll just say it's infinite.
</code></pre>
","natural-language-processing"
"37267","How do Transformer decoders handle arbitrary length input?","2022-10-03 21:04:37","","4","1582","<natural-language-processing><transformer><machine-translation>","<p>I am working through a Tensorflow Neural Machine Translation tutorial (<a href=""https://www.tensorflow.org/text/tutorials/transformer"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer</a>) and am confused about how the decoder handles inputs when making inferences after it has been trained.</p>
<p>In the section where we create a class for translating a sentence (<a href=""https://www.tensorflow.org/text/tutorials/transformer#run_inference"" rel=""nofollow noreferrer"">https://www.tensorflow.org/text/tutorials/transformer#run_inference</a>) it appears that we feed the decoder an array populated with the START token only, then append the last element from the predicted sequence it makes to the growing translated sentence. This does not make sense to me as we trained the transformer on a fixed length sequence that was padded to length MAX_TOKENS=128, so I can't figure out why it would be able to accept input of an arbitrary length tensor.</p>
<p>Here is the code for inference in question that confuses me:</p>
<pre><code>    # As the output language is English, initialize the output with the
    # English `[START]` token.
    start_end = self.tokenizers.en.tokenize([''])[0]
    start = start_end[0][tf.newaxis]
    end = start_end[1][tf.newaxis]

    # `tf.TensorArray` is required here (instead of a Python list), so that the
    # dynamic-loop can be traced by `tf.function`.
    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)
    output_array = output_array.write(0, start)

    for i in tf.range(max_length):
      output = tf.transpose(output_array.stack())
      predictions, _ = self.transformer([encoder_input, output], training=False)

      # Select the last token from the `seq_len` dimension.
      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.

      predicted_id = tf.argmax(predictions, axis=-1)

      # Concatenate the `predicted_id` to the output which is given to the
      # decoder as its input.
      output_array = output_array.write(i+1, predicted_id[0])

      if predicted_id == end:
        break

</code></pre>
<p><code>self.transformer</code> takes in the &quot;encoder_input&quot; which is fed to the encoder and &quot;output&quot; which is fed into the decoder, where we then take the last prediction in the sequence returned from the decoder, append it to &quot;output&quot;, then repeat the process. But I don't understand how the decoder can process a tensor of length 1, then 2, then 3, and so on if it is always expecting a tensor of length 128.</p>
<p>It seems like the input to the decoder should be padded to 128 tokens and then the prediction at the i-th index should be appended to the output (rather than always the last element in the predicted sequence) before repeating.</p>
<p>Is the tutorial mistaken in the implementation on of how this transformer preforms inference? Or am I missing something that Tensorflow does behind the scenes that allow this to work?</p>
<p>Note, I realize the title to this question is similar to <a href=""https://ai.stackexchange.com/questions/22957/how-can-transformers-handle-arbitrary-length-input"">How can Transformers handle arbitrary length input?</a> but the answer given appears to verify that the input to the decoder should be fixed length and padded, which contradicts how inference is done in the tutorial I am referencing. So I hope this question isn't considered a duplicate but I am asking a similar question in the context of the mentioned tutorial.</p>
<p>Thank you for any insight someone might be able to provide!</p>
","natural-language-processing"
"37205","Papers on Prompt Engineering","2022-09-27 06:22:45","","1","1129","<natural-language-processing><reference-request><papers><language-model><gpt-3>","<p>I am into AI in general and NLP in particular. Besides, I have a background in philosophy, and the new LLMs like GPT-3 seem to have exciting capabilities. I want to study prompt engineering (for example, teaching the model to reason, etc.)</p>
<p>Do you know any specific papers to start? I am looking for studies on the techniques of prompt engineering.</p>
","natural-language-processing"
"37172","What is the role of self loop in Hidden Markov Models(HMM)?","2022-09-23 11:53:44","37201","0","146","<machine-learning><natural-language-processing><pattern-recognition><natural-language-understanding><hidden-markov-model>","<p>What actually does the self-loop (within the single hidden state ) in the Hidden Markov model helpful for?</p>
<p>I learn that one of the use cases concerning Natural language Understanding is that it helps a model to stay within the current state in case of (time variable: long sound/ short sound) pronunciation of the same word. But I can't understand what role the self-loop plays here.</p>
<p>Any explanations would be much appreciated.</p>
","natural-language-processing"
"37154","Which language model technique should be used with a low-resource language?","2022-09-21 11:01:28","","1","25","<natural-language-processing><language-model>","<p>I am working with a language for which the amount of text available is relatively small (less than a billion words), what techniques exist? In particular, is it worth using a transformer or is it better to use more traditional techniques?</p>
<p>The aim is to generate texts in continuation of a given prompt.</p>
","natural-language-processing"
"37148","Left-to-Right vs Encoder-decoder Models","2022-09-20 22:28:58","","1","391","<natural-language-processing><objective-functions><bert><gpt><encoder-decoder>","<p><a href=""https://arxiv.org/pdf/2202.13169.pdf"" rel=""nofollow noreferrer"">Xu et al. (2022)</a> distinguishes between popular pre-training methods for language modeling: (see Section 2.1 PRETRAINING METHODS)</p>
<ul>
<li>Left-to-Right:</li>
</ul>
<blockquote>
<p>Auto-regressive, Left-to-right models, predict the probability of a
token given the previous tokens.</p>
</blockquote>
<ul>
<li>Encoder-Decoder:</li>
</ul>
<blockquote>
<p>An encoder-decoder model first uses an encoder to encode an input
sequence, and then uses a left-to-right LM to decode an output
sequence conditioned on the input sequence.</p>
</blockquote>
<p>My question is, what are the differences between those two methods?
Do they suggest that the first method is a decoder-only? If so, what is the input to this decoder?</p>
<p>Based on what I know about auto-regressive models and the above definition, I understand that in Left-to-Right, we predict the <span class=""math-container"">$i$</span>-th token given the <span class=""math-container"">$1,...,i-1$</span> tokens (which could be our past predictions).</p>
","natural-language-processing"
"37026","How to combine pretrained language models with additional feature set?","2022-09-08 12:06:55","","0","1108","<natural-language-processing><bert><fine-tuning><language-model>","<p>Are there any techniques to combine a feature set (other than the text itself) with pretrained language models.</p>
<p>Let's say I have a random NLP task that tries to predict a binary class label based on e.g. Twitter data. One could easily utilize a pretrained language model such as BERT/GPT-3 etc. to fine-tune it on the text of the tweets. However the tweets come with a lot of useful metadata such as likes/retweets etc. or if I want to add additional syntactic features such as POS-Tags, dependency relation or any other generated feature. Is it possible to use additional features I extracted for the finetuning step of the pretrained language model? Or is the only way of doing so to use an ensemble classifier and basically write a classifier for each of the extracted features and combine all of their predictions with the finetuned LMs predictions?</p>
","natural-language-processing"
"36940","Clarification on GANs for text generation","2022-08-31 17:04:55","36943","2","336","<natural-language-processing><recurrent-neural-networks><math><generative-adversarial-networks><text-generation>","<p>A GAN-like architecture for text generation is proposed in <a href=""https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10"" rel=""nofollow noreferrer"">'Generative Adversarial Networks for Text Generation'</a>.</p>
<p><strong>The setup is the following:</strong></p>
<ul>
<li>The generator of the GAN is proposed to be a recurrent neural network that its by itself a text generator.</li>
<li>The internal latent vectors of the GAN ( denoted by <span class=""math-container"">$G(\vec{z})$</span> ) are the outputs of the generator RNN.</li>
<li>The discriminator is not made explicit; but let's imagine that is <em>&quot;any architecture that can classify text into two categories&quot;</em> (&quot;real&quot; and &quot;fake&quot; in our case).</li>
<li>The generator RNN is trained to minimize <span class=""math-container"">$(1- D(G(\vec{z})))$</span> (where <span class=""math-container"">$D(G(\vec{z})))$</span> is the discriminator output) as usual.</li>
</ul>
<p>Now it comes a somewhat obscure statement:</p>
<blockquote>
<p>Remember that while decoding using an RNN, at every time step we make the choice of the next word by picking the word corresponding to the maximum probability from the output of the softmax function. <em><strong>This “picking” operation is non-differentiable.</strong></em></p>
</blockquote>
<p><strong>Question:</strong></p>
<p><strong>What is the precise statement of that vague paragraph?</strong></p>
<p>My expectation is to explicitly write the function that is just continuous but not differentiable.</p>
<p><strong>Thanks in advance!</strong></p>
","natural-language-processing"
"36812","Can you make Q&A language model stay on topic?","2022-08-19 12:19:02","","0","136","<natural-language-processing><chat-bots>","<p>I’m thinking of fine-tuning a pre-trained language model for a Q&amp;A task. More specifically, I’d like to fine-tune the model on a single chapter in a classic college textbook. Afterward, the reader of the chapter should be able to engage in a Q&amp;A session with the model about the content of the chapter.</p>
<p>But how do I make sure that the model stays on topic and doesn’t go out of a tangent? I know it is possible when looking at what <a href=""https://play.aidungeon.io/"" rel=""nofollow noreferrer"">https://play.aidungeon.io/</a> has achieved, but I don’t know if it will require me to build a model from the ground for each chapter. Can anyone tell me if I’m out of my mind or if it’s feasible?</p>
<p>Edit:</p>
<p>I've just learned that AI Dungeon's models has also struggled with a tendency to create graphic and sexual content despite not being prompted by players.</p>
","natural-language-processing"
"36584","What is the most important predecessor of the transformer model?","2022-08-02 11:07:32","38339","3","163","<natural-language-processing><transformer><attention>","<p>I'm wondering what the origins of the transformer as proposed in <a href=""https://arxiv.org/pdf/1706.03762.pdf"" rel=""nofollow noreferrer"">Attention Is All You Need</a> are. The paper itself provides some interesting pointers to the literature on self-attention such as:</p>
<ol>
<li><a href=""https://aclanthology.org/D16-1244.pdf"" rel=""nofollow noreferrer"">A Decomposable Attention Model for Natural Language Inference</a></li>
<li><a href=""https://openreview.net/pdf?id=BJC_jUqxe"" rel=""nofollow noreferrer"">A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING</a></li>
<li><a href=""https://arxiv.org/pdf/1706.03762.pdf"" rel=""nofollow noreferrer"">NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</a></li>
</ol>
<p>It seems like using attentional mechanisms was widespread (at least in combination with recurrent networks) and 'A Decomposable Attention Model for Natural Language Inference' paper from 2016 already conjectured that scaling attention might be feasible.
Is it from this prior work 'only' an engineering leap? Or what additional papers at the time likely influenced the architecture?</p>
","natural-language-processing"
"36510","How to encode both sentences and categorical data?","2022-07-28 15:14:15","","1","44","<natural-language-processing><classification><data-preprocessing>","<p>I have a DataFrame that contains several columns where some columns contain single words that can be category encoded since I know how many of them are there in total. However one column is an actual sentence with several pieces of information that outlines prices of something, delivery month, product name and sometimes some other info. That column is basically a text message and its format can vary.</p>
<p>Example DataFrame looks like this:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Name</th>
<th>User</th>
<th>Text</th>
<th>Target</th>
</tr>
</thead>
<tbody>
<tr>
<td>sarah</td>
<td>noro</td>
<td>@-23.50 july 380/crx</td>
<td>CRX Laptop</td>
</tr>
<tr>
<td>john</td>
<td>simons</td>
<td>(atlas5) sep nc8 npc 131.5 @ 132.5</td>
<td>NPC Playstation</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>
<p>The columns <em><strong>Name, User, Text</strong></em> are features, and column <em><strong>Target</strong></em> is the target column that I want to predict. I would like to use a <strong>classifier</strong> (Random Forest, or Neural Net, or GBDT) to classify the Target based on other three columns.</p>
<p>I can category encode the columns <em>Name, User, Target</em> as I know how many of unique names, users, and targets there are.</p>
<ol>
<li>How do I encode the <strong>Text</strong> column as it is a sentence?</li>
<li>Would it be better to regex split the <strong>Text</strong> column and simplify it (remove numbers etc) or just feed in the whole thing?</li>
</ol>
","natural-language-processing"
"36418","Hot to calculate Maximum Normalized log Probability for Active Learning with BERT","2022-07-20 07:06:37","","0","327","<neural-networks><deep-learning><natural-language-processing><definitions><bert>","<p>I have encountered difficulties understanding the calculation of Maximum Normalized Log Probabilities acording to <a href=""https://aclanthology.org/W17-2630.pdf"" rel=""nofollow noreferrer"">Shen et al.</a>.</p>
<p><a href=""https://i.sstatic.net/jmIcm.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/jmIcm.png"" alt=""formular for MNLP"" /></a></p>
<p>With n being the sequence length, yi the label of word i. Xij is the representation (the input).</p>
<p>Let me describe my setting. I'm using the implementation of BERT provided by pytorch to finetune a BERT-Base model for sequence labeling. The goal is to determine a label for each word in the sequence. There are three possible labels for each word. The basic model is set up and runs no problem. Implementing Active Learning based on Maximum Normalized Log Probability is not the problem. Im just not sure if i understand the formular correcly. The Model output is a 128 long (since each sequence is 128 words. Overflow from wordPiece Tokenization is not relevant) list of Labels.</p>
<p>So far i'm using the softmax-function to get the probability for each label instead of the logits the BERT-Model provides as i hand it the unlabeled data. Then i calculate the log probabilities for every label via the log10 function. In the end I sum up the maxima of the predictions  over all the words (=the probability of the predicted label for each word) and average them. This is my MNLP value i use to identify the most uncertain instances.</p>
<p>Am i doing it right? My main problem is the max with lowered yi ... yn. As far as i understand it, its used to indicate that only the maximum of the label likelihoods per word is relevant, aka. the probability of the predicted label.</p>
","natural-language-processing"
"36342","How special tokens in BERT-Transformers work?","2022-07-14 15:43:51","","0","499","<neural-networks><deep-learning><natural-language-processing><transformer>","<p>&quot;[SEP] tokens are useful to differentiate the questions from answers through type_ids&quot; Yes, but how is this helping model to understand that &quot;I should look paragraph and generate answers from here&quot;? We don't have if-else inside the model that will say: &quot;if type_id==1, generate questions from here&quot;</p>
<p>The same question appears for this example too:</p>
<p>[CLS] previous question [Q] current question [SEP] text [EOS]</p>
<p>How model says: &quot;I should look at the previous question, understand the meaning from here too with the current question, and answer the question.&quot; We need if-else in here too like:</p>
<p>If there is a previous question:
get the meaning from it and use it with the current question</p>
<p>One more example based on this paper:<a href=""https://arxiv.org/pdf/2005.01107v1.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/2005.01107v1.pdf</a>
In this paper, we have a dataset like this: <a href=""https://huggingface.co/datasets/iarfmoose/question_generator"" rel=""nofollow noreferrer"">https://huggingface.co/datasets/iarfmoose/question_generator</a></p>
<p>In the t5 transformer, if we don't have those  and  tokens, the model will not learn anything. And I have no idea how specifying  and  we are helping the model to generate questions based on that answer in the context.</p>
<p>I hope I am clear with my question.</p>
","natural-language-processing"
"36255","What is the best approach/model for classifying document images with over 70+ classes of documents?","2022-07-08 03:43:24","","1","42","<machine-learning><natural-language-processing><algorithm-request>","<p>What is the best approach/model for classifying document images with over 70+ classes of documents? I have tried LayoutLM which is a model that incorporated both NLP and Computer vision to classify but it's accuracy is not upto the mark. Are there any other models/methods I could try to come up with a better solution?</p>
","natural-language-processing"
"36192","How does GPT use the same embedding matrix for both input and output?","2022-07-04 20:35:57","40133","1","3666","<natural-language-processing><transformer><word-embedding><embeddings><gpt>","<p>My understanding is that GPT uses the <strong>same embedding matrix</strong> for both inputs and output: Let <span class=""math-container"">$V$</span> be the vocab size, <span class=""math-container"">$D$</span> the number of embedding dimensions, and <span class=""math-container"">$E$</span> be a <span class=""math-container"">$V \times D$</span> embedding matrix:</p>
<ul>
<li>On input, if <span class=""math-container"">$x$</span> is a one-hot <span class=""math-container"">$V$</span>-dimensional vector, GPT uses <span class=""math-container"">$Ei$</span>.</li>
<li>On output, if <span class=""math-container"">$\hat y$</span> is a <span class=""math-container"">$D$</span>-dimensional prediction vector, GPT uses softmax(<span class=""math-container"">$E^\top{\hat y}$</span>) as its predictions.</li>
</ul>
<h2>Q1. Is the above correct?</h2>
<p>I cannot find this stated clearly in the paper, but it is stated explicitly <a href=""https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens"" rel=""nofollow noreferrer"">here</a>.  It's also clearly implied by the parameter count listed <a href=""https://jalammar.github.io/illustrated-gpt2/"" rel=""nofollow noreferrer"">here</a>, and argued for as best practice <a href=""https://paperswithcode.com/method/weight-tying"" rel=""nofollow noreferrer"">here</a>.  Yet, for example, Karpathy's mini-GPT implementation seems to use two different matrices:</p>
<pre><code>self.tok_emb = nn.Embedding(config.vocab_size, config.n_embd) # &lt;--- This would be E
self.pos_emb = nn.Parameter(torch.zeros(1, config.block_size, config.n_embd))
self.drop = nn.Dropout(config.embd_pdrop)
# transformer
self.blocks = nn.Sequential(*[Block(config) for _ in range(config.n_layer)])
# decoder head
self.ln_f = nn.LayerNorm(config.n_embd)
self.head = nn.Linear(config.n_embd, config.vocab_size, bias=False) # &lt;--- This has the same dimensions as Etranspose but is clearly a different matrix

</code></pre>
<h2>Q2. If it is correct, how does can it work?</h2>
<p>This seems to be tasking <span class=""math-container"">$E$</span> with two very different, even opposing, functions:</p>
<ul>
<li>Map vocab to their <em>meaning</em> on the input side; higher magnitude indicates &quot;more meaning&quot;</li>
<li>Map meaning to the <em>most likely</em> vocab on the output side; higher magnitude indicates greater likelihood</li>
</ul>
<p>When outputting, we want the softmax to be highest when the word is most likely; magnitude of the output matrix should be roughly proportional to how likely the word is two appear.</p>
<p>Yet, when inputting, magnitude has <em>nothing to do with likelihood</em>.  Magnitude on the input side captures some element of meaning: perhaps how extreme or intense the meaning is, perhaps another aspect (not necessarily easily interpreted).</p>
","natural-language-processing"
"36128","In-batch negative training Improves the results","2022-06-30 13:02:57","","0","1237","<machine-learning><natural-language-processing><papers><question-answering>","<p>I have read <a href=""https://arxiv.org/abs/2004.04906"" rel=""nofollow noreferrer"">Dense passage retrieval for Open Domain Question Answering</a>, and in page 6 it talks about in-batch negative training, it states the following:</p>
<blockquote>
<p>We find that using a similar
configuration (7 gold negative passages), in-batch
negative training improves the results substantially.
The key difference between the two is whether the
gold negative passages come from the same batch
or from the whole training set. Effectively, in-batch
negative training is an easy and memory-efficient
way to reuse the negative examples already in the
batch rather than creating new ones. It produces
more pairs and thus increases the number of train-
ing examples, which might contribute to the good
model performance. As a result, accuracy consis-
tently improves as the batch size grows.</p>
</blockquote>
<p>I know that it is more efficient and hence we can increase the number of negatives by increasing the batch size (or we can use other techniques if we cannot do that), but in the paper they have the following table:</p>
<p><a href=""https://i.sstatic.net/G868r.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/G868r.png"" alt=""table 3"" /></a></p>
<p>How having the same number of negatives (3rd &amp; 4th rows) gave different results?</p>
<p>Is that something realted to the gradient or something, since we sample from the same examples that contribute to calculating the gradient in one step?</p>
","natural-language-processing"
"35905","What is the best way to create a vector representation (with fasttext) of a list of words?","2022-06-13 15:35:41","","0","187","<natural-language-processing><word-embedding><word2vec>","<p>Basically what I want to do is to create a single vector representation of a list of skills belonging to employees at a company (one list per employee). The embedding will be a representation of an employee's &quot;profile&quot;. The motivation behind this is (among other reasons) that I want to be able to identify clusters among the employees.</p>
<p>Assume I already have a trained FastText model (or Word2vec) that can generate good representations of the individual words in the list.</p>
<p>My current solution is simply to add all the word embeddings in an employee's list together (without any form of normalization). But I'm very unsure about whether this is the best approach to generating a good representation of an employee's profile.</p>
<p>The dimensions of the vectors are 300 and there are usually around 10 to 30 skills in a single list.</p>
<p>Any help would be greatly appreciated!</p>
<p>Example:</p>
<p>Let's say we have an it-consulting firm where each employee has their own set of skills. Some consultants are more experienced or versatile, thus having more skills listed in their profiles. eg we have:</p>
<pre><code> alex_skills = ['microsoft azure', 'machine learning', 'data science', 'python', 'sklearn', 'xgboost', 'nginx', 'flask', 'SHAP', 'git', 'word2vec', 'statistics', 'deep learning', 'linux','docker compose', 'pandas']

carla_skills = ['devops', 'machine learning', 'deep learning', 'continuous integration', 'kubernetes', 'python','git', 'speech recognition', 'github', 'bitbucket', 'scikit-learn', 'natural language processing', 'pandas']

adam_skills = ['automation', 'robotic process automation', 'banking and finance', 'process mapping', 'IAM', 'väsentlighetsanalys', 'business intelligence', 'auditor', 'requirements handling', 'risk management', 'coordinator', 'project manager', 'data visualization']
</code></pre>
<p>As you can see Alex and Carla are more similar and should possibly be in the same cluster, while Adam might not be.</p>
<p>So I wan't to make a vector representation of the entire list of skills. And then I will use these vector representations in some clustering algorithm (eg HDBscan) and by some distance metric (eg. cosine distance), capture the relation between Alex and Carla.</p>
<p>I suspect the fact that the lists have different lengths might cause problems, therefore maybe divide by the length of the list after adding?</p>
","natural-language-processing"
"35886","Can I use Sentence-Bert to embed event triples?","2022-06-12 08:08:36","","0","48","<natural-language-processing><bert><embeddings><information-retrieval>","<p>I extracted event triples from sentences using OpenIE. Can I concatenate the components in the event triple to make it a sentence and use Sentence-Bert to embed the event?
It seems no one has done this way before so I am questioning my idea.</p>
","natural-language-processing"
"35878","Current state of the art and datasets for combining NLP and CV?","2022-06-11 09:15:54","","1","338","<natural-language-processing><reference-request><computer-vision>","<p>I was considering a scenario where natural language processing (NLP) and computer vision (CV) are combined, for example in extended reality systems that get as input both natural language and non-verbal information, e.g. human gestures, and can comprehend it. For example, the agent would get language and non-verbal input and talk to a user.</p>
<p>How could this be realized? My naive guess would be a conditional transformer, where the conditioning happens on the non-verbal input, but I'm not sure how exactly the conditioning could happen. <strong>What is a current state-of-the-art model for combining NLP and CV?</strong></p>
<p>Also, are there datasets available for the aforementioned use case? I'm thinking of the scenario where a sentence, e.g.</p>
<blockquote>
<p>Yeah, I like him too!</p>
</blockquote>
<p>can either mean what is said, and the non-verbal input could be that the person saying it is smiling. However, if the non-verbal input is some laughter, then the above sentence might be meant ironically. <strong>Is there any dataset for this, where sentences and non-verbal inputs are combined?</strong> (Please note that I'm not talking about the generation of a sentence to an image, I'm referring to a <strong>combination</strong> of NLP and CV.)</p>
<p>Thanks a lot!</p>
","natural-language-processing"
"35874","Why use a fully connected layer for attention?","2022-06-11 00:48:34","","2","411","<natural-language-processing><recurrent-neural-networks><attention>","<p>In the paper <a href=""https://arxiv.org/pdf/1409.0473.pdf"" rel=""nofollow noreferrer"">Neural Machine Translation by Jointly Learning to Align and Translate</a>, attention is used with a single fully connected layer. Specifically, in the auto-regressive set up (equation 4), the context vector c_i is computed using attention  from all the annotations (equation 5).</p>
<p>I'm curious why a fully connected layer is used here and not some other architecture that captures &quot;locality&quot; better: the relationship between adjacent states should be similar independent of where in the sentence they occur. I.e. the relationship between state 1 and 2 should be analogous or similar to the relationship between states n and n+1? However, the fully connected layer treats these two relationships as completely independent weights: a[1,2] vs a[n,n+1].</p>
<p><a href=""https://i.sstatic.net/NlHEZ.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/NlHEZ.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"35818","How to configure a neural network to selectively change only certain characters in a string?","2022-06-07 00:09:55","","0","114","<neural-networks><natural-language-processing><applications>","<p>I'm trying to figure out how to train a neural network to macronize Latin text.
Essentially, in Latin, vowels can either be long or short, and length is indicated with a macronized character: i.e. o is short, ō is long. Most advanced texts don't mark vowel length, which can be an issue because vowel length determines pronunciation and word meaning: liber means book, līber means free, for example.</p>
<p>Is there any way to train a neural network to replace only vowels in a word while contextually evaluating it as part of a larger sentence? I've tried training an RNN many-to-many model to map unmacronized text to macronized text, but it ends up being incredibly inefficient and inaccurate because an unmacronized word can map to <em>any</em> macronized word. Ultimately, the only characters in each word that should ever change are the vowels, and even then only to their macronized counterparts: liber can be liber, līber, libēr, or lībēr only.</p>
<p>There is an abundance of training data in the form of parallel macronized and unmacronized text. This feels like a simple question but I've been unable to find any resources specifically detailing how to implement this. Any pointers would be greatly appreciated.</p>
","natural-language-processing"
"35782","Is there any way to train a regression model with negative values that is more stable?","2022-06-04 13:17:24","","0","1030","<machine-learning><natural-language-processing><activation-functions><prediction><regression>","<p>I have a regression model where my target values contain roughly 60% negative values and 40% positive values. My model architecture includes a robert-large, 1 linear layer. I trained it after 1 epoch, the loss goes down to 0.089, but when I try to predict on test-set, every samples have the same values.</p>
<p>I try to add tanh activation in the last layer and switch to roberta base model, this time the model predict different values, on the train set, it predicts positive and negative values but on the test-set, it only produces positive ones.</p>
<p>Is there any way to train a regression model with negative values that is more stable?</p>
","natural-language-processing"
"35748","What are semantic word spaces in NLP?","2022-06-02 09:17:29","","1","99","<natural-language-processing><terminology><papers>","<p>In the abstract of <a href=""https://aclanthology.org/D13-1170.pdf"" rel=""nofollow noreferrer"">this paper</a>, it's written</p>
<blockquote>
<p><strong>Semantic word spaces</strong> have been very useful but cannot express the meaning of longer phrases in a principled way.</p>
</blockquote>
<p>I would like to understand what <strong>semantic word spaces</strong> are. I find <a href=""https://en.wikipedia.org/wiki/Semantic_space"" rel=""nofollow noreferrer"">Wikipedia's</a> explanation unsatisfactory:</p>
<blockquote>
<p>Semantic spaces in the natural language domain aim to create representations of natural language that are capable of capturing meaning.</p>
</blockquote>
<p>How exactly are these representations computed? For example, if we take the sentence</p>
<blockquote>
<p>I like reading books.</p>
</blockquote>
<p>What would be its semantic word space? Or am I confusing semantic <strong>word</strong> spaces with semantic spaces here?</p>
","natural-language-processing"
"35530","Why do Convolution Neural Networks work on NLP/sequential tasks?","2022-05-16 05:55:11","","3","164","<convolutional-neural-networks><natural-language-processing><applications>","<p>I have read some articles where people use 1D CNN for NLP tasks like sentiment analysis. My questions are, given that CNNs are largely used for images, how/why does this work on sequences/NLP tasks? And, are there any specific CNN-based architectures that outperform transformers?</p>
","natural-language-processing"
"35509","Is there an unsupervised learning method for determine the most common questions within a dataset?","2022-05-13 21:41:44","","0","21","<natural-language-processing><unsupervised-learning><question-answering>","<p>I have a dataset consisting of questions from customers. I am curious of the n most frequent asked questions, regardless of the variation the questions might appear in.</p>
<p>Is there NLP methods for finding n most frequent asked questions?</p>
","natural-language-processing"
"35444","Can you train GPT-J to use a specific list of words and prioritise them?","2022-05-07 15:12:32","","1","204","<machine-learning><natural-language-processing><gpt><natural-language-generation><gpt-3>","<p>Can you train GPT-J to use a specific list of words and prioritise them? If so, please could you share how I would go about this?</p>
<p>Say you're using GPT-J to write a story, you might wish to mention certain key terms more than others, or in a specific order.</p>
","natural-language-processing"
"35424","Examples of self-explainable models used in NLP other than prototype-based","2022-05-05 13:41:04","","1","48","<natural-language-processing><explainable-ai>","<p>I am looking for all the methods used in NLP that are self-explainable, or explainable by design. That is to say, the ones that use the predictive model itself to explain the entire model's predictive reasoning (a.k.a. directly interpretable model).</p>
<p>I have only a few example in mind:</p>
<ul>
<li><em>prototype-based methods</em>, models that reveal the network's reasoning by providing prototypical explanations. It may allow users to directly manipulate a network component according to their preferences like Rasa or, more recently, <a href=""https://www.researchgate.net/publication/355092869_Interactively_Generating_Explanations_for_Transformer-based_Language_Models"" rel=""nofollow noreferrer"">Proto-Trex</a>.</li>
<li><em>Human-in-the-loop ML</em>, where the co-creation allows to interpret and update the model logic directly by enabling interaction with rule generators themselves. But as the first of these are created with deep learning, is it truly part of explainable AI? An example of this is <a href=""https://arxiv.org/pdf/1907.11184.pdf"" rel=""nofollow noreferrer"">HEIDL</a>, which did reference to related work such as <a href=""https://www.cs.rochester.edu/hci/pubs/pdfs/chorus.pdf"" rel=""nofollow noreferrer"">Chorus</a></li>
</ul>
","natural-language-processing"
"35423","BERT2: How to use GPT2LMHeadModel to start a sentence, not complete it","2022-05-05 13:34:16","","0","585","<natural-language-processing><machine-translation><natural-language-generation><gpt-2>","<p>I am using GPT2LMHeadModel to change the way GPT2 choose the next word in a sentence. At this point, I have to give the initial part of the sentence and GTP2 starts to predict the better next word.</p>
<p>I want GPT2 to read an entire sentence and then start a new one based on that (like it does with translation)</p>
<p>Is there any kind of parameter that I need to set up in order to make GPT2 start a sentence from zero, not complete an initial one?</p>
","natural-language-processing"
"35369","Is there any research on anger and distrust detection (presence and level of political cynicism)?","2022-04-29 21:22:39","","1","40","<machine-learning><natural-language-processing><reference-request>","<p>The undergrad research project I'm working on would require me to detect presence and level of <strong>political cynicism</strong> from reddit posts.
According to definition political cynicism consists of</p>
<ul>
<li>anger</li>
<li>distrust</li>
</ul>
<p>towards politicians or political institutions.</p>
<p>Does anyone know of existing research relevant for my goal?
I know approaches exist for emotion detection, so the anger component should be no problem.</p>
<p>But how could I model distrust or at least come close to it?</p>
<p>I have access to a large dataset consisting of reddit posts (from politics related subreddits) with labels measuring the political extremity of the user. Political cynicism is one of the most distinguishing features of those on the extreme ends of the political spectrum compared to moderates according to data from psychology, so the data should somehow reflect this correlation, and therefore there should be a some opportunity for a CNN to pick up on it. But would there be a way to then isolate this component?</p>
<p>Any guidance would be appreciated.</p>
<p>I'm a newbie to NLP so please forgive any ignorance expressed through this post.</p>
","natural-language-processing"
"35307","How to represent multi-label colours in one-hot encoding?","2022-04-23 13:43:41","","0","78","<neural-networks><machine-learning><natural-language-processing><data-preprocessing><bag-of-words>","<p>Say I want to predict the price of a gemstone based on its colour.</p>
<p>I have two options:</p>
<ul>
<li>averaging over its colour on an RGB scale, or</li>
<li>using its textual description.</li>
</ul>
<p>If I was to choose the latter, how would I go about feeding this to my neural network?</p>
<p>Priori knowledge: Usually a gemstone is defined by its colour and the &quot;degree&quot; of this colour: Example fancy bright green.</p>
<p>Here I could obviously let every combination of colour and degree be its own value in the one-hot vector. To implement this I could use some sort of hash function, if this makes sense, how specifically would I make a hash function that could do this?</p>
<p>If this solution doesn't make sense, what would you suggest?</p>
<p>Tough example of data:
&quot;Natural Fancy Deep Yellowish Brown&quot;</p>
","natural-language-processing"
"35305","How can I vectorize fictional single word (not sentence!) for classification?","2022-04-23 08:07:33","35308","0","38","<natural-language-processing><reference-request><classification><feature-engineering><vectors>","<p>I am working on fictional single words (names) generator that have to sound like words from a given sample. I have the generator up and running that gives reasonable words 70% of time. I thought of improving this value, ideally to ~99% (so no manual step is necessary to discard clearly missed words).</p>
<p>I've already attempted <em>fuzzy matching</em> to any word in the initial sample (and rejecting words below given thresholds), and this winded up reasonable answers to 95%-99%, but in my experiments this approach is rejecting too many well-sounding names (even 60-70 rejections per 1 generated name - this removes a lot of entropy from the initial set).</p>
<p>Now, I am thinking of using classification instead to tackle the problem from another angle: using classification to discard the generated name.</p>
<p>The problem I have is I have to vectorize a single word based on its sound for classification. I've already excessively searched the Internet and the only solution I see are for vectorizing <em>texts</em>, not <em>single words</em>.</p>
<p>So, the question here: what kind of algorithm for vectorization of single fictional word based on its sounding have I missed?</p>
","natural-language-processing"
"35293","How do I perform automatic evaluation of my NLP model?","2022-04-21 11:24:34","","0","35","<machine-learning><natural-language-processing><metric>","<p>I have a model which converts sets of keywords to sentence, but I've to quantify it's quality. In computer vision, we would calculate the model's accuracy, I'm kind of lost and how do I go about using baselines as well, am thinking of using BLEU and ROUGE on pairs of data not used during training, is this the correct way to go? Can someone please advise?</p>
<p>And should I average my BLEU/ROUGE scores I got for each iteration? Is there a better metric to evaluate NLP models?</p>
<p>My dataset is like</p>
<pre><code>keyword, keyword, keyword -&gt; sentence
</code></pre>
","natural-language-processing"
"35290","When training a seq2seq model is it better to train using the models outputs or expected outputs?","2022-04-21 02:04:05","","1","98","<natural-language-processing><recurrent-neural-networks><transformer><attention><seq2seq>","<p>When training any seq2seq model you have a <code>target</code> and a <code>source</code>. The <code>source</code> may be a sentence such as:</p>
<blockquote>
<p>I_walked_the_dog</p>
</blockquote>
<p>And the target being</p>
<blockquote>
<p>_walked_the_dogg</p>
</blockquote>
<p>Where as you can see the expected output for the initial <code>I</code> is a space <code>_</code>. My question is, at training time, whether to use the models previous outputs for predicting the next output, or to run the training simultaneously using the expected outputs. To illustrate this more clearly, see below:</p>
<p><a href=""https://i.sstatic.net/kEOcz.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kEOcz.png"" alt=""enter image description here"" /></a></p>
<p>The incentive for training using the expected outputs is that all time steps can be trained simultaneously, so it speeds up training by a factor of the sequence lengths. However, it means that training is not representative of what the network will realistically be doing at testing time, as at testing time the network will not have perfect previous outputs, but rather only it's own.</p>
","natural-language-processing"
"35204","Is attention always better then an RNN/CNN?","2022-04-14 07:05:24","","1","1617","<machine-learning><natural-language-processing><recurrent-neural-networks><attention>","<p>We've all read the <a href=""https://arxiv.org/abs/1706.03762"" rel=""nofollow noreferrer"">attention is all you need</a> paper, but is it really <em>all</em> you need? Can you effectively replace any RNN/CNN with an attention transformer and see better results?</p>
","natural-language-processing"
"35195","Convolutional network for multilabel classification in NLP","2022-04-13 15:51:52","","1","23","<convolutional-neural-networks><natural-language-processing><tensorflow><multi-label-classification>","<p>I am trying to label code snippets and I base on this article: <a href=""https://arxiv.org/pdf/1906.01032.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/1906.01032.pdf</a></p>
<p>My dataset is just code snippets (tokenized as ascii characters) and 500 different labels from StackOverflow. Currently I have around 1,600,000 samples after filtering these with negative votes and less than 10 characters</p>
<p>This is my current implementation of network architecture in TensorFlow:</p>
<pre><code>def build_cnn(config, hparams) -&gt; tf.keras.Model:
    params = config[&quot;params&quot;]
    inputs = tf.keras.layers.Input((1024, ))
    x = tf.keras.layers.Embedding(input_dim=1024, output_dim=16)(inputs)

    conv_outputs = []
    for filters, kernel in [
        (128, 2),
        (192, 3),
        (256, 4),
        (512, 5)
    ]:
        data = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel, padding=&quot;valid&quot;)(x)
        data = tf.keras.layers.BatchNormalization()(data)
        data = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel, padding=&quot;valid&quot;)(data)
        data = tf.keras.layers.Lambda(lambda a: tf.reduce_sum(a, axis=1))(data)
        conv_outputs.append(data)

    # Concatenation: output size is sum of all convolution filters
    concat_output = tf.keras.layers.Concatenate()(conv_outputs)
    concat_output = tf.keras.layers.BatchNormalization()(concat_output)

    concat_output = tf.keras.layers.Dense(480, activation=&quot;relu&quot;)(concat_output)
    concat_output = tf.keras.layers.BatchNormalization()(concat_output)

    concat_output = tf.keras.layers.Dense(480, activation=&quot;relu&quot;)(concat_output)
    concat_output = tf.keras.layers.BatchNormalization()(concat_output)

    outputs = tf.keras.layers.Dense(500, activation=&quot;sigmoid&quot;)(concat_output)

    return tf.keras.Model(inputs=inputs, outputs=outputs)
</code></pre>
<p>As my metric I use <code>F1Score</code> from <code>tensorflow_addons</code>:</p>
<pre><code>model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=[
        F1Score(num_classes=500, average=&quot;micro&quot;, threshold=0.5, name=&quot;f1_micro&quot;),
        F1Score(num_classes=500, average=&quot;macro&quot;, threshold=0.5, name=&quot;f1_macro&quot;),
    ]
)
</code></pre>
<p>After 5 epochs results look like this (later it wasn't really improving):
<a href=""https://i.sstatic.net/Cp4I3.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Cp4I3.png"" alt=""enter image description here"" /></a></p>
<p>My first idea was to apply class weights but it didn't help. Next idea was an experiment with only 10 tags (still multilabel) and this is the result:</p>
<pre><code>{
    &quot;step&quot;: 12,
    &quot;loss&quot;: 0.2092941254377365,
    &quot;f1_micro&quot;: 0.6354409456253052,
    &quot;f1_macro&quot;: 0.5389766097068787,
    &quot;val_loss&quot;: 0.25258970260620117,
    &quot;val_f1_micro&quot;: 0.547073483467102,
    &quot;val_f1_macro&quot;: 0.4620901644229889
}
</code></pre>
<p>Last thing: after I saw some results with evaluation I saw that most of the outputs are empty or only 1 class, but using smaller threshold didn't increase the metric</p>
<p>Any idea how to improve the model for bigger number of tags? is it the metric?</p>
","natural-language-processing"
"35166","Does it make sense to add an additional attention layer while fine-tuning Bert?","2022-04-11 11:03:52","","0","856","<neural-networks><deep-learning><natural-language-processing><attention><bert>","<p>I'm fine tuning a Bert/Roberta model for a classification task.
As I need to improve my results, I'm thinking about to add an additional attention layer after Bert model and before dense and dropout layers. Is this a good idea?</p>
","natural-language-processing"
"35106","What are examples of simple gradient based NLP models?","2022-04-05 17:07:33","","0","63","<natural-language-processing>","<p>I am looking for a simple example of gradient-based methods for NLP. More specifically I am looking for post-hoc local explanations gradient-based methods, that is to say, which explain a single prediction by performing additional operations (after the model has emitted a prediction). Here is an example of a gradient-based method for &quot;Finance&quot;? (I'm not very sure of what domain it is as it is not NLP, nor Computer Vision, nor time series ...):</p>
<blockquote>
<p>Let us consider a minimal example, where a linear regression is used to estimate the future capital asset <span class=""math-container"">$y_{c}$</span>, based on two investments <span class=""math-container"">$x_{1}$</span> and <span class=""math-container"">$x_{2}$</span>. Let assume the assumptions above are met and the model parameters are estimated as follows:
<span class=""math-container"">$$\mathbb{E}\left[y_{c} \mid x_{1}, x_{2}\right]=1.05 x_{1}+1.50 x_{2},$$</span>
We can derive immediately a global interpretation of this model. Every dollar invested in fund <span class=""math-container"">$x_{1}$</span> will produce capital of <span class=""math-container"">$1.05 \\\$$</span>, while every dollar invested in <span class=""math-container"">$x_{2}$</span> will produce a capital of <span class=""math-container"">$1.50 \\\$$</span>, independently of the values <span class=""math-container"">$x_{1}$</span> and <span class=""math-container"">$x_{2}$</span> might assume in a concrete scenario. Notice that this explanation is purely based on the learned coefficient <span class=""math-container"">$w_{1}=1.05$</span> and <span class=""math-container"">$w_{2}=1.50$</span>. These, sometimes called partial regression coefficients, are themselves candidate attribution values to explain the influence of the independent variables of the target variable:
<span class=""math-container"">$$R_{1}(x)=1.05 \quad R_{2}(x)=1.50$$</span>
Notice also that the coefficients are the partial derivatives of the target variable with respect to the independent variable, therefore this attribution is nothing but the model gradient.</p>
</blockquote>
<p>I thought about transformating it to an NLP example like:</p>
<p><em>Let us consider a minimal example, where a linear regression is used to estimate the toxicity of a text <span class=""math-container"">$y_{c}$</span>, based on the occurence of words <span class=""math-container"">$x_{1}$</span> and <span class=""math-container"">$x_{2}$</span>. Let's assume the assumptions above are met and the model parameters are estimated as follows:</em></p>
<p><span class=""math-container"">$$\mathbb{E}\left[y_{c} \mid x_{1}, x_{2}\right]=1.05 x_{1}+1.50 x_{2},$$</span></p>
<p><em>We can derive immediately a global interpretation of this model. Every occurrence of word <span class=""math-container"">$x_{1}$</span> will produce a toxicity of <span class=""math-container"">$1.05$</span>, while every occurrence of word in <span class=""math-container"">$x_{2}$</span> will produce a capital of <span class=""math-container"">$1.50$</span>, independently of the values <span class=""math-container"">$x_{1}$</span> and <span class=""math-container"">$x_{2}$</span> might assume in a concrete scenario. Notice that this explanation is purely based on the learned coefficient <span class=""math-container"">$w_{1}=1.05$</span> and <span class=""math-container"">$w_{2}=1.50$</span>. These, sometimes called partial regression coefficients, are themselves candidate attribution values to explain the influence of the independent variables of the target variable</em></p>
<p>That look pretty dumb, isn't it? Do you have any better example</p>
<h1>Update : does the ablation model use gradient?</h1>
<p>So it seems my model isn't so dumb, but Ant gave the idea of using the ablation model. I didn't know about this technique but it seems straightforward: you iterate over your text and get rid of a given word in part of the text and see how much the text gains or loses toxicity. It looked very gradient-friendly.</p>
<p>However, I tried to create an ablation algorithm that looks at the k next words and tries to get the toxicity of the word by doing the difference between the text predicted toxicity <span class=""math-container"">$\hat y$</span> and the same one when the text is being ablated <span class=""math-container"">$\hat y_{ablated}$</span>. I inspired myself from <a href=""https://www.mdpi.com/2076-3417/12/3/1427/pdf"" rel=""nofollow noreferrer"">Warren Freeborough's example for time series in his paper page 5</a>.</p>
<p><a href=""https://i.sstatic.net/vAswe.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/vAswe.png"" alt=""enter image description here"" /></a></p>
<p>I get an en error, or sensibility, matrix <span class=""math-container"">$E_{avg}$</span>. But I don't see where any gradient has been used. At most I could say that the model can use gradient. For instance, if it is an RNN, it uses a gradient method, isn't it? But I don't see where ablation uses gradient.</p>
","natural-language-processing"
"34973","Why are GAN models not heavily used for NLP?","2022-03-24 18:14:37","34974","4","4321","<natural-language-processing><generative-adversarial-networks>","<p>I am wondering why there has not been more usage of GANs for NLP. I know there has been research on the subject (The Google Scholar page for the subject is <a href=""https://scholar.google.com/scholar?q=GANs+for+nlp&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart"" rel=""nofollow noreferrer"">here</a>).</p>
<p>Are there any specific reasons why GANs do not work for NLP specifically VQGAN + CLIP variants? I do not understand why most text generated by AI is done through predicting the next letter or word in a sequence with RNNs when GANs have had so much success generating deep fakes and the such instead of say, predicting the next pixel.</p>
","natural-language-processing"
"34966","ontological tree for the concept of a word (eg ""chair"")","2022-03-24 15:55:50","34969","1","35","<natural-language-processing>","<p>I am novice to AI, but I would like to learn the general idea that a machine understands the concepts in a text document.</p>
<p>I would like to ask wether there is an ontological tree of concepts, like a higher class of OBJECTS in which there belongs the FURINTURE, in which there belongs the CHAIR and the TABLE. Is such a thing in NLP? If yes, could someone provide me a way to find such relationships?</p>
","natural-language-processing"
"34898","How might AI analyze abusive discussion using natural language grammar?","2022-03-20 06:19:24","34902","2","86","<natural-language-processing><reference-request><model-request><natural-language-understanding>","<h1>Opening thoughts</h1>
<p>This does not only apply to SE comments, but the idea in general.</p>
<p>This is <em>not</em> a Question for <a href=""https://linguistics.stackexchange.com/"">Linguistics.SE</a>; those Questions might come later, <em>after</em> AI analysis. Example Linguistics Quesions:</p>
<ul>
<li><strong>What grammar categories might AI use to research for an analysis of abusive vs helpful discussion?</strong> <em>(before the AI research, after this OP Question is answered)</em></li>
<li><strong>What grammar patterns can we identify from AI researched that analyzed abusive vs helpful discussion?</strong> <em>(after the AI research)</em></li>
</ul>
<p>This is a Question about how AI might be useful in the real world, thus helping AI programmers decide where to effectively focus energies.</p>
<h1>AI analyzes comments and discussion</h1>
<p>Many web apps and sites (including Facebook, YouTube, and Stack Exchange) analyze posted content using what some people call AI algorithms.</p>
<p>Presuming this is used also for comments on posts on sites such as these...</p>
<p>AI may take many factors into consideration, viz buzz words (type 'COVID' on a post and watch the info-notice pop up), profanities, bigotous phrases, etc.</p>
<p>I'm curious about the results if AI analyzed just the grammar of a history of comments that were deemed &quot;abusive&quot; juxtaposed against a history that was not deemed abusive.</p>
<h1>Why ask?</h1>
<p>Creative-analytical thinkers like Steven Levitt (viz <a href=""https://www.freakonomics.com/"" rel=""nofollow noreferrer"">Freakonomics</a>) and <a href=""https://www.gladwellbooks.com/"" rel=""nofollow noreferrer"">Malcolm Gladwell</a> like to discuss counter-intuitive findings from research. Levitt says that this is &quot;economics&quot; (nothing to do with money). Even the video game <a href=""https://leagueoflegends.com"" rel=""nofollow noreferrer"">League of Legends</a> has stats on how often certain gaming choices (items, champion, etc) win and lose. But, we need the data. I want to know if &quot;grammar&quot; is a good place to dig.</p>
<p>I would be curious if there were any grammar patterns that might indicate abuse, as might be found by AI research from past comments. Pardon the grammar lingo, but for example:</p>
<ul>
<li>Complex subjects</li>
<li>Imperatives</li>
<li>Subjunctives</li>
<li>Passives</li>
<li>Verbal pauses (Bothering to type out &quot;Um...&quot; in &quot;Um... No.&quot;)</li>
<li>Direct Objects vs Indirect Objects vs &quot;<a href=""https://english.stackexchange.com/questions/441683"">Raised Objects</a>&quot;</li>
<li>Prepositions</li>
</ul>
<p>...Say research finds that comments containing &quot;at&quot; were 60% more likely to be flagged as abusive. That would be great content to ask on Linguistics to see if there were other patterns to analyze.</p>
<p>I don't know what should be analyzed, nor do I know what all grammatical categories would go into such an analysis. That would be my next Question for Linguistics.</p>
<h1>Scope of my question</h1>
<p>I'm trying to ask for open-ended answers, not binary (yes/no) answers, while also narrowing scope. So, let me put it this way...</p>
<h2>Can AI be used to analyse abusive vs non-abusive discussions through grammar patterns and categories?</h2>
<p>If so, which models or algorithms can be used to achieve that? References are also appreciated.</p>
","natural-language-processing"
"34892","Are any AI systems available, or in development, for finding and analysing fallacious inference in natural language text?","2022-03-19 15:00:01","","2","72","<natural-language-processing><reference-request>","<p>Poor reasoning, and ignorance in general, is the source of a lot of <a href=""https://philosophy.stackexchange.com/questions/64954/is-the-moral-compass-of-an-individual-inherent-or-is-this-aspect-of-their-nature/89759#89759"">suffering and evil</a>. Covertly erroneous logic is often used in manipulation. And much of this broken thought is being used directly in the training of AI.</p>
<p>There has been talk of, and development in, <em>fact-checking</em>, such as for language transformers. But what about <em>reasoning</em>?</p>
<p>The function in mind is specifically being able to process a potentially large text body, analysing all logic and implied relations for fallacy and other misleading reasoning. Perhaps shades of colour could indicate level of error. A bonus would be output listing and explaining the mistakes, maybe like compiler errors -- &quot;fallacy x between premise y and conclusion z&quot;.</p>
<p><strong>Are any AI systems available, or in development, for finding and analysing <em>fallacious inference</em> in natural language text?</strong></p>
","natural-language-processing"
"34790","Is there any reason for giving an index to a token based on its frequency in the text?","2022-03-11 06:09:59","","1","258","<natural-language-processing><recurrent-neural-networks><sequence-modeling>","<p>In pre-processing of text, we need to assign a number for each token in a text. Then only we can pass it to a model. In pre-processing of text, we need to assign a number for each token in a text. The paragraph  from <a href=""https://d2l.ai/chapter_recurrent-neural-networks/text-preprocessing.html"" rel=""nofollow noreferrer"">this section</a> named <strong>Text Preprocessing</strong> recommended indexing according to the frequency of the token</p>
<blockquote>
<p>The string type of the token is inconvenient to be used by models,
which take numerical inputs. Now let us build a dictionary, often
called vocabulary as well, to map string tokens into numerical indices
starting from 0. To do so, we first count the unique tokens in all the
documents from the training set, namely a corpus, and then <strong>assign a
numerical index to each unique token according to its frequency</strong>.
Rarely appeared tokens are often removed to reduce the complexity. Any
token that does not exist in the corpus or has been removed is mapped
into a special unknown token “”. We optionally add a list of
reserved tokens, such as “” for padding, “” to present the
beginning for a sequence, and “” for the end of a sequence.</p>
</blockquote>
<p>I want to know whether it is necessary to index in accordance with the frequency of token or any unique index serves the purpose?</p>
","natural-language-processing"
"34765","Next Sentence Prediction for 5 sentences using BERT","2022-03-09 01:25:58","","0","510","<natural-language-processing><recurrent-neural-networks><bert>","<p>I am given a dataset in which each instance consisting of 5 sentences. The goal is to predict the sequence of numbers which represent the order of these sentences.</p>
<blockquote>
<p>For example, given a story:</p>
<p>He went to the store. He found a lamp he liked. He bought the lamp.
Jan decided to get a new lamp. Jan's lamp broke.</p>
<p>your system needs to provide an answer in the following form:</p>
<p>2   3   4   1   0</p>
<p>where the numbers correspond to the zero-based index of each sentence
in the correctly ordered story. So &quot;2&quot; for &quot;He went to the store.&quot;
means that this sentence should come 3rd in the correctly ordered
target story. In This particular example, this order of indices
corresponds to the following target story:</p>
<p>Jan's lamp broke. Jan decided to get a new lamp. He went to the store.
He found a lamp he liked. He bought the lamp.</p>
</blockquote>
<p>My initial idea is to extended the NSP algorithm used to train BERT, to 5 sentences somehow. I can't find an efficient way to go about doing so. All suggestions would be appreciated.</p>
<p>Thank you!</p>
","natural-language-processing"
"34760","Dimensions of a Transformer model and purpose of masking","2022-03-08 13:30:58","34763","1","1007","<neural-networks><machine-learning><natural-language-processing><transformer>","<p>I'm currently studying the Transformer model (<strong>Attention is all you need</strong>) and after reading it I still have some questions for which I get conflicting answers if I google them:</p>
<ul>
<li>What exactly are the dimensions of the input to the encoder of a transformer, from what I've seen you can input sentences with dynamic lengths but in the paper it seems like all layers expect the K/Q/V matrices to have dimensions of <code>d_model, d_k</code> or <code>d_v/d_q</code></li>
<li>Same question for the decoder, what exactly are the input dimensions and how do the attention layers handle dynamic dimensions if its possible</li>
<li>Another question is is masking only used for training where you input the whole sentence as the input to the decoder or does it have another purpose than that (especially in inference)</li>
</ul>
","natural-language-processing"
"34739","How do we reduce the output dimensions of BERT?","2022-03-05 17:38:08","","0","2183","<machine-learning><natural-language-processing><transformer><bert>","<p>The output dimensions of BERT are 768-dimensional, is it possible to reduce them to a lower, custom number? For example, if there is another BERT-based transformer model which has a lower count of ouput dimensions, if it's possible to fine tune BERT on MLM to output lower dimension encodings etc.</p>
<p>And if not, are there any possible workarounds for this issue?</p>
","natural-language-processing"
"34710","Are positional embeddings computed during or before training?","2022-03-03 11:14:43","","0","180","<natural-language-processing><transformer><positional-encoding>","<p>I'm trying to practically frame the concept of <em>positional embeddings</em> as introduced in the original <a href=""https://arxiv.org/abs/1706.03762"" rel=""nofollow noreferrer"">paper</a>.</p>
<p>As far as I've understood, what we do is basically creating some other vectors in addition to the original <em>embeddings</em> of our inputs. So if I have my input <span class=""math-container"">$X \in \mathbb{R}^{n \times d}$</span> with shape <code>(64,103)</code> (so <span class=""math-container"">$n$</span> here is the batch size), I will be creating a matrix <span class=""math-container"">$P \in \mathbb{R}^{n \times d}$</span> where each <span class=""math-container"">$d$</span> dimensional vector will contain information about positions. Now, these vectors are generated from sinusoid functions with an initial frequency of <code>1e-4</code>, and then initial embeddings <span class=""math-container"">$X \in \mathbb{R}^{n \times d}$</span> and positional embeddings <span class=""math-container"">$P \in \mathbb{R}^{n \times d}$</span> are summed together to get a new input <span class=""math-container"">$X' \in \mathbb{R}^{n \times d}$</span>.</p>
<p>Now, all this process is happening <em>before</em> the start of training right? Positional embeddings are not <em>learned/modified</em> during backpropagation?</p>
","natural-language-processing"
"34660","Compare Strings composed from 2-3 words using NLP/ML(Python)","2022-02-26 13:36:05","","0","1824","<machine-learning><natural-language-processing><python><algorithm-request><spacy>","<p>I have a database of books. Each book have a list of categories that describe the genre/topics of the book (I use Python models).</p>
<p>Most of the time, the categories in the list are composed from 1-3 words.</p>
<p>Examples of a book category list:</p>
<pre><code>['Children', 'Flour mills', 'Jealousy', 'Nannies', 'Child labor', 'Conduct of life'],
[&quot;Children's stories&quot;, 'Christian life'],
['Children', 'Brothers and sisters', 'Conduct of life', 'Cheerfulness', 'Christian life'],
['Fugitive slaves', 'African Americans', 'Slavery', 'Plantation life', 'Slaves', 'Christian life', 'Cruelty']
</code></pre>
<p>I want to create/use an algorithm to compare the books and find similarity between 2 books using NLP/machine learning models.</p>
<p>The categories are not well defined and tend to change. For example, there can be a category of <code>'story'</code> and other called <code>'stories'</code> category (since the text in the system don't saved categories and use a open text box).</p>
<p>So far I tried 2 algorithms:</p>
<ul>
<li>cosine similarity with WordNet - split the category to bag of words and check if each word have synonym in the other book lists.</li>
<li>Check the similarity using the <code>nlp</code> model of the spacy library (Python) - distance algorithm.</li>
</ul>
<p>So far I used WordNet model from the <code>nltk</code> package and <code>spacy</code>
had problem with those two algorithms because when the algorithm compare a categories that contain 2 or 3 words the results wasn't accurate and each of them had specific problems.</p>
<p>Which algorithm and models (in Python), can I use to compare between the books that can handle strings that contain 2 or 3 words?</p>
<p>B.w is the first time I ask here. If you need more details about the database or what I did so far please tell me.</p>
","natural-language-processing"
"34461","Sequence Embedding using embedding layer: how does the network architecture influence it?","2022-02-08 10:49:06","","2","1709","<deep-learning><natural-language-processing><long-short-term-memory><sequence-modeling><embeddings>","<p>I want to obtain a dense vector representation of protein sequences so that I can meaningfully represent them in an embedding space. We can consider them as sequences of letters, in particular there are 21 unique symbols which are the amino acids (for example: MNTQILVFIACVLIEAKGDKICL).</p>
<p>My approach is to use a sequence embedding that can be learned as a part of a deep learning model (built with Python using Keras libraries), that is a classifier (supervised) neural network which I train to classify sequences according to the host species they belong to. The steps I follow are the following:</p>
<ol>
<li><em><strong>Tokenization</strong></em>. The only way I can tokenize these sequences of amino acids symbols is to consider single characters as tokens. I also found this example in Kaggle <a href=""https://www.kaggle.com/danofer/deep-protein-sequence-family-classification"" rel=""nofollow noreferrer"">Deep Protein Sequence family Classification</a> in Python that classifies different proteins and uses single amino acids as tokens.</li>
<li><em><strong>Embedding</strong></em>. Stealing words from the answer to the question <a href=""https://datascience.stackexchange.com/questions/27025/how-the-embedding-layer-is-trained-in-keras-embedding-layer"">How the embedding layer is trained in Keras Embedding layer</a>:</li>
</ol>
<blockquote>
<p>An embedding layer is <em>a trainable layer</em> that contains 1 embedding matrix, <em>which is two dimensional</em>, in one axis <em>the number of unique values the categorical input can take</em> (for example 26 in the case of lower case alphabet) and on the other axis <em>the dimensionality of your embedding space</em>. The role of the embedding layer is to map a category into a dense space in a way that is useful for the task at hand, at least in a supervised task. This usually means there is some semantic value in the embedding vectors and categories that are close in this space will be close in meaning for the task.</p>
</blockquote>
<p>Moreover, useful words from the blog titled as <a href=""https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526"" rel=""nofollow noreferrer"">Neural Network Embeddings Explained</a>:</p>
<blockquote>
<p>The main issue with one-hot encoding is that the transformation does not rely on any supervision. We can greatly improve embeddings by learning them using a neural network on a supervised task. <em>The embeddings form the parameters — weights — of the network which are adjusted to minimize loss on the task. The resulting embedded vectors are representations of categories where similar categories — relative to the task — are closer to one another.</em></p>
</blockquote>
<p>Thus putting all these pieces together in my case: I choose as tokens the single amino acids, so I have 21 unique symbols (i.e. number of amino acids) and I choose 10 as dimension of the embedding space, thus my embedding layer dimension is 21 x 10. This means that, once the neural network is trained, I can extract the weights of the embedding layer that are 21 vectors (one for each amino acid) and each vector is a 10 dimensional vector.</p>
<p>As the second extract explains, each element of these vectors are values that are adjusted to minimize the loss in the task. I could see each amino acid as if it was a letter in a word and I wanted to classify these words according to something (like positive or negative comment); or as if it was a word in a sentence and I chose as tokens words and I wanted to classify these sentences according to something (like positive or negative comment).</p>
<p>Since I want sequence representation, I have to find a way to put together the embeddings of single amino acids and the only way that I found feasible is to average all the 10 dimensional vectors so to obtain for each sequence a 10 dimensional vector that is the average of the embeddings of all the amino acids. This would for sure highlight if there are over-represented symbols in one sequence with respect to other. <strong>Furthermore</strong>, since each symbol is associated to vectors whose values are adjusted to minimize loss on the task, averaging should preserve each single amino acid meaningful embedding (meaningful embedding according to the task) and give &quot;a global meaningful embedding&quot; of the whole sequence that minimizes the loss on the task. This, in fact, seems to work for simple sentences embeddings. See the answer to a my question post: <a href=""https://datascience.stackexchange.com/questions/104087/how-to-obtain-vector-representation-of-phrases-using-the-embedding-layer-and-do"">How to obtain vector representation of phrases using the embedding layer and do PCA with it</a> in which each word of sentences were considered as tokens and I was looking for vectors embedding the whole sentences. Similarly, here I can see each single amino acid symbol as word and the whole sequence as sentence.</p>
<p>Hence this method should carry/embed two information: frequencies of letters of sequences and classes to which each sequence belong to (in this case host species).</p>
<p>But I would like it to consider also the global structure of letters positions (not only the relative frequencies), because with this method sequences like: MNTQILVFIACVLIE<strong>AKGDKICL</strong> (sequence 1) and <strong>AKGDKICL</strong>MNTQILVFIACVLIE (sequence 2) are represented by the same 10 dimensional vector.</p>
<p>Thus... from here the third point:</p>
<ol start=""3"">
<li><em><strong>Choice of neural network architecture</strong></em>. <strong>Does the choice of neural network architecture influence the embedding of each single amino acid symbol and, consequently, the embedding of the entire sequence ?</strong> For example, if I use a LSTM neural network that should &quot;memorize&quot; the global structure of sequences, would it improve the dense vector representation (both in general and in this particular case) ? <strong>I would expect yes</strong> since, as reported also in the extracts, this embedding layer (so its weights) is trained as all the others so the backpropagation algorithm updates also these weights. In other words, if LSTM network has the power to recognize the importance of the position of each character according to the task (for example, it is able to learn that: if a letter is in position 1, it means it belongs to human, while instead if it is in position 2, it means it belongs to dog) then weights should be updated also according to this. Differently from a simple deep learning model that is not able to consider this information and to deal with sequences.</li>
</ol>
<p>I understand that if I average the embeddings of the single amino acids, I would have anyway the problem that sequences like MNTQILVFIACVLIE<strong>AKGDKICL</strong> sequence 1 and <strong>AKGDKICL</strong>MNTQILVFIACVLIE sequence 2 would have the same dense vector representation. <em>But does, also in this case, a better choice of the network architecture give a better result in some way ?</em></p>
<p>I apologize for the long question and I thank you in advance.</p>
","natural-language-processing"
"34448","model to generate suggestions for improving the cosine similarity of two documents?","2022-02-07 12:06:48","","0","28","<machine-learning><natural-language-processing><cosine-similarity>","<p>I am working on a system that compares a source document to a target document and then generate alternative variations of the source document. The goal is to reach a higher cosine similarity between the two documents, say +80%. There's already plenty of articles on how to find the similarity difference, but not many on how to generate suggestions or improvements.</p>
<p>I've never heard of a model that can do this, so how do I build a model that can suggest altered variations of a source document with the ultimate goal of increasing its similarity to a given target document?</p>
<p><strong>Articles on document similarity</strong></p>
<ul>
<li><a href=""https://medium.com/@adriensieg/text-similarities-da019229c894"" rel=""nofollow noreferrer"">https://medium.com/@adriensieg/text-similarities-da019229c894</a></li>
<li><a href=""https://www.sciencedirect.com/topics/computer-science/cosine-similarity"" rel=""nofollow noreferrer"">https://www.sciencedirect.com/topics/computer-science/cosine-similarity</a></li>
</ul>
","natural-language-processing"
"34115","Which data representation of text as input for NLP Deep Learning models?","2022-01-10 19:18:45","","0","628","<machine-learning><deep-learning><natural-language-processing><bag-of-words><tf-idf>","<p>I have been given a data set with 30.000 text documents (each text file is rather small with respect to its length and consists in most cases of around 20 sentences), which are labelled with 0 or 1. Using this data set, I want to train machine learning and deep learning models in order to be able to classify new text files.</p>
<p>On the one hand, I want to use classical machine learning models (such as logistic regression, random forest, SVM, etc.) with the Bag of Words (BoW)/TF-IDF approach. In this context, the text data are represented by a matrix with 30.000 rows (and a number of columns that correspond to the unique words in the overall data set), where each row stands for one observation (i.e., a text document) and each column stands for a unique word. The entries of this matrix are then (kind of) frequencies of the unique words in a text document. However, these approaches do not take the sequence of words, negations, etc. into account.</p>
<p>On the other hand, I want to use new deep learning models (such as RNN, LSTM, BERT, XLNET, etc.), which take the sequence of words, etc. in a text document into account. Obviously, the data set of text files cannot be represented with the BoW or TF-IDF approach in this case as this would neglect the order of words, etc.
Which data representation technique can be used to input a data set with labelled text files into a deep learning model (such as RNN, LSTM, BERT, XLNET, etc.)? Is there something similar like the BoW or TF-IDF approach that also pays attention to the sequence of words, etc.?</p>
","natural-language-processing"
"33939","Generating automatic sports commentary (NLG)","2021-12-28 00:17:20","","0","563","<machine-learning><deep-learning><natural-language-processing>","<p>I am trying to develop a &quot;simple&quot; announcer for sports segments that mainly consists of events like goals, fouls, substitutions, and many other events that could happen in many sports. The idea is that I already have key info like the player who does the action, the location in the court, the time that it takes place, and more extra info. I also have information like the sport being played and the type of event, so this task is purely focused on NLG.</p>
<p>The naïve idea that I had was to extract commentaries of soccer, which can be found on so many websites, and extract the key info of these commentaries that will act as the ground truth in the model for getting the input, i.e.,:</p>
<p><strong>['football', 'goal', 'Bob', 'fourth minute'] -&gt; Goal! that was a nice goal from Bob in the fourth minute of the match.</strong></p>
<p>I would say that the first two words are being used for steering the model to generate sports according to phrases (a cricket player kicking the ball doesn't make sense).</p>
<p>The comments generated by the fine-tuned model on this input-output are acceptable.</p>
<p>The problem is that I have to build a dataset for many sports (or at least 2 with the same quality as soccer ones like in Flashscore) and I can't find any.</p>
<p>I have also been looking for Plug and Play methods to generate sentences.</p>
<p>What do you think? Is fine-tuning a must-do in this situation or can it be thought of in another way?</p>
","natural-language-processing"
"32721","What are the types of inputs used for RNN in literature given sentences?","2021-12-12 08:33:17","","0","28","<natural-language-processing><recurrent-neural-networks><word-embedding>","<p>Suppose there are <span class=""math-container"">$m$</span> sentences in a text file and the number of distinct words is equal to <span class=""math-container"">$n$</span>. The goal is to get word embeddings using RNN.</p>
<p>We know that it is impossible to pass any word, which is in text format, as an input to RNN. We need to convert each word into some number and then pass it to the RNN to get word embeddings.</p>
<p>I know only the following method, if correct:</p>
<ol>
<li>Assign an index to each word. So, the index ranges from <span class=""math-container"">$0$</span> to <span class=""math-container"">$n-1$</span>.</li>
<li>Use the indices as input to RNN.</li>
</ol>
<p>Is it the only technique used in the literature? If not, what are the names of other techniques that are used in the context of RNN encoders?</p>
","natural-language-processing"
"32718","Is image machine translation done in two steps?","2021-12-11 21:53:33","","1","63","<convolutional-neural-networks><natural-language-processing><recurrent-neural-networks><machine-translation>","<p>Suppose I have images of hand-written Japanese text. If I want to translate those images, would my ML algorithm be a 2-step model (for example, a CNN to convert the image into Japanese characters/tokens and then feed those tokens in an RNN)? Is this normally how it would be done, or is there an end-to-end solution?</p>
","natural-language-processing"
"32679","Which pre-processing steps are necessary for Deep Learning models to solve a document classification problem?","2021-12-08 11:57:09","","1","295","<deep-learning><natural-language-processing><data-preprocessing><text-classification><binary-classification>","<p>I have created a data set with 30.000 text documents (each text file is rather small with respect to its length), which are labelled with 0 and 1. Using this data set, I want to train machine learning and deep learning models in order to be able to classify new text files.</p>
<p>On the one hand, I want to use classical machine learning models (such as logistic regression, random forest, SVM, etc.) with the Bag of Words/TF-IDF approach. This requires extensive text pre-processing, such as tokenization, stemming, converting to lower case, removing of stopwords and punctuation, lemmatization, etc.</p>
<p>On the other hand, I want to use new deep learning models (such as RNN, LSTM, BERT, XLNET, etc.).</p>
<p>Which pre-processing steps are necessary/advantageous for these deep learning models? Should I also use tokenization, stemming, converting to lower case, removing of stopwords and punctuation, lemmatization, etc. or can I omit most of these steps?</p>
","natural-language-processing"
"32662","Fine tuning BERT for token level classification","2021-12-07 02:08:17","","0","250","<neural-networks><machine-learning><deep-learning><natural-language-processing><bert>","<p>I want to try self-supervised and semi-supervised learning for my task, which relates to token-wise classification for the 2 sequences of sentences (source and translated text). The labels would be just 0 and 1, determining if the word level translation is good or bad on both the source and target sides.</p>
<p>To begin, I used XLMRoberta, as I thought it would be best suited for my problem. First, I just trained normally using nothing fancy, but the model overfits after just 1-2 epochs, as I have very little data to fine-tune on (approx 7k).</p>
<p>I decided to freeze the BERT layers and just train the classifier weights, but it performed worse.</p>
<p>I thought of adding a more dense network on top of BERT, but I am not sure if it would work well or not.</p>
<p>One more thought that occurred to me was data augmentation, where I increased the size of my data by multiple factors, but that performed badly as well. (Also, I am not sure what should be the proper number to increase the data size with augmented data.)</p>
<p>Can you please suggest which approach could be suitable here and if I am doing something wrong? Shall I just use all the layers for my data or freezing is actually a good option? Or you suspect I am ruining somewhere in the code and this is not what is expected.</p>
","natural-language-processing"
"32646","What kind of NN to use to find misprints in test","2021-12-05 18:44:43","","1","40","<neural-networks><natural-language-processing><recurrent-neural-networks><long-short-term-memory>","<p>I have a bunch of unique full names of users. I made pseudo-physical model to emulate misprints of desktop and mobile users (hence, fatfingering, jumpy fingers, accidentals touches of touch bar etc.)</p>
<p>So, I have pairs like John Snow - joh Snown</p>
<p>I tried first Recurrent networks, LSTM, like some kind of vocabulary to &quot;translate&quot; from bad words to good ones, but it return only known predicted result, and when I try to put unknown last names, it returns wrong results.</p>
<p>I wish to find some patterns in misspelled words, and to predict correct spelling.</p>
<p>Can you please advice some kind of NN to cope with the task, or maybe some contributions in that domain?</p>
<p>P.S. Yes, I know that there exist other AI methods to get things done</p>
<p>P.P.S. This vocabulary is not in English, just in case</p>
<p><strong>UPDATE</strong></p>
<p>LSTM nn works nice with known names and last names endings for new last names. Right now I use 2 different nn, first to correct mistypes, second to determine first, last and middle name.</p>
<p><strong>UPDATE2</strong></p>
<p>Sequence to sequence solution also can normalize name (put them in order), find sex of person, find probability of error, etc.</p>
","natural-language-processing"
"32526","Why do Transformers have a sequence limit at inference time?","2021-11-26 15:32:55","34263","6","2879","<machine-learning><natural-language-processing><transformer><architecture><sequence-modeling>","<p>As far as I understand, Transformer's time complexity increases quadratically with respect to the sequence length. As a result, during training to make training feasible, a maximum sequence limit is set, and to allow batching, all sequences smaller are padded.</p>
<p>However, after a Transformer is trained, and we want to run it on a single sequence at inference time, the computational costs are far less than training. Thus, it seems reasonable that I would want to run the transformer on a larger input sequence length during inference time. From a technical perspective, this should be feasible.</p>
<p>I keep reading online that a Transformer cannot be run on a sequence size larger than the one seen during training. Why is this? Is it because the network weights will be unfamiliar with sequences of this length? Or is it more fundamental?</p>
","natural-language-processing"
"32501","How much labelling is required for NER with SpaCy?","2021-11-23 15:44:47","","0","934","<machine-learning><deep-learning><natural-language-processing><named-entity-recognition><spacy>","<p>I have transaction data and I would like to extract the merchant from the transaction description. I am new to this but I just came across Named Entity Recognition and SpaCy. I have hundreds of thousands of different merchants.</p>
<p>Some questions that I have:</p>
<ul>
<li><p>How much labelling do I need to do given the number of merchants I need to extract?</p>
</li>
<li><p>How many different instances of the same merchant I need to label to get decent results?</p>
</li>
</ul>
","natural-language-processing"
"32500","What does it mean to apply decomposition at inference-time in a machine translation system?","2021-11-23 05:50:17","32532","0","35","<natural-language-processing><terminology><transformer><machine-translation><inference>","<p>I'm reading <a href=""https://aclanthology.org/2020.wat-1.21.pdf"" rel=""nofollow noreferrer"">this paper</a> for sub-character decomposition for logographic languages and the authors mention decomposition at inference-time. They're using Transformer architecture.</p>
<p>More specifically, the authors write:</p>
<blockquote>
<p>We propose a flexible inference-time sub-character decomposition procedure which targets unseen characters, and show that it aids adequacy and reduces misleading overtranslation in unseen character translation.</p>
</blockquote>
<p>What do inference-time and inference-only decomposition mean in this context? My best guess would be that inference-time would be at some point during the decoding process, but I'm not 100% clear on whether that's the case and, if so, when exactly.</p>
<p>I'm going to keep digging and update if I find something helpful. In the meantime, if anyone needs more context just let me know.</p>
","natural-language-processing"
"32485","General approaches in text encoding and labelling for NLP","2021-11-21 20:05:44","","1","435","<neural-networks><natural-language-processing><data-preprocessing><word-embedding><data-labelling>","<p>What are the approaches of encoding text data? I would be glad to hear some summarization from experienced persons.</p>
<p>And are there any solutions accepting words outside the vocabulary and including them to the results (online machine learning)?</p>
<p><strong>Data input</strong></p>
<p>So my basic understanding is that if we want predict some value (linear regression) or say what is the probability of occuring some event (logistic regression) we have to gather some features as our input and encode them as number. But this is not necessarily true when working with continuous data like sentences.</p>
<p>The most naive aproach, which comes to my mind is just to assign some natural numbers to each word in the vocabulary. But this number does not contain any meaningful data about the word itself. On the other hand what seems to be important in NLP is just the order of the words. This is where I think about n-grams so we feed network with more than just one word. Or attention like in the Transformer.</p>
<p>Another idea, which cames to my mind is to vectorize the word using one of the Word Embedding technique. Here we have some context about the word so the input is not just a dumb number. But does it have any value when we want to predict the next word? Can Word Embedding be used in that way or it's purpose is completely different.</p>
<p>Last thing I was reading of was to encode characters rather than words but it feels pointless in such basic example as next word prediction. I would think about it more for sub-word tasks like inflection generating.</p>
<p><strong>Labelling</strong></p>
<p>Again based on my knowledge when we want to solve yes/no problem we're using sigmoid function. If we have more classes we can use one-hot encoding. But sometimes the output of the network might give us ambiguous meaning so we're using the softmax function so all output sum to 1.</p>
<p>How this looks in NLP area? When having a vocabulary consisting of 600k words do we really need 600k softmaxed outputs? I'm also thinking there about Word Embedding solutions where we can reduce the number of outputs to let's say 300 numbers and then find the closest word matching the output without using softmax.</p>
","natural-language-processing"
"32436","How to fine-tune GPT-J with small dataset","2021-11-17 13:46:12","","0","5160","<natural-language-processing><tensorflow><hyperparameter-optimization><gpt><fine-tuning>","<p>I have followed this guide as closely as possible: <a href=""https://github.com/kingoflolz/mesh-transformer-jax"" rel=""nofollow noreferrer"">https://github.com/kingoflolz/mesh-transformer-jax</a></p>
<p>I'm trying to fine-tune GPT-J with a small dataset of ~500 lines:</p>
<pre><code>You are important to me. &lt;|endoftext|&gt;
I love spending time with you. &lt;|endoftext|&gt;
You make me smile. &lt;|endoftext|&gt;
feel so lucky to be your friend. &lt;|endoftext|&gt;
You can always talk to me, even if it’s about something that makes you nervous or scared or sad. &lt;|endoftext|&gt;
etc...
</code></pre>
<p>Using the <strong>create_finetune_tfrecords.py</strong> script (from the repo mentioned above) outputs a file with <strong>2</strong> in it. I understand that means my data has 2 sequences.</p>
<p>I could really use some advice with the <code>.json</code> config file. What hyperparameters do you recommend for this small dataset?</p>
<p>The best I came up with trying to follow the guide:</p>
<pre><code>{
  &quot;layers&quot;: 28,
  &quot;d_model&quot;: 4096,
  &quot;n_heads&quot;: 16,
  &quot;n_vocab&quot;: 50400,
  &quot;norm&quot;: &quot;layernorm&quot;,
  &quot;pe&quot;: &quot;rotary&quot;,
  &quot;pe_rotary_dims&quot;: 64,

  &quot;seq&quot;: 2048,
  &quot;cores_per_replica&quot;: 8,
  &quot;per_replica_batch&quot;: 1,
  &quot;gradient_accumulation_steps&quot;: 2,

  &quot;warmup_steps&quot;: 1,
  &quot;anneal_steps&quot;: 9,
  &quot;lr&quot;: 1.2e-4,
  &quot;end_lr&quot;: 1.2e-5,
  &quot;weight_decay&quot;: 0.1,
  &quot;total_steps&quot;: 10,

  &quot;tpu_size&quot;: 8,

  &quot;bucket&quot;: &quot;chat-app-tpu-bucket-europe&quot;,
  &quot;model_dir&quot;: &quot;finetune_dir&quot;,

  &quot;train_set&quot;: &quot;james_bond_1.train.index&quot;,
  &quot;val_set&quot;: {},

  &quot;eval_harness_tasks&quot;: [
  ],

  &quot;val_batches&quot;: 2,
  &quot;val_every&quot;: 400000,
  &quot;ckpt_every&quot;: 1,
  &quot;keep_every&quot;: 1,

  &quot;name&quot;: &quot;GPT3_6B_pile_rotary&quot;,
  &quot;wandb_project&quot;: &quot;mesh-transformer-jax&quot;,
  &quot;comment&quot;: &quot;&quot;
}
</code></pre>
<p>The problem is that, when I test the fine-tuned model, I get responses that make no sense:</p>
<p><a href=""https://i.sstatic.net/GTVV3.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/GTVV3.png"" alt=""Screenshot"" /></a></p>
","natural-language-processing"
"32418","Which AI algorithm to use for identifying API for a specific use from a list of APIs?","2021-11-16 10:52:31","","0","31","<machine-learning><natural-language-processing><python><ai-basics><text-classification>","<p>We have a legacy code solution in C#. We have to change the code so that it fetches internal data via APIs and not via DB calls.</p>
<p>E.g. if the current code GETS Payment object from DB, we have to replace the logic so that the code calls the GET PAYMENT API instead.</p>
<p>Since there are 100s of code files and multiple DB hits in a single file, doing this manually is not feasible.</p>
<p>I was thinking of building an AI-based tool that would take my code file as input and point me out where I would need to replace the existing code and suggest what API to call at that place.</p>
<p>I have never worked on AI and it would be great if anyone suggests which algorithm to refer for my tool and also how should I proceed with solving the above problem.</p>
","natural-language-processing"
"32396","Is Positional Encoding always needed for using Transformer models correctly?","2021-11-14 19:44:12","32429","2","503","<deep-learning><natural-language-processing><transformer><positional-encoding>","<p>I am trying to make a model that uses a <em>Transformer</em> to see the relationship between several data vectors, but the order of the data is not relevant in this case, so I am not using the <em>Positional Encoding</em>.</p>
<p>Since the performance of models using Transformers is quite improved with the use of this part, do you think that if I remove that part I am breaking the potential of Transformers or is it correct to do so?</p>
","natural-language-processing"
"32377","Why do we multipy context_size with embedding_dim? (PyTorch)","2021-11-12 12:23:28","32378","3","155","<natural-language-processing><pytorch><word-embedding>","<p>I've been using Tensorflow and just started learning PyTorch. I was following the tutorial: <a href=""https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py"" rel=""nofollow noreferrer"">https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#sphx-glr-beginner-nlp-word-embeddings-tutorial-py</a></p>
<p>Where we try to create an n-gram language model. However, there's something I don't understand.</p>
<pre><code>class NGramLanguageModeler(nn.Module):

    def __init__(self, vocab_size, embedding_dim, context_size):
        super(NGramLanguageModeler, self).__init__()
        self.embeddings = nn.Embedding(vocab_size, embedding_dim)
        self.linear1 = nn.Linear(context_size * embedding_dim, 128)
        self.linear2 = nn.Linear(128, vocab_size)
</code></pre>
<p>at <code>self.linear1 = nn.Linear(context_size * embedding_dim, 128)</code> why did we multiply embedding_dim with context_size? Isn't the embedding_dim input size? So why do we multiply it by the context size?</p>
","natural-language-processing"
"32184","What is the Intermediate (dense) layer in between attention-output and encoder-output dense layers within transformer block in PyTorch implementation?","2021-10-25 20:05:50","","5","1843","<natural-language-processing><pytorch><transformer><bert>","<p>In PyTorch, transformer (BERT) models have an intermediate dense layer in between attention and output layers whereas the BERT and Transformer papers just mention the attention connected directly to output fully connected layer for the encoder just after adding the residual connection.</p>
<p>Why is there an intermediate layer within an encoder block?</p>
<p>For example,</p>
<blockquote>
<p>encoder.layer.11.attention.self.query.weight<br />
encoder.layer.11.attention.self.query.bias<br />
encoder.layer.11.attention.self.key.weight<br />
encoder.layer.11.attention.self.key.bias<br />
encoder.layer.11.attention.self.value.weight<br />
encoder.layer.11.attention.self.value.bias<br />
encoder.layer.11.attention.output.dense.weight<br />
encoder.layer.11.attention.output.dense.bias<br />
encoder.layer.11.attention.output.LayerNorm.weight<br />
encoder.layer.11.attention.output.LayerNorm.bias<br />
<strong>encoder.layer.11.intermediate.dense.weight<br />
encoder.layer.11.intermediate.dense.bias</strong><br />
encoder.layer.11.output.dense.weight<br />
encoder.layer.11.output.dense.bias<br />
encoder.layer.11.output.LayerNorm.weight<br />
encoder.layer.11.output.LayerNorm.bias</p>
</blockquote>
<p>I am confused by this third (intermediate dense layer) in between attention output and encoder output dense layers</p>
","natural-language-processing"
"32141","Given the immaturity of NLP tools for non-English languages, should I first translate the non-English language to English before text pre-processing?","2021-10-22 02:05:18","32142","0","123","<natural-language-processing><data-preprocessing><machine-translation><lemmatization>","<p>For non-English languages (in my case Portuguese), what is the best approach? Should I use the not-so-complete tools in my language, or should I translate the text to English, and after using the tools in English? Lemmatization, for example, is not so good in non-English languages.</p>
","natural-language-processing"
"32120","Why does research on faster Transformers focus on the query-key product?","2021-10-19 21:22:36","","1","55","<deep-learning><natural-language-processing><transformer><attention><computational-complexity>","<p>A lot of recent research on Transformers has been devoted to reducing the cost of the self-attention mechanism:</p>
<p><span class=""math-container"">$$\text{softmax}\left(\frac{Q K^T}{\sqrt{d}} \right)V,$$</span></p>
<p>As I understand it, the runtime, assuming <span class=""math-container"">$\{Q, K, V\}$</span> are each of shape <span class=""math-container"">$(n, d)$</span>, is <span class=""math-container"">$O(n^2 d + n d^2)$</span>. In general, the issue is the <span class=""math-container"">$n^2 d$</span> term, because the sequence length <span class=""math-container"">$n$</span> can be much bigger than the model dimension <span class=""math-container"">$d$</span>. So far, so good.</p>
<p>But as far as I can tell, current research focuses on speedups for <span class=""math-container"">$Q K^T$</span>, which is <span class=""math-container"">$O(n^2 d)$</span>. There's less focus on computing <span class=""math-container"">$A V$</span>, where <span class=""math-container"">$A = \text{softmax} \left(\frac{Q K^T}{\sqrt{d}} \right)$</span> -- which also has complexity <span class=""math-container"">$O(n^2 d)$</span>.</p>
<p>Why is the first matrix product the limiting factor?</p>
<p>Examples of these faster Transformer architectures include <a href=""https://arxiv.org/abs/2004.05150"" rel=""nofollow noreferrer"">Longformer</a>, which approximates <span class=""math-container"">$QK^T$</span> as a low-rank-plus-banded matrix, <a href=""https://arxiv.org/abs/2102.03902"" rel=""nofollow noreferrer"">Nystromformer</a>, which approximates <span class=""math-container"">$\text{softmax}(QK^T)$</span> as a low-rank matrix with the Nystrom transformation, and <a href=""https://arxiv.org/abs/2007.14062"" rel=""nofollow noreferrer"">Big Bird</a>, which approximates it with a low-rank-plus-banded-plus-random matrix.</p>
","natural-language-processing"
"32058","Probability that two words appear in the same sentence","2021-10-15 10:19:19","32061","-1","331","<natural-language-processing>","<p>How can I know if two words are likely to appear in the same sentence in (British) English (or English in general to enhance the chance of getting a result).</p>
<p>As I don't have access to a powerful machine, is there any relevant website? Or a pretrained model I can use? Or something else?</p>
","natural-language-processing"
"32028","A recommender system based on millions of fields including text and number","2021-10-12 13:11:18","","1","68","<machine-learning><natural-language-processing><recommender-system>","<p>I want to train a model based on millions of fields, including text and number, that are stored in a SQL database and recommend a perfect match based on some inputs. Now, which algorithm is the best for this problem?</p>
<p>For instance, consider this database pattern:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Title</th>
<th>Content</th>
<th>Volume</th>
<th>Count</th>
</tr>
</thead>
<tbody>
<tr>
<td>First</td>
<td>row1</td>
<td>5.36</td>
<td>34</td>
</tr>
<tr>
<td>Second</td>
<td>row2</td>
<td>36.1</td>
<td>239</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
</div>","natural-language-processing"
"31791","How to reduce the number of clusters produced by the Markov Clustering Algorithm?","2021-09-22 07:05:33","37498","0","161","<natural-language-processing><hyper-parameters><clustering><cosine-similarity>","<p>I have used the Markov Clustering Algorithm (MCL) to cluster tweets, based on their similarity. However, I got a too high number of clusters, and most of the clusters have only one tweet. Any suggestions to reduce the number of clusters?</p>
","natural-language-processing"
"31760","How to generate a response while considering past questions as well?","2021-09-20 03:40:33","","2","109","<natural-language-processing><python><transformer><question-answering>","<pre><code>User: What is the tallest mountain?
Agent: Everest
User: Where is it located? # Agent hears: &quot;Where is Everest located?&quot;
Agent: Nepal
</code></pre>
<p>I want to be able to generate a sequence that has been generated using the user's current query as well as the past conversation.</p>
<p>More specifically, I am using Google's T5 for closed-book question answering, but, instead of trivial questions, we use the user's frequently asked queries.</p>
<p>I want to be able to encode their past questions and the agent's past answers, then use them to generate the agent's next answer. How can I do that?</p>
","natural-language-processing"
"31730","Is Speech to Speech with changing the voice to a given other voice possible?","2021-09-18 09:06:21","","1","128","<natural-language-processing><reference-request><deepfakes><speech-synthesis>","<p><strong>Background:</strong></p>
<p>I am working on a research project to use (demonstrate) the possibilities of Machine Learning and AI in artistic projects. One thing we are exploring is demonstrating deep fakes on stage. Of course, a deep fake is not easy to make. Still, we are exploring creating a &quot;minor quality&quot; deep fake live on a stage (or maybe in some other ways where people can make deep fakes of themselves) in which we put words into someone's mouth. I discovered that a semi-nice deep fake of the facial movement is possible, now a also want to add voice.</p>
<p>There are a lot of text-to-speech systems, which allow using a voice that is created from the recording of the voice of a real person. That is already nice.</p>
<p>The video is based on the facial movements of another person. So the Audio has to match the facial movements. The easiest way would be, if the &quot;fake&quot; voice says it exactly the same way, as the person doing the &quot;facial acting&quot; for the deep fake said it.</p>
<p><strong>Question:</strong></p>
<p>Is it possible to do a fake voice of a person in this way:</p>
<ol>
<li>Another person (the actor, or source) speaks the words in his voice and records it.</li>
<li>The person with the faked voice (the destination) gives a voice sample with some random spoken text.</li>
<li>An AI/algorithm/whatever modifies the recording from (1) in such a way, that the tone/voice is modified so it matches the voice from (2).</li>
</ol>
<p>Do systems/research like this exist? I did not find anything using google, but maybe I did not use the correct keywords.</p>
","natural-language-processing"
"31729","NLP problem Phrase/Token labeling","2021-09-18 07:28:56","","-1","63","<neural-networks><machine-learning><natural-language-processing><recurrent-neural-networks>","<p>Looking for suggestions on how to define the following NLP problem and different ways in which it can be modeled to leverage machine learning. I believe there are multiple ways to model this problem.  Deep-learning-based suggestions also work as there is a good amount of data is available for training.</p>
<p>Will evaluate different approaches for the given dataset. Please share relevant papers, blogs, or GitHub repos. Thanks!</p>
<p><strong>Input</strong>: Given a sentence S having words W1 to W10.</p>
<p>S = W1 W2 W3 W4 W5 W6 W7 W8 W9 W10</p>
<p>The sentence has some syntactic and semantic patterns, but it is not exactly freely written natural language but it's in English. These are words, can be punctuation</p>
<p><strong>Output</strong>: should be something like this.</p>
<p>Label1 - W4</p>
<p>Label2 - W3</p>
<p>Label3 - [W2 W1] continuous // semantically related. Means words [W2 W1] in-order are assigned a Label3. <em>Also okay with solutions that don't output in-order.</em></p>
<p>Label4 - [W6 W8]</p>
<p>Label5- W10</p>
<p>Noise- W7, W9. Means words W7 and W9 independently are assigned a
Label3.</p>
<p>Label7- W5</p>
<p>Need to solve the problem. Looking for research/thoughts on how this problem can be defined in different ways to exploit different patterns in the structure of sentences. Looking for similar tasks which are already defined in NLP such as token labeling, parsing which can be used.</p>
<p>Would be really helpful to get the suggestions to the latest research on solving/defining this problem.</p>
","natural-language-processing"
"31689","Why do the authors of the T5 paper say that the ""architectural changes are orthogonal to the experimental factors""?","2021-09-14 19:58:32","31696","1","329","<machine-learning><natural-language-processing><papers><transformer>","<p>Here's a quote from the <code>T5 paper</code> (T5 stands for &quot;Text-to-Text Transfer Transformer&quot;) titled <a href=""https://www.jmlr.org/papers/volume21/20-074/20-074.pdf"" rel=""nofollow noreferrer"">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a> by <em>Colin Raffel et al.</em>:</p>
<blockquote>
<p>To summarize, our model is roughly equivalent to the original
Transformer proposed by Vaswani et al. (2017) with the exception of
removing the Layer Norm bias, placing the layer normalization outside
the residual path, and using a different position embedding scheme.
Since these architectural changes are <strong>orthogonal</strong> to the experimental
factors we consider in our empirical survey of transfer learning, we
leave the ablation of their impact for future work.</p>
</blockquote>
<p>What exactly does 'orthogonal' mean in this context? Also, is it just me or have I seen the word used in a similar way before, but can't remember where?</p>
","natural-language-processing"
"31686","Identify whether two companies are the same","2021-09-14 12:10:48","","0","149","<natural-language-processing><python>","<p>I am trying to solve a problem where I need to map multiple variations of a company name to a single name. For example: say I have a company named <code>Super Idea Corporation Limited</code>.</p>
<p>I need to resolve the following to <code>Super Idea Corporation Limited</code></p>
<ul>
<li>SICL</li>
<li>Super Idea Corp Ltd</li>
<li>SIC Ltd</li>
<li>SIC Limited</li>
</ul>
<p>Is there a non regex way of doing this? The reason I am averse to using regex is that there are a lot of business names that can be represented in many different ways. I want something that is more flexible and adaptive.</p>
","natural-language-processing"
"31632","Can I always use ""encoding"" and ""embedding"" interchangeably?","2021-09-10 02:06:49","","6","5940","<natural-language-processing><terminology><word-embedding>","<p>This question is restricted to the text domain only.</p>
<p>The meaning of the word &quot;<a href=""https://www.lexico.com/definition/encode"" rel=""noreferrer"">encode</a>&quot; is <em>Convert (information or instruction) into a particular form</em>. One which performs encoding is called an encoder.</p>
<p>In deep learning, an encoder can also be the first part of a neural network (autoencoder) that simulates identity function, which governs the English meaning of encoder since it encodes the input.</p>
<p>Embeddings are encodings where the intention is to preserve semantics. You can observe the following excerpt from the chapter <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/6.pdf"" rel=""noreferrer"">Vector Semantics and Embeddings</a></p>
<blockquote>
<p>In this chapter we introduce vector semantics, which instantiates this
linguistic hypothesis by learning representations of the meaning of
words, called <strong>embeddings</strong>, directly from their distributions in texts.</p>
</blockquote>
<p><strong>But all encodings may not be the embeddings</strong> since encodings might not always preserve semantics (?). I have doubt in this statement which I inferred based on my current knowledge.</p>
<p>Many times, I came across the terms text encoding and text embedding interchangeably. But failing to catch whether they are the same or we need to be choosy while using them.</p>
<p>Consider the following usages of encoding and embedding in the paper titled <a href=""https://arxiv.org/pdf/1605.05396.pdf"" rel=""noreferrer"">Generative Adversarial Text to Image Synthesis</a> by <em>Scott Reed et al</em>.</p>
<blockquote>
<p>#1: The intuition here is that a <strong>text encoding</strong> should have a higher compatibility score with images of the correspondong class compared to any other class and vice-versa.</p>
<p>#2: <strong>Text encoding</strong> <span class=""math-container"">$\phi(t)$</span> is used by both generator and discriminator.</p>
<p>#3: ...where <span class=""math-container"">$T$</span> is the dimension of the <strong>text description embedding</strong>.</p>
<p>#4: ... we encode the text query <span class=""math-container"">$t$</span> using <strong>text encoder</strong> <span class=""math-container"">$\phi$</span>. The <strong>description embedding</strong> <span class=""math-container"">$\phi(t)$</span> is first compressed ...</p>
</blockquote>
<p>I think they are used interchangeably. Is it true? Can I use any word if I am confident enough that my encoding is semantic preserving? Or is there any strong reason for choosing the words?</p>
<p>If you observe the last point, the word &quot;encoder&quot; is used. Can I use embedder instead of it?</p>
","natural-language-processing"
"31582","Is there something like person-specific sentiment analysis?","2021-09-07 06:03:04","","1","33","<natural-language-processing><natural-language-understanding><sentiment-analysis>","<p>Sentiment analysis, as we know, measures &quot;Cake sucks&quot; as say -0.4, and &quot;Cake is great&quot; as 0.7.
What I'm looking for is something a bit different like so:</p>
<ol>
<li>Given input text data written by 1 person (say a blog)</li>
<li>Predict how they (the person who wrote the text) might react to a certain piece of text</li>
</ol>
<hr />
<p>What might something like this look like?</p>
<ul>
<li>Let's suppose that Person A with a blog has written in his blog posts thousands of times about how much cake is the best thing to happen to humanity.</li>
<li>The system should probably infer that if that person read something like &quot;Cake is the WORST food ever&quot;, they would react negatively to it, if say, they also believe that there is such a thing as 'objective taste' somehow (<a href=""https://en.wikipedia.org/wiki/Aesthetic_absolutism"" rel=""nofollow noreferrer"">aesthetic absolutism</a>).</li>
<li>Or if Person A has made anti-racist statements, that racist statements would be strongly negative.</li>
<li>If Person A reads the statement &quot;I hate lawyers&quot; and in their blog they have written about how they don't care either way about law, it should probably be 0.</li>
<li>Finally, if Person A reads the statement &quot;iPhones are better than Android&quot; and there is <em>zero</em> data about either iPhones or Androids, or even related data about Apple or Google, then it should probably be 0, with an additional &quot;confidence&quot; metric at 0 (since there is no data, this confidence metric will let us know whether there is any data to support the measurement or not).</li>
</ul>
<hr />
<p>This model would need to be able to somehow inductively 'infer' a value system of some kind, and assign intensities of probable reactions based on the frequency of an expressed view, as well as pick up on nuances (such as philosophical assumptions, (for example in the above cake example: aesthetic absolutism) etc.) that may inform that measurement.</p>
<p>In other words, I'd like to create a model (or find a pre-trained model to fine-tune), that would be able to, given text data from that 1 person, predict their sentiment in response to a new piece of text.</p>
<p>Would love any help whatsoever regarding:</p>
<ol>
<li>What types of pre-trained models I should look at</li>
<li>Any ideas of any kind whatsoever you might have on how to achieve this</li>
<li>What sorts of architectures/resources/concepts may be relevant to look at</li>
</ol>
","natural-language-processing"
"30464","What is meant by a ""relevant document"" in NLP?","2021-08-31 11:09:13","","1","209","<natural-language-processing><terminology><precision><recall><information-retrieval>","<p>In natural language processing, I came across the concept of &quot;relevant document&quot; several times. And several analytical formulas, such as precision, recall are based on the relevant documents.</p>
<p>Precision = <span class=""math-container"">$\dfrac{\text{Number of documents that are relevant and retrieved to the query Q}}{\text{Number of retrieved documents to the query Q}}$</span></p>
<p>Recall = <span class=""math-container"">$\dfrac{\text{Number of documents that are relevant and retrieved to the query Q}}{\text{Number of relevant documents to the query Q}}$</span></p>
<p>What is meant by &quot;relevance&quot; in such cases? Is it a universally objective term or subjective term, decided by the designer, based on that particular context?</p>
","natural-language-processing"
"30440","Is there any difference between the phrases ""text representation"" and ""text feature representation""?","2021-08-30 01:59:12","","0","47","<natural-language-processing><terminology><definitions><vector-semantics>","<p>Text representation, in simple words, is representing text in sensible numeric form. You can read in detail <a href=""https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-39940-9_420"" rel=""nofollow noreferrer"">from</a> the following paragraph</p>
<blockquote>
<p>Text representation is one of the fundamental problems in text mining
and Information Retrieval (IR). It aims to <strong>numerically represent the
unstructured text documents to make them mathematically computable</strong>.
For a given set of text documents <span class=""math-container"">$D = \{d_i, i=1, 2,...,n\}$</span>, where
each <span class=""math-container"">$d_i$</span> stands for a document, the problem of text representation
is to represent each <span class=""math-container"">$d_i$</span> of <span class=""math-container"">$D$</span> as a point <span class=""math-container"">$s_i$</span> in a numerical space
<span class=""math-container"">$S$</span>, where the distance/similarity between each pair of points in
space <span class=""math-container"">$S$</span> is well defined.</p>
</blockquote>
<p>But, I came across the phrase &quot;text feature representation&quot; in research papers. Features, in general, are <a href=""https://ai.stackexchange.com/questions/30378/can-i-always-interpret-features-as-random-variables-in-machine-learning-safely"">present in dataset</a>. But, I think, features can be characters or words or documents or complete text (as a single feature?) in the case of the text. I am not sure about what we call features in the text.</p>
<p>So, I am not sure about what is meant by <strong>text feature representation</strong>. Is it the same as text representation?</p>
","natural-language-processing"
"30423","Get the name of a merchant from records","2021-08-29 06:15:38","","0","847","<machine-learning><natural-language-processing><text-classification>","<p>I have a bunch of bank transaction records from which I want to extract merchants' names. In a few subsets of these records, the structure of the string is the same within the subset with only the merchant name changing. For example</p>
<p>subset 1</p>
<ul>
<li><code>XXXXX_ID_TIME_STAMP MERCHANT1 CREDIT</code></li>
<li><code>XXXXX_ID_TIME_STAMP MERCHANT2 CREDIT</code></li>
</ul>
<p>subset 2</p>
<ul>
<li><code>BILL PAYMENT BANK_NAME MERCHANT NAME 3 </code></li>
<li><code>BILL PAYMENT BANK_NAME MERCHANT NAME 4 </code></li>
</ul>
<p>In the above two subsets, the structure of the string is the same, only the merchant names changes</p>
<p>and so on ...</p>
<p>Using NLP, I want to extract merchant names in such cases. How should I approach this?</p>
<p>Using regex is not feasible because I'd have to manually go through the complete data, identify all such patterns and create regex strings that'll extract the name. I would also have to do this for every new pattern.</p>
<p>Is there a way where I can train a model that can identify/extract merchants in such cases?</p>
","natural-language-processing"
"30386","Bag of Tricks: n-grams as additional features?","2021-08-26 13:15:58","30411","1","86","<natural-language-processing><papers><feature-extraction><bag-of-words><n-gram>","<p>I've been playing with PyTorch's <code>nn.EmbeddingBag</code> for sentence classification for about a month. I've been doing some feature engineering, playing with different tokenizers, etc. I'm just trying to get the best performance out of this simple model as I can. I'm new to NLP, so I figured I should start small.</p>
<p>Today, by chance, I stumbled on this paper <a href=""https://arxiv.org/abs/1607.01759"" rel=""nofollow noreferrer"">Bag of Tricks for Efficient Text Classification</a>, which very well may be the inspiration for <code>nn.EmbeddingBag</code>. Regardless, I read the paper and saw that they increased performance through using <em>&quot;n-grams as additional features to capture some partial information about the local word order&quot;</em></p>
<p>So by the wording of this sentence, specifically &quot;additional features&quot;, I take it to mean that they made n-grams as part of their vocabulary. For example &quot;abc news&quot; is treated as a single word in the vocabulary, and then appended to the training data that is being embedded like so:</p>
<pre><code>dataset = TextFromPandas(tweet_df)
label, sentence, ngrams = dataset[0]
label, sentence, ngrams

# out:

(1,
 'quake our deeds are the reason of this # earthquake may allah forgive us all',
 ['quake our',
  'our deeds',
  'deeds are',
  'are the',
  'the reason',
  'reason of',
  'of this',
  'this #',
  '# earthquake',
  'earthquake may',
  'may allah',
  'allah forgive',
  'forgive us',
  'us all'])
</code></pre>
<p>I just wanted to check my assumption, because the paper is not very explicit. I already tried to string n-grams together as a new sentence in place of the old, but performance dropped significantly.</p>
<p>I will continue to experiment, but I was wondering if anyone knows the specific mechanism?</p>
","natural-language-processing"
"30288","Is there a survey that describes the most effective approaches for an answer retrieval problem?","2021-08-21 00:18:01","","0","21","<natural-language-processing><reference-request><question-answering><information-retrieval>","<p>I have a dataset that contains pairs of a question and an answer. My problem is to train a model that can search for the right answer from the pool of my answers given the newly input question, so this is a kind of answer retrieval problem.</p>
<p>Can anyone provide me a survey and effective approaches for this problem?</p>
","natural-language-processing"
"30189","What is the reason for a training loss that drops but validation that NEVER does","2021-08-16 16:35:45","30384","0","57","<natural-language-processing><long-short-term-memory>","<p>I've been working on learning about NLP via a beginners competition on Kaggle.</p>
<p>I first trained a model with an embedding layer and then a simple linear layer. I actually got way better than a flip of the coin with this model, so I decided to try to step it up with an LSTM.</p>
<p>What happened was that training loss decreased and then palteaued while validation loss never decreased at all.</p>
<p>In the case of overfitting, I would expect validation loss to decrease for a while but then either remain steady or perhaps even increase as the model starts to overfit.</p>
<p>I can't find any reason for the strange loss curves I'm seeing:</p>
<p><a href=""https://i.sstatic.net/kubq8.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kubq8.png"" alt=""enter image description here"" /></a>
<a href=""https://i.sstatic.net/UFb6a.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/UFb6a.png"" alt=""enter image description here"" /></a></p>
<p><strong>What could cause such a phenomenon?</strong></p>
<p>I would be happy to share my network architecture and training code if there isn't a straightforward answer (I know there usually isn't).</p>
","natural-language-processing"
"30049","Training and Evaluating BERT and XLNET","2021-08-06 11:35:30","","0","196","<deep-learning><natural-language-processing><bert><text-classification>","<p>I am thinking about a project and have a few questions before I accept it. Would be grateful I anyone experienced of you could give me some advice.</p>
<p>In the project, I have been given a data set with (rather small) 30.000 text documents, which are labeled with 0 and 1. I want to train and evaluate (with respect to accuracy) a BERT and XLNet model.</p>
<p>Can you give me some rough estimates for the following questions?:</p>
<ol>
<li>How much computing power do I need for this task, i.e. can I simply use my private laptop for this or do I need a special CPU/GPU for it?</li>
<li>So far, I just worked with classical machine learning models (e.g. random forests, SVMs, etc.). I am not experienced deep learning architectures yet. How difficult would it be to implement a BERT oder XLNet model with my own data set, having no experience with BERT oder XLNet yet? I.e. how much code would it be that I have to develop by myself? And would I need a deep understanding for it or would be sufficient to follow an online tutorial and basically copy the code from there?
Many thanks.</li>
</ol>
","natural-language-processing"
"28861","An online editor that allows data labeling format","2021-07-27 14:43:00","28876","0","33","<natural-language-processing><datasets><data-labelling>","<p>I have a set of students (~20) that will work on annotating data for an NLP project.</p>
<p>The annotation task will be as in the following:</p>
<pre><code>text: I like this piza place.
label: [pos, neg]
comments: 
text fluency: [1,2,3,4,5]
</code></pre>
<p>The students will need to correct the text first (e.g. correcting <code>piza</code> word), and then fill the fields below.</p>
<p>Is there an online solution to add the data in this format and then to share the link with the students?</p>
<p>I tried to do this in Google forum, but I wasn't able to; I don't know actually if it's possible there.</p>
<p>I am looking for a solution that can allow saving the edits after annotating # instances, as there are many instances and the students won't be able to annotate everything at once. I know that a good solution would be building a website, but I am looking for something that already exists.</p>
","natural-language-processing"
"28838","How will actual labels be matched with predicted labels when LSTM discards data even from current time stamp input data?","2021-07-26 06:57:01","","0","46","<deep-learning><natural-language-processing><long-short-term-memory>","<p>I read the tutorial of LSTM from <a href=""http://colah.github.io/posts/2015-08-Understanding-LSTMs/"" rel=""nofollow noreferrer"">here</a>. However, I have certain doubts that I need to address.</p>
<ol>
<li><p>Since we use true labels and do not remove anything from the original data, then how is it possible for the LSTM model's predicted output to match the real labels as it throws data?</p>
</li>
<li><p>And how do we determine the number of output neurons?</p>
</li>
</ol>
<p>According to my understanding, in word-to-word prediction, one cell's outputs are the number of words (exiting in vocabulary).</p>
","natural-language-processing"
"28833","Isn't attention mask for BERT model useless?","2021-07-25 17:46:51","","3","8471","<deep-learning><natural-language-processing><attention><bert>","<p>I have just dived into deep learning for NLP, and now I'm learning how the BERT model works. What I found odd is why the BERT model needs to have an attention mask. As clearly shown in this tutorial <a href=""https://huggingface.co/transformers/glossary.html"" rel=""nofollow noreferrer"">https://huggingface.co/transformers/glossary.html</a>:</p>
<pre><code>from transformers import BertTokenizer
tokenizer = BertTokenizer.from_pretrained(&quot;bert-base-cased&quot;)

sequence_a = &quot;This is a short sequence.&quot;
sequence_b = &quot;This is a rather long sequence. It is at least longer than the sequence A.&quot;

encoded_sequence_a = tokenizer(sequence_a)[&quot;input_ids&quot;]
encoded_sequence_b = tokenizer(sequence_b)[&quot;input_ids&quot;]

padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)
</code></pre>
<p>Output of padded sequences input ids:</p>
<pre><code>padded_sequences[&quot;input_ids&quot;]

[[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102]]
</code></pre>
<p>Output of padded sequence attention mask:</p>
<pre><code>padded_sequences[&quot;attention_mask&quot;]
[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]
</code></pre>
<p>In the tutorial, it clearly states that an attention mask is needed to tell the model (BERT) which input ids need to be attended and which not (if an element in attention mask is 1 then the model will pay attention to that index, if it is 0 then model will not pay attention).</p>
<p>The thing I don't get is: why does BERT have an attention mask in the first place? Doesn't model need only input ids because you can clearly see that attention_mask has zeros on the same indices as the input_ids. Why does the model need to have an additional layer of difficulty added?</p>
<p>I know that BERT was created in google's &quot;super duper laboratories&quot;, so I think the creators had something in their minds and had a strong reason for creating an attention mask as a part of the input.</p>
","natural-language-processing"
"28754","Building an AI that predicts the pronunciation of words","2021-07-20 13:14:17","","0","442","<natural-language-processing>","<p>I want to create an AI that converts words to  International Phonetic Alphabet (IPA), but I am not sure which architecture I am supposed to use.</p>
<p>It is not possible to translate the characters one by one since there are multiple characters in the source word corresponding to one IPA character. There are solutions for this kind of problem, for example using an Encoder that encodes the content of the input which the decoder then translates, but I am uncertain if this isn't too abstract for this problem.</p>
<p>Can anyone think of a suitable solution for this task?</p>
","natural-language-processing"
"28700","The model learns well, but the validation decreases over time","2021-07-16 14:33:38","28739","0","67","<reinforcement-learning><natural-language-processing>","<p>I have trained a model for four days. I noticed a behaviour quite strange/unnatural.</p>
<p>During the training, the score and loss look like this:</p>
<p><a href=""https://i.sstatic.net/Z1xxO.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Z1xxO.png"" alt=""enter image description here"" /></a></p>
<p>However, when I see the validation score, I got:</p>
<p><a href=""https://i.sstatic.net/mMoL9.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/mMoL9.png"" alt=""enter image description here"" /></a></p>
<p>It seems the model learning by heart at the beginning and not generalise well afterwards. Is this a natural behavior? Maybe it's really not normal and there must be some errors in the code or algorithm? I don't know what to think anymore. Can you help me? What is a good solution?</p>
","natural-language-processing"
"28635","Language Processing: Determine if one paragraph is relevant to another paragraph","2021-07-12 21:06:29","28636","0","74","<natural-language-processing><resource-request>","<p><strong>Context:</strong> I want to determine if someone's written review contains content that is relevant to a paragraph that they are reviewing.</p>
<p>To do so, I am trying to determine if one paragraph is relevant to another paragraph. I initially tried to use TF-IDF to calculate the relevancy, but I think TF-IDF works well for determining if one paragraph is relevant to a whole set of paragraphs. I only want to determine if two paragraphs are relevant with each other.</p>
<p>What would be a good approach for this problem?</p>
","natural-language-processing"
"28570","Semantic-based evaluation of translations instead of BLEU","2021-07-07 17:13:55","","0","101","<natural-language-processing><machine-translation><text-generation>","<p>I have a text generation model and I want to evaluate its output by comparing it to a set of gold human-annotated references.</p>
<p>I went through machine-translation metrics and I found that BLEU is used as the main metric usually.
I didn't like using it because it's shallow as it uses ngrams comparison; the semantics of the translation is missed.</p>
<p>Is there any other metric to do a semantic-based evaluation?</p>
<p>I've thought of using a text similarity model to evaluate the output or even an NLI (Natural language inference) system. I am not sure how precise the evaluation will be because SOTA systems are not really accurate.</p>
","natural-language-processing"
"28556","How to measure the similarity the pronunciation of two words?","2021-07-07 06:54:19","28647","2","1566","<natural-language-processing><natural-language-understanding><speech-synthesis>","<p>I would like to know how I could measure the pronunciation of two words. These two words are quite similar and differ only in one vowel.
I know there is, e.g., the Hamming distance or the Levenshtein distance but they measure the &quot;general&quot; difference between words. I'm also interested in that but mainly I would like to know how they sound differently. I think there must be something like this to test text-to-speech results?</p>
<p>Best would even be an online source where I could just type in those two words.</p>
","natural-language-processing"
"28528","How to Study Improving In-depth Reading Comprehension?","2021-07-05 01:20:21","","0","22","<natural-language-processing><computational-linguistics>","<p>There are multiple datasets for machine comprehension tasks such as <a href=""https://arxiv.org/pdf/1606.05250.pdf"" rel=""nofollow noreferrer"">SQuAD</a>. However, most of the questions are straightforward. One can find the answers easily by using the find feature of the browser to look for the question keywords in the passage.</p>
<p>I'd appreciate it if you let us know about standardized in-depth reading comprehension tests for either human or machine that are generalizable. By generalizable, I mean they include a broad range of disciplines and academic levels and are not specifically designed for a target population.</p>
<p>I thought of GRE reading comprehension but was not able to find any study indicating that GRE reading comprehension questions are standardized or generalizable.</p>
","natural-language-processing"
"28526","How would the probability of a document $P(d)$ be computed in the Naive Bayes classifier?","2021-07-04 23:29:29","","2","177","<natural-language-processing><classification><probability><naive-bayes><probability-theory>","<p>In naive Bayes classification, we estimate the class of a document as follows</p>
<p><span class=""math-container"">$$\hat{c} = \arg \max_{c \in C}  P(c \mid d) = \arg \max_{c \in C} \dfrac{ P(d \mid c)P(c) }{P(d)} $$</span></p>
<p>It has been said in page 4 of <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/4.pdf"" rel=""nofollow noreferrer"">this textbook</a> that we can ignore the probability of document since it remains constant across classes.</p>
<blockquote>
<p>We can conveniently simplify the above equation by dropping the denominator <span class=""math-container"">$p(d)$</span>.  This is possible because we will be computing <span class=""math-container"">$\dfrac{P(d \mid  c)P(c)}{P(d)}$</span>for each possible class. But <span class=""math-container"">$P(d)$</span> <strong>doesn't change for each class</strong>; we are always asking about the most likely class for the same document <span class=""math-container"">$d$</span>, which must have the same probability <span class=""math-container"">$P(d)$</span>.  Thus, we can choose the class that maximizes this simpler
formula</p>
<p><span class=""math-container"">$$\hat{c} = \arg \max_{c \in C}  P(c \mid d) = \arg \max_{c \in C}
 P(d \mid  c)P(c)  $$</span></p>
</blockquote>
<p>Since the value of the document does not influence the choice of the class, naive Bayes algorithm does not consider that.</p>
<p>But, I want to know the value of <span class=""math-container"">$P(d)$</span>. Is it <span class=""math-container"">$\dfrac{1}{N}$</span>, if total number of documents are <span class=""math-container"">$N$</span>? How should I calculate <span class=""math-container"">$P(d)$</span>?</p>
","natural-language-processing"
"28495","Are the held-out datasets used for testing, validation or both?","2021-07-02 01:59:10","28508","1","369","<natural-language-processing><terminology><books><test-datasets><validation-datasets>","<p>I came across a new term &quot;held-out corpora&quot; and I confused regarding its usage in the NLP domain</p>
<p>Consider the following three paragraphs from <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/3.pdf"" rel=""nofollow noreferrer"">N-gram Language Models</a></p>
<p>#1: <strong>held-out corpora as a non-train data</strong></p>
<blockquote>
<p>For an intrinsic evaluation of a language model we need a test set. As
with many of the statistical models in our field, the probabilities of
an <span class=""math-container"">$n-$</span>gram model come from the corpus it is trained on, the training
set or training corpus. We can then measure training set the quality
of an n-gram model by its performance on some unseen data called the
test set or test corpus.  <strong>We will also sometimes call test sets and
other datasets that are not in our training sets held out corpora
because we hold them out from the held out training data</strong>.</p>
</blockquote>
<p>This paragraph clearly says that held-out corpora can be used for either testing or validation or others except training.</p>
<p>#2: <strong>development set or devset for hyperparameter tuning</strong></p>
<blockquote>
<p><strong>Sometimes we use a particular test set so often that we implicitly
tune to its characteristics. We then need a fresh test set that is
truly unseen. In such cases, we call the initial test set the
development test set or,devset</strong>. How do we divide our data into
training, development, and test sets? We want our test set to be as
large as possible, since a small test set may be accidentally
unrepresentative, but we also want as much training data as possible.
At the minimum, we would want to pick the smallest test set that gives
us enough statistical power to measure a statistically significant
difference between two potential models. In practice, <strong>we often just
divide our data into 80% training, 10% development, and 10% test.</strong>
Given a large corpus that we want to divide into training and test,
test data can either be taken from some continuous sequence of text
inside the corpus, or we can remove smaller “stripes” of text from
randomly selected parts of our corpus and combine them into a test
set.</p>
</blockquote>
<p>This paragraph clearly says that development set is used for hyperparameter tuning.</p>
<p>#3: <strong>held-out corpora for hyperparameter tuning</strong></p>
<blockquote>
<p>How are these <span class=""math-container"">$\lambda$</span> values set? Both the simple interpolation and
conditional interpolation <span class=""math-container"">$\lambda'$</span>s are learned from a held-out
corpus.  <strong>A held-out corpus is an additional training corpus that we
use to set hyperparameters</strong> like these <span class=""math-container"">$\lambda$</span> values, by choosing
the <span class=""math-container"">$\lambda$</span> values that maximize the likelihood of the held-out
corpus.</p>
</blockquote>
<p>This paragraph is clearly saying that held-out corpus is used for hyper-parameter training.</p>
<p><strong>I am interpreting or understanding the terms as follows</strong>:</p>
<p><strong>Train corpus</strong> is used to train the model for learning parameters.</p>
<p><strong>Test corpus</strong> is used for evaluating the model wrt parameters.</p>
<p><strong>Development set</strong> is used for evaluating the model wrt hyperparameters.</p>
<p><strong>Held-out corpus</strong> includes any corpus outside training corpus. So, it can be used for evaluating either parameters or hyperparameters.</p>
<p>To be concise, informally, data = training data + held-out data = training data + development set + test data</p>
<p>Is my understanding true? I got confusion because of paragraph 3, which says that held-out corpus is used (only) for learning the hyperparameters while paragraph 1 says that held-out corpus includes any corpus outside train corpus. Does held-out corpora include devset or same as devset?</p>
","natural-language-processing"
"28430","Example of lemma having multiple boldface forms","2021-06-27 23:08:48","","3","302","<natural-language-processing><books>","<p>Number of lemmas can be used as a rough measure for the number of words in a language. A lemma can have multiple word-form types. It can be understood from the following paragraph taken from p12 of <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/2.pdf"" rel=""nofollow noreferrer"">Regular Expressions,Text Normalization, Edit Distance</a></p>
<blockquote>
<p>Another measure of the number of words in the language is the number
of lemmas instead of wordform types. Dictionaries can help in giving
lemma counts; dictionary entries or <strong>boldface forms</strong> are a very rough
upper bound on the number of lemmas (<strong>since some lemmas have multiple
boldface forms</strong>). The 1989 edition of the Oxford English Dictionary had
615,000 entries.</p>
</blockquote>
<p>It is also given that a lemma can have multiple boldface forms, what are the boldface forms referred here? Are they different from wordforms?</p>
<p>If possible, provide an example for lemma having multiple boldface forms.</p>
","natural-language-processing"
"28410","Which tasks are called as downstream tasks?","2021-06-26 08:54:45","28424","8","16828","<natural-language-processing><terminology>","<p>The following paragraph is from page no 331 of the textbook <a href=""https://cseweb.ucsd.edu/%7Ennakashole/teaching/eisenstein-nov18.pdf#page=350"" rel=""noreferrer"">Natural Language Processing</a> by <em>Jacob Eisenstein</em>. It mentions about certain type of tasks called as downstream tasks. But, it provide no further examples or details regarding these tasks.</p>
<blockquote>
<p>Learning algorithms like perceptron and conditional random fields
often perform better with discrete feature vectors. A simple way to
obtain discrete representations from distributional statistics is by
clustering, so that words in the same cluster have similar
distributional statistics. This can help in <strong>downstream tasks</strong>, by
sharing features between all words in the same cluster. However, there
is an obvious tradeoff: if the number of clusters is too small, the
words in each cluster will not have much in common; if the number of
clusters is too large, then the learner will not see enough examples
from each cluster to generalize.</p>
</blockquote>
<p>Which tasks in artificial intelligence or NLP are called as downstream tasks?</p>
","natural-language-processing"
"28405","Is there any dataset to convert text to sign language?","2021-06-25 20:09:09","","1","33","<natural-language-processing>","<p>I'm going to start working on one university project and I would like to ask a question regarding it. My project is about &quot;Sign language synthesis from NLP&quot; and I need to develop an application where:</p>
<ol>
<li>Take spoken language from user microphone</li>
<li>Recognize a word with an algorithm and convert words to sign language</li>
</ol>
<p>Output should be images with sign language.</p>
<p>For instance, if we say &quot;I go home&quot;, we should have images of those words in sign language.</p>
<p>My question is that is there any dataset you would recommend to get the images for the sign language?</p>
","natural-language-processing"
"28292","Extracting keywords from messages","2021-06-17 11:38:22","","0","67","<machine-learning><natural-language-processing><supervised-learning><named-entity-recognition>","<p>I'm starting a project where I want to extract keywords from given messages. The keywords are for example something like: &quot;hard disk&quot;, &quot;watch&quot; or other technical components. I'm working with a dataset where a technician wrote a small text if he maintenanced something on a given object.</p>
<p>The messages are often very different in their form. For example sometimes the messages start with the repaired object and sometimes with the current date.</p>
<p>I looked into some NER-Libaries and it doesn't seem like they can handle tasks like that. Especially the German language makes it hard for those libaries to detect entities.</p>
<p>I had the idea to use CRFsuite to train my own NER-model. But I'm not sure how accurate the outcome will be. It would mean that I have to tag <em>a lot</em> of training data and I'm not sure if the outcome will match the time I have to spend to tag those keywords.</p>
<p>Does anybody have any experience with such custom NER-models? How accurate can such a model extract wanted keywords?</p>
","natural-language-processing"
"28236","How do very rare words tend to have very high PMI values?","2021-06-14 00:22:32","","2","577","<natural-language-processing><intuition>","<p>Consider the following formulation for pointwise mutual information (PMI):</p>
<p><span class=""math-container"">$$\text{PMI}(w, c) = \dfrac{p(w, c)}{p(w)p(c)}$$</span></p>
<p>Suppose there are <span class=""math-container"">$W$</span> words with <span class=""math-container"">$C$</span> context words. Then one can write in terms of frequency that</p>
<p><span class=""math-container"">$$\text{PMI}(w, c) = \dfrac{\sum\limits_{i = 1}^{W} \sum\limits_{j = 1}^{C} f_{ij} }{\sum\limits_{i = 1}^{W}f_i \sum\limits_{j = 1}^{C} f_j} $$</span></p>
<p>I am going to calculate <span class=""math-container"">$\text{PMI}(w, c)$</span> for two different words and contexts based on the following table. The table is taken from fig 6.10 of <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/6.pdf"" rel=""nofollow noreferrer"">this</a> book.</p>
<p><a href=""https://i.sstatic.net/XNoXK.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/XNoXK.png"" alt=""enter image description here"" /></a></p>
<p>I calculated PMI for all pairs and tabulated below.</p>
<p><span class=""math-container"">$$\begin{array}{|c|c|c|} \hline
    &amp; \text{computer} &amp; \text{data} &amp; \text{result} &amp; \text{pie} &amp;  \text{sugar} \\  \hline
  \text{cherry} &amp; 8.2 \times 10^{-7} &amp; 2.9 \times 10^{-6} &amp; 3.9 \times 10^{-5} &amp; 1.7 \times 10^{-3} &amp; 8.4 \times 10^{-4} \\ \hline
\text{strawberry} &amp; 0 &amp; 0 &amp; 2.6 \times 10^{-5} &amp; 1.4 \times 10^{-3} &amp; 3.8 \times 10^{-3} \\ \hline
\text{digital} &amp; 9.6 \times 10^{-5} &amp; 8.6 \times 10^{-5} &amp; 5.2  \times 10^{-5} &amp; 2.8 \times 10^{-6} &amp; 1.9 \times 10^{-5} \\ \hline
\text{information} &amp; 8.6 \times 10^{-5} &amp; 9.1 \times 10^{-5} &amp; 1.03  \times 10^{-4} &amp; 1.2 \times 10^{-6}&amp; 2.7 \times 10^{-5}\\ \hline
\end{array}$$</span></p>
<p>Based on the above values, we can also notice the following fact:</p>
<blockquote>
<p>PMI has the problem of being biased toward infrequent events; very rare words tend to have very high PMI values.</p>
</blockquote>
<p>However, it's unclear to me how this apparent behaviour is related to the mathematical formulation of the PMI above.</p>
<p>How do we understand the fact quoted above from the fractional form of PMI given by the equations above?</p>
","natural-language-processing"
"28217","Why do we commonly use the $\log$ to squash frequencies?","2021-06-13 00:04:14","","3","313","<natural-language-processing><definitions><books><tf-idf><logarithm>","<p>Term frequency and inverse document frequency are well-known terms in information retrieval.</p>
<p>I am presenting the definitions for both from p:12,13 of <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/6.pdf"" rel=""nofollow noreferrer"">Vector Semantics and Embeddings</a></p>
<p><strong>On term frequency</strong></p>
<blockquote>
<p>Term frequency is the frequency of the word <span class=""math-container"">$t$</span> in the term frequency
document <span class=""math-container"">$d$</span>. We can just use the raw count as the term frequency:</p>
<p><span class=""math-container"">$$tf_{t, d} = \text{count}(t, d)$$</span></p>
<p>More commonly <strong>we squash the raw frequency a bit, by using the
<span class=""math-container"">$\log_{10}$</span></strong> of the frequency instead. The intuition is that a word appearing 100 times in a document doesn’t make that word 100 times more likely to be relevant to the meaning of the document.</p>
</blockquote>
<p><strong>On inverse document frequency</strong></p>
<blockquote>
<p>The <span class=""math-container"">$\text{idf}$</span> is defined using the fraction <span class=""math-container"">$\dfrac{N}{df_t}$</span>, where <span class=""math-container"">$N$</span> is the total number of documents in the collection, and <span class=""math-container"">$\text{df}_t$</span> is the number of documents in which term <span class=""math-container"">$t$</span> occurs.......</p>
<p>Because of the large number of documents in many collections,  <strong>this measure too is usually squashed with a log function</strong>. The resulting  definition  for  inverse document frequency (<span class=""math-container"">$\text{idf}$</span>) is thus</p>
<p><span class=""math-container"">$$\text{idf}_t = \log_{10} \left(\dfrac{N}{df_t} \right)$$</span></p>
</blockquote>
<p>If we observe the bolded portion of the quotes, it is evident that the <span class=""math-container"">$\log$</span> function is used commonly. It is not only used in these two definitions. It has been across many definitions in the literature. For example: <a href=""https://ai.stackexchange.com/questions/28220/product-of-probabilities-raised-to-own-powers-that-can-be-used-for-entropy-calcu"">entropy</a>, mutual information, log-likelihood. So, I don't think squashing is the only purpose behind using the <span class=""math-container"">$\log$</span> function.</p>
<p>Is there any reason for selecting the logarithm function for squashing? Are there any advantages for <span class=""math-container"">$\log$</span> compared to any other squash functions, if available?</p>
","natural-language-processing"
"28128","Changing a CNN-LSTM image captioning architecture to use BiLSTMs","2021-06-07 10:26:58","28187","0","107","<deep-learning><natural-language-processing><computer-vision><long-short-term-memory><pytorch>","<p>Currently I'm dealing with an assignment that made us implement the network mentioned in <a href=""https://arxiv.org/abs/1502.03044"" rel=""nofollow noreferrer"">this paper</a>. The network has an architecture similar to this:</p>
<p><a href=""https://i.sstatic.net/rWWnE.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/rWWnE.jpg"" alt=""Network Architecture"" /></a></p>
<p>As you can see it uses a Unidirectional RNN (in my case LSTM), which does the many to many sequence prediction task while training, giving LSTM outputs to dense layers with softmax activation. For generating the captions, the network is only given the image at first, and then using the prediction of the image, generates a word, which is then fed to the network along with the generated hidden state, and the model does this recursively to find a unique stop token. Here's the prediction code:</p>
<pre><code>def predict(self, image, max_len = 30):
      output = []
      hidden = None
      inputs = self.encoder(image).unsqueeze(1) # Image features
      for i in range(max_len): # Recursively feed generated words to LSTM 
        lstm_out, hidden = self.decoder.lstm(inputs,hidden)
        output_vocab = self.decoder.fc(lstm_out)    
        output_vocab = F.softmax(output_vocab.squeeze(1), dim=1).detach().cpu().numpy()
        words_indices = output_vocab.argsort(axis=1).squeeze()
        word = words_indices[-1]
        if word == self.unk_token_index:
            word = indices[-2]
        output.append(int(word))
        if word == self.end_token_index:
          break  
        inputs = self.decoder.embed(torch.LongTensor([[word]]).to(image.device))
      return output
</code></pre>
<p>The problem I'm having right now is that I don't know whether this generation scheme works with BiLSTMs. Right now my training loss is way better for the sequence to sequence prediction task than the UniLSTM, but my generated captions are far worse.</p>
<p>This is a sample caption generated by Bi-LSTM:</p>
<p><a href=""https://i.sstatic.net/rzLMX.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/rzLMX.png"" alt=""Sample generated by ‌BiLSTM, picture from Flickr8k dataset."" /></a></p>
<p>This is a sample caption generated by UniLSTM:</p>
<p><a href=""https://i.sstatic.net/9KRLN.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/9KRLN.png"" alt=""Sample generated by ‌UniLSTM, picture from Flickr8k dataset."" /></a></p>
<p>My training loss for BiLSTM converges to 10e-3, while for UniLSTM it converges to 0.5. But the problem is that even before overfitting, BiLSTM is only generating gibberish.</p>
","natural-language-processing"
"28070","Which AI techniques are there that combine multiple models to make sense of data at different stages?","2021-06-03 04:29:25","28077","2","421","<natural-language-processing><reference-request><optical-character-recognition><named-entity-recognition><text-detection>","<p>I have been working to design a system that uses multiple machine learning models to make sense of data that is dynamically webscraped. Each AI would handle a specific task, for example:</p>
<p>An AI model would identify text in an image, then attempt to create plain text of what it might be. Once the text is extracted, it would be passed in a stored variable to an AI that can read the text to determine if it is a US city/state.</p>
<p>I tried to look into if others have done this, but didn't find much on it relating to what I was looking for. Does anyone know if there are potential issues with this? Logically, it looks good to me, but I figured I'd ask.</p>
<p>If anyone can put me in the right direction for reading material or further information, I would appreciate it.</p>
","natural-language-processing"
"28065","Why are BERT embeddings interpreted as representations of the corresponding words?","2021-06-02 14:59:59","","2","102","<natural-language-processing><word-embedding><bert><embeddings>","<p>It's often assumed in literature that BERT embeddings are contextual representations of the corresponding word. That is, if the 5th word is &quot;cold&quot;, then the 5th BERT embedding is a representation of that word, using context to disambiguate the word (e.g. determine whether it's to do with the illness or temperature).</p>
<p>However, because of the self-attention encoder layers, this embedding can in theory incorporate information from any of the other words in the text. BERT is trained using masked language modelling (MLM), which would encourage each embedding to learn enough to predict the corresponding word. But why wouldn't it contain additional information from other words? In other words, is there any reason to believe the BERT embeddings for different words contain well-separated information?</p>
","natural-language-processing"
"28045","How do sparse word embeddings fail to capture synonymy?","2021-06-01 06:01:16","","1","60","<natural-language-processing><word-embedding><sparse-word-embedding>","<p>While reading some explanations of why dense word embeddings work better than sparse word embeddings, the following statement has been given in the chapter <a href=""https://web.stanford.edu/%7Ejurafsky/slp3/6.pdf"" rel=""nofollow noreferrer"">Vector Semantics and Embeddings</a>, showing a drawback of sparse word embeddings.</p>
<blockquote>
<p>Dense vectors may also do a better job of capturing synonymy. For example, in a sparse vector representation, <strong>dimensions for synonyms like car and automobile dimension are distinct and unrelated</strong>; sparse vectors may thus fail to capture the similarity between a word with car as a neighbor and a word with automobile as a neighbor.</p>
</blockquote>
<p>It says that the dimensions of synonyms may be unrelated and distinct. I am facing difficulty in understanding it.</p>
<p>Can anyone provide me a simple example to understand it by taking some simple dimensions which are unrelated and distinct?</p>
<p>You can consider either documents or (context) words as dimensions for the example.</p>
","natural-language-processing"
"28025","What is an ""input embedding"" in the context of NLP?","2021-05-30 20:31:01","28026","3","2310","<natural-language-processing><embeddings>","<p>When reading about NLP, I saw it said that &quot;input embeddings&quot; are a main element of encoder-decoder learning frameworks for sequence modelling. What is an &quot;input embedding&quot; in the context of NLP?</p>
","natural-language-processing"
"27997","Can unsupervised models learn something from cat vocalizations?","2021-05-28 02:49:54","","1","22","<natural-language-processing><unsupervised-learning><natural-language-understanding><machine-translation><natural-language-generation>","<p>I love cats, and over the years have noticed that they have recurrent patterns of vocalizations. For example, upon seeing a bird, a cat may start chittering, but the same cat would never chitter at humans. Then there are complex vocalizations, like meow-wow, which I have observed across multiple cats on different continents. At the same time, we have birds and monkeys which have vocabularies of up to 300 (?) words. It seems like cats are communicating something, but humans may be too tone-deaf to understand that.</p>
<p>It seems to me like the task of understanding what a cat is trying to communicate to humans is suitable for some kind of machine learning process.</p>
<p>My question is: <strong>has any of these unsupervised models been applied to cat vocalizations?</strong> In other words, if a model can draw or generate text, can it generate cat meows? How close are we to understanding what cats are meowing about and translating it into English?</p>
<p>I remember that some work has been done with trying to decode dolphin vocalizations, but as you can imagine, that requires specialized equipment, while a cat model can be tested in the real world with simpler equipment.</p>
","natural-language-processing"
"27985","How to perform multi-class text classification with a dataset of 80 documents?","2021-05-27 17:00:18","","0","129","<machine-learning><natural-language-processing><transfer-learning><pretrained-models><multiclass-classification>","<p>I have a training dataset of 80 text documents with an average number of characters in each document of 25000 and 210 unique tags.</p>
<p>How can I perform multi-class text classification with such a small dataset, without using the pre-trained model? If it cannot be done without a pre-trained model, then which pre-trained model should I use?</p>
","natural-language-processing"
"27958","How to build a custom morphological analyser for translation system","2021-05-25 17:23:14","","0","34","<natural-language-processing>","<p>I want to build a machine translation system from English to Georgian. Georgian is a language similar (and simpler) to the Russian language. its syntax looks like <strong>base</strong> + <strong>suffix</strong>, only <strong>suffix</strong> changes, most of the time <strong>base</strong> is frozen, to describe the time the only suffix is changed. Unfortunately, I couldn't find a morphological analyser for the Georgian language, so could you link or provide useful resources to help me to build one? or can you give me some suggestions?</p>
","natural-language-processing"
"27957","Book(s) for text embedding","2021-05-25 14:55:28","27974","0","454","<natural-language-processing><reference-request><word-embedding><books><vector-semantics>","<p>Text here refers to either character or word or sentence.</p>
<p>Is there any recent <strong>textbook</strong> that encompasses from classical methods to the modern techniques for embedding texts?</p>
<p>If a single textbook is unavailable then please recommend a list of books covering the whole spectrum as mentioned above.</p>
<p>Modern textbooks that are similar to <a href=""https://nlp.stanford.edu/IR-book/information-retrieval-book.html"" rel=""nofollow noreferrer"">Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008</a> are highly encouraged.</p>
<p><a href=""https://ai.stackexchange.com/questions/20911/is-there-a-good-book-or-paper-on-word-embeddings"">This question</a> asks for textbook/research paper on word embedding only.</p>
","natural-language-processing"
"27951","Current extensions of the ""Turing Test""?","2021-05-25 03:27:24","","1","91","<natural-language-processing><reference-request><turing-test><ai-milestones><journalism>","<p>In 2014 it was widely reported that the Turing Test had been passed, and that this was a major AI milestone.</p>
<p>See: Computer AI passes Turing test in 'world first<a href=""https://www.bbc.com/news/technology-27762088"" rel=""nofollow noreferrer""> [BBC]</a>; Turing Test Success Marks Milestone in Computing History [<a href=""http://www.reading.ac.uk/news-archive/press-releases/pr583836.html"" rel=""nofollow noreferrer"">reading.ac.uk</a>]; What is the Turing test? And are we all doomed now? [<a href=""https://www.theguardian.com/technology/2014/jun/09/what-is-the-alan-turing-test"" rel=""nofollow noreferrer"">The Guardian</a>]</p>
<p>Never mind that the &quot;Imitation Game&quot; is subjective, and that porn bots have been passing it since there were porn bots—University of Reading was clear about their metrics.</p>
<p>But I understand that it did lead to revised tests, and extension of thinking on what constitutes passing such a threshold.</p>
<ul>
<li>How have Turing Tests been extended since 2014?</li>
</ul>
<p>How strong was the 2014 test?  What have been the criticisms of the 2014 determinations?</p>
","natural-language-processing"
"27927","How to detect the description of spine segments in short text using a neural network?","2021-05-23 10:48:45","","1","12","<natural-language-processing>","<p>The input data is a set of text chunks containing the description of the pathology or the surgical procedure:</p>
<p>For instance:</p>
<ol>
<li>Tere is a lumbar stenosis L3/4</li>
<li>Patient ist suffering from [...], MRI and X ray showed lumbar stenosis L3/4, segmental instability L3-5, foraminal stenosis L5/S1 both sides</li>
<li>The patient [...] underwent an MRI showing cervical stenosis C4-7 with myelopathy</li>
<li>[...] showed lumbar adult scoliosis L2-S1 with Cobb angle of 42°</li>
<li>Patient fell from the chair [...] showed osteoporotic fracture L3</li>
</ol>
<p>Now, the ideal classificator would give me:</p>
<ol>
<li>Segments: L3,L4; typeofpathology: degenerative; subtypepathology: stenosis</li>
<li>Segments: L3,L4,L5,S1; type of pathology: degenerative; subtypepathology: stenosis, instability</li>
<li>Segments C4, C5, C6, C7;type of pathology: degenerative; subtypepathology: myelopathy</li>
<li>Segments L2,L3,L4,L5,S1;type of pathology: deformity; subtypepathology: de novo scoliosis</li>
<li>Segments L3; type of pathology: pathological fracture; subtypepathology: -</li>
</ol>
<p>I think that this cannot be reasonably achieved by a pre-programmed algorithm, because the amount of the text before the description can vary, and the choice of words can vary too. Is there an approach using neural networks or NLP tools that would have chance at reaching such classification? How large would the dataset used for training have to be (approximately)?</p>
<p>Maybe it would be reasonable to separate the two problems: detection of the segments AND detection of the pathology. For the segments, one could search for a pattern of C? T? L? or S? with ? being a number and then include all such segment descriptions in the next 20-30 characters, then use an algorithm to mark the continuous segments from the upper to the lower vertebra.</p>
<p>Done this, do neural networks offer any significant advantages over simple keyword matching classification? Most importantly, which NLP neural network tools would be the ones you would start trying with?</p>
","natural-language-processing"
"27810","Do the training and test datasets need to be equally preprocessed as one whole dataset?","2021-05-15 18:52:22","","0","56","<machine-learning><natural-language-processing><prediction><data-preprocessing><feature-engineering>","<p>I have developed, trained and tested an NLP model. It is persisted in a pickle file. The model contains the data preprocessing function that includes text cleaning and new features engineered with word2vec.</p>
<p>With the trained model, I want to make predictions on a new text. The new text data, after preprocessing, won't contain the same engineered features of the training dataset.</p>
<p>Therefore my question is, how can the trained model make predictions on the new dataset as it has different engineered features (different numbers of columns and different columns)?</p>
<p>Should I preprocess the new text data and the training dataset as one dataset?</p>
","natural-language-processing"
"27761","What language is the GPT-3 engine written in?","2021-05-12 00:06:58","27762","16","23972","<natural-language-processing><programming-languages><c++><gpt-3><c>","<p>I know that the API is python based, but what's the gpt-3 engine written in mostly? C? C++? I'm having some trouble finding this info.</p>
","natural-language-processing"
"27714","Speech diarization for a conversation detector: A good idea or not?","2021-05-08 23:08:32","","0","48","<natural-language-processing><audio-processing><speech-recognition><spectral-clustering>","<p>I am trying to write a program in which an ai can detect whether a conversation is occurring or not. The ai does not need to transcribe words or have any meaning about the conversation, simply if one is occurring. A conversation can then simply be defined as having more than one speaker.</p>
<p>Anyways, while searching for past research on the subject, I came across the field of speech diarization, which is where an AI is trained to distinguish the numbers of speakers in a conversation. This seems perfect to me, however, while implementing I came across a few troubles. First of all, it wasn't good. I used this tutorial: <a href=""https://medium.com/saarthi-ai/who-spoke-when-build-your-own-speaker-diarization-module-from-scratch-e7d725ee279"" rel=""nofollow noreferrer"">https://medium.com/saarthi-ai/who-spoke-when-build-your-own-speaker-diarization-module-from-scratch-e7d725ee279</a> to write a simple program for this task, but I found it wasn't good at finding if there was a single or two speakers. Also the times where it was distinguishing speakers were all off.</p>
<p>It occurred to me that perhaps speech diarization may not be the best approach for this problem, so I decided to ask here about if this is the best solution, or if there are better ones out there. If it is the best solution, I would love some insight into why this wasn't working for me. Is the tutorial simply not good enough? I used 45 second - 1 minute long clips of just myself speaking or other people speaking with me and it did not work well at all like I said.</p>
","natural-language-processing"
"27649","Training seq2seq translation model with one source and multiple target","2021-05-05 01:10:04","","1","87","<neural-networks><natural-language-processing><recurrent-neural-networks><machine-translation><seq2seq>","<p>So basically I'm training a sequence to sequence model that translates English sentences to Arabic sentences. I'm using the data provided by <a href=""http://www.manythings.org/anki/"" rel=""nofollow noreferrer"">Anki @ manythings</a>. I realized that some of the sentences in English (source) have multiple sentences in Arabic (target), for example:</p>
<p>This is one case, where the Arabic harakat are not shown but the idea is that the same word has different translations (yes in arabic the first, fourth and fifth are not the same translations).</p>
<p><a href=""https://i.sstatic.net/OMOit.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/OMOit.png"" alt=""example-1"" /></a></p>
<p>A better example is the following one:</p>
<p><a href=""https://i.sstatic.net/juujK.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/juujK.png"" alt=""example-2"" /></a></p>
<p>I'm not sure how to deal with these cases, should I reduce the data and keep one translation, or should I have for each source key a list of target values. Any advice or &quot;tips &amp; tricks&quot; in preparing the data before training translation models?</p>
","natural-language-processing"
"27508","Creating a NLP driven chatbot","2021-04-26 06:47:01","","0","45","<natural-language-processing><reference-request><chat-bots><resource-request>","<p>I would like to create a chat bot for an e-commerce website that sells a wide range of general merchandize items, from t-shirts, jumpers to calculators. Its primary objective is to develop a Q&amp;A option for visitors/potential customers, to improve engagement on the website. As such, the chat bot is required to be fairly conversational.</p>
<p>I am experienced in classification et al, but know only the very basics on NLP. Can you provide suggestions on where to begin, e.g., recommended readings/ sources?</p>
<p>Also note, there is currently has no chat bot system in place, and hence no historical conversation data of any form.</p>
","natural-language-processing"
"27497","Is there any specific SW framework, libraries or algorithms designed for implementing a practical artificial general intelligence (AGI) system?","2021-04-25 10:42:27","27499","1","194","<machine-learning><natural-language-processing><agi><singularity><neuroscience>","<p><strong>Any (AGI)-KERAS like libraries useful to develop a real Artificial General Intelligence (AGI) system?</strong> Any deep-learning framework to develop AGI applications? any real Transformer-based (like Chat-GPT) libraries that can be used to achieve a minimum level of Artificial General Intelligence?</p>
<p>Existing frameworks/algorithms used in NN, NLP, ML, etc are not enough in my opinion. In my opinion any framework has to be based on building blocks from: Cognitive Science, Neuroscience, Mathematics, Artificial Intelligence, Computer Science, psycology, sociology, etc.</p>
","natural-language-processing"
"27471","Embedding from Transformer-based model from paragraph or documnet (like Doc2Vec)","2021-04-22 18:50:17","","2","27","<natural-language-processing><transformer><bert><embeddings>","<p>I have a set of data that contains the different lengths of sequences. On average the sequence length is 600. The dataset is like this:</p>
<pre><code>S1 = ['Walk','Eat','Going school','Eat','Watching movie','Walk'......,'Sleep']
S2 = ['Eat','Eat','Going school','Walk','Walk','Watching movie'.......,'Eat']
.........................................
.........................................
S50 = ['Walk','Going school','Eat','Eat','Watching movie','Sleep',.......,'Walk']
</code></pre>
<p>The number of unique actions in the dataset are fixed. That means some sentences may not contain all of the actions.</p>
<p>By using Doc2Vec (Gensim library particularly), I was able to extract embedding for each of the sequences and used that for later task (i.e., clustering or similarity measure)</p>
<p>As transformer is the state-of-the-art method for NLP task. I am thinking if Transformer-based model can be used for similar task. While searching for this technique I came across the &quot;sentence-Transformer&quot;-
<a href=""https://github.com/UKPLab/sentence-transformers"" rel=""nofollow noreferrer"">https://github.com/UKPLab/sentence-transformers</a>. But it uses a pretrained BERT model (which is probably for language but my case is not related to language) to encode the sentences. Is there any way I can get embedding from my dataset using Transformer-based model?</p>
","natural-language-processing"
"27261","What is the meaning of ""Our current objective weights every token equally and lacks a notion of what is most important to predict"" in the GPT-3 paper?","2021-04-11 00:39:23","","1","29","<natural-language-processing><papers><open-ai><gpt-3>","<p>On page 34 of OpenAI's <a href=""https://arxiv.org/pdf/2005.14165v2.pdf"" rel=""nofollow noreferrer"">GPT-3</a>, there is a sentence demonstrating the limitation of objective function:</p>
<blockquote>
<p>Our current objective weights every token equally and lacks a notion of what is most important to predict and what is less important.</p>
</blockquote>
<p>I am not sure if I understand this correctly. In my understanding, the objective function is to maximize the log-likelihood of the token to predict given the current context, i.e., <span class=""math-container"">$\max L \sim \sum_{i} \log P(x_{i} | x_{&lt;i})$</span>. Although we aim to predict every token that appears in the training sentence, the tokens have a certain distribution, and therefore we do not actually assign equal weight to every token in loss optimization.</p>
<p>And what should be an example for a model to get the notion of &quot;what is important and what is not&quot;. What is the importance refer to in here? For example, does it mean that &quot;the&quot; is less important compared to a less common noun, or does it mean that &quot;the current task we are interested in is more important than the scenario we are not interested in ?&quot;</p>
<p>Any idea how to understand the sentence by OpenAI?</p>
","natural-language-processing"
"27254","How to Select Model Parameters for Transformer (Heads, number of layers, etc)","2021-04-10 15:24:46","","3","571","<natural-language-processing><transformer><hyperparameter-optimization><attention><gpt>","<p>Is there a general guideline on how the Transformer model parameters should be selected, or the range of these parameters that should be included in a hyperparameter sweep?</p>
<ul>
<li>Number of heads</li>
<li>Number of encoder &amp; decoder layers</li>
<li>Size of transformer model (<code>d_model</code> in Pytorch)</li>
<li>Size of hidden layers</li>
</ul>
<p>Are there general guidelines like number of decoder layers should be equal to encoder layers? Thank you</p>
","natural-language-processing"
"27244","Extracting ""hidden"" costs from financial statements using NLP","2021-04-09 19:17:03","","2","88","<natural-language-processing><named-entity-recognition><spacy>","<p>I'm designing a NLP model to extract various kinds of &quot;hidden&quot; expenses from 10-K and 10-Q financial statements. I've come up with about 7 different expense categories (restructuring costs, merger and acquisitions, etc.) and for each one I have a list of terms/synonyms that different companies call them. I'm new to NLP would like some advice on the best approach for extracting them.</p>
<p>Values are usually hidden in two different areas of the document:</p>
<h3>Type 1: Free-form text (footnotes)</h3>
<p>Values are nested in sentences. Here are some examples, with the <em>Expense Type</em> and <strong>Monetary value</strong> indicated.</p>
<blockquote>
<p><em>Exploratory dry-hole costs</em> were <strong>\$12.7 million</strong>, \$1.3 million, and \$1.0 million for the years ended December 31, 2012, 2011, and 2010, respectively.</p>
</blockquote>
<blockquote>
<p>2012 includes the recognition of a <strong>$3,340 million</strong> <em>impairment charge</em> related to the carrying value of Citi's remaining 35% interest in the Morgan Stanley Smith Barney joint venture</p>
</blockquote>
<blockquote>
<p>During the year ended December 31, 2017, we decided to discontinue the internal development of AMG 899, resulting in an <em>impairment charge</em> of <strong>$400 million</strong> for the IPR&amp;D asset</p>
</blockquote>
<h3>Type 2: Table data</h3>
<p>SEC statements also contain &quot;structured&quot; data in HTML tables. Some line items, like the first row below, correspond to the expense type I'm looking for:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Item</th>
<th>2020</th>
<th>2019</th>
<th>2018</th>
</tr>
</thead>
<tbody>
<tr>
<td>impairment related to real estate assets(2):</td>
<td>398.2</td>
<td>200</td>
<td>0</td>
</tr>
<tr>
<td>research and development</td>
<td>100</td>
<td>200</td>
<td>300</td>
</tr>
<tr>
<td>other expenses</td>
<td>20</td>
<td>30</td>
<td>40</td>
</tr>
</tbody>
</table>
</div>
<p>Correct value = <code>398.2</code></p>
<hr />
<p>I'm thinking about a two-model approach:</p>
<ol>
<li><p>Define a new NER model based off the terms I already know (e.g. &quot;dry-hole costs&quot;, &quot;impairment charges&quot;). I would need to manually annotate extracts from historic statements that contain these terms for the training set.</p>
<ul>
<li>For free-form text, it would match the sentence and pass it on for further processing (see 2).</li>
<li>For table data, I would loop over each row using beautifulsoup and pandas, check the first column for a match (e.g. using spaCy's comparison function), and then grab that year's value from the dataframe and finish.</li>
</ul>
</li>
<li><p>For free-form matches, I still need to grab the monetary value for the correct year (sometimes multiple values are given for various years, see the first example above).</p>
</li>
</ol>
<p>One potential problem here is that sentences like this would cause problems:</p>
<blockquote>
<p>We gained $100 million this year, despite facing restructuring charges.</p>
</blockquote>
<p>If the NLP algo is split into the above two-model process, model 1 would pass (because it contains a known term like &quot;restructuring charges&quot;), and model 2 would extract <code>$100 million</code>, which is incorrect because it doesn't actually correspond to the expense itself.</p>
<p>Is there a better solution here? As I said, I'm new to NLP and data extraction so would really appreciate any advice or resources to learn more about solving these types of key/value problems.</p>
","natural-language-processing"
"27048","Extracting values from text based on keywords","2021-03-28 12:32:39","","-1","38","<natural-language-processing><recurrent-neural-networks><natural-language-understanding>","<p>I am trying to read a PDF file and put it in Python string and trying to fetch information based on keywords. The text here is completely irregular.</p>
<p>Example of text</p>
<blockquote>
<p>Blockquote
Ram has taken an insurance of his premises with total sum insured of INR 256,200,000,000. XYZ company provides an insured with limit of liability of INR 100,250,000 and 90 days indemnity period. Insured with deductible of INR 200,000.</p>
</blockquote>
<p>Here I want to find 3 things from this text</p>
<ul>
<li>limit of liability amount</li>
<li>Deductible amount</li>
<li>Sum insured amount</li>
</ul>
<p>For example</p>
<p>Limit of liability  = 100,250,000</p>
","natural-language-processing"
"27038","Why does GPT-2 Exclude the Transformer Encoder?","2021-03-27 19:55:30","","20","13588","<natural-language-processing><transformer><attention><bert><gpt>","<p>After looking into transformers, BERT, and GPT-2, from what I understand, GPT-2 essentially uses only the decoder part of the original transformer architecture and uses masked self-attention that can only look at prior tokens.</p>
<p>Why does GPT-2 not require the encoder part of the original transformer architecture?</p>
<p><strong>GPT-2 architecture with only decoder layers</strong></p>
<p><a href=""https://i.sstatic.net/Kb8Gq.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/Kb8Gq.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"27009","Why (not) using pre-processing before using Transformer models?","2021-03-25 18:37:05","","0","314","<natural-language-processing><pytorch><transformer><data-preprocessing>","<p>Regarding the use of pre-processing techniques before using Transformers models, I read <a href=""https://stackoverflow.com/a/63986348/13745968"">this post</a> that apparently says that these measures are not so necessary nor interfere so much in the final result.</p>
<p>The arguments raised seemed to me quite convincing, but someone would know how to explain better, perhaps with a bibliographic reference, why is it not so necessary to use these techniques?</p>
","natural-language-processing"
"26966","I have 5000 html files (structured text), how can I generate a new one that ""resembles"" those?","2021-03-23 16:39:07","","2","149","<natural-language-processing><natural-language-generation>","<p>I don't know anything about ML or NLP, but I was asked by someone to create brand new statutes (written laws) that resemble the ones currently in effect in my country. I have already gathered the laws, and have 5000 html files now, one per law.</p>
<p>The average size of each html file is 49 kB. The entire corpus is 300 MB.</p>
<p>I have two alternative goals (doing both would be perfect of course):</p>
<ul>
<li><p>Generate a new, complete HTML file, that would imitate the 5000 existing ones (it would typically have 1 big heading at the top, sub-headings, articles with their own title and number, etc.)</p>
</li>
<li><p>Generate sentences that sound as if they could be found in a typical law (the laws are written in French)</p>
</li>
</ul>
<p>Is any of those goals feasible, with such a small corpus (~300 MB total)?</p>
<p>Should I try and fine-tune an existing model (but in that case, wouldn't the small size of my corpus be a problem? Wouldn't it be &quot;drowned out&quot; in the rest of the training data?), or should I create one from scratch?</p>
<p>I've tried following guides on huggingface, but between the obsolete files, the undocumented flags and my general lack of knowledge of the subject, I'm completely lost.</p>
<p>Thanks in advance.</p>
<p>BTW, if you want to take a peek at the data, there it is: <a href=""https://github.com/Biganon/rs/"" rel=""nofollow noreferrer"">https://github.com/Biganon/rs/</a></p>
","natural-language-processing"
"26932","How to train a sequence labeling model with annotations from three annotators?","2021-03-21 04:54:25","26933","0","45","<neural-networks><natural-language-processing><python><sentiment-analysis><named-entity-recognition>","<p>I have a dataset of movie reviews annotated by 3 persons. The following example contains one sentence with corresponding annotations from 3 different persons.</p>
<pre><code>sentence = ['I', 'like', 'action', 'movies','!']
annotator_1 = ['O','O', 'B_A', 'I_A', 'O'] 
annotator_2 = ['O','O', 'B_A', 'I_A', 'O'] 
annotator_3 = ['O','O', 'B_A', 'O', 'O']
</code></pre>
<p>The labels follow the BIO format. That is, <code>B_A</code> means the beginning of aspect-term (action) and <code>I_A</code> indicates inside of aspect-term (movie).
Unfortunately, the annotators do not agree always together. While the first two persons assigned the right labels for aspect-term (action movie), the last one mislabeled the token (movies).</p>
<p>I am using Bi-LSTM-CRF sequence tagger to train the model. However, I am not sure if am using the training data correctly.</p>
<p><em>Is it correct to feed the model the same sentence with annotations from 3 persons? Then test it in the same way, i.e., the same sentence with different annotations?</em></p>
<p>Another question.</p>
<p>I merged the annotations in one final list of labels as follows:</p>
<pre><code>final_annotation = ['O','O', 'B_A', 'I_A', 'O']
</code></pre>
<p>In this case, the final label is chosen based on the majority of labels among three annotators.</p>
<p><em>Is it right to feed the model the same sentence with corresponding annotations from all users during the testing phase?</em></p>
","natural-language-processing"
"26906","Can Facebook's LASER be used like BERT?","2021-03-18 19:54:47","","2","275","<deep-learning><natural-language-processing><sentiment-analysis><question-answering><fine-tuning>","<p>Can <a href=""https://engineering.fb.com/2019/01/22/ai-research/laser-multilingual-sentence-embeddings/"" rel=""nofollow noreferrer"">Facebook's LASER</a> be fine-tuned like BERT for Question Answering tasks or Sentiment Analysis?</p>
<p>From my understanding, they created an embedding that allows for similar words in different languages to be close to each other. I just don't understand if this can be used for fine-tuning tasks like BERT can.</p>
","natural-language-processing"
"26882","Is my approach to building an RNN to predict the probability that the word is in English appropriate?","2021-03-18 00:22:17","26931","0","150","<neural-networks><natural-language-processing><recurrent-neural-networks><data-preprocessing>","<h2>Goal</h2>
<p>To build an RNN which would receive a word as an input, and output the probability that the word is in English (or at least would be English sounding).</p>
<p><strong>Example</strong></p>
<pre><code>input:  hello 
output: 100%

input:  nmnmn 
output: 0%
</code></pre>
<h2>Approach</h2>
<p>Here is my approach.</p>
<h3>RNN</h3>
<p>I have built an RNN with the following specifications: (the subscript <span class=""math-container"">$i$</span> means a specific time step)</p>
<p>The vectors (neurons):</p>
<p><span class=""math-container"">$$
x_i \in \mathbb{R}^n \\
s_i \in \mathbb{R}^m \\
h_i \in \mathbb{R}^m \\
b_i \in \mathbb{R}^n \\
y_i \in \mathbb{R}^n \\
$$</span></p>
<p>The matrices (weights):
<span class=""math-container"">$$
U \in \mathbb{R}^{m \times n} \\
W \in \mathbb{R}^{m \times m} \\
V \in \mathbb{R}^{n \times m} \\
$$</span></p>
<p>This is how each time step is being fed forward:</p>
<p><span class=""math-container"">$$
y_i = softmax(b_i) \\
b_i = V h_i \\
h_i = f(s_i) \\
s_i = U x_i + W h_{i-1} \\
$$</span>
Note that the <span class=""math-container"">$ + W h_{i-1}$</span> will not be used on the first layer.</p>
<h3>Losses</h3>
<p>Then, for the loss of each layer, I used cross entropy (<span class=""math-container"">$t_i$</span> is the target, or expected output at time <span class=""math-container"">$i$</span>):
<span class=""math-container"">$$
L_i = -\sum_{j=1}^{n} t_{i,j} \ln(y_{i,j})
$$</span></p>
<p>Then, the total loss of the network:
<span class=""math-container"">$$
L = \sum L_i
$$</span></p>
<h3>RNN diagram</h3>
<p>Here is a picture of the network that I drew:</p>
<p><a href=""https://i.sstatic.net/MeIA8m.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/MeIA8m.png"" alt=""enter image description here"" /></a></p>
<h3>Data pre-processing</h3>
<p>Here is how data is fed into the network:</p>
<p>Each word is split into characters, and every character is split into a one-hot vector. Two special tokens START and END are being appended to the word from the beginning and the end. Then the input at each time step will be every sequential character without END, and the output at each time step will be the following character to the input.</p>
<p><strong>Example</strong></p>
<p>Here is an example:</p>
<ol>
<li>Start with a word: &quot;cat&quot;</li>
<li>Split it into characters and append the special tags: <code>START  c  a  t  END</code></li>
<li>Transform into one-hot vectors: <span class=""math-container"">$v_1, v_2, v_3, v_4, v_5$</span></li>
<li>Then the input is <span class=""math-container"">$v_1, v_2, v_3, v_4$</span> and the output <span class=""math-container"">$v_2, v_3, v_4, v_5$</span></li>
</ol>
<h3>Dataset</h3>
<p>For the dataset, I used a list of English words.</p>
<p>Since I am working with English characters, the size of the input and output is <span class=""math-container"">$n=26+2=28$</span> (the <span class=""math-container"">$+2$</span> is for the extra START and END tags).</p>
<h3>Hyper-parameters</h3>
<p>Here are some more specifications:</p>
<ul>
<li>Hidden size: <span class=""math-container"">$m=100$</span></li>
<li>Learning rate:  <span class=""math-container"">$0.001$</span></li>
<li>Number of training cycles:  <span class=""math-container"">$15000$</span> (each cycle is a loss calculation and backpropagation of a random word)</li>
<li>Activation function: <span class=""math-container"">$f(x) = \tanh(x)$</span></li>
</ul>
<h2>Problem/question</h2>
<p>However, when I run my model, I get that the probability of some word being valid is about 0.9 regardless of the input.</p>
<p>For the probability of a word begin valid, I used the value at the last layer of the RNN at the position of END tag after feeding forward the word.</p>
<p>I wrote a gradient checking algorithm and the gradients seem to check up.</p>
<p><em>Is there conceptually something wrong with my neural network?</em></p>
<p>I played a bit with <span class=""math-container"">$m$</span>, the learning rate, and the number of cycles, but nothing really improved the performance.</p>
","natural-language-processing"
"26877","Is there a relationship between Computer Algebra and NLP?","2021-03-17 17:49:14","27020","3","306","<natural-language-processing><comparison><symbolic-computing>","<p>My intuition is that there is some overlap between understanding language and symbolic mathematics (e.g. algebra). The rules of algebra are somewhat like grammar, and the step-by-step arguments get you something like a narrative. If one buys this premise, it might be worth training an AI to do algebra (solve for x, derive this equation, etc).</p>
<p>Moreover, when variables represent &quot;real&quot; numbers (as seen in physics, for example) algebraic equations describe the real world in an abstracted, &quot;linear,&quot; way somewhat similar to natural language.</p>
<p>Finally, there are exercises in algebra, like simplifying, deriving useful equations, etcetera which edge into the realm of the subjective, yet it is still much more structured and consistent than language. It seems like this could be a stepping stone towards the ambiguities of natural language.</p>
<p>Can anyone speak to whether this has either (1) been explored or (2) is a totally bogus idea?</p>
","natural-language-processing"
"26794","Should I need to use BERT embeddings while tokenizing using BERT tokenizer?","2021-03-13 10:12:54","","2","1657","<natural-language-processing><word-embedding><bert><word2vec>","<p>I am new to BERT and NLP and I am a little confused with tokenization and word embedding.
My doubt is if I use the BertTokenizer for tokenizing a sentence then do I have to compulsorily use BertEmbedding for generating its corresponding word vectors of the tokens or I can train my own word2vec model to generate my word embedding while using BertTokenizer?</p>
<p>Pardon me if this question doesn't make any sense.</p>
","natural-language-processing"
"26771","Are training sequences for LMs sampled in an IID fashion?","2021-03-11 18:14:33","","2","111","<natural-language-processing><language-model><iid>","<p>If I understand correctly, when training language models, we take a document and then chunk the document into a sequences of k tokens. So if the document is of length 30 and k=10, then we'll have 20 chunks of 10 tokens each (token 1-11, 2-12, and so on).</p>
<p>However these training sequences are not iid, right? If so, are there any papers that try and deal with this?</p>
","natural-language-processing"
"26739","What is the difference between a language model and a word embedding?","2021-03-09 21:43:24","26745","5","7926","<natural-language-processing><comparison><word-embedding><language-model><bleu>","<p>I am self-studying applications of deep learning on the NLP and machine translation.</p>
<p>I am confused about the concepts of &quot;Language Model&quot;, &quot;Word Embedding&quot;, &quot;BLEU Score&quot;.</p>
<p>It appears to me that a language model is a way to predict the next word given its previous word. Word2vec is the similarity between two tokens. BLEU score is a way to measure the effectiveness of the language model.</p>
<p>Is my understanding correct? If not, can someone please point me to the right articles, paper, or any other online resources?</p>
","natural-language-processing"
"26667","Given the word embeddings, how do I create the sentence composed of the corresponding words?","2021-03-04 13:39:49","","1","49","<natural-language-processing><long-short-term-memory><word-embedding><sentiment-analysis><word2vec>","<p>I have done some reading. I want to implement an LSTM with pre-trained word embeddings (I also have plans to create my word embeddings, but let's cross that bridge when we come to it).</p>
<p>In any given sentence, you don't usually need to have all the words as most of them do not contribute to the sentiment, such as the <a href=""https://en.wikipedia.org/wiki/Stop_word"" rel=""nofollow noreferrer"">stop words</a> and noise. So, let's say there is a sentence. I remove the stop words and anything else that I deem unnecessary for the project. Then I run the remaining words through the word embedding algorithm to get the word vectors.</p>
<p>Then what? How does it represent the sequence or the sentence 'cause it's just vector for a word.</p>
<p>For example, take the sentence:</p>
<blockquote>
<p>The burger does not taste good.</p>
</blockquote>
<p>I could remove certain words and still retain the same sentiment like so:</p>
<blockquote>
<p>Burger not good.</p>
</blockquote>
<p>Let's assume some arbitrary vectors for those three words:</p>
<ul>
<li><p><code>Burger</code>: <span class=""math-container"">$[0.45, -0.78, .., 1.2]$</span></p>
</li>
<li><p><code>not</code>: <span class=""math-container"">$[9.6, 4.0, .., 5.6]$</span></p>
</li>
<li><p><code>good</code>: <span class=""math-container"">$[3.5, 0.51, 0.8]$</span></p>
</li>
</ul>
<p>So, those vectors represent the individual words. How do I make a sentence out of them? Just concatenate them?</p>
","natural-language-processing"
"26662","CAPTCHA based on text comprehension and random tokens","2021-03-04 11:35:00","","1","136","<natural-language-processing><captcha>","<p>I developed a novel type of CAPTCHA based on <strong>text comprehension and random tokens</strong>. Given a task <code>Pick the first pair of adjacent letters</code> and a random token <code>8NBA596V</code>, the user has to provide the solution <code>NB</code>. It offers basic protection and an attacker can solve individual tasks with <strong>specific</strong> effort. I am curious, whether contemporary AI can solve it <strong>generically</strong>?</p>
<p>You can access more example tasks here:
<a href=""https://www.topincs.com/manual/captcha"" rel=""nofollow noreferrer"">https://www.topincs.com/manual/captcha</a></p>
<p>There is a task database and at every attempt a new task is presented with a new random token. They always have a solution of varying length and pure guessing thus has limited chances of success. It is easy to attack an individual task by writing a small piece of code, thus a large task database is essential. What intrigues me is the question whether natural language processing or machine learning at its current state can attack the CAPTCHA generically by building a model of the meaning of the task
– essentially a predicate in a tiny universe of discourse – and then applying it to the random token.</p>
","natural-language-processing"
"26597","What is the difference between zero-padding and character-padding in Recurrent Neural Networks?","2021-02-27 11:04:17","","3","101","<natural-language-processing><recurrent-neural-networks><seq2seq><padding>","<p>For RNN's to work efficiently, we vectorize the operations, which results in an input matrix of shape</p>
<pre><code>(m, max_seq_len) 
</code></pre>
<p>where <code>m</code> is the number of examples, e.g. sentences, and <code>max_seq_len</code> is the maximum length that a sentence can have. Some examples have smaller lengths than this <code>max_seq_len</code>. A solution is to pad these sentences.</p>
<p>One method to pad the sentences is called &quot;zero-padding&quot;. This means that each sequence is padded with zeros. For example, given a vocabulary where each word is related to some index number, we can represent a sentence with length 4,</p>
<pre><code>I am very confused 
</code></pre>
<p>by</p>
<pre><code>[23, 455, 234, 90] 
</code></pre>
<p>Padding it to achieve a <code>max_seq_len=7</code>, we obtain a sentence represented by:</p>
<pre><code>[23, 455, 234, 90, 0, 0, 0] 
</code></pre>
<p>The index 0 is not part of the vocabulary.</p>
<p>Another method to pad is to add a padding character, e.g. <code>&lt;&lt;pad&gt;&gt;</code>, in our sentence:</p>
<pre><code>I am very confused &lt;&lt;pad&gt;&gt;&gt; &lt;&lt;pad&gt;&gt; &lt;&lt;pad&gt;&gt;
</code></pre>
<p>to achieve the <code>max_seq_len=7</code>. We also add <code>&lt;&lt;pad&gt;&gt;</code> in our vocabulary. Let's say its index is 1000. Then the sentence is represented by</p>
<pre><code>[23, 455, 234, 90, 1000, 1000, 1000]
</code></pre>
<p>I have seen both methods used, but why is one used over the other? Are there any advantages or disadvantages comparing zero-padding with character-padding?</p>
","natural-language-processing"
"26531","How are certain machine learning models able to produce variable-length outputs given variable-length inputs?","2021-02-24 06:42:08","26534","3","2087","<machine-learning><natural-language-processing><recurrent-neural-networks><transformer><natural-language-generation>","<p>Most machine learning models, such as multilayer perceptrons, require a fixed-length input and output, but generative (pre-trained) transformers can produce sentences or full articles of variable length. How is this possible?</p>
","natural-language-processing"
"26511","Adding corpus to BERT for QA","2021-02-22 14:41:40","","2","39","<natural-language-processing><bert><fine-tuning>","<p>I was wondering about <strong>SciBERT</strong>'s QA abilities using SQuAD. I have a scarce textual dataset consisting of less than 100 files where doctors are discussing cancer in dialogues. I want to add it to SciBERT to see if the QA abilities will improve in the cancer disease domain.</p>
<p>After concatenating them into one large file which will be our vocab, I then clean the file (all char to lower, white space splitting, char filtering, punctuation, stopword filtering, short tokens and etc) which leaves me with a list of 3000 unique tokens</p>
<p>If I wanted to add these tokens, do I just do <code>scibert_tokenizer.add_tokens(myList)</code> where myList is the 3k tokens?</p>
<p>I can confirm that more tokens are added doing <code>print(len(scibert_tokenizer))</code> and I can see that embeddings do change such as <code>corona</code> and <code>##virus</code> changes to <code>coronavirus</code> and <code>##virus</code>.</p>
<p>Does the model need to be trained from scratch again?</p>
","natural-language-processing"
"26440","Are the Word2Vec encoded embeddings available online?","2021-02-18 13:05:36","26464","0","394","<deep-learning><natural-language-processing><word-embedding><word2vec><embeddings>","<p>I am trying to do an NLP project and was wondering if there is anywhere online where the Word2Vec embeddings are stored (the actual n-dimmensional vectors).
I want to search up a word and see what its encoding is. I have tried looking but couldn't find anything.
Thank you</p>
","natural-language-processing"
"26405","NLP: Are hashtags tokenised?","2021-02-16 09:38:20","26409","0","135","<natural-language-processing><recurrent-neural-networks><word-embedding>","<p>I am exploring a potential NLP project. I was wondering what generally is done with the hashtags words (e.g. <code>#hello</code>). Are those words ignored? is the <code>#</code> removed and the word tokenised? Is it tokenised with the <code>#</code>?</p>
","natural-language-processing"
"26346","How to keep track of the subject/entity in a sentence?","2021-02-11 23:41:50","26347","1","379","<natural-language-processing><bert><sentiment-analysis>","<p>I'm working on Sentiment Analysis, using HuggingFace to perform sentiment analysis on articles</p>
<pre><code> classifier = pipeline('sentiment-analysis', model=&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;)
 classifier(['We are very happy to show you the 🤗 Transformers library.',  &quot;We hope you don't hate it.&quot;])
</code></pre>
<p>This returns</p>
<blockquote>
<p>label: POSITIVE, with score: 0.9998</p>
</blockquote>
<blockquote>
<p>label: NEGATIVE, with score: 0.5309</p>
</blockquote>
<p>Now I'm trying to understand how to keep track of a subject when performing the sentiment analysis.</p>
<p>Suppose I'm given a sentence like this.</p>
<blockquote>
<p>StackExchange is a great website. It helps users answer questions.  Hopefully, someone will help answer this question.</p>
</blockquote>
<p>I would like to keep track of the subject when performing sentiment analysis. In the example above, in the 2nd sentence 'it' refers to 'StackExchange'. I would like to be able to do track a subject between sentences.</p>
<p>Now, I could try to manually try to parse this by finding the verb and trying to figure find the phrase that comes before it. However, it doesn't sound like a very safe or accurate way to find the subject.</p>
<p>Alternatively, I could train similar to a Named Entity Recognition. However, finding a dataset for this is very hard, and training it would be very time-consuming.</p>
<p>How can I keep track of an entity within an article?</p>
","natural-language-processing"
"26318","How would one disambiguate between two meanings of the same word in a sentence?","2021-02-10 20:27:43","","3","194","<natural-language-processing><natural-language-understanding><word2vec><semantic-networks>","<blockquote>
<p>The boy lifted the bat and hit the ball.</p>
</blockquote>
<p>In the above sentence, the noun &quot;bat&quot; means the wooden stick. It does not mean bat, the flying mammal, which is also a noun. Using NLP libraries to find the noun version of the definition would still be ambiguous.</p>
<p>How would one go about writing an algorithm that gets the exact definition, given a word, and the sentence it is used in?</p>
<p>I was thinking you could use word2vec, then use autoextend <a href=""https://arxiv.org/pdf/1507.01127.pdf"" rel=""nofollow noreferrer"">https://arxiv.org/pdf/1507.01127.pdf</a> to differentiate between 2 different lexemes e.g. bat (animal) and bat (wooden stick).</p>
<p>Then the closest cosine distance between the dictionary definition and any of the words of the sentence might indicate the correct definition.</p>
<p>Does this sound correct?</p>
","natural-language-processing"
"26284","What does the outputlayer of BERT for masked language modelling look like?","2021-02-08 19:16:14","","1","623","<natural-language-processing><transformer><attention><word-embedding><bert>","<p>In the tutorial <a href=""https://www.lyrn.ai/2018/11/07/explained-bert-state-of-the-art-language-model-for-nlp/"" rel=""nofollow noreferrer"">BERT – State of the Art Language Model for NLP</a> the masked language modeling pre-training steps are described as follows:</p>
<blockquote>
<p>In technical terms, the prediction of the output words requires:</p>
<ol>
<li>Adding a classification layer on top of the encoder output.</li>
</ol>
<p>2.Multiplying the output vectors by the embedding matrix, transforming them into the vocabulary dimension.</p>
<p>3.Calculating the probability of each word in the vocabulary with softmax.</p>
</blockquote>
<p>In the Figure below this process is visualized and also from the tutorial.</p>
<p>I am confused about what exactly is done. Does it mean that each output vector O is fed into a fully connected layer with embedding_size neurons and then multiplied by the embedding matrix from the input layer?</p>
<p>Update:</p>
<p>In the tutorial <a href=""http://jalammar.github.io/illustrated-gpt2/"" rel=""nofollow noreferrer"">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a> I found an explanation for GPT-2 which seems to be similar to my question.</p>
<p>In the tutorial is said that each output vector is multiplied by the input embedding matrix to get the final output.</p>
<p>Does the same mechanic apply to BERT?</p>
<p><img src=""https://miro.medium.com/max/698/0*ViwaI3Vvbnd-CJSQ.png"" alt=""Text"" /></p>
","natural-language-processing"
"26235","What kind of word embedding is used in the original transformer?","2021-02-05 18:51:59","26246","20","13440","<natural-language-processing><transformer><attention><word-embedding>","<p>I am currently trying to understand transformers.</p>
<p>To start, I read <a href=""https://arxiv.org/pdf/1706.03762.pdf"" rel=""noreferrer"">Attention Is All You Need</a> and also <a href=""https://nlp.seas.harvard.edu/2018/04/03/attention.html"" rel=""noreferrer"">this</a> tutorial.</p>
<p>What makes me wonder is the word embedding used in the model. Is word2vec or GloVe being used? Are the word embeddings trained from scratch?</p>
<p>In the tutorial linked above, the transformer is implemented from scratch and nn.Embedding from pytorch is used for the embeddings. I looked up this function and didn't understand it well, but I tend to think that the embeddings are trained from scratch, right?</p>
","natural-language-processing"
"26218","Is there a reason why no one combines word embeddings with the median?","2021-02-05 07:05:52","","0","66","<natural-language-processing><word-embedding>","<p>Could you combine word embeddings with the median per dimension to get a document embedding? In my case I have a huge amount of words to build one document, which in turn should describe a topic. I feel like using the median is the right thing to do, as I get the most common parameter value per dimension. However, I cannot find anyone trying it before. This is why I'm wondering, is there something speaking against it?</p>
","natural-language-processing"
"26203","How to scrape product data on supplier websites?","2021-02-04 18:13:11","","1","63","<natural-language-processing><python><pretrained-models><fine-tuning>","<p>I'm currently trying to build a semantic scraper that can extract product information from different company websites of suppliers in the packaging industry (with as little manual customization per supplier/website as possible).</p>
<p>The current approach that I'm thinking of is the following:</p>
<ol>
<li>Get all the text data via scrapy (so basically a HTML-tag search). This data would hopefully be already semi-structured with for example: name, description, product image, etc.</li>
<li>Fine-tune a pre-trained NLP model (such as BERT) on a domain specific dataset for packaging to extract more information about the product. For example: weight and size of the product</li>
</ol>
<p>What do you think about the approach? What would you do differently?</p>
<p>One challenge I already encountered is the following:</p>
<ul>
<li>Not all of the websites of the suppliers are as structured as for example e-commerce sites are → So small customisations of the XPath for all websites is needed. How can you scale this?</li>
</ul>
<p>Also does anyone know an open-source project as a good starting point for this?</p>
","natural-language-processing"
"25962","Is using a LSTM, CNN or any other neural network model on top of a Transformer(using hidden states) overkill?","2021-01-25 03:34:28","","1","647","<deep-learning><natural-language-processing><transformer><text-classification><sentiment-analysis>","<p>I have recently come across transformers, I am new to Deep Learning. I have seen a <a href=""https://arxiv.org/pdf/2007.10819.pdf"" rel=""nofollow noreferrer"">paper</a> using   CNN and BiLSTM on top of a transformer, the paper uses a transformer(XLM-R) for sentiment analysis in code-mixed domain. But many of the blogs only use a normal feed formal network on top of the transformer.</p>
<p>I am trying to use transformers for sentiment analysis, short text classification.</p>
<p>Is it overkill to use models like CNN and BiLSTM on top of the transformer considering the size of the data it is trained on and its complexity?</p>
","natural-language-processing"
"25956","Is the working of RNNs, LSTM and GRU sequential or parallel?","2021-01-24 18:40:07","25959","0","2531","<neural-networks><deep-learning><natural-language-processing><recurrent-neural-networks><long-short-term-memory>","<p>You take any blog or any example and all they tell you about is the given picture below.</p>
<p><a href=""https://i.sstatic.net/hyb25.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/hyb25.png"" alt=""enter image description here"" /></a></p>
<p>It has 4 different matrices and 3 of whose weights are shared. So, I'm wondering how is this achieved in practice?</p>
<p>Please correct me:</p>
<p>I think the first word &quot;hello&quot; goes in as a one-hot encoded form and changes the Hidden matrix. And then after it, &quot;world&quot; goes and gets multiplied and then changes the matrix again and so on. What people make it look like is that all of the words going are in Parallel. It can't be the case because the Hidden matrix is dependent on the previous word and without changing the matric, you can not pass the current word. Please correct if my idea is wrong but I think the execution is in sequential order.</p>
","natural-language-processing"
"25908","Is there any neural network model that can perform multiple NLP steps at once?","2021-01-22 02:06:39","","0","25","<neural-networks><natural-language-processing><natural-language-understanding><expert-systems><natural-language-generation>","<p>I realize most NLP algorithms have multiple steps. (e.g. OCR/speech rec &gt; syntax &gt; semantics &gt; response logic &gt; semantic output &gt; natural language output)</p>
<p>Is there any NN model that can perform multiple steps in NLP at once? For example, a single network which accepts audio input and returns a semantic analysis of the given speech, or a single network which accepts text input and returns natural language output?</p>
","natural-language-processing"
"25907","What is the best approach for sentiment analysis when the text is very brief?","2021-01-21 21:17:31","","1","31","<natural-language-processing><reference-request><sentiment-analysis>","<p>I'm working on a project to do sentiment analysis but my data is not long and properly formatted text. It's more likely to be very short sentences, e.g. tweets (in full tweet lingo), quick reviews of maybe 2-5 short sentences, etc.</p>
<p>If my text is of that nature, what approach would you recommend? E.g. CNNs (spaCy has a ready-made text classifier), LSTM (e.g. something like Keras), etc.</p>
<p>What are the pros/cons of your suggested approach (i.e. why is it better suited for classifying short paragraphs/sentences)?</p>
<p>I'm starting out in the area so any links/papers/etc. will be most welcome!</p>
","natural-language-processing"
"25892","What dataset might Elon Musk's Dall-E have used?","2021-01-21 02:34:05","","1","246","<natural-language-processing><datasets><generative-adversarial-networks><image-generation><natural-language-understanding>","<p>Dall-E, it can generate many imaginative images from the description, even some peculiar images, how did they actually create this kind of dataset to train this AI , because there is not much of that kind of data which include weird images and descriptive text, how did they create this massive dataset. Does anyone have any idea?</p>
<p>If you have no idea what I am talking about, please refer to this link: <a href=""https://openai.com/blog/dall-e/"" rel=""nofollow noreferrer"">https://openai.com/blog/dall-e/</a>.</p>
","natural-language-processing"
"25750","How to extract parameters from a text using AI/NLP","2021-01-13 13:34:53","","1","707","<neural-networks><machine-learning><convolutional-neural-networks><natural-language-processing><natural-language-understanding>","<p>lets say I have three texts:</p>
<ol>
<li>&quot;make a heading that says hello word&quot;</li>
<li>&quot;make a heading of hello world&quot;</li>
<li>&quot;create heading consist of hello world&quot;</li>
</ol>
<p>How can I fetch those groups of words using AI which is referring to heading i.e hello world in this case. Which AI frameworks or libraries can do that?</p>
<p>in all examples heading is pointing to hello world (which i am referring as group of words). so basically i want those words which will be a part of heading or in other word there is a relationship between them. another example i can give is &quot;I am watching Breaking bad&quot; so there is a relationship between watching and breaking bad and i want to extract what are you watching.</p>
<p>What's the best approach? Do I have to train a model for that or there are some other techniques that can get it done?</p>
","natural-language-processing"
"25676","How can I find words in a string that are related to a given word, then associate a sentiment to that found word?","2021-01-10 12:39:09","25682","2","882","<natural-language-processing><sentiment-analysis><stemming><lemmatization>","<p>I came up with an NLP-related problem where I have a list of words and a string. My goal is to find any word in the list of words that is related to the given string.</p>
<p>Here is an example.</p>
<p>Suppose a word from the list is <strong>healthy</strong>. If the string has any of the following words: healthy, healthier, healthiest, not healthy, more healthy, zero healthy, etc., it will be extracted from the string.</p>
<p>Also, I want to judge whether the extracted word/s is/are bearing positive/negative sentiment.</p>
<p>Let me further explain what I mean by using the previous example.</p>
<p>Our word was <strong>healthy</strong>. So, for instance, if the word found in the string was <strong>healthier</strong>, then we can say it is bearing <strong>positive</strong> sentiment with respect to the word <strong>healthy</strong>. If we find the word <strong>not healthy</strong>, it is <strong>negative</strong> with respect to the word <strong>healthy</strong>.</p>
","natural-language-processing"
"25643","Is there a reference that describes Recurrent Neural Networks for NLP tasks?","2021-01-08 19:48:29","","0","29","<deep-learning><natural-language-processing><recurrent-neural-networks><reference-request>","<p>I would like some references of works that try to understand the functioning of any kind of RNN in natural language processing tasks. They can be any work that tries to explain the functioning of the model by studying the structure of the model itself. I have the feeling that it is very common for researchers to use models, but there is still little theory about how they work in solving natural language processing tasks.</p>
","natural-language-processing"
"25627","How to understand 'losses' in Spacy's custom NER training engine?","2021-01-08 09:23:29","25636","4","4963","<machine-learning><natural-language-processing><objective-functions><spacy><named-entity-recognition>","<p>From the tid-bits, I understand of neural networks (NN), the Loss function is the difference between predicted output and expected output of the NN. I am following <a href=""https://github.com/explosion/spaCy/blob/master/examples/training/train_ner.py"" rel=""nofollow noreferrer"">this tutorial</a>, the losses are included at line #81 in the <code>nlp.update()</code> function.</p>
<p>I am getting losses in the range 300-100. How to interpret them? <strong>What should be the ideal output of this losses variable</strong>? I went through Spacy's documentation, but nothing much is written there about losses. Also, please let me know the links to relevant theories to understand this in general.</p>
","natural-language-processing"
"25616","T5 or BERT for sentence correction/generation task?","2021-01-07 10:11:26","","3","483","<natural-language-processing><bert><text-generation>","<p>I have sentences with some grammatical errors , with no punctuations and digits written in words... something like below:</p>
<p><a href=""https://i.sstatic.net/TAQkT.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/TAQkT.png"" alt=""enter image description here"" /></a></p>
<p>As you can observe, a proper noun , <strong>winston</strong> isnt highlighted with capital in Sample column. 'People' is spelled wrong and there are no punctuations in Sample column. The date in the first row isnt in right format. I have millions of rows like this and want to train a model to learn punctuations and corrections. Can a single BERT or T5 handle this task? or only option is to try 1 model for each task?
Thanks in advance</p>
","natural-language-processing"
"25587","Should we use a pre-trained model or a blank model for custom entity training of NER in spacy?","2021-01-05 15:15:09","25594","0","473","<natural-language-processing><spacy><named-entity-recognition>","<p>Further to my <a href=""https://ai.stackexchange.com/q/25498/43434"">last question</a>, I am training a custom entity of FOODITEM to be recognized by Spacy's  Name Entity Recognition engine. I am following tutorials online, following is the advise given in most of the tutorials;</p>
<blockquote>
<p><strong>Load the model or create an empty model</strong></p>
</blockquote>
<blockquote>
<p>We can create an empty model and train it with our annotated dataset or we can use the existing spacy model and re-train with our annotated data.</p>
</blockquote>
<p>But none of the tutorials tell how/why to choose between the two options. Also, I don't understand how will the choice affect my final output or the training of the model.</p>
<p>How do I make the choice between a pre-trained model or a blank model? What are the factors to consider?</p>
","natural-language-processing"
"25531","Is there any research work that shows that we should explicitly mark the word boundaries for 1D CNNs?","2021-01-03 00:58:30","","1","27","<neural-networks><convolutional-neural-networks><natural-language-processing><reference-request><embeddings>","<p>I'm doing character embedding for NLP tasks using one-dimensional convolutional neural networks (see <a href=""https://arxiv.org/abs/1511.08308"" rel=""nofollow noreferrer"">Chiu and Nichols (2016)</a> for the motivation). I haven't found any empirical evidence of whether or not marking the word boundaries makes a difference. As an example, a 1-D CNN with kernel size 2 would take <code>&quot;the&quot;</code> as input and use <code>{&quot;th&quot;, &quot;he&quot;}</code> in its filters. But if I explicitly marked the boundaries it would give me <code>{&quot;t&quot;, &quot;th&quot;, &quot;he&quot;, &quot;h&quot;}</code>.</p>
<p>Is there a go-to paper or project that definitively answers this question?</p>
","natural-language-processing"
"25507","Time series analysis using computer vision principles","2021-01-01 19:46:22","","0","66","<natural-language-processing><computer-vision><time-series>","<p>I'm just starting to explore topics within computer vision and curious if there are any concepts in that area that could be applied to segmenting multivariate time series with the goal of grouping individual data points similar to how a human might do the same.  I know that there are a number of time series segmentation methods, but in-depth explanations of multivariate methods are more scarce and it seems like somewhat of an underdeveloped topic overall. Since segmentation is such a fundamental part of CV and is inherently multidimensional, I'm wondering if concepts there can be modified to apply to time series.</p>
<p>Specifically, I'd like to be able segment a time series and reformulate a prediction problem as something closer to a language processing problem.  The process would look something like this:</p>
<ol>
<li>Segment a multivariate time series into near-homogenous segments of variable length.  Some degree of preprocessing might be required but I can worry about that separately.</li>
<li>Encode the properties of each segment based on summary statistics (e.g., mean, variance, derivative values, etc.) such that the segments fall into discrete buckets.</li>
<li>Each bucket will represent a &quot;word&quot; and the goal of the model will be to predict the next word given a series of words, i.e., the next segment given a series of segments.</li>
</ol>
<p>In a few days of reading about CV, it seems like there's a ton to learn.  If there are traditional time series segmentation techniques that are more suitable, that would be of interest, but I'd still be curious about a CV approach since that approach likely better aligns with how a person might look at a graph to identify segments.</p>
","natural-language-processing"
"25498","How to design a NLP algorithm to find a food item in menu card list?","2021-01-01 10:38:11","25515","1","907","<machine-learning><natural-language-processing><algorithm>","<p>I am new to NLP and AI in general. I am just expecting springboard information so that I can skip all the introduction to NLP websites.  I have just started studying NLP and want to know how to go about solving this problem. I am creating a chatbot that will take voice input from customers ordering food at restaurants. The customer input I am expecting as;</p>
<blockquote>
<p>I want to order Chicken Biryani</p>
</blockquote>
<blockquote>
<p>Can I have a Veg Pizza, please</p>
</blockquote>
<blockquote>
<p>Coca-cola  etc</p>
</blockquote>
<p>I want to write an algorithm that can separate the name of the food item from the user input and compare it with the list of food items in my menu card and come up with the right item.</p>
<p>I am new to NLP, I am studying it online for this particular project, I can do the required coding, I just need help with the overall algo or sort of flow chart. It will save my time tremendously. Thanks.</p>
","natural-language-processing"
"25317","Building a resume recommendation for a job post?","2020-12-20 23:06:19","","1","43","<neural-networks><machine-learning><deep-learning><natural-language-processing><sequence-modeling>","<p>There are few challenges I am facing when building a resume recommendation for a particular job positing.</p>
<p>Let's say we convert the resume into a vector on n-dimensions and job description also as an n-dimension vector and in order to see how similar, we can use any similarity metrics like cosine.</p>
<p>Now, for me the biggest problem with such approach is not able to provide more importance to the job title required. Some times, for a cloud engineer position I am getting java developer resume recommended in top 10 just because some of the skills/keywords are overlapping between two so their embeddings becomes similar.</p>
<p>I want to provide more weightage to the job title as well. What are some possible things I can do to make my recommendations consider or put bit emphasis on job title.</p>
<p>Note:- A common job title lookup in resume will fails because people write job titles in multiple ways.
(java engineer (or) java developer) | (cloud engineer or aws engineer) etc.,</p>
<p>How can I overcome this issue?</p>
","natural-language-processing"
"25270","Are there any good alternatives to an LSTM language model for text generation?","2020-12-18 17:08:31","25271","0","646","<natural-language-processing><reference-request><language-model><text-generation>","<p>I have a trained LSTM language model and want to use it to generate text. The standard approach for this seems to be:</p>
<ol>
<li>Apply softmax function</li>
<li>Take a weighted random choice to determine the next word</li>
</ol>
<p>This is working reasonably well for me, but it would be nice to play around with other options. Are there any good alternatives to this?</p>
","natural-language-processing"
"25253","Can the attention mechanism improve the performance in the case of short sequences?","2020-12-17 22:00:33","","1","195","<deep-learning><natural-language-processing><transformer><attention><performance>","<p>I am aware that the attention mechanism can be used to deal with long sequences, where problems related to gradient vanishing and, more generally, representing effectively the whole sequence arise.</p>
<p>However, I was wondering if attention, applied either to seq2seq RNN/GRU/LSTM or via Transformers, can contribute to improving the overall performance (as well as giving some sort of interpretability through the attention weights?) in the case of relatively short sequences (let's say around 20-30 elements each).</p>
","natural-language-processing"
"25173","How to handle long sequences with transformers?","2020-12-13 20:25:08","","2","341","<deep-learning><natural-language-processing><transformer><time-series><attention>","<p>I have a time series sequence with 10 million steps. In step <span class=""math-container"">$t$</span>, I have a 400 dimensional feature vector <span class=""math-container"">$X_t$</span> and a scalar value <span class=""math-container"">$y_t$</span> which I want to predict during inference time and I know during the train time. I want to use a <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""nofollow noreferrer"">transformer model</a>. I have 2 questions:</p>
<ol>
<li>If I want to embed the 400 dimensional input feature vector into another space before feeding into the transformer, what are the pros and cons of using let's say 1024 and 64 for the embedding space dimension? Should I use a dimension more than 400 or less?</li>
<li>When doing <em>position embedding</em>, I cannot use a maximum position length of 10 million as that blows up the memory. What is the best strategy here if I want to use maximum position length of 512? Should I chunk the 10 million steps into blocks of size 512 and feed each block separately into the transformer? If so, how can I connect the subsequent blocks to take full advantage of parallelization while keeping the original chronological structure of the sequence data?</li>
</ol>
","natural-language-processing"
"25148","What is different in each head of a multi-head attention mechanism?","2020-12-12 22:22:23","25149","12","8513","<neural-networks><natural-language-processing><papers><transformer><attention>","<p>I have a difficult time understanding the &quot;multi-head&quot; notion in the original <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""noreferrer"">transformer paper</a>. What makes the learning in each head unique? Why doesn't the neural network learn the same set of parameters for each attention head? Is it because we break <em>query, key</em> and <em>value</em> vectors into smaller dimensions and feed each portion to a different head?</p>
","natural-language-processing"
"25096","When we translate a text from one language to another, how does the frequency of various POS tags change?","2020-12-10 10:14:32","","1","11","<natural-language-processing><transformer><language-model><pos-tagging>","<p>When we translate a text from one language to another, how does the frequency of various POS tags change?</p>
<p>So, let's say we have a text in English, with 10% nouns, 20% adjectives, 15% adverbs, 25% verbs, etc., which we now translate to German, French, or Hindi. Can we say that in these other languages the POS tag frequency will remain the same as earlier?</p>
","natural-language-processing"
"25055","What is the gradient of an attention unit?","2020-12-08 00:49:59","","3","3012","<neural-networks><natural-language-processing><gradient-descent><transformer><attention>","<p>The paper <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""nofollow noreferrer"">Attention Is All You Need</a> describes the Transformer architecture, which describes attention as a function of the queries <span class=""math-container"">$Q = x W^Q$</span>, keys <span class=""math-container"">$K = x W^K$</span>, and values <span class=""math-container"">$V = x W^V$</span>:</p>
<p><span class=""math-container"">$\text{Attention(Q, K, V)} = \text{softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right) V \\
= \text{softmax}\left( \frac{x W^Q (W^K)^T x}{\sqrt{d_k}} \right) x W^V$</span></p>
<p>In the Transformer, there are 3 different flavors of attention:</p>
<ol>
<li><strong>Self-attention in the Encoder</strong>, where the queries, keys, and values all come from the input to the Encoder.</li>
<li><strong>Encoder-Decoder attention in the Decoder</strong>, where the queries come from the input to the Decoder, and the keys and values come from the output of the Encoder</li>
<li><strong>Masked self-attention in the Decoder</strong>, where the queries, keys and values all come from the input to the Decoder, and, for each token, the <span class=""math-container"">$\text{softmax}\left( \frac{QK^T}{\sqrt{d_k}} \right)$</span> operation is masked out (zero'd out) for all tokens to the right of that token (to prevent look-ahead, which is cheating during training).</li>
</ol>
<p>What is the gradient (i.e. the partial derivatives of the loss function w.r.t. <span class=""math-container"">$x$</span>, <span class=""math-container"">$W^Q$</span>, <span class=""math-container"">$W^K$</span>, <span class=""math-container"">$W^V$</span>, and any bias term(s)) of each of these attention units? I am having a difficult time wrapping my head around derivating a gradient equation because I'm not sure how the softmax function interacts with the partial derivatives, and also, for the Encoder-Decoder attention in the Decoder, I'm not clear how to incorporate the encoder output into the equation.</p>
","natural-language-processing"
"25053","What is the cost function of a transformer?","2020-12-07 23:18:06","25094","8","6247","<neural-networks><natural-language-processing><objective-functions><transformer><attention>","<p>The paper <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""noreferrer"">Attention Is All You Need</a> describes the transformer architecture that has an encoder and a decoder.</p>
<p>However, I wasn't clear on what the cost function to minimize is for such an architecture.</p>
<p>Consider a translation task, for example, where give an English sentence <span class=""math-container"">$x_{english} = [x_0, x_1, x_2, \dots, x_m]$</span>, the transformer decodes the sentence into a French sentence <span class=""math-container"">$x_{french}' = [x_0', x_1', \dots, x_n']$</span>. Let's say the true label is <span class=""math-container"">$y_{french} = [y_0, y_1, \dots, y_p]$</span>.</p>
<p>What is the object function of the transformer? Is it the MSE between <span class=""math-container"">$x_{french}'$</span> and <span class=""math-container"">$y_{french}$</span>? And does it have any weight regularization terms?</p>
","natural-language-processing"
"25042","Finding or creating a dataset for Neural Text Simplification","2020-12-07 14:13:05","","0","27","<natural-language-processing><machine-translation>","<p>I'm currently starting a research project focused on NLP.</p>
<p>One of the steps involved in this project will be the development of a text simplification system, probably using a neural encoder-decoder architecture.</p>
<p>For most Text Simplification research available, the most commonly used dataset is one derived from pairing Wikipedia entries in both English and Simplified English. My problem arises from the fact that the focus of my research is not on the English Language, but rather in Portuguese, specifically Portugal Portuguese.</p>
<p>There exists no Simple Portuguese Wikipedia page and it seems that there exists no publicly available text simplification dataset in Portugal Portuguese at all. Due to this fact I'm curious if there would be any way of tackling this problem. Maybe having a dataset simply of complex Portuguese and simple portuguese, but with no pairings, although I'm not quite sure how that could be formulated to train a NN with.</p>
<p>So my question is if there are any text simplification datasets in Portugal (or maybe Bazil, as a last resource) Portuguese and, if not, what would be the optimal way to build that dataset.</p>
<p>Thank you.</p>
","natural-language-processing"
"25015","Transformers: how to get the output (keys and values) of the encoder?","2020-12-06 09:23:08","25030","2","726","<natural-language-processing><transformer><bert><attention>","<p>I was reading the paper <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""nofollow noreferrer"">Attention Is All You Need</a>.</p>
<p>It seems like the last step of the encoder is a LayerNorm(relu(WX + B) + X), i.e. an add + normalization. This should result in a <span class=""math-container"">$n$</span> x <span class=""math-container"">$d^{model}$</span> matrix, where <span class=""math-container"">$n$</span> is the length of the input to the encoder.</p>
<p>How do we convert this <span class=""math-container"">$n$</span> x <span class=""math-container"">$d^{model}$</span> matrix into the keys <span class=""math-container"">$K$</span> and values <span class=""math-container"">$V$</span> that are fed into the decoder's encoder-decoder attention step?</p>
<p>Note that, if <span class=""math-container"">$h$</span> is the number of attention heads in the model, the dimensions of <span class=""math-container"">$K$</span> and <span class=""math-container"">$V$</span> should both be <span class=""math-container"">$n$</span> x <span class=""math-container"">$\frac{d^{model}}{h}$</span>. For <span class=""math-container"">$h=8$</span>, this means we need a <span class=""math-container"">$n$</span> x <span class=""math-container"">$\frac{d^{model}}{4}$</span> matrix.</p>
<p>Do we simply add an extra linear layer that learns a <span class=""math-container"">$d^{model}$</span> x <span class=""math-container"">$\frac{d^{model}}{4}$</span> weight matrix?</p>
<p>Or do we use the output of the final Add &amp; Norm layer, and simply use the first <span class=""math-container"">$\frac{d^{model}}{4}$</span> columns of the matrix and discard the rest?</p>
","natural-language-processing"
"25013","Transformers: how does the decoder final layer output the desired token?","2020-12-06 08:25:45","25026","5","1073","<natural-language-processing><transformer><bert><attention>","<p>In the paper <a href=""https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"" rel=""nofollow noreferrer"">Attention Is All You Need</a>, this section confuses me:</p>
<blockquote>
<p>In our model, we share the same weight matrix between the two embedding layers [in the encoding section] and the pre-softmax linear transformation [output of the decoding section]</p>
</blockquote>
<p>Shouldn't the weights be different, and not the same? Here is my understanding:</p>
<p>For simplicity, let us use the English-to-French translation task where we have <span class=""math-container"">$n^e$</span> number of English words in our dictionary and <span class=""math-container"">$n^f$</span> number of French words.</p>
<ul>
<li><p>In the encoding layer, the input tokens are <span class=""math-container"">$1$</span> x <span class=""math-container"">$n^e$</span> one-hot vectors, and are embedded with a <span class=""math-container"">$n^e$</span> x <span class=""math-container"">$d^{model}$</span> learned embedding matrix.</p>
</li>
<li><p>In the output of the decoding layer, the final step is a linear transformation with weight matrix <span class=""math-container"">$d^{model}$</span> x <span class=""math-container"">$n^f$</span>, and then applying softmax to get the probability of each french word, and choosing the french word with the highest probability.</p>
</li>
</ul>
<p>How is it that the <span class=""math-container"">$n^e$</span> x <span class=""math-container"">$n^{model}$</span> input embedding matrix share the same weights as the <span class=""math-container"">$d^{model}$</span> x <span class=""math-container"">$n^f$</span> decoding output linear matrix? To me, it seems more natural for both these matrices to be learned independently from each other via the training data, right? Or am I misinterpreting the paper?</p>
","natural-language-processing"
"24856","Can One-Hot Vectors be used as Inputs for Recurrent Neural Networks?","2020-11-25 22:18:09","","2","126","<natural-language-processing><recurrent-neural-networks><long-short-term-memory><word-embedding><gated-recurrent-unit>","<p>When using an RNN to encode a sentence, one normally takes each word, passes it through an embedding layer, and then uses the dense embedding as the input into the RNN.</p>
<p>Lets say instead of using dense embeddings, I used a one-hot representation for each word, and fed that sequence into the RNN. My question is which of these two outcomes is correct:</p>
<ol>
<li><p>Due to the way in which an RNN combines inputs, since these vectors are all orthogonal, absolutely nothing can be combined, and the entire setup does not make sense.</p>
</li>
<li><p>The setup does make sense and it will still work, but not be as effective as using a dense embedding.</p>
</li>
</ol>
<p>I know I could run an experiment and see what happens, but this is fundamentally a theoretical question, and I would appreciate if someone could clarify so that I have a better understanding of how RNNs combine inputs. I suspect that the answer to this question would be the same regardless of whether we are discussing a vanilla RNN or an LSTM or  GRU, but if that is not the case, please explain why.</p>
<p>Thank you.</p>
","natural-language-processing"
"24788","Making generated texts from ""data-to-text"" more variable","2020-11-22 14:52:41","31764","1","263","<natural-language-processing><text-generation><natural-language-generation>","<p>I am diving in data-to-text generation for long articles (&gt; 1000 words). After creating a template and fill it with data I am currently going down on paragraph level and adding different paragraphs, which are randomly selected and put together. I also added on a word level different outputs for date, time and number formats.</p>
<p>The challenge I see is, that when creating large amounts of such generated texts they become boring to read as the uniqueness for the reader goes down.</p>
<p>Furthermore, I also think it's easy to detect that such texts have been autogenerated. However, I still have to validate this hypotheses.</p>
<p>I was wondering if there is an even better method to bring in variability in such a text?</p>
<p>Can you suggest any methods, papers, resources or share your experience within this field.</p>
<p>I highly appreciate your replies!</p>
","natural-language-processing"
"24753","Predict next event based on previous events and discrete reward values","2020-11-20 17:47:43","24756","2","333","<reinforcement-learning><deep-learning><natural-language-processing><prediction>","<p>Suppose, I have several sequences that include a series of text (the length of sequence can be varied). Also, I have some related reward value. however, the value is not continuous like the text. It has many missing values. Here is an example of the dataset.</p>
<pre><code>Sequence 1        Sequence 2 .............. Sequence n
------------      ----------                -------------
Action  Reward    Action  Reward            Action  Reward
  A                 C                          D
  B       5         A                          B      6
  C                 A       7                  A       
  C       6         B       10                 D           
  A                 C                          A           
  B       2         A                          B           
  ..                ...                        ...
 ...               .....                      .....
  D       5         C      4                   D          
</code></pre>
<p>Now I want to predict the next action based on the reward value. The idea is I want to predict the actions that leads to more rewards. Previously, I used only action data to predict the next action using LSTM and GRU. However, how could I use this reward value in this prediction? I was if thinking Reinforcement learning (MDP) could solve the problem. However, as the rewards are discrete, I am not sure if RL could do that. Also, is it possible to solve this problem with Inverse RL? I have some knowledge of deep learning. However, I am new to reinforcement learning. If anyone gives me some suggestion or provide me useful papers link regarding this problem, it could help me a lot.</p>
","natural-language-processing"
"24524","How is Google Translate able to convert texts of different lengths?","2020-11-10 05:38:30","","2","456","<natural-language-processing><recurrent-neural-networks><machine-translation><google-translate><seq2seq>","<p>According to my experience with Tensorflow and many other frameworks, neural networks have to have a fixed shape for any output, but how does Google translate convert texts of different lengths?</p>
","natural-language-processing"
"24349","Are there any meaningful books entirely written by an artificial intelligence?","2020-10-31 20:49:18","","2","174","<natural-language-processing><applications><natural-language-understanding><natural-language-generation>","<p>Are there any meaningful books entirely written by an artificial intelligence? I mean something with meaning, unlike random words or empty books.
Something that can be charactersed as fiction literature.</p>
<p>If yes, then I think it is also interesting to know if any of those books is available for sale. Is there a specific name for such books? Like &quot;robot books&quot;?</p>
","natural-language-processing"
"24332","Is there a way to provide multiple masks to BERT in MLM task?","2020-10-31 06:23:52","24384","1","1482","<natural-language-processing><bert><language-model>","<p>I'm facing a situation where I've to fetch probabilities from BERT MLM for multiple words in a single sentence.</p>
<pre><code>Original : &quot;Mountain Dew is an energetic drink&quot;
Masked : &quot;[MASK] is an energetic drink&quot;
</code></pre>
<p>But BERT MLM task doesn't consider two tokens at a time for the MASK. I strongly think that there should be some sort of work around that I'm unable to find other than fine-tuning.</p>
","natural-language-processing"
"24238","Are FSA and FSTs used in NLP nowadays?","2020-10-24 10:59:36","24258","0","300","<natural-language-processing><computational-linguistics>","<p>Finite state automata and transducers are computational models that were widely used decades before in natural language processing for morphological parsing and other nlp tasks. I wonder if these computational models are still used in NLP nowadays for significant purposes. If these models are in use, can you give me some examples ?</p>
","natural-language-processing"
"24125","Is my interpretation of the mathematics of the CBOW and Skip-Gram models correct?","2020-10-18 05:57:43","","1","809","<natural-language-processing><math><word2vec><cbow><skip-gram>","<p>I am a mathematics student who is learning NLP, so I have paid a high amount of attention on the mathematics used in the subject, but my interpretations may or may not be right sometimes. Please correct me if any of them are incorrect or do not make sense.</p>
<p>I have learned CBOW and Skip-Gram models.</p>
<p>I think I have understood the CBOW model, and here is my interpretation: First, we fix a number of neighbors of the unknown center word which we would like to predict; let the number be <span class=""math-container"">$m$</span>. We then input the original characteristic vectors (vectors of zeros and ones only) of those <span class=""math-container"">$2m$</span> context words. By multiplying those vectors by a matrix, we obtain <span class=""math-container"">$2m$</span> new vectors. Next, we take the average of those <span class=""math-container"">$2m$</span> vectors and this is our hidden layer, namely <span class=""math-container"">$v$</span>. We finally multiply <span class=""math-container"">$v$</span> with another matrix, and that is the &quot;empirical&quot; result.</p>
<p>I tried to follow the logic to Skip-Gram similarly, but I have been stuck. I understand that Skip-Gram is kind of a &quot;reversal&quot; of CBOW, but the specific steps have given me a hard time. So, in Skip-Gram, we only have a center word, and based upon that we are trying to predict <span class=""math-container"">$2m$</span> context words. By similar steps, we obtain a hidden layer, which is again a vector. The final process also involves multiplication with a matrix, but I don't know how we can get <span class=""math-container"">$2m$</span> new vectors based upon one, unless we have <span class=""math-container"">$2m$</span> different matrices?</p>
","natural-language-processing"
"24075","Bechmark models for Text Classification / Sentiment Classification","2020-10-14 17:26:52","","1","26","<natural-language-processing><word-embedding><text-classification><word2vec><benchmarks>","<p>I am currently working on a novel application in NLP where I try to classify empathic and non-empathic texts. I would like to compare the performance of my model to some benchmark models. As I am working with models based on Word2Vec embeddings, the benchmark models should also be based on Word2Vec, however I am looking for some relatively easy, quick to implement models.</p>
<p>Do you have any suggestions?</p>
","natural-language-processing"
"23995","What is the difference between text-based image retrieval and natural language object retrieval?","2020-10-10 01:27:00","","2","101","<machine-learning><deep-learning><natural-language-processing><comparison><object-detection>","<p>I'm working on creating a model that locates the object in the scene (2D image or 3D scene) using a natural language query. I came across this paper on <a href=""https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Hu_Natural_Language_Object_CVPR_2016_paper.pdf"" rel=""nofollow noreferrer"">natural language object retrieval</a>, which mentions that this task is different from text-based image retrieval, in the sense that natural language object retrieval requires an understanding of objects in the image, spatial configurations, etc. I am not able to see the difference between these two approaches. Could you please explain it with an example?</p>
","natural-language-processing"
"23938","Determining if an entity in free text is 'present' or 'absent'; what is this called in NLP?","2020-10-07 13:20:47","","1","68","<natural-language-processing><python><named-entity-recognition>","<p>I'm processing a semi-structured scientific document and trying to extract some specific concepts. I've actually made quite good progress without machine-learning so far, but I got to a block of true free text and I'm wondering whether a very narrow sense NLP/learning algorithm can help.</p>
<p>Specifically, there are concepts I know to be important that are discussed in this section, but I'll need some NLP to get the 'sentiment'. I thought this might 'entity sentiment' analysis, however, I'm not trying to capture the writer's emotion about a concept. It's literally whether the writer of the text thinks the entity is present, absent, or is uncertain about an entity.</p>
<p>Simple example. &quot;First, there are horns. And second, the sheer size of this enormous fossil record argues for an herbivore or omnivore. The jaws are large, but this is not a carnivore.&quot;</p>
<p>And say my entities are horns (presence or absence), and type of dinosaur (herbivore, omnivore, carnivore). Desired output:</p>
<p><code>Horns (present)
Carnivore (absent)
Herbivore (possible/present) -- fine if it thinks 'present'
Omnivore (possible/present) -- fine if it thinks 'present'
</code></p>
<p><strong>What is the class of NLP analysis that takes an explicit input entity (or list of entities) and tries to assess based on context whether that entity is present or absent according to the writer of the input text?</strong> It's actually fine if this isn't a learning algorithm (maybe better). Bonus if you have suggestions for python packages that could be used in this narrow sense. I've looked casually through NLTK and spacy packages but they're both vast, wasn't obvious which class of model or functions I'd need to solve this problem.</p>
","natural-language-processing"
"23906","What is the best algorithm to solve the regression problem of predicting the number of languages a Wikipedia article can be translated to?","2020-10-05 10:59:52","","1","82","<natural-language-processing><reference-request><regression>","<p>I'm doing a student project where I construct a model predicting the number of languages that a given Wikipedia article is translated into (for example, the article <a href=""https://en.wikipedia.org/wiki/Toyota"" rel=""nofollow noreferrer"">TOYOTA</a> is translated into 93 languages). I've tried extracting basic info (article length, number of links, etc.) to create a simple regression model, but can't get the <span class=""math-container"">$R^2$</span> value above <span class=""math-container"">$0.25$</span> or so.</p>
<p>What's the most appropriate NLP algorithm for <strong>regression</strong> problems? Almost all examples I find online are <strong>classification</strong> problems. FYI I'm aware of the basics of NLP preprocessing (tokenization, lemmatization, bag of words, etc).</p>
","natural-language-processing"
"23898","Any comparison between transformer and RNN+Attention on the same dataset?","2020-10-04 23:48:19","23904","3","2379","<natural-language-processing><recurrent-neural-networks><long-short-term-memory><transformer><attention>","<p>I am wondering what is believed to be the reason for superiority of transformer?</p>
<p>I see that some people believe because of the attention mechanism used, it’s able to capture much longer dependencies. However, as far as I know, you can use attention also with RNN  architectures as in the famous paper attention is introduced(<a href=""https://arxiv.org/pdf/1409.0473"" rel=""nofollow noreferrer"">here</a>)).</p>
<p>I am wondering whether the only reason for the superiority of transformers is because they can be highly parallelized and trained on much more data?</p>
<p>Is there any experiment comparing transformers and RNN+attention trained on the exact same amount of data comparing the two?</p>
","natural-language-processing"
"23889","What is the purpose of Decoder mask (triangular mask) in Transformer?","2020-10-03 20:18:01","23923","11","10129","<natural-language-processing><transformer><attention>","<p>I'm trying to implement transformer model using <a href=""https://www.tensorflow.org/tutorials/text/transformer#create_the_transformer"" rel=""noreferrer"">this tutorial</a>.  In the decoder block of the Transformer model, a mask is passed to &quot;<strong>pad and mask future tokens in the input received by the decoder</strong>&quot;. This mask is added to attention weights.</p>
<pre><code>import tensorflow as tf

def create_look_ahead_mask(size):
    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)
    return mask
</code></pre>
<p>Now my question is, how is doing this step (adding mask to the attention weights) equivalent to revealing the words to model one by one? I simply can't grasp the intuition of it's role. Most tutorials won't even mention this step like it's very obvious. Please help me understand. Thanks.</p>
","natural-language-processing"
"23884","Why aren't the BERT layers frozen during fine-tuning tasks?","2020-10-03 11:03:30","","4","1931","<natural-language-processing><computer-vision><bert><transfer-learning><fine-tuning>","<p>During transfer learning in computer vision, I've seen that the layers of the base model are frozen if the images aren't too different from the model on which the base model is trained on.</p>
<p>However, on the NLP side, I see that the layers of the BERT model aren't ever frozen. What is the reason for this?</p>
","natural-language-processing"
"23876","speech comment detection by deep speech mozilla for data set","2020-10-02 16:33:14","","-1","87","<machine-learning><deep-learning><natural-language-processing><speech-recognition>","<p>I want to create a system so that when a human being says a word or command through a microphone, such as &quot;shut down&quot;, the system can execute that command &quot;shut down&quot;.</p>
<p>I used the Deep Speech algorithm on the Persian language database, which takes audio data through a microphone and returns the text. The problem I have now is what I have to do from this point on. I need to explain that my system has to work offline and also the number of commands I have is limited.</p>
","natural-language-processing"
"23809","Transformer Language Model generating meaningless text","2020-09-28 18:48:17","","0","201","<natural-language-processing><pytorch><transformer><text-generation>","<p>I currently learning on Transformers, so check my understanding I tried implementing a small transformer-based language model and compare it to RNN based language model. Here's the code for transformer. I'm using PyTorch inbuilt layer for Transformer Encoder</p>
<pre><code>class TransformerLM_1(nn.Module):

    def __init__(self, head, vocab_size, embedding_size, dropout = 0.1, device = 'cpu', 
                 pad_idx = 0, start_idx = 1, end_idx = 2, unk_idx = 3):
      
        super(TransformerLM_1, self).__init__()
      
        self.head = head
        self.embedding_size = embedding_size
        self.vocab_size = vocab_size
        self.device = device
        self.embed = WordEmbedding(self.vocab_size, self.embedding_size, pad_idx)
        self.postional_encoding = PostionalEncoding(embedding_size, device)
        self.decoder = nn.TransformerEncoderLayer(self.embedding_size, self.head)
        self.out_linear = nn.Linear(self.embedding_size, vocab_size)
        self.dropout = dropout
        self.pad_idx = pad_idx
        self.start_idx = start_idx
        self.end_idx = end_idx
        self.unk_idx = unk_idx
        self.device = device

    
    def make_src_mask(self, src_sz):
        mask = (torch.triu(torch.ones(src_sz, src_sz)) == 1).transpose(0, 1)
        mask = mask.float().masked_fill(mask == 0, 10e-20).masked_fill(mask == 1, float(0.0))
        mask = mask.to(self.device)
        return mask

    def forward(self, x):
        dec_in = x.clone()[:, :-1]
        src_mask = self.make_src_mask(dec_in.size()[1])
        src = self.embed(dec_in)
        src = self.postional_encoding(src) 
        src = src.transpose(0,1)
        transformer_out = self.decoder(src, src_mask)
        out = self.out_linear(transformer_out)
        return out
</code></pre>
<p>I'm using teacher forcing to make it converge faster. From what I saw from the results, the text generated by the RNN model is better than transformer's.</p>
<p>Here is sample generated text with the expected</p>
<pre><code>Expected: you had to have been blind not to see the scenario there for what it was and is and will continue to be for months and even years a part of south carolina that has sustained a blow that the red cross expects will cost that organization alone some <span class=""math-container"">$ n million &lt;eos&gt; 
Predicted: some &lt;unk&gt; been the been &lt;unk&gt; not be $</span> the total has was the may has &lt;unk&gt; the that that be to the &lt;unk&gt; the 

Expected: citicorp and chase are attempting to put together a new lower bid &lt;eos&gt; 
Predicted: a are &lt;unk&gt; carries n't to the together with &lt;unk&gt; jersey than 

Expected: it ' s amazing the amount of money that goes up their nose out to the dog track or to the tables in las vegas mr . katz says &lt;eos&gt; 
Predicted: &lt;unk&gt; ' s &lt;unk&gt; comeback money of the in mr to their &lt;unk&gt; and of &lt;unk&gt; &lt;unk&gt; or or &lt;unk&gt; the money 

Expected: moreover while asian and middle eastern investors &lt;unk&gt; gold and help &lt;unk&gt; its price silver does n't have the same &lt;unk&gt; dealers say &lt;eos&gt; 
Predicted: the production the routes &lt;unk&gt; of its 

Expected: a board of control spokesman said the board had not seen the claim and declined to comment &lt;eos&gt; 
Predicted: the board said declined of said 

Expected: property capital trust said it dropped its plan to liquidate because it was n't able to realize the value it had expected &lt;eos&gt; 
Predicted: the claims markets said its was n &lt;unk&gt; to sell insolvent of was n't disclosed to sell its plan 

Expected: similarly honda motor co . ' s sales are so brisk that workers &lt;unk&gt; they have n't had a saturday off in years despite the government ' s encouragement of more leisure activity &lt;eos&gt; 
Predicted: the honda ' credit . s s &lt;unk&gt; 

Expected: we expect a big market in the future so in the long term it will be profitable &lt;eos&gt; 
Predicted: it can it &lt;unk&gt; board 

Expected: u . k . composite or &lt;unk&gt; insurers which some equity analysts said might be heavily hit by the earthquake disaster helped support the london market by showing only narrow losses in early trading &lt;eos&gt; 
Predicted: the . s . s trading sell said which &lt;unk&gt; traders market said the be able in the the earthquake 

Expected: this will require us to define and &lt;unk&gt; what is necessary or appropriate care &lt;eos&gt; 
Predicted: &lt;unk&gt; is be the $ &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; &lt;unk&gt; is the to &lt;unk&gt; and or 
</code></pre>
<p>As you can see Transformer fails to grasp grammar compared to RNN. Is there anything wrong with my understanding?</p>
<p>EDIT</p>
<p>This is one example that caught my eye</p>
<pre><code>Expected: also the big board met with angry stock specialists &lt;eos&gt; 
Predicted: also met specialists board met the stock big with after 
</code></pre>
<p>Most of the words predicted have is from the expected but in a different order. I have read that transformers are permutation invariant which is the reason why we include positional encoding with the word embedding.</p>
","natural-language-processing"
"23803","How are weight matrices in attention learned?","2020-09-28 10:05:19","","2","281","<deep-learning><natural-language-processing><backpropagation><transformer><attention>","<p>I have been looking into transformers lately and have been reading tons of tutorials. All of them address the intuition behind attention, which I understand. However, they treat learning the weight matrices (for query, key, and value) as it is the most trivial thing.</p>
<p>So, how are these weight matrices learned? Is the error just backpropagated, and the weights are updated accordingly?</p>
","natural-language-processing"
"23798","Are there any examples of state-of-the-art NLP applications that are still n-gram based and use Naive Bayes?","2020-09-27 17:56:39","","0","32","<natural-language-processing><reference-request><state-of-the-art><naive-bayes>","<p>As far as I can tell, most NLP tasks today use word embeddings and recurrent networks or transformers.</p>
<p>Are there any examples of state-of-the-art NLP applications that are still n-gram based and use Naive Bayes?</p>
","natural-language-processing"
"23786","Is there a complement to GPT/2/3 that can be trained using supervised learning methods?","2020-09-26 23:02:50","","3","128","<natural-language-processing><models><natural-language-understanding><text-generation>","<p>This is a bit of a soft question, not sure if it's on topic, please let me know how I can improve it if it doesn't meet the criteria for the site.</p>
<p>GPT models are unsupervised in nature and are (from my understanding) given a prompt and then they either answer the question or continue the sentence/paragraph. They also seem to be the most advanced models for producing natural language, capable of giving outputs with correct syntax and (to my eye at least) indistinguishable from something written by a human (sometimes at least!).</p>
<p>However if I have a problem where I have an input (could be anything, but lets call it an image or video) and a description of the image or video as the output I could in theory train a model with convolutional filters to identify the object and describe the image (assuming any test data is within the bounds of the training data). However when I've seen models like this in the past the language is either quite simple or 'feels' like it's been produced by a machine.</p>
<p><strong>Is there a way to either train a GPT model as a supervised learning model</strong> with inputs (of some <strong>non language</strong> type) and outputs (of sentences/paragraphs); or a similar type of <strong>machine learning model that can be used for this task</strong>?</p>
<p>A few notes:</p>
<p>I have seen the deep learning image captioning methods - these are what I mention above. I'm more looking for something that can take an input-output pair where the output is text and the input is any form.</p>
","natural-language-processing"
"23723","Is it possible to classify the subject of a conversation?","2020-09-24 08:50:23","23855","1","87","<natural-language-processing><recurrent-neural-networks><text-summarization><natural-language-understanding>","<p>I would like to classify the subject of a conversation. I could classify each messages of the conversation, but I will loose some imformation because of related messages.</p>
<p>I also need to do it gradually and not at the end of the conversation.</p>
<p>I searched near <strong>recurrent neural network</strong> and <strong>connectionist classification</strong> but I'm not sure it answer really well my issue.</p>
","natural-language-processing"
"23703","How to implement or avoid masking for transformer?","2020-09-22 19:02:56","","1","95","<convolutional-neural-networks><natural-language-processing><python><pytorch><transformer>","<p>When it comes to using Transformers for image captioning is there any reason to use masking?</p>
<p>I currently have a resnet101 encoder and am trying to use the features as the input for a transformer model in order to generate a caption for the image, is there any need to use masking? and what would I mask if I did need to?</p>
<p>Any help would be much appreciated</p>
<p>Thanks in advance.</p>
","natural-language-processing"
"23687","Estimating an $n$-Gram model using on bigrams","2020-09-21 18:08:22","","2","55","<machine-learning><natural-language-processing>","<p>One of the main arguments against <span class=""math-container"">$n$</span>-gram models is that, as <span class=""math-container"">$n$</span> increases, there is no way to compute <span class=""math-container"">$P(w_n|w_1,\cdots,w_{n-1})$</span> from training data (since the chance of visiting <span class=""math-container"">$w_n,...,w_1$</span> is practically zero).</p>
<p>Wondering why we cannot estimate <span class=""math-container"">$P(w_n|w_1,\cdots,w_{n-1})$</span> using the following:</p>
<p>Let <span class=""math-container"">$P_i(u|v)$</span> be the probability of having sequences where word <span class=""math-container"">$u$</span> comes exactly <span class=""math-container"">$i$</span> words after word <span class=""math-container"">$v$</span> (This is easy to compute).</p>
<p>Then we can esitmate <span class=""math-container"">$P(w_n|w_1,\cdots,w_{n-1})$</span> as a function of <span class=""math-container"">$P_i(u|v)$</span>. I could not find any reference to such approach in the literature. The most similar approach is the smoothing/backoff methods.</p>
<p>Is there any reason why no-one used this approach? Or if one can share some previous work about this approach.</p>
<p>P.S.1. The disadvantage of this approach, comparing with standard <span class=""math-container"">$n$</span>-gram model, is its running time.</p>
<p>P.S.2. We could use bucketing idea: Instead of computing/storing/using <span class=""math-container"">$P_i$</span>, for every <span class=""math-container"">$i$</span>, we can compute/store/use <span class=""math-container"">$PB_{i}=P_{2^i}$</span> . Then <span class=""math-container"">$P_i(u|v) \approx PB_{\log i}(u|v)$</span>.</p>
","natural-language-processing"
"23682","What are some good models to use for spelling corrections?","2020-09-21 16:02:43","","0","54","<neural-networks><machine-learning><deep-learning><natural-language-processing>","<p>I used OCR to extract text from an image, but there are some spelling mistakes in it :</p>
<p>The text is as follows :</p>
<pre><code>'gaRBOMATED WATER\n\nSFMEETENED CARBONATED 6\nBSREDERTS: CARBONATED WATER,\nSUGAR. ACIOITY REGULATOR (338),\n\nCFFENE. CONTAINS PERMITTED NATURAL\nCOLOUR (1506) AMD ADDED FLAVOURS QUcTURAL,\nSATIRE: OENTICAL AND ARTIFICIAL PLIVOUREE\n\nCOLA\nl 1187.3 PIRANGUT, TAL. MULSHI,\nGBST. PUME 612111, MAHARASHTRA.\nHELPLINE: 1800- 180-2653\ntet indishetptine@cocs-cola.com\nAUTHORITY OF THE COCA-COLA\n‘COCA-COLA PLAZA, ATLANTA, GA 36313, USA\nme DATE OF MANUFACTURE. BATCH NO. &amp;\nLP CNL. OF ae TAXES}:\nSE BOTTOM OF CAN.\n\nTST Fone Sor MOTHS FROM\nWe, RE WHEN STORED ft.\n\nY PLACE.\nChe coca conn\nnee\n\n| BRA License uo:\n‘ eS wo:\n\n \n\x0c'
</code></pre>
<p>I would like to know if there are some NLP models/libraries that I can use to correct spelling mistakes(like correcting <code>gaRBOMATED</code> to <code>CARBONATED</code></p>
","natural-language-processing"
"23611","Are there transformer-based architectures that can produce fixed-length vector encodings given arbitrary-length text documents?","2020-09-15 16:16:37","","8","932","<natural-language-processing><reference-request><autoencoders><transformer><bert>","<p><a href=""https://arxiv.org/abs/1810.04805"" rel=""nofollow noreferrer"">BERT</a> encodes a piece of text such that each token (usually words) in the input text map to a vector in the encoding of the text. However, this makes the length of the encoding vary as a function of the input length of the text, which makes it more cumbersome to use as input to downstream neural networks that take only fixed-size inputs.</p>
<p>Are there any transformer-based neural network architectures that can encode a piece of text into a fixed-size feature vector more suitable for downstream tasks?</p>
<p><strong>Edit:</strong> To illustrate my question, I’m wondering whether there is some framework that allows the input to be either a sentence, a paragraph, an article, or a book, and produce an output encoding on the same, fixed-sized format for all of them.</p>
","natural-language-processing"
"23585","NLP Bible verse division problem: Whats the best model/method?","2020-09-14 13:25:07","","2","142","<natural-language-processing><sequence-modeling><text-classification>","<p>I'm working on a project compiling various versions of the Bible into a dataset. For the most part versions separate verses discreetly. In some versions, however, verses are combined. Instead of verse 16, the marker will say 16-18. I wonder if, given I have a lot of other versions that separate them discretely, I can train an NLP model (I have about 30 versions that could act as a training set which would constitute  to separate those combined verses into discrete verses. I'm fairly new at deep learning, having done a few toy projects. I wonder how to think about this problem? What kind of problem is it? I think it might be similar to auto-punctuation problems and it seems the options there are seq2seq and classifier. This makes more sense to me as a classification problem, but maybe my inexperience is what drives me that direction. Can people suggest ways to think about this problem and resources I might use?</p>
<p>In answer to questions in the comment, I am dealing only with text, not images. An example might be like this:</p>
<p>Genesis 2, New Revised Standard Version:</p>
<blockquote>
<p>5 when no plant of the field was yet in the earth and no herb of the field had yet sprung up—for the Lord God had not caused it to rain upon the earth, and there was no one to till the ground; 6 but a stream would rise from the earth, and water the whole face of the ground— 7 then the Lord God formed man from the dust of the ground, and breathed into his nostrils the breath of life; and the man became a living being.</p>
</blockquote>
<p>Genesis 2, The message version:</p>
<blockquote>
<p>5-7 At the time God made Earth and Heaven, before any grasses or shrubs had sprouted from the ground—God hadn’t yet sent rain on Earth, nor was there anyone around to work the ground (the whole Earth was watered by underground springs)—God formed Man out of dirt from the ground and blew into his nostrils the breath of life. The Man came alive—a living soul!</p>
</blockquote>
<p>The goal then would be to divide the message version into discrete verses in the way that the NRSV is. Certainly, a part of the guide would be that a verse always ends in some kind of punctuation, though while necessary it is not sufficient to assign a distinct verse.</p>
","natural-language-processing"
"23560","Appropriate metric and approach for natural language generation for small sentences","2020-09-13 12:45:40","","1","60","<natural-language-processing><long-short-term-memory><attention><language-model>","<p>I am trying to create a language generation model to generate very short sentences/words, like a rapper name generator. The sentences in my dataset are anywhere between 1 word and 15 words (3-155 characters). So far, I have tried LSTM's with 1-3 layers and inputs as subwords and characters. The results so far are not that great, I am getting ~0.5 crossentropy loss and ~50% accuracy.</p>
<p>My inputs are like a sliding window with prepadding, (eg. (for a batch) <code>Inputs = [[0,0,0,1], [0,0,1,2]...[n-4,..n-1]]</code>, <code>outputs=[[0,0,1,2], ...[n-3,n-2,n-1,n]]</code>) where 0 is padding, <code>1</code> is the start token and <code>n</code> is the end token. Outputs are 1 hot encoded.</p>
<p>The model is an embedding layer, few lstm and dropout layers, followed by time distributed dense and then a dense layer.</p>
<p>My doubt is, is accuracy a right metric, I am using it because at the end, I am making a classification for 4 output values. Another one is, will a transformer be suitable for this, since I want to generate small sentences, (which are nouns) and models like GPT/ Bert are more suitable for capturing dependency between long sentences.</p>
","natural-language-processing"
"23504","Can we use NLP to understand/parse/compile programming code?","2020-09-10 18:46:36","","1","815","<natural-language-processing><machine-translation>","<p>I wonder if we can use Natural Language Processing (NLP) to process programming code:
Given a piece of code, can we</p>
<ol>
<li><strong>Translate</strong> it to human language to <em>understand</em> what it does? The input could be a function definition（normally lack of documentation) in Python and the output could be the documentation for that function.</li>
<li><strong>Compile</strong> or translate it to another programming language? Compile Python code to C or machine code, or translate C code to Python code?</li>
</ol>
","natural-language-processing"
"23449","How could facts be distinguished from opinions?","2020-09-06 13:31:51","23684","1","536","<natural-language-processing><reference-request><natural-language-understanding><text-summarization>","<p>As a software engineer, I am searching for an existing solution or, if none exists, willing to create one that will be able to process texts (e.g. news from online media) to extract/paraphrase <strong>dry facts</strong> from them, leaving all opinions, analysis, speculations, humor, etc., behind.</p>
<p>If no such solution exists, what would be a good way to start creating it (considering that I have zero experience in AI/machine learning)?</p>
<p>It would be no problem to manually create a set of examples (pairs of original news + dry facts extracted), but is that basically what it takes? I doubt so.</p>
<p>(This knowledge domain is already huge, so which parts of it need to be learned first and foremost to figure out how to achieve the goal?)</p>
","natural-language-processing"
"23420","What are some programming related topics that can be solved using NLP?","2020-09-04 00:32:55","","1","41","<natural-language-processing>","<p>I've been working on the Punctuation Restoration Problem for my Master's Thesis, however, me being primarily a programmer at heart, I wish I could use some of my NLP skills to solve issues related to programming in general.</p>
<p>I know Microsoft does lots of research in NLP and I think after they acquired Github, they have an immense dataset to work with for any problems related to programming they want to tackle. Most recently I think they did a great job on their new python suggestion extension on VSCode.</p>
<p>So, could you suggest to me some issues you think are interesting research topics? This is something that I would like to work with, but I have no idea where to start yet.</p>
","natural-language-processing"
"23371","What makes Google Translate fail on the Latin language?","2020-09-01 08:55:48","23374","4","656","<natural-language-processing><google-translate>","<p>As it is discussed <a href=""https://www.reddit.com/r/latin/comments/6akqdi/why_is_google_translate_so_bad_for_latin_a/"" rel=""nofollow noreferrer"">here</a>, and I saw it on other Latin language forums too, everybody complains about how Google Translate fails to translate the Latin language. From my personal experience, it is not that much bad on other languages, including romance languages.</p>
<p>So, what makes Google Translate fail so much to translate the Latin language? Is it about its syntax and grammar or lack of data?</p>
","natural-language-processing"
"23348","How can I classify houses given a dataset of houses with descriptions?","2020-08-30 21:21:30","23353","1","96","<natural-language-processing><classification><datasets>","<p>I have a dataset with a number of houses, for each house, I have a description. For example &quot;The house is luxuriously renovated&quot; or &quot;The house is nicely renovated&quot;. My aim is to identify for each house whether it is luxuriously, well or poorly renovated. I am new to NLP so any tips on how to approach this problem would be much appreciated.</p>
","natural-language-processing"
"23263","Compressing text using AI by sending only prediction rank of next word","2020-08-26 12:11:58","","1","305","<natural-language-processing><reference-request><prediction><game-theory><information-theory>","<p>Is there any effort made to compress text (and maybe other media) using prediction of next word and thus sending only the order number of the word/token which will be predicted on the client side
i.e<br>
<strong>Server text</strong>: This is an example of a long text example, custom word flerfom inserted to confuse, that may appear on somewhere<br>
<strong>Compressed Text transmitted</strong> : This [choice no 3] [choice no 4] [choice no 1] [choice no 6] [choice no 1] [choice no 3] [choice no 1], custom word flerfom [choice no 4] inserted [choice no 4] confuse [choice no 5] [choice no 4] [choice no 6] [choice no 5] on somewhere
<br><br>(Note: of course [choice no 3] will be shortened to [3] to save bytes and also maybe we can do much better in some cases by sending the first letter of the word)
<br><br>of course it means that the client side neural network has to be static or only updated in a predictable fasion, so the server knows for sure that the client neural network's predictions will follow the given choice orders. I tried example with <a href=""https://demo.allennlp.org/next-token-lm"" rel=""nofollow noreferrer"">https://demo.allennlp.org/next-token-lm</a>, but the prediction is not that good. maybe gpt-3 can do better . but its too heavy for use in a normal pc / mobile device</p>
<p>In more details, the process is</p>
<p>Deploy the same model on both sides<br>
Predict the next word after the starting word<br>
Keep the prediction limit say 100<br>
For any word which have more than 2 characters we do the prediction<br>
If the current word is predicted within the top 100 predictions of the model , we can essentially replace it with a numeric char between 0-99 (inclusive) so we are replacing a say , 5 character word with a 2 character numerical char..<br>
And if the word is not predicted in top 100 we send the word as it is..<br>
As much better the model predicts, that much better the compression<br>
And under no scenario it will work worse than the existing method..<br></p>
","natural-language-processing"
"23243","Feeding YOLOv4 image data into LSTM layer?","2020-08-25 09:57:38","","0","644","<natural-language-processing><long-short-term-memory><pytorch><yolo>","<p>How would one extract the feature vector from a given input image using <a href=""https://github.com/Tianxiaomo/pytorch-YOLOv4"" rel=""nofollow noreferrer"">YOLOv4</a> and pass that data into an LSTM to generate captions for the image?</p>
<p>I am trying to make an image captioning software in PyTorch using YOLO as the base object classifier and an LSTM as the caption generator.</p>
<p>Can anyone help me figure out what part of the code I would need to call and how I would achieve this?</p>
<p>Any help is much appreciated.</p>
","natural-language-processing"
"23221","How is BERT different from the original transformer architecture?","2020-08-24 14:56:35","23683","30","17305","<natural-language-processing><comparison><transformer><bert>","<p>As far as I can tell, BERT is a type of Transformer architecture. What I do not understand is:</p>
<ol>
<li><p>How is Bert different from the original transformer architecture?</p>
</li>
<li><p>What tasks are better suited for BERT, and what tasks are better suited for the original architecture?</p>
</li>
</ol>
","natural-language-processing"
"23217","How homographs is an NLP task can be treated?","2020-08-24 07:53:03","","1","320","<natural-language-processing><word-embedding><natural-language-understanding>","<blockquote>
<p>A <em>homograph</em> - is a word that shares  the same written form as another word but has a different meaning.</p>
</blockquote>
<p>They can be even different parts of speech. For example:</p>
<ol>
<li>close(verb) - close(adverb)</li>
<li>lead(verb) - lead(noun)</li>
<li>wind(noun) - wind(verb)</li>
</ol>
<p>And there is rather a big list <a href=""https://en.wikipedia.org/wiki/List_of_English_homographs"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/List_of_English_homographs</a>.</p>
<p>As far as I understand, after processing the text data in any conventional way, lemmatization, building an embedding, these words, despite having different meaning, and appearing in different contexts, would be absolutely the same for the algorithm, and in the end we would get some averaged context between two or more meainings of the word. And this embedding would be meaningless.</p>
<p>How is this problem treated or these words are regarded to be too rare to have a significant impact on the quality of resulting embedding?</p>
<p>I would appreciate comments and references to the papers or sources</p>
","natural-language-processing"
"23162","When to convert data to word embeddings in NLP","2020-08-21 05:37:41","23250","3","149","<natural-language-processing><data-preprocessing><word-embedding>","<p>When training a network using word embeddings, it is standard to add an embedding layer to first convert the input vector to the embeddings.</p>
<p>However, assuming the embeddings are pre-trained and frozen, there is another option. We could simply preprocess the training data prior to giving it to the model so that it is already converted to the embeddings. This will speed up training, since this conversion need only be performed once, as opposed to on the fly for each epoch.</p>
<p>Thus, the second option seems better. But the first choice seems more common. Assuming the embeddings are pre-trained and frozen, is there a reason I might choose the first option over the second?</p>
","natural-language-processing"
"23159","How is dropout applied to the embedding layer's output?","2020-08-21 01:08:31","23168","1","2689","<natural-language-processing><tensorflow><recurrent-neural-networks><long-short-term-memory><word-embedding>","<pre><code>model = tf.keras.Sequential([
    tf.keras.layers.Embedding(1000, 16, input_length=20), 
    tf.keras.layers.Dropout(0.2),                           # &lt;- How does the dropout work?
    tf.keras.layers.Conv1D(64, 5, activation='relu'),
    tf.keras.layers.MaxPooling1D(pool_size=4),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
</code></pre>
<p>I can understand when dropout is applied between <code>Dense layers</code>, which randomly drops and prevents the former layer neurons from updating parameters. I don't understand how dropout works after an embedding layer.</p>
<p>Let's say the output shape of the Embedding layer is <code>(batch_size,20,16)</code> or simply <code>(20,16)</code> if we ignore the batch size. How is dropout applied to the embedding layer's output?</p>
<p>Randomly dropout rows or columns?</p>
","natural-language-processing"
"23115","What are the best techniques to perform text simplification?","2020-08-18 16:36:09","","1","30","<natural-language-processing><python><text-summarization>","<p>I'm evaluating the state of the art techniques to translate legal text to simple text, what are the best approaches for a non-English language (Portuguese)?</p>
","natural-language-processing"
"22957","How can Transformers handle arbitrary length input?","2020-08-10 04:01:13","22960","38","22810","<natural-language-processing><recurrent-neural-networks><long-short-term-memory><transformer>","<p>The transformer, introduced in the paper <a href=""https://arxiv.org/abs/1706.03762"" rel=""noreferrer"">Attention Is All You Need</a>, is a popular new neural network architecture that is commonly viewed as an alternative to recurrent neural networks, like LSTMs and GRUs.</p>
<p>However, having gone through the paper, as well as several online explanations, I still have trouble wrapping my head around how they work. How can a non-recurrent structure be able to deal with inputs of arbitrary length?</p>
","natural-language-processing"
"22930","Get Neural Network to predict a tag/class on a certain word using the surrounding words as context [PyTorch]?","2020-08-08 22:58:14","22935","0","135","<neural-networks><natural-language-processing><python><pytorch>","<p>I am somewhat a novice at the topic of Neural Netoworks and PyTorch.</p>
<p>I am trying to create a model that takes a word (that I have modified very slightly) and a 'window' of context around it and predicts one of 5 tags (the tags relate to what sort of action I should perform on that word to get its correct form).</p>
<p>For example, here's what I would call a window of size 7 and it's tag (what it means isn't too important, it's just the 'target'):</p>
<pre><code>        Sentence                    Label
here is a sentence for my network     N
</code></pre>
<p><code>sentence</code> is the word that I want the network to predict the label for, but the 3 words on either side provide contextual meaning. My problem is, how would I get a network to know I want it to predict for that central word but not outright ignore the others? I am familiar with more normal NLP tasks such as NMT and character level classification.</p>
<p>I have already gotten my dataset 'padded' out so they're all of equal size.</p>
<p>Any help is appreciated</p>
","natural-language-processing"
"22810","How to use text as an input for a neural network - regression problem? How many likes/claps an article will get","2020-08-01 16:05:07","22876","4","2155","<neural-networks><machine-learning><deep-learning><natural-language-processing><recurrent-neural-networks>","<p>I am trying to predict the number of likes an article or a post will get using a NN.</p>
<p>I have a dataframe with ~70,000 rows and 2 columns: &quot;text&quot; (predictor - strings of text) and &quot;likes&quot; (target - continuous int variable). I've been reading on the approaches that are taken in NLP problems, but I feel somewhat lost as to what the input for the NN should look like.</p>
<p>Here is what I did so far:</p>
<ol>
<li>Text cleaning: removing html tags, stop words, punctuation, etc...</li>
<li>Lower-casing the text column</li>
<li>Tokenization</li>
<li>Lemmatization</li>
<li>Stemming</li>
</ol>
<p>I assigned the results to a new column, so now I have &quot;clean_text&quot; column with all the above applied to it. However, I'm not sure how to proceed.</p>
<p>In most NLP problems, I have noticed that people use word embeddings, but from what I have understood, it's a method used when attempting to predict the next word in a text. Learning word embeddings creates vectors for words that are similar to each other syntax-wise, and I fail to see how that can be used to derive the weight/impact of each word on the target variable in my case.</p>
<p>In addition, when I tried to generate a word embedding model using the Gensim library, it resulted in more than 50k words, which I think will make it too difficult or even impossible to onehot encode. Even then, I will have to one hot encode each row and then create a padding for all the rows to be of similar length to feed the NN model, but the length of each row in the new column I created &quot;clean_text&quot; varies significantly, so it will result in very big onehot encoded matrices that are kind of redundant.</p>
<p>Am I approaching this completely wrong? and what should I do?</p>
","natural-language-processing"
"22782","NLP: What is expected from the output of a perfect coreference system?","2020-07-31 02:29:51","","0","59","<natural-language-processing>","<p>For instance, consider the following piece of text:</p>
<p>'The father of Richard is a very nice guy. He was born in a poor family. Because of that, Richard learnt very good values. Richard is also a very nice guy. However, Richard's mother embarasses the family. She was born rich and she does not know the real value of the money. She did not have to be a hard worker to succeed in life.&quot;</p>
<p>How should a perfect coreference should work? Is this solution the perfect solution?</p>
<p>Cluster 1:</p>
<pre><code>'The father of Richard' (first sentence) &lt;-&gt; 'He' (second sentence)
</code></pre>
<p>Cluster 2:</p>
<pre><code>'Richard' (third sentence) &lt;-&gt; 'Richard' (forth sentence)
</code></pre>
<p>Cluster 3:</p>
<pre><code>'Richard\'s mother' (fifth sentence) &lt;-&gt; She (sixth sentence) &lt;-&gt; she (sixth sentence) &lt;-&gt; She (seventh sentence)  
</code></pre>
<p>If I use the coreference library of spacy (neuralcoref), I get these clusters:</p>
<p>Clusters:</p>
<pre><code>[Richard: [The father of Richard, He, Richard, Richard, Richard], a poor family: [a poor family, the family], Richard's mother: [Richard's mother, She, she, She]]
</code></pre>
<p>Note that this output says that &quot;Richard&quot; is the same for sentences that is true. However, &quot;He&quot; in the second sentence is not related to &quot;Richard&quot;, but to his father. Also &quot;Richard&quot; and the &quot;Father of Richard&quot; are together in the same cluster. Furthermore, &quot;poor family&quot; and &quot;family&quot; should not come together. However, this is realy difficulty since in this case there is some level of ambiguity.'</p>
<p>I know that this is a very difficult problem. The point is not criticize this fantastic library. I am just trying to understand what I should expect as perfect result.</p>
<p>If I change a little the text:</p>
<p>'The mother of Richard is a very nice woman. She was born in a poor family. Because of that, Richard learnt very good values. Richard is a very nice guy. However, Richard's father embarasses the family. He was born rich and he does not know the real value of the money. He did not have to be a hard worker to succeed in life.'</p>
<p>The clusters are:</p>
<pre><code>[Richard: [The mother of Richard, She, Richard, Richard, Richard, He, he, He], a poor family: [a poor family, the family]]
</code></pre>
<p>In this case, the clusters become stranger, since &quot;She&quot; and &quot;Richard&quot; are in the same cluster. Furthermore, the &quot;He&quot; related to the &quot;father of Richard&quot; belongs to the cluster, but not &quot;Richard's father&quot;.</p>
<p>So, my question is:</p>
<p>What is the perfect result that I should expect from a &quot;perfect&quot; coreference system?</p>
","natural-language-processing"
"22768","How to predict the ""word"" based on the meaning in a document?","2020-07-30 12:15:20","","2","104","<natural-language-processing><training><python><natural-language-understanding>","<p>What I mean to say is</p>
<ol>
<li>For example, if I give the meaning of Apple from the dictionary as input to the program, it should give output as Apple.</li>
<li>Or I say My day to day job involves monitoring and managing the resources - the output should be Project management.</li>
</ol>
<p>The meaning and the word could be a dictionary or it could be custom. I am looking for ideas and tools to go further on this.</p>
","natural-language-processing"
"22763","How to train an LSTM with varying length input?","2020-07-30 07:00:11","","0","3816","<deep-learning><natural-language-processing><tensorflow>","<p>I have a dataset where each of the training instances is different in the length and the data is sequential. So, I design an LSTM but I am thinking about how to train the LSTM. In fixed-length data, we just keep all of the input in an array and pass it to the network, but here the case is different. I can not store varying length data in an array and I do not want to use padding to make it fixed length. Now, should I train the LSTM where each training instance are varying in length?</p>
","natural-language-processing"
"22752","Using transformer but masking in reverse direction/smart sampling for desired final word?","2020-07-29 18:37:36","","0","53","<natural-language-processing><transformer>","<p>I'm trying to generate rhymes, so it would be very helpful to have a language model where I could input a final word, and have it output a sequence of words that ends with that word.</p>
<p>I could train my own model and reverse the direction of the mask, but I was wondering if there was any way I could use a pretrained model but apply a different mask to achieve this goal.</p>
<p>If this isn't possible, what's the best way to sample a forward-predicting model to achieve the highest probability sentence ending with a particular word?</p>
<p>Thanks!</p>
","natural-language-processing"
"22734","How large should the corpus be to optimally retrain the GPT-2 model?","2020-07-29 06:36:26","","2","762","<deep-learning><natural-language-processing><tensorflow><training><gpt>","<p>I just started working with the GPT-2 models and want to retrain one on a pretty narrow topic, so I have problems finding training material.</p>
<p>How large should the corpus be to optimally retrain the GPT-2 model? And what is the bare minimum size? Should it simply be as large as possible or can it flip over and make the model worse in some way?</p>
<p>I am also not certain how many steps you should let the retraining run. I have been using 6000 steps when testing, and it seems not much happens after that, loss only moved from 0.2 to 0.18 last 1000 steps.</p>
","natural-language-processing"
"22701","Embedding Layer into Convolution Layer","2020-07-27 13:48:40","","1","127","<natural-language-processing><tensorflow><keras><convolution>","<p>I'm looking to encode PDF documents for deep learning such that an image representation of the PDF refers to word embeddings instead of graphic data</p>
<p>So I've indexed a relatively small vocabulary (88 words). I've generated images that replace graphic data with word indexed (1=cat, 2=dog, etc) data. Now I'm going to my NN model</p>
<pre><code>right_input = Input((width, height, 1), name='right_input')
right = Flatten()(right_input)
right = Embedding(wordspaceCount, embeddingDepth)(right)
right = Reshape((width, height, embeddingDepth))(right)
right = vgg16_model((width, height, embeddingDepth))(right)
</code></pre>
<p>Image data is positive-only and embedding outputs negative values though so I'm wondering if it is necessary to normalize the embedding layer with something like this after the <code>Embedding</code> layer</p>
<pre><code>right = Lambda(lambda x: (x + 1.)/2.)(right)
</code></pre>
<p>The word indexed image looks like this:</p>
<p><a href=""https://i.sstatic.net/d3bHD.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/d3bHD.png"" alt=""Word Encoded Document"" /></a></p>
<p>Also, is this a problematic concept generally?</p>
","natural-language-processing"
"22676","How is the F1 score calculated in a question-answering system?","2020-07-26 14:13:41","","8","6635","<natural-language-processing><natural-language-understanding><metric><question-answering>","<p>I have an NLP model for answer-extraction. So, basically, I have a paragraph and a question as input, and my model extracts the span of the paragraph that corresponds to the answer to the question.</p>
<p>I need to know how to compute the F1 score for such models. It is the standard metric (along with Exact Match) used in the literature to evaluate question-answering systems.</p>
","natural-language-processing"
"22654","Is there an optimal way to split the text into small parts when working with co-reference resolution?","2020-07-24 12:33:55","","1","65","<natural-language-processing>","<p>I am working with co-reference resolution in a large text. Is there an optimal way to split the text into small parts? Or the best correct procedure is to use the entire text?</p>
<p>Just for reference, I am using the library <a href=""https://spacy.io/universe/project/neuralcoref"" rel=""nofollow noreferrer"">spacy-neuralcoref</a> in Python that is based on <a href=""https://www.aclweb.org/anthology/D16-1245.pdf"" rel=""nofollow noreferrer"">Deep Reinforcement Learning for Mention-Ranking Coreference Models</a> by Kevin Clark and Christopher D. Manning, EMNLP 2016.</p>
<p>Why am I asking about splitting the text?</p>
<p>I am applying coreference to chapters of books (roughly 30 pages of text). All the examples I have seen show situations of coreference applied to small pieces of texts. I applied to a chapter and I found strange results. However, this is not a clear justification for that since the state of art in coreference is about 60%. Am I right?</p>
<p>I didn't check all databases that people use to test coreference but the ones I took a look (like MUC 3 and MUC 4 Data Sets), if I understand well, they were composed by a collection of a small number of paragraphs.</p>
<p><strong>A test Example</strong>:</p>
<blockquote>
<p><strong>TST1-MUC3-0001</strong></p>
<p>GUATEMALA CITY, 4 FEB 90 (ACAN-EFE) -- [TEXT] THE GUATEMALA ARMY
DENIED TODAY THAT GUERRILLAS ATTACKED THE &quot;SANTO TOMAS&quot; PRESIDENTIAL
FARM, LOCATED ON THE PACIFIC SIDE, WHERE PRESIDENT CEREZO HAS BEEN
STAYING SINCE 2 FEBRUARY.</p>
<p>A REPORT PUBLISHED BY THE &quot;CERIGUA&quot; NEWS AGENCY -- MOUTHPIECE OF
THE GUATEMALAN NATIONAL REVOLUTIONARY UNITY (URNG) -- WHOSE MAIN
OFFICES ARE IN MEXICO, SAYS THAT A GUERRILLA COLUMN ATTACKED THE FARM
2 DAYS AGO.</p>
<p>HOWEVER, ARMED FORCES SPOKESMAN COLONEL LUIS ARTURO ISAACS SAID
THAT THE ATTACK, WHICH RESULTED IN THE DEATH OF A CIVILIAN WHO WAS
PASSING BY AT THE TIME OF THE SKIRMISH, WAS NOT AGAINST THE FARM, AND
THAT PRESIDENT CEREZO IS SAFE AND SOUND.</p>
<p>HE ADDED THAT ON 3 FEBRUARY PRESIDENT CEREZO MET WITH THE
DIPLOMATIC CORPS ACCREDITED IN GUATEMALA.</p>
<p>THE GOVERNMENT ALSO ISSUED A COMMUNIQUE DESCRIBING THE REBEL REPORT
AS &quot;FALSE AND INCORRECT,&quot; AND STRESSING THAT THE PRESIDENT WAS NEVER
IN DANGER.</p>
<p>COL ISAACS SAID THAT THE GUERRILLAS ATTACKED THE &quot;LA EMINENCIA&quot;
FARM LOCATED NEAR THE &quot;SANTO TOMAS&quot; FARM, WHERE THEY BURNED THE
FACILITIES AND STOLE FOOD.</p>
<p>A MILITARY PATROL CLASHED WITH A REBEL COLUMN AND INFLICTED THREE
CASUALTIES, WHICH WERE TAKEN AWAY BY THE GUERRILLAS WHO FLED TO THE
MOUNTAINS, ISAACS NOTED.</p>
<p>HE ALSO REPORTED THAT GUERRILLAS KILLED A PEASANT IN THE CITY OF
FLORES, IN THE NORTHERN EL PETEN DEPARTMENT, AND BURNED A TANK TRUCK.</p>
</blockquote>
","natural-language-processing"
"22514","Do we have to use the IOB format on labels in the NER dataset? If so, why?","2020-07-16 07:40:16","","-1","479","<machine-learning><natural-language-processing><named-entity-recognition>","<p>Do we have to use the IOB format on labels in the NER dataset (such as B-PERSON, I-PERSON, etc.) instead of using the usual format (PERSON, ORGANIZATION, etc.)? If so, why? How will it affect the performance of the model?</p>
","natural-language-processing"
"22375","How can I identify bigrams and trigrams that represent concepts?","2020-07-07 10:11:22","","2","353","<natural-language-processing>","<p>I have many text documents and I want to identify concepts in these documents in an unsupervised manner. One of my problems is that the concepts can be bigrams, trigrams, or even longer.</p>
<p>So, for example, out of all the bigrams, how can I identify the ones that are more likely to represent a concept?</p>
<p>A concept could be &quot;machine learning&quot;.</p>
<p>Are you aware of any standard approaches to solve this problem?</p>
<p><strong>Edit:</strong> The corpus I am working with consists of papers accessed from web of science. That is, they are all in some given domain niche. I want to extract words, bigrams, trigrams... that represent common concepts/buzzwords from these papers. These could be &quot;Automated machine learning&quot;, &quot;natural language processing&quot; et cetera. I need to be able to distinguish these from other common n-grams such as &quot;New York&quot;, &quot;Barack Obama&quot;,...</p>
<p>I know that I could do this using a NER approach but this would require hand-labelling. Are you aware of any unsupervised ways to approach this problem? Or even a semi-superised method with little labelled data?</p>
","natural-language-processing"
"22373","What is the score used to visualize attention in this paper?","2020-07-07 09:22:15","","1","28","<natural-language-processing><papers><implementation><dialogue-systems>","<p>I'm reading this paper <a href=""https://www.aclweb.org/anthology/P18-1135.pdf"" rel=""nofollow noreferrer"">Global-Locally Self-Attentive Dialogue State Tracker</a> and follow through the implementation published in <a href=""https://github.com/salesforce/glad"" rel=""nofollow noreferrer"">GLAD</a>.</p>
<p>I was wondering if someone can clarify what variable or score is used to calculate the global and local self-attention scores in Figure 4 (the heatmap).</p>
<p>For me, it is not really clear how to derive these scores. The only score that would match the given dimension would be in the scoring module  <span class=""math-container"">$p_{utt}=softmax(a_{utt})$</span>. However, I do not see in their implementation that anything is done with this value.</p>
<p>So, what I did was the following:</p>
<pre><code> q_utts = []
 a_utts=[]
 for c_val in C_vals:
     q_utt, a_utt = attend(H_utt, c_val.unsqueeze(0).expand(len(batch), *c_val.size()), lens=utterance_len)
     q_utts.append(q_utt)
     a_utts.append(a_utt)
attention_score= torch.mean(torch.stack(a_utts,dim=1),dim=1)
</code></pre>
<p>But the resulting attention score differs very much from what I expect.</p>
","natural-language-processing"
"22358","How to fine tune BERT for question answering?","2020-07-06 09:53:56","","4","4124","<natural-language-processing><bert><fine-tuning><question-answering>","<p>I wish to train two domain-specific models:</p>
<ul>
<li>Domain 1: Constitution and related Legal Documents</li>
<li>Domain 2: Technical and related documents.</li>
</ul>
<p>For Domain 1, I've access to a text-corpus with texts from the constitution and no question-context-answer tuples. For Domain 2, I've access to Question-Answer pairs.</p>
<p>Is it possible to fine-tune a light-weight BERT model for Question-Answering using just the data mentioned above?</p>
<p>If yes, what are the resources to achieve this task?</p>
<p>Some examples, from the huggingface/models library would be mrm8488/bert-tiny-5-finetuned-squadv2, sshleifer/tiny-distilbert-base-cased-distilled-squad, /twmkn9/albert-base-v2-squad2.</p>
","natural-language-processing"
"22318","Text classification of non-equal length texts, should I pad left or right?","2020-07-03 04:37:45","22324","0","97","<natural-language-processing><long-short-term-memory><sequence-modeling><text-classification><padding>","<p>Text classification of equal length texts works without padding, but in reality, practically, texts never have the same length.</p>
<p>For example, spam filtering on blog article:</p>
<pre><code>thanks for sharing    [3 tokens] --&gt; 0 (Not spam)
this article is great [4 tokens] --&gt; 0 (Not spam)
here's &lt;URL&gt;          [2 tokens] --&gt; 1 (Spam)
</code></pre>
<p>Should I pad the texts on the right:</p>
<pre><code>thanks for     sharing --
this   article is      great
here's URL     --      --
</code></pre>
<p>Or, pad on the left:</p>
<pre><code>--   thanks  for    sharing
this article is     great
--   --      here's URL
</code></pre>
<p>What are the pros and cons of either pad left or right?</p>
","natural-language-processing"
"22262","Is it possible to create a named entity recognition system without using POS tagging in the corpus?","2020-06-30 08:32:22","","2","277","<natural-language-processing><named-entity-recognition><pos-tagging>","<p>Is it possible to create a named entity recognition system without using POS tagging in the corpus?</p>
","natural-language-processing"
"22259","NLP Identifying important key words in a corpus","2020-06-30 01:38:03","","0","1205","<machine-learning><natural-language-processing><text-classification><text-summarization>","<p>I am intrigued with the idea of <a href=""https://www.lesswrong.com/posts/NfdHG6oHBJ8Qxc26s/the-zettelkasten-method-1"" rel=""nofollow noreferrer"">Zettelkasten</a> but unsatisfied with the current implementations. It seems to me that a machine learning and NLP approach could be productive by helpfully identifying “important” keywords on which to links could be created, with learning to help narrow the selection of keywords over time.</p>
<p>My problem is that it’s been 30 years since AI classes in grad school and things have moved on. I’m sure I could become an nlp expert with study but I don’t wanna. So I’m looking for guidance: what are the right terms to describe identifying keywords in context, ideally with some semantic content; how would I apply ML with my training to improve the keyword identification.</p>
<p>I’d love references, ideas, and packages references. Python is preferred, but not strongly; I write most common (and many uncommon, SNOBOL and COBOL anyone?) languages so language isn’t all that much of an issue.</p>
","natural-language-processing"
"22154","Do transformers have success in other domains different than NLP?","2020-06-24 23:55:48","22830","2","225","<deep-learning><natural-language-processing><applications><sequence-modeling><transformer>","<p>Everybody knows how successful transformers have been in NLP. Is there known work on other domains (e.g that also have a sequential natural way of occurring, such as stock price prediction or other problems)?</p>
","natural-language-processing"
"22086","What are the main differences between a language model and a machine translation model?","2020-06-23 04:08:03","","1","923","<natural-language-processing><comparison><models><machine-translation><language-model>","<p>What are the main differences between a language model and a machine translation model?</p>
","natural-language-processing"
"21946","How to make spacy lemmatization process fast?","2020-06-16 14:15:42","21971","0","3750","<natural-language-processing><python><spacy>","<p>I am applying spacy lemmatization on my dataset, but already 20-30 mins passed and the code is still running. </p>

<p>Is there anyway to make it faster? Is there any option to do this process using GPU?</p>

<p>My dataset size is 20k number of rows &amp; 3 columns </p>
","natural-language-processing"
"21928","How to use speaker's information as well as text for fine-tuning BERT?","2020-06-16 08:04:09","","1","342","<natural-language-processing><classification><bert>","<p>I want to classify my corporate chat messages into a few categories such as question, answer, and report. I used a fine-tuned BERT model, and the result wasn't bad. Now, I started thinking about ways to improve it, and a rough idea came up, but I don't know what to do it exactly.</p>

<p>Currently, I simply put chat text into the model, but don't use the speaker's information (who said the text, the speaker's ID in our DB). The idea is if I can use the speaker's information, the model might better understand the text and classify it better.</p>

<p>The question is, are there any examples or prior researches similar to what I want to achieve? I googled for a few hours, but couldn't find anything useful. (Maybe the keywords weren't good.)</p>

<p>Any advice would be appreciated.</p>
","natural-language-processing"
"21899","What are the main ideas behind NER?","2020-06-15 09:53:13","21901","2","386","<natural-language-processing><named-entity-recognition>","<blockquote>
  <p><strong><a href=""https://www.kdnuggets.com/2018/08/named-entity-recognition-practitioners-guide-nlp-4.html"" rel=""nofollow noreferrer"">Named entity recognition (NER)</a>, also known as entity chunking/extraction, is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.</strong></p>
</blockquote>

<p>Briefly, how does NER work? What are the main ideas behind it? And which algorithms are used to perform NER? </p>
","natural-language-processing"
"21868","How to autocorelate multiple variants of same text into one?","2020-06-14 08:07:43","","1","22","<natural-language-processing><ai-design><machine-translation>","<p>I want to improve quality of translations for open-source projects in Ukrainian language. We have multiple translations from different authors. We can also translate messages using machine translations. Sometimes machine translation is even better than human translation.</p>

<p>Given multiple variants of translation of the same original text, I want to create AI which will be able to ""translate"" from Ukrainian to Ukrainian, using these multiple variants in parallel as the source, to produce one variant of higher quality.</p>

<p>So, in general, given multiple similar input sequences, the neural network needs to ""understand"" them, and produce a single output sequence.</p>

<p><span class=""math-container"">$$S_1, S_2, \dots \rightarrow S$$</span></p>

<p>For a simple example, we may want to train a NN to recognize a sequence of natural numbers: <span class=""math-container"">$1,2,3,4, \dots$</span>. We give two sequences to NN: <span class=""math-container"">$23,4,24,6,8$</span> and <span class=""math-container"">$3,65,5,6,23$</span>, then trained the NN is expected to produce <span class=""math-container"">$3,4,5,6,7$</span>.</p>

<p>How to modify an existing neural network to achieve that? Is it possible at all?</p>
","natural-language-processing"
"21811","Can we use a pre trained Encoder (BERT, XLM ) with a Decoder (GPT, Transformer-XL) to build a Chatbot instead of Language Translation?","2020-06-12 03:26:21","","2","680","<machine-learning><deep-learning><natural-language-processing><deep-neural-networks><bert>","<p>I was wondering if the <code>BERT</code> or <code>T5</code> models can do the task of generating sentences in English. Most of the models I have mentioned are trained to translate from English to German or French. Is it possible that I can use the output of <code>BERT</code> as an input to my Decoder? My theory is that when I already have the trained <code>Embeddings</code>, I do not need to train the Encoder part. I can just add the outputs of sentences to the decoder to generate the sentences.</p>
<p>In place of finding the loss value from the translated version, Can I compute loss on the reply of a sentence?</p>
<p>Can someone point me toward a tutorial where I can use the <code>BERT</code> output for the decoder part? I have a data of conversation with me. I want to build a <code>Chatbot</code> from that data.</p>
<p>I have already implemented <code>LSTM</code> based <code>Sequence2sequence</code> model but it is not providing me satisfactory answer.</p>
<p>After some research, 2 such models are there as <code>T5</code> and <code>BART</code> which are based on the same idea.</p>
<p>If possible, can someone tell me how can I use <code>BART</code> or <code>T5</code> to make a conversational bot?</p>
","natural-language-processing"
"21793","When to use NLP, NLG and NLU in conversation agents?","2020-06-11 04:05:56","","1","172","<natural-language-processing><comparison><chat-bots><natural-language-understanding>","<p>I had read some blogs (like <a href=""https://medium.com/@narrativesci/natural-language-processing-vs-natural-language-generation-1b2d18dd0b67"" rel=""nofollow noreferrer"">1</a>, <a href=""https://towardsdatascience.com/nlp-vs-nlu-vs-nlg-know-what-you-are-trying-to-achieve-nlp-engine-part-1-1487a2c8b696"" rel=""nofollow noreferrer"">2</a> or <a href=""https://www.houseofbots.com/news-detail/11507-1-which-parameters-separates-nlp-nlu-and-nlg"" rel=""nofollow noreferrer"">3</a>) about what the difference between all three of them is. I am trying to build an open domain conversation agent using natural language AI. That agent can do casual conversation, like a friend. So, for that, I want to know what is the importance of NLP, NLG, and NLU, so that I can learn that part first.</p>
","natural-language-processing"
"21632","What are the keys and values of the attention model for the encoder and decoder in the ""Attention Is All You Need"" paper?","2020-06-04 07:18:40","","4","1012","<deep-learning><natural-language-processing><transformer><attention>","<p>I have recently encountered the paper on NLP. It is very new to me and I am still unable to see how that works. I have used all the resources over there from the original paper to Youtube videos and the very famous ""Illustrated Transformer"".</p>

<p>Suppose I have a training example of ""I am a student"" and I have the respective French as ""Je suis etudient"". </p>

<p>I want to know how these 3 words are converted to 4 words. What are the query, keys, values? </p>

<p>This is my understanding of the topic so far.</p>

<p><strong>The encoder part is:</strong></p>

<ul>
<li><p>Query: a single word embedded in a vector form. such as ""I"" expressed as a vector of length 5 as <span class=""math-container"">$[.2, 0.1, 0.4, 0.9, 0.44]$</span>.</p></li>
<li><p>Keys: the matrix of all the vectors or in simple words, a matrix that has all the words from a sentence in the form of embeddings.</p></li>
<li><p>Values = Keys</p></li>
</ul>

<p><strong>For decoder:</strong></p>

<ul>
<li><p>Query: the input word in the form of a vector (which is output given by the decoder from the previous pass).</p></li>
<li><p>Keys = values = outputs from the encoder's layers.</p></li>
</ul>

<p><strong>BUT there are 2 different attention layers and one of which do not use the encoder's output at all</strong>. So, what are the keys and values now? (I think they are just like encoder, but just the generated <strong>until that pass</strong>)?</p>
","natural-language-processing"
"21536","Why does the BERT NSP head linear layer have two outputs?","2020-05-30 23:50:37","22113","1","329","<machine-learning><natural-language-processing><transformer><bert>","<p>Here's the code in question. </p>

<p><a href=""https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L491"" rel=""nofollow noreferrer"">https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L491</a></p>

<pre><code>class BertOnlyNSPHead(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.seq_relationship = nn.Linear(config.hidden_size, 2)

    def forward(self, pooled_output):
        seq_relationship_score = self.seq_relationship(pooled_output)
        return seq_relationship_score
</code></pre>

<p>I think it was just ranking how likely one sentence would follow another? Wouldn't it be one score?</p>
","natural-language-processing"
"21474","Low accuracy during training for text summarization","2020-05-26 09:43:00","","1","42","<neural-networks><natural-language-processing><tensorflow><training><accuracy>","<p>I am trying to implement an extractive text summarization model. I am using keras and tensorflow. I have used bert sentence embeddings and the embeddings are fed into an LSTM layer and then to a Dense layer with sigmoid activation function. I have used adam optimizer and binary crossentropy as the loss function. The input to the model are the sentence embeddings.</p>

<p>The training y labels is a 2d-array i.e [array_of_documents[array_of_biniary_labels_foreach_sentence]]</p>

<p>The problem is that during training, I am getting the training accuracy of around 0.22 and loss 0.6.</p>

<p>How can I improve my accuracy for the model?</p>
","natural-language-processing"
"21448","Two questions about the architecture of Google Bert model (in particular about parameters)","2020-05-24 12:37:55","","1","42","<natural-language-processing><bert>","<p>I'm looking for someone who can help me clarify a few details regarding the architecture of Bert model. Those details are necessary for me to come with a full understanding of Bert model, so your help would be really helpful. Here are the questions:</p>

<ul>
<li><p>Does the self-attention layer of Bert model have parameters? Do the embeddings of words change ONLY according to the actual embeddings of other words when the sentence is passed through the self-attention layer?</p></li>
<li><p>Are the parameters of the embedding layer of the model (the layer which transforms the sequence of indexes passed as input into a sequence of embeddings of size=size of the model) trainable or not?</p></li>
</ul>
","natural-language-processing"
"21389","What is the intuition behind the attention mechanism?","2020-05-22 02:43:06","21404","12","5573","<neural-networks><deep-learning><natural-language-processing><attention>","<blockquote>
  <p><a href=""https://medium.com/saarthi-ai/transformers-attention-based-seq2seq-machine-translation-a28940aaa4fe"" rel=""noreferrer"">Attention</a> idea is one of the most influential ideas in deep learning. The main idea behind attention technique is that it allows the decoder to ""look back” at the complete input and extracts significant information that is useful in decoding.</p>
</blockquote>

<p>I am really having trouble understanding the intuition behind the attention mechanism. I mean how the mechanism works and how to configure.</p>

<p>In simple words (and maybe with an example), what is the intuition behind the attention mechanism?</p>

<p>What are some applications, advantages &amp; disadvantages of attention mechanism?</p>
","natural-language-processing"
"21385","Transformer encoding for regression","2020-05-21 19:25:46","","1","253","<natural-language-processing><transformer>","<p>I have a string of characters encoding a molecule. I want to regress some properties of those molecules. I tried using an LSTM that encodes all one hot encdoed characters, and then I take the last hidden state fed into a linear layer to regress the property. This works fine, but I wanted to see if transformers can do better, since they are so good in NLP.</p>

<p>However, I am not quiet sure about two things:</p>

<ol>
<li>Pytorch transformer encoder layer has two masking parameters: ""src_mask"" and ""src_key_padding_mask"". The model needs the whole string to do the regression, so I dont think I need ""src_mask"", but I do padding with 0 for parallel processing, is that what ""src_key_padding_mask"" is for?</li>
<li>What output from the transformer do I feed into the linear regression layer? For the LSTM I took the last hidden output. For the transformer, since everything is processed in parallel, I feel like I should rather use the sum of all, but it doesn't work well. Instead using only the last state works better, which seems arbitrary to me. Any ideas on how to properly do this, how do sentiment analysis model do it?</li>
</ol>
","natural-language-processing"
"21237","Why does this multiplication of $Q$ and $K$ have a variance of $d_k$, in scaled dot product attention?","2020-05-18 01:28:13","25057","8","6701","<neural-networks><machine-learning><natural-language-processing><transformer><attention>","<p>In scaled dot product attention, we scale our outputs by dividing the dot product by the square root of the dimensionality of the matrix:</p>
<p><a href=""https://i.sstatic.net/wLI4m.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/wLI4m.png"" alt=""enter image description here"" /></a></p>
<p>The reason why is stated that this constrains the distribution of the weights of the output to have a standard deviation of 1.</p>
<p>Quoted from <a href=""https://www.tensorflow.org/tutorials/text/transformer"" rel=""noreferrer"">Transformer model for language understanding | TensorFlow</a>:</p>
<blockquote>
<p>For example, consider that <span class=""math-container"">$Q$</span> and <span class=""math-container"">$K$</span> have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of <span class=""math-container"">$d_k$</span>. Hence, square root of <span class=""math-container"">$d_k$</span> is used for scaling (and not any other number) because the matmul of <span class=""math-container"">$Q$</span> and <span class=""math-container"">$K$</span> should have a mean of 0 and variance of 1, and you get a gentler softmax.</p>
</blockquote>
<p>Why does this multiplication have a variance of <span class=""math-container"">$d_k$</span>?</p>
<p>If I understand this, I will then understand why dividing by <span class=""math-container"">$\sqrt({d_k})$</span> would normalize to 1.</p>
<p>Trying this experiment on 2x2 arrays I get an output of 1.6 variance:</p>
<p><a href=""https://i.sstatic.net/GCe3t.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/GCe3t.png"" alt=""enter image description here"" /></a></p>
","natural-language-processing"
"21176","How can I make ELIZA more realistic?","2020-05-15 02:45:10","","3","241","<natural-language-processing><ai-design><chat-bots><natural-language-understanding>","<p>I’ve coded a simple ELIZA chatbot for a high school coding competition. The chatbot is part of an app that’s designed to help its user cope with depression, anxiety, and similar mental health disorders. It uses sentiment analysis to identify signs of mental illness, and to track it's user's progress toward ""happiness"" over time.</p>

<p>My question is, what steps can I take to make it more realistic (without using some pre-existing software, library, etc, which isn't allowed)? Also, are there any existing tables of questions/responses I can add to my ELIZA bot's repertoire so that it can handle more conversations?</p>
","natural-language-processing"
"21116","How is the Jacobian a generalisation of the gradient?","2020-05-13 02:18:59","21132","4","493","<deep-learning><natural-language-processing><math><gradient-descent>","<p>I came across these slides <a href=""http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture04-neuralnets.pdf"" rel=""nofollow noreferrer"">Natural Language Processing with Deep Learning CS224N/Ling284</a>, in the context of natural language processing, which talk about the Jacobian as a generalization of the gradient.</p>

<p>I know there is a lot of topic regarding this on the internet, and trust me, I've googled it. But things are getting more and more confused for me.</p>

<p>In simple words, how is the Jacobian a generalization of the gradient? How can it be used in gradient descent?</p>
","natural-language-processing"
"20991","Which NLP model to use to handle long context?","2020-05-07 16:47:20","","1","141","<natural-language-processing><long-short-term-memory>","<p>I'm trying to process product data for an e-commerce platform. The goal is to understand products' size.</p>

<p>Just to show you some examples on how messy product dimension description is:</p>

<pre><code>Overall Dimensions: 66 in W x 41 in D x 36 in H
Overall: 59 in W x 28.75 in D x 30.75 in H
92w 37d 32h"",
86.6 in W x 33.9 in D x 24 in H
W: 95.75\"" D: 36.5\"" H: 28.75\"""",
W: 96\"" D: 39.25\"" H: 32\"""",
""118\""W x 35\""D x 33\""T."",
""28 L x 95 W x 41 H""
""95\"" W x 26.5\"" H x 34.75\"" D""
""98\""W x 39\""D x 29\""H""
""28\"" High x 80\"" Wide x 32\"" Deep""

</code></pre>

<p>Now assume that the product dimension description is short &lt; 60 characters, I trained a two layer bidirectional LSTM, which can handle this task perfectly.</p>

<p>But the problem is, the above dimension is usually embedded in a long context (as a part of the product description). How can I extract the useful information from the long context and understand it? My LSTM can only accept context size of 60.</p>

<p>What language model is more suitable for this?</p>
","natural-language-processing"
"20979","Designing a chatbot personal project with zero coding experience, using an existing platform","2020-05-07 05:33:46","","1","62","<natural-language-processing><chat-bots><natural-language-understanding>","<p>My girlfriend has a masters degree in linguistics and would like to create an AI chatbot personal project to show potential employers her linguistics skills since she is struggling to find a job.</p>

<p>Unfortunately she doesn't know how to program except for extremely basic Python skills. She has been searching for weeks for tools to create a chatbot without needing to program, refusing to ask on forums for help so I'm asking the StackExchange community. Sort of like a plugin/widget for Slack, Facebook Messenger or website that you can just install on your website and just concentrate on the workflow/data/conversational design in a similar way to programming in Scratch or Node-Red.</p>

<p>I know nothing about NLP, neural networks or anything like that and I can't understand for the life of me  what exactly it is a linguist needs to do in AI. Adversely, she doesn't have the computer knowledge to understand how an API works, or how to get some sort of service and a chat interface are needed to bootstrap her conversational designs with some code somewhere.</p>

<p>So my question is: Is there a way for a linguist to create a chatbot without knowing programming or going in too deep, all by themselves? We looked at tools like hubspot.com, where the chatbot design is either multiple choices questions with predefined answers or offers expensive paid solutions for companies. I'm sure there are free educational or community open-source platforms doing this.</p>
","natural-language-processing"
"20977","Creating Text Features using word2vec","2020-05-06 19:43:47","","1","55","<natural-language-processing><word-embedding><word2vec><text-classification>","<p>My task is to classify some texts. I have used word2vec to represent text words and I pass them to an LSTM as input. Taking into account that texts do not contain the same number of words, is it a good idea to create text features of fixed dimension using the word2vec word representations of the text and then classify the text using these features as an input of a neural network? And in general is it a good idea to create text features using this method?</p>
","natural-language-processing"
"20911","Is there a good book or paper on word embeddings?","2020-05-04 17:14:38","","3","122","<natural-language-processing><reference-request><word-embedding>","<p>Is there a good and modern book that focuses on word embeddings and their applications? It would also be ok to provide the name of a paper that provides a good overview of word embeddings.</p>
","natural-language-processing"
"20868","What is meant by the expected BLEU cost when training with BLEU and SIMILE?","2020-05-03 08:15:07","","3","100","<natural-language-processing><training><metric><expectation>","<p>Recently I was reading <a href=""https://arxiv.org/abs/1909.06694"" rel=""nofollow noreferrer"">a paper</a> based on a new evaluation metric SIMILE. In a section, validation loss comparison had been made for SIMILE and BLEU. The plot showed the expected BLEU cost when training with BLEU and SIMILE. </p>

<p>What I'm unable to understand is what is meant by the expected BLEU cost when training with BLEU and SIMILE? Are there any separate cost functions defined for these scores?</p>

<p>I'm attaching the image of the graph.</p>

<p><a href=""https://i.sstatic.net/A2m0N.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/A2m0N.png"" alt=""enter image description here""></a></p>
","natural-language-processing"
"20817","What are the best datasets available for music information retrieval?","2020-05-01 06:07:42","","1","28","<natural-language-processing><datasets><data-science><audio-processing><structured-data>","<p>I am interested in doing some work in classification problems in music information retrieval. I know that there are some formats of datasets (such as MIDI, Spectrogram, Piano-roll, MusicXML, etc.) for this work but have been unable to find any nice large datasets for this. What are the best free datasets for such work? I am mainly looking into western classical music.</p>
","natural-language-processing"
"20783","Similarity score between 2 words using Pre-trained BERT using Pytorch","2020-04-30 04:23:46","22886","2","1173","<natural-language-processing><bert><similarity>","<p>I'm trying to compare Glove, Fasttext, Bert on the basis of similarity between 2 words using Pre-trained Models. Glove and Fasttext had pre-trained models that could easily be used with gensim word2vec in python.</p>
<blockquote>
<p><strong>Does BERT have any such models?</strong></p>
<p><strong>Is it possible to check the similarity between two words using BERT?</strong></p>
</blockquote>
","natural-language-processing"
"20738","Building a spell check model","2020-04-28 18:04:46","","1","31","<deep-learning><natural-language-processing>","<p>I have customer review texts. The data consists of the the raw and manually corrected texts of the reviews. I have aligned these pairs by using similarity algorithms and matched the words on them. Since there are some mis-matched words pairs, I have eliminated the pairs under a threshold value for their counts.</p>

<p>Now there are raw and corrected word pairs. What kind of machine learning model can I build for spellcheck by using the data mentioned as well?</p>
","natural-language-processing"
"20722","Are there any good resources (preferably books) about techniques used for entity extraction?","2020-04-28 10:54:04","","1","30","<natural-language-processing><resource-request><books><named-entity-recognition>","<p>Given some natural language sentences like</p>
<blockquote>
<p>I would like to talk to Mr. Smith</p>
</blockquote>
<p>I would like to extract entities, like the person &quot;Smith&quot;.</p>
<p>I know that frameworks, which are capable of doing so (f. e. RASA or spaCy), exist, but I would like to dive deeper and understand the theory behind all this.</p>
<p>At university, I learned a few of the basic models like CRF's or SVM's used for this task, but I wonder if there are any good resources (preferably books) about this topic.</p>
","natural-language-processing"
"20681","How to use pre-trained BERT to extract the vectors from sentences?","2020-04-27 13:55:43","21079","2","5619","<natural-language-processing><bert><pretrained-models>","<p>I'm trying to extract the vectors from the sentences. Spent soo much time searching for the pre-trained BERT models but found nothing.</p>
<blockquote>
<p><strong>Is it possible to get the vectors using pre-trained BERT from the data?</strong></p>
</blockquote>
","natural-language-processing"
"20591","GPT-2: (Hardware) requirements for fine-tuning the 774M model","2020-04-24 09:15:59","","0","4424","<natural-language-processing><gpt><fine-tuning><gpt-2>","<p>I wonder if there's anyone who has actually succeeded in fine-tuning GPT-2's 774M model without using cloud TPU's. My GeForce RTX 2070 SUPER couldn't handle it in previous attempts.</p>
<p>I'm running TensorFlow 1.14.0 with CUDA V 9.1 on Ubuntu 18.04. For fine-tuning I'm using <a href=""https://github.com/minimaxir/gpt-2-simple"" rel=""nofollow noreferrer"">gpt-2-simple</a>.</p>
<p>When fine-tuning using the 77M model, I keep running into OOM errors, such as:
<code>W tensorflow/core/common_runtime/bfc_allocator.cc:314] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.25MiB (rounded to 6553600).  Current allocation summary follows.</code></p>
<p>So far I've tried:</p>
<ul>
<li>Using different a optimizer (<code>RMSPropOptimizer</code> instead of <code>AdamOptimizer</code>)</li>
<li>Setting batch-size to 1</li>
<li><code>use_memory_saving_gradients</code></li>
<li><code>only_train_transformer_layers</code></li>
</ul>
<p>Fine-tuning works smoothly on the 355M model.</p>
<p>So what I'm really asking is:</p>
<ul>
<li>is it possible to fine-tune GPT-2's 774M model without industrial-sized hardware?</li>
<li>if so, please tell me about your successful attempts</li>
<li>apart from hardware-recommendations, how could fine-tuning be optimized to make 77M fit in memory?</li>
</ul>
","natural-language-processing"
"20588","Levenshtein Distance between each word in a given string","2020-04-24 04:24:55","21072","3","1566","<natural-language-processing><similarity>","<p>From <a href=""https://codereview.stackexchange.com/questions/217065/calculate-levenshtein-distance-between-two-strings-in-python"">Calculate Levenshtein distance between two strings in Python</a> it is possible to calculate distance and similarity between two given strings(sentences).</p>

<p>And from <a href=""https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/"" rel=""nofollow noreferrer"">Levenshtein Distance and Text Similarity in Python</a> to return the matrix for each character and distance for two strings.</p>

<p>Are there any ways to calculate distance and similarity between each word in a string and print the matrix for each word in a string(sentences)?</p>

<pre><code>a = ""This is a dog.""
b = ""This is a cat.""

from difflib import ndiff

def levenshtein(seq1, seq2):
    size_x = len(seq1) + 1
    size_y = len(seq2) + 1
    matrix = np.zeros ((size_x, size_y))
    for x in range(size_x):
        matrix [x, 0] = x
    for y in range(size_y):
        matrix [0, y] = y

    for x in range(1, size_x):
        for y in range(1, size_y):
            if seq1[x-1] == seq2[y-1]:
                matrix [x,y] = min(
                    matrix[x-1, y] + 1,
                    matrix[x-1, y-1],
                    matrix[x, y-1] + 1
                )
            else:
                matrix [x,y] = min(
                    matrix[x-1,y] + 1,
                    matrix[x-1,y-1] + 1,
                    matrix[x,y-1] + 1
                )
    print (matrix)
    return (matrix[size_x - 1, size_y - 1])

levenshtein(a, b)
</code></pre>

<p><strong>Outputs</strong></p>

<pre><code>&gt;&gt; 3
</code></pre>

<p><strong>Matrix</strong></p>

<pre><code>[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14.]
 [ 1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13.]
 [ 2.  1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]
 [ 3.  2.  1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]
 [ 4.  3.  2.  1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]
 [ 5.  4.  3.  2.  1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]
 [ 6.  5.  4.  3.  2.  1.  0.  1.  2.  3.  4.  5.  6.  7.  8.]
 [ 7.  6.  5.  4.  3.  2.  1.  0.  1.  2.  3.  4.  5.  6.  7.]
 [ 8.  7.  6.  5.  4.  3.  2.  1.  0.  1.  2.  3.  4.  5.  6.]
 [ 9.  8.  7.  6.  5.  4.  3.  2.  1.  0.  1.  2.  3.  4.  5.]
 [10.  9.  8.  7.  6.  5.  4.  3.  2.  1.  0.  1.  2.  3.  4.]
 [11. 10.  9.  8.  7.  6.  5.  4.  3.  2.  1.  1.  2.  3.  4.]
 [12. 11. 10.  9.  8.  7.  6.  5.  4.  3.  2.  2.  2.  3.  4.]
 [13. 12. 11. 10.  9.  8.  7.  6.  5.  4.  3.  3.  3.  3.  4.]
 [14. 13. 12. 11. 10.  9.  8.  7.  6.  5.  4.  4.  4.  4.  3.]]
</code></pre>

<p>General Levenshtein distance for character level shown in below fig. 
<a href=""https://i.sstatic.net/wYCIl.gif"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/wYCIl.gif"" alt=""enter image description here""></a></p>

<blockquote>
  <p><strong>Is it possible to calculate Levenshtein Distance for Word Level?</strong></p>
</blockquote>

<p><strong>Required Matrix</strong></p>

<pre><code>          This is a cat

This
is
a
dog
</code></pre>
","natural-language-processing"
"20528","How well can NLP techniques recognize connotations in natural languages?","2020-04-21 15:02:14","","1","41","<natural-language-processing><reference-request><natural-language-understanding><state-of-the-art>","<p>What is the state of the art with respect to recognizing connotations in natural languages?</p>

<p>For instance:</p>

<ul>
<li>Trump is a better president than Obama.           [Praising]</li>
<li>Trump is the worst president since Obama.         [Insulting]</li>
</ul>

<p>or:</p>

<ul>
<li>The rock star did not infect over 100 groupies.   [Defending against rumor]</li>
<li>The rock star infected no more than 100 groupies. [Attacking (0 is no more than 100)]</li>
</ul>

<p>In each example, both statements logically mean exactly the same thing, but any human hearing them would interpret them as having quite opposite meanings.</p>

<p>How well can current natural language processors recognize the difference between logically equivalent statements?</p>
","natural-language-processing"
"20352","Could clustering be used to parse pdf documents to get headings and titles?","2020-04-17 15:01:01","","2","178","<machine-learning><natural-language-processing><unsupervised-learning><clustering>","<p>I'm a bit new to AI and I'd like to use some kind of clustering algorithm to solve a problem:</p>

<p>I'm trying to parse pdf documents to get headings and titles. I can parse pdf to html and I'm then able to get some information on the lines of the document. I've identified some properties that can be useful for identifying the headings.</p>

<ul>
<li>font-size (int): of course it's quite usual that heading's font-size is bigger than normal text</li>
<li>font-family (string): it's possible for headings to be  bold so font-family may differ</li>
<li>left property (int): it's also possible that headings are aligned a bit to the right, there's an indentation that's not always there on normal paragraphs</li>
<li>bonus boolean: I have identified some properties that I can combine to get a boolean value. When the boolean is set to true it can increase the chances of the paragraph being a heading.</li>
</ul>

<p>Of course, these are not rules that apply to all headings. Some headings may follow some of these but not all of them. It could also be possible that some 'normal' paragraphs follow all these points, but what I've seen is that, in general, those rules where what made headings different from paragraphs.</p>

<p>With this information, is there a way of doing what I'm looking for? As I said, I'm new to AI even though I have a background in CS and mathematics. I thought clustering could be interesting since I'm trying to create 2 clusters: headings and normal paragraphs.</p>

<p>What algorithm do you think might work for this use case. Should I look outside clustering?</p>
","natural-language-processing"
"20321","Top Frequent occurrence word effect in Model Efficiency?","2020-04-16 16:14:20","20426","3","110","<natural-language-processing><text-classification>","<p>Assume that I have a Dataframe with the text column.
Problem: Classification / Prediction</p>
<pre><code>    sms_text
0   Go until jurong point, crazy.. Available only ...
1   Ok lar... Joking wif u oni...
2   Free entry in 2 a wkly comp to win FA Cup fina...
3   U dun say so early hor... U c already then say...
4   Nah I don't think he goes to usf, he lives aro...
</code></pre>
<p>After preprocessing the text
<a href=""https://i.sstatic.net/4EQWp.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/4EQWp.png"" alt=""enter image description here"" /></a></p>
<p>From the above WordCloud, we can find the most frequent(occurred) words like</p>
<pre><code>Free
Call
Text
Txt
</code></pre>
<p>As these are the most frequent words and adds less importance in prediction/classification as they appear a lot. (My Opinion)</p>
<blockquote>
<p>My Question is
Removing top frequent(most occurred) words will improve the model score?</p>
<p>How does this impact on model performance?</p>
<p>Is it ok to remove the most occurred words?</p>
</blockquote>
","natural-language-processing"
"20317","How should I design a reward function for a NLP problem where two models interoperate?","2020-04-16 12:29:23","","2","85","<reinforcement-learning><natural-language-processing><generative-adversarial-networks><rewards><text-generation>","<p>I would like to design a reward function. I am training two models from the first model that classify set of texts (paragraphs and keywords) and I also got some hidden states. The second model is trying to generate keywords for those paragraphs.</p>

<p>I want to use those hidden states from the first model to give rewards for key phrases that are generated from the second model. I want to know how can I implement this reward function since I have never used it before.</p>
","natural-language-processing"
"20277","How would you build an AI to output the primary concept of a paragraph?","2020-04-15 09:52:52","20279","2","98","<natural-language-processing><reference-request><natural-language-understanding><text-summarization>","<p>My thinking is you input a paragraph, or sentence, and the program can boil it down to the primary concept(s).</p>
<p>Example:</p>
<p><strong>Input:</strong></p>
<blockquote>
<p>Sure, it would be nice if morality was simply a navigation toward greater states of conscious well-being, and diminishing states of suffering, but aren't there other things to value independent of well-being? Like truth, or beauty?</p>
</blockquote>
<p><strong>Output:</strong></p>
<blockquote>
<p>Questioning moral philosophy.</p>
</blockquote>
<hr />
<p>Is there any group that's doing this already? If not, why not?</p>
","natural-language-processing"
"20176","What is the intuition behind the dot product attention?","2020-04-11 12:53:21","","22","11744","<natural-language-processing><papers><transformer><attention><bert>","<p>I am watching the video <a href=""https://www.youtube.com/watch?v=iDulhoQ2pro&amp;t=6s"" rel=""noreferrer"">Attention Is All You Need</a> by Yannic Kilcher.</p>
<p>My question is: what is the intuition behind the dot product attention?</p>
<p><span class=""math-container"">$$A(q,K, V) = \sum_i\frac{e^{q.k_i}}{\sum_j e^{q.k_j}} v_i$$</span></p>
<p>becomes:</p>
<p><span class=""math-container"">$$A(Q,K, V) = \text{softmax}(QK^T)V$$</span></p>
","natural-language-processing"
"20149","Could zero-padding affect learning in a negative way?","2020-04-10 09:39:23","","4","131","<machine-learning><natural-language-processing><keras><long-short-term-memory>","<p>I implemented an <code>LSTM</code> with <code>Keras</code> to perform word ordering task (given a syntactically unordered sentence, the goal is to label each word of the sentence with the right position in this one.)
So, my dataset is composed by numerical vectors and each numerical vector represents a word.</p>

<p>I train my model trying to learn the local order of a syntactic subtree composed by words that have syntactic relationships (for example, a subtree could be a set of three words in which the root is the verb and children are subject and object relationship).</p>

<p>I padded each subtree to a length of 20, which is the maximum subtree length that I found in my dataset. With padding introduction, I inserted a lot of vectors composed of only zeros.</p>

<p>My initial dataset shape is <code>(700000, 837)</code>, but knowing that <code>Keras</code> wants a 3D dataset, I reshaped it to <code>(35000, 20, 837)</code> and the same for my labels (from 700000 to <code>(35000, 20)</code>).</p>

<p>As loss function, I'm using the <code>ListNet</code> algorithm loss function, which takes a list of words and for each computes the probability of the element to be ranked in the first position (then ranking these scores, I obtain the predicted labels of each word).</p>

<p>The current implementation is the following:</p>

<pre><code>model = tf.keras.Sequential()
model.add(LSTM(units=100, activation='tanh', return_sequences=True, input_shape=(timesteps, features)))
model.add(Dense(1, activation='sigmoid'))

model.summary()

model.compile(loss=listnet_loss, optimizer=keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.9, beta_2=0.999, amsgrad=True), metrics=[""accuracy""])

model.fit(training_dataset, training_dataset_labels, batch_size=1, epochs=number_of_epochs, workers=10, verbose=1, callbacks=[SaveModelCallback()])
</code></pre>

<p>And <code>SaveModelCallback</code> simply saves each model during training.</p>

<p>At the moment I obtain, at each epoch, very very similar results:</p>

<pre><code>Epoch 21/50
39200/39200 [==============================] - 363s 9ms/step - loss: 2.5483 - accuracy: 0.8246
Epoch 22/50
39200/39200 [==============================] - 359s 9ms/step - loss: 2.5480 - accuracy: 0.8245
Epoch 23/50
39200/39200 [==============================] - 360s 9ms/step - loss: 2.5478 - accuracy: 0.8246
</code></pre>

<p>I have to questions:</p>

<ol>
<li><p>Could zero-padding affect learning in a negative way? And if yes, how could we not consider this padding?</p></li>
<li><p>Is it a good model for what I have to do?</p></li>
</ol>
","natural-language-processing"
"20100","Is there any literature on the design of dialogue systems for interviews and questionnaire administration?","2020-04-08 15:59:14","20101","4","128","<natural-language-processing><reference-request><dialogue-systems><human-robot-interaction>","<p>For my master thesis I am working on a dialogue system that should be deployed in hospitals to administer simple questionnaires to patients. I already did literature research and I'm fine with what I found since I don't have to replicate something which has been already done, but I noticed that there are really few papers regarding this specific 'robot interviewer' topic. </p>

<p>Let me explain the task a bit more in details: in a real interview a human interviewer usually starts with greetings and with an explanation of the questionnaire to administer, and then he/she starts asking some more or less structured questions to the person to interview. The idea here is to replace a human interviewer with a dialogue system. </p>

<p>Now, at a first glimpse it seems like a task that can be easily hand coded, and indeed lot of real application simply use systems in which specific questions are stored in memory in association with some already made answers to choose from (<a href=""https://www.aclweb.org/anthology/W13-4050.pdf"" rel=""nofollow noreferrer"">here's an example</a>), and the system simply show them (or read in the case of humanoid robots) to the people being interviewed, the system then wait for the answer and then move on with the next questions.</p>

<p>The point is that in real interviews the conversation flow is obviously much more smooth and natural. A human being can detect doubts in the voice of the interviewed person, which can also explicitly ask for explanations, a human being can also understand when an answer comes with emotional implications ('yes I feel sad every day') and we are able to automatically react to these hidden implications with emotional fillers ('I'm sorry to hear that'). All these aspects require to train some natural language understanding module in order to be replicated in an artificial agent (and this is actually what I'm currently working on), so I though I would have found more papers on this.</p>

<p>Now, despite having found a tons of paper related to open domain dialogue systems, affective and attentive systems, even systems able to reply with irony, I did not found many papers about dialogue systems for smooth interviews or questionnaire administration, which in my opinion sounds like an much easier task to tackle (especially if compared to open domain conversations).
The only two papers that I found which truly focused on interviewer systems are:</p>

<ul>
<li><p><a href=""http://www.ifaamas.org/AAMAS/aamas2014/proceedings/aamas/p1061.pdf"" rel=""nofollow noreferrer"">SimSensei Kiosk: A Virtual Human Interviewer for Healthcare Decision Support</a></p></li>
<li><p><a href=""http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/HAR-IWSDS19.pdf"" rel=""nofollow noreferrer"">A job interview dialogue system with autonomous android ERICA</a></p></li>
</ul>

<p>So my question is: did I miss something, like some specific keywords? Or is there actually a gap in the literature with regard to the design of dialogue systems for interviews and questionnaire (or surveys) administration? I'm interested in any link or hint from anyone working on similar applicants, thank you in advance!   </p>
","natural-language-processing"
"20075","Why does the transformer do better than RNN and LSTM in long-range context dependencies?","2020-04-07 12:05:31","20084","76","107687","<machine-learning><natural-language-processing><recurrent-neural-networks><long-short-term-memory><transformer>","<p>I am reading the article <a href=""https://towardsdatascience.com/transformers-141e32e69591"" rel=""noreferrer"">How Transformers Work</a> where the author writes</p>

<blockquote>
  <p>Another problem with RNNs, and LSTMs, is that it’s hard to parallelize the work for processing sentences, since you have to process word by word. Not only that but there is no model of <strong>long and short-range dependencies</strong>. </p>
</blockquote>

<p>Why exactly does the transformer do better than RNN and LSTM in <strong>long-range context dependencies</strong>?</p>
","natural-language-processing"
"20065","Should I be balancing the data before creating the vocab-to-index dictionary?","2020-04-07 05:53:40","20070","1","52","<natural-language-processing><python><training><sentiment-analysis>","<p>My question is about when to balance training data for sentiment analysis. </p>

<p>Upon evaluating my training dataset, which has 3 labels (good, bad, neutral), I noticed there were twice as many neutral labels as the other 2 combined, so I used a function to drop neutral labels randomly. </p>

<p>However, I wasn't sure if I should do this before or after creating the <code>vocab2index</code> mappings. </p>

<p>To explain, I am numericizing my text data by creating a vocabulary of words in the training data and linking them to numbers using enumerate. I think to use that dictionary of <code>vocab2index</code> values to numericise the training data. I also use that same dictionary to numericise the testing data, dropping any words that do not exist in the dictionary. </p>

<p>When I took a class on this, they had balanced the training data AFTER creating the vocab2index dictionary. However, when I thought about this in my own implementation, it did not make sense. What if some words from the original vocabulary are gone completely, then we aren't training the machine learning classifier on those words, but they would not be dropping from the testing data either (since words are dropping from <code>X_test</code> based on whether they are in the <code>vocab2index</code> dictionary). </p>

<p>So should I be balancing the data BEFORE creating the vocab2index dictionary? </p>

<p>I linked the code to create <code>X_train</code> and <code>X_test</code> below in case it help.</p>

<pre><code>def create_X_train(training_data='Sentences_75Agree_csv.csv'):
    data_csv = pd.read_csv(filepath_or_buffer=training_data, sep='.@', header=None, names=['sentence','sentiment'], engine='python')
    list_data = []
    for index, row in data_csv.iterrows():
        dictionary_data = {}
        dictionary_data['message_body'] = row['sentence']
        if row['sentiment'] == 'positive':
             dictionary_data['sentiment'] = 2
        elif row['sentiment'] == 'negative':
             dictionary_data['sentiment'] = 0
        else:
             dictionary_data['sentiment'] = 1 # For neutral sentiment
        list_data.append(dictionary_data)
    dictionary_data = {}
    dictionary_data['data'] = list_data
    messages = [sentence['message_body'] for sentence in dictionary_data['data']]
    sentiments = [sentence['sentiment'] for sentence in dictionary_data['data']]

    tokenized = [preprocess(sentence) for sentence in messages]
    bow = Counter([word for sentence in tokenized for word in sentence]) 
    freqs = {key: value/len(tokenized) for key, value in bow.items()} #keys are the words in the vocab, values are the count of those words

    # Removing 5 most common words from data
    high_cutoff = 5
    K_most_common = [x[0] for x in bow.most_common(high_cutoff)] 
    filtered_words = [word for word in freqs if word not in K_most_common]

    # Create vocab2index dictionary:
    vocab = {word: i for i, word in enumerate(filtered_words, 1)}
    id2vocab = {i: word for word, i in vocab.items()}
    filtered = [[word for word in sentence if word in vocab] for sentence in tokenized] 

    # Balancing training data due to large number of neutral sentences
    balanced = {'messages': [], 'sentiments':[]}
    n_neutral = sum(1 for each in sentiments if each == 1)
    N_examples = len(sentiments)
    # print(n_neutral/N_examples)
    keep_prob = (N_examples - n_neutral)/2/n_neutral
    # print(keep_prob)
    for idx, sentiment in enumerate(sentiments):
        message = filtered[idx]
        if len(message) == 0:
            # skip this sentence because it has length 0
            continue
        elif sentiment != 1 or random.random() &lt; keep_prob:
            balanced['messages'].append(message)
            balanced['sentiments'].append(sentiment)

    token_ids = [[vocab[word] for word in message] for message in balanced['messages']]
    sentiments_balanced = balanced['sentiments']

    # Unit test:
    unique, counts = np.unique(sentiments_balanced, return_counts=True)
    print(np.asarray((unique, counts)).T)
    print(np.mean(sentiments_balanced))
    ##################

    # Left padding and truncating to the same length 
    X_train = token_ids
    for i, sentence in enumerate(X_train):
        if len(sentence) &lt;=30:
            X_train[i] = ((30-len(sentence)) * [0] + sentence)
        elif len(sentence) &gt; 30:
            X_train[i] = sentence[:30]
    return vocab, X_train, sentiments_balanced
</code></pre>

<pre><code>def create_X_test(test_sentences, vocab):
    tokenized = [preprocess(sentence) for sentence in test_sentences]
    filtered = [[word for word in sentence if word in vocab] for sentence in tokenized] # X_test filtered to only words in training vocab
    # Alternate method with functional programming:
    # filtered = [list(filter(lambda a: a in vocab, sentence)) for sentence in tokenized]
    token_ids = [[vocab[word] for word in sentence] for sentence in filtered] # Numericise data

    # Remove short sentences in X_test
    token_ids_filtered = [sentence for sentence in token_ids if len(sentence)&gt;10]
    X_test = token_ids_filtered
    for i, sentence in enumerate(X_test):
        if len(sentence) &lt;=30:
            X_test[i] = ((30-len(sentence)) * [0] + sentence)
        elif len(sentence) &gt; 30:
            X_test[i] = sentence[:30]
    return X_test
</code></pre>
","natural-language-processing"
"20054","What are the challenges faced by using NLP to convert mathematical texts into formal logic?","2020-04-06 21:39:35","","2","248","<natural-language-processing><math><logic><natural-language-understanding><automated-theorem-proving>","<p>From what I've figured</p>

<p>(a) converting mathematical theorems and proofs from English to formal logic is a straightforward job for mathematicians with sufficient background, except that it takes time. </p>

<p>(b) once converted to formal logic, computer verification of the proof becomes straightforward.  </p>

<p>If we can automate (a), a lot of time and intellectual labour (that could be dedicated elsewhere) is saved in doing (b) on published research papers. </p>

<p>Note that if solving (a) in its entirety is hard, we could expect the mathematicians to meet the computer system halfway and avoid writing lengthy English paras that are hard to convert. If it becomes doable enough, submitting a formal logical version of your paper could even become a standard procedure that is expected. </p>

<p>Additional benefit of solving (a) would be to do the process in reverse: mathematicians could delegate smaller tasks and lemmas (both trivial and non-trivial tasks) to an automated theorem prover (ATP). Assisted theorem proving will become more popular and boost productivity, maybe even surprise us once in a while by coming up with proofs that the paper writer couldn't. This is further of value if we predict a sharp upward trajectory of the capability of ATPs in the future. If anything, this could be self-fulfilling, as the demonstration of potential for good ATPs combined by a large corpus of proofs and problems in formal logical format could drive an increase in research on ATPs.</p>

<p>Forgive me if I sound like a salesman, but how doable is this? <strong>What will be the main challenges faced in developing NLP-based AI to convert papers, and how tractable are these challenges given today's state of the field?</strong></p>

<p>P.s. I understand that proofs generated by ATPs are often hard to understand intuitively and can end up proving results without clearly exposing the underlying proof method used. But it is still a benefit to be able to use the final results</p>
","natural-language-processing"
"20052","How do LSTM and GRU avoid to overcome the vanishing gradient problem?","2020-04-06 19:42:34","","2","398","<natural-language-processing><long-short-term-memory><vanishing-gradient-problem>","<p>I'm watching the video <a href=""https://www.youtube.com/watch?v=y7qrilE-Zlc"" rel=""nofollow noreferrer"">Recurrent Neural Networks (RNN) | RNN LSTM | Deep Learning Tutorial | Tensorflow Tutorial | Edureka</a> where the author says that the LSTM and GRU architecture help to reduce the vanishing gradient problem. How do LSTM and GRU prevent the vanishing gradient problem?</p>
","natural-language-processing"
"20027","How does one detect linguistic recursion so as to know how much nesting there is, if any?","2020-04-05 19:47:07","","2","32","<natural-language-processing><computational-linguistics>","<p>To be clear, <a href=""https://linguistics.stackexchange.com/a/3254/28348"">recursion in linguistics is here better called &quot;nesting&quot;</a> in this CS context to avoid confusing it with the <em>other</em> recursion. How does one detect nesting? I am particularly interested in the example case of conjunctions. For example: say that I want to look for sentences that look like this:</p>
<blockquote>
<p>Would you rather have ten goldfish <strong>or</strong> a raccoon?</p>
</blockquote>
<p>Seems straightforward: a binary choice. However, how do you distinguish a binary choice with nesting from a ternary (or <em>n</em>-ary) choice?</p>
<blockquote>
<p>Would you rather have (one <strong>or</strong> two dogs) <strong>or</strong> (a raccoon)?</p>
<p>Would you rather have (two dogs) <strong>or</strong> (ten goldfish) <strong>or</strong> (a raccoon)?</p>
</blockquote>
<p>Ditto for implied uses of &quot;or,&quot; which is more common than the latter of the above:</p>
<blockquote>
<p>Would you rather have (one <strong>or</strong> two dogs),<em><strong>[nothing]</strong></em> (ten goldfish), <strong>or</strong> (a raccoon)?</p>
</blockquote>
<p>Given the available tools for NLP (POS-taggers and the like), how do you count the number of conjunctions to say &quot;there are <em>n</em> surface-level clauses in the sentence, with <em>n</em>-or-zero clauses nested within.&quot;?</p>
","natural-language-processing"
"20016","What are examples of tutorials and blogs for beginners to master the cross-lingual information retrieval?","2020-04-05 08:02:50","","1","42","<natural-language-processing><resource-request><information-retrieval>","<p>Currently, I am following the <a href=""https://www.youtube.com/playlist?list=PLQiyVNMpDLKnZYBTUOlSI9mi9wAErFtFm"" rel=""nofollow noreferrer"">Dan Jurofsky NLP Tutorial</a> and <a href=""https://www.youtube.com/watch?v=8rXD5-xhemo&amp;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z"" rel=""nofollow noreferrer"">CS 224 Stanford 2019</a>. Can you list tutorials and blogs for beginners to master the cross-lingual information retrieval?</p>
","natural-language-processing"
"19940","What are the current research trends in recognizing narrative similarity?","2020-04-02 17:30:13","","1","27","<machine-learning><natural-language-processing><natural-language-understanding>","<p>I am currently working on a term paper on the topic of Narrative Similarity, based on Loizos Michael's work ""Similarity of Narratives"". I am trying to find the latest trends within this field of study for the literature overview in my assignement. However up untill now I wasn't able to find any new work on this particular subject. </p>

<p>I would appreciate any literature recommendation by anyone out there that has worked on this topic or is currently doing so.</p>

<p>Link to Michael's work:
<a href=""https://www.researchgate.net/publication/316280937_Similarity_of_Narratives"" rel=""nofollow noreferrer"">https://www.researchgate.net/publication/316280937_Similarity_of_Narratives</a></p>
","natural-language-processing"
"19853","Building a template based NLG system to generate a report from data","2020-03-29 09:20:58","","1","361","<natural-language-processing><long-short-term-memory><bert>","<p>I am a newbie to NLP and NLG. I am tasked to develop a system to generate a report based on a given data table. The structure of the report and the flow is predefined. I have researched on several existing python libraries like BERT, SimpleNLG but they don't seem to fit my need. </p>

<p>For example:
input_data(country = 'USA', industry = 'Coal', profit = '4m', trend = 'decline')
output: The coal industry in USA declined by 4m. </p>

<p>The input data array can be different combinations (and dynamic) based on a data table. I would like to know if  there is any python package available, or any resource discussing a practical approach for this. </p>
","natural-language-processing"
"19844","Is text preprocessing really all that necessary for NLP?","2020-03-28 18:26:49","","1","364","<neural-networks><natural-language-processing><data-preprocessing><structured-data>","<p>As a first step in many NLP courses, we learn about text preprocessing. The steps include lemmatization, removal of rare words, correcting typos etc. But I am not so sure about the actual effectiveness of doing such a step; in particular, if we are learning a neural network for a downstream task, it seems like modern state of the art (BERT, GPT-2) just take essentially raw input. </p>

<p>For instance, <a href=""https://www.aclweb.org/anthology/W18-5406.pdf"" rel=""nofollow noreferrer"">this ACL paper</a> seems to show that the result of text preprocessing is mixed, to say the least. </p>

<p>So is text preprocessing really all that necessary for NLP? In particular, I want to contrast/compare against vision and tabular data, where I have empirically found that standardization usually actually does help. Feel free to share your personal experiences/what use cases where text preprocessing helps! </p>
","natural-language-processing"
"18794","What are the pros and cons of supervised, semi-supervised and unsupervised relation extraction in NLP?","2020-03-25 11:07:13","","0","625","<natural-language-processing><comparison><unsupervised-learning><supervised-learning><semi-supervised-learning>","<p>I am following the NLP course taught by Dan Jurafsky. In the video lectures <a href=""https://www.youtube.com/watch?v=a48vIACEC_w&amp;list=PLQiyVNMpDLKnZYBTUOlSI9mi9wAErFtFm&amp;index=50"" rel=""nofollow noreferrer"">Supervised Relation Extraction</a> and <a href=""https://www.youtube.com/watch?v=Jxqx70iX9kc&amp;list=PLQiyVNMpDLKnZYBTUOlSI9mi9wAErFtFm&amp;index=51"" rel=""nofollow noreferrer"">Semi Supervised and Unsupervised Relation Extraction</a> Jurafsky explains supervised, semi-supervised and unsupervised relation extraction.</p>

<p>But what are the pros and cons of every relation extraction method compared with the other two relation extraction methods?</p>
","natural-language-processing"
"18773","Can you train Transformers sequentially?","2020-03-24 09:02:02","","1","241","<natural-language-processing><pytorch><transformer>","<p>I’m currently trying to train a BART, which is a denoising Transformer created by Facebook researchers. Here’s my Transformer code</p>

<pre><code>import math
import torch
from torch import nn
from Constants import *

class Transformer(nn.Module):
    def __init__(self, input_dim: int, output_dim: int, d_model: int = 200, num_head: int = 8, num_e_layer: int = 6,
                 num_d_layer: int = 6, ff_dim: int = 1024, drop_out: float = 0.1):
        '''
        Args:
            input_dim: Size of the vocab of the input
            output_dim: Size of the vocab for output
            num_head: Number of heads in mutliheaded attention models
            num_e_layer: Number of sub-encoder layers
            num_d_layer: Number of sub-decoder layers
            ff_dim: Dimension of feedforward network in mulihead models
            d_model: The dimension to embed input and output features into
            drop_out: The drop out percentage
        '''
        super(Transformer, self).__init__()
        self.d_model = d_model
        self.transformer = nn.Transformer(d_model, num_head, num_e_layer, num_d_layer, ff_dim, drop_out,
                                          activation='gelu')
        self.decoder_embedder = nn.Embedding(output_dim, d_model)
        self.encoder_embedder = nn.Embedding(input_dim, d_model)
        self.fc1 = nn.Linear(d_model, output_dim)
        self.softmax = nn.Softmax(dim=2)
        self.positional_encoder = PositionalEncoding(d_model, drop_out)
        self.to(DEVICE)

    def forward(self, src: torch.Tensor, trg: torch.Tensor, src_mask: torch.Tensor = None,
                trg_mask: torch.Tensor = None):
        embedded_src = self.positional_encoder(self.encoder_embedder(src) * math.sqrt(self.d_model))
        embedded_trg = self.positional_encoder(self.decoder_embedder(trg) * math.sqrt(self.d_model))
        output = self.transformer.forward(embedded_src, embedded_trg, src_mask, trg_mask)
        return self.softmax(self.fc1(output))

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)    
        self.register_buffer('pe', pe)
</code></pre>

<p>and here’s my training code</p>

<pre><code>def train(x: list):
    optimizer.zero_grad()
    loss = 0.
    batch_sz = len(x)
    max_len = len(max(x, key=len)) + 1  # +1 for EOS xor SOS
    noise_x = noise(x)
    src_x = list(map(lambda s: [SOS] + [char for char in s] + [PAD] * ((max_len - len(s)) - 1), noise_x))
    trg_x = list(map(lambda s: [char for char in s] + [EOS] + [PAD] * ((max_len - len(s)) - 1), x))
    src = indexTensor(src_x, max_len, IN_CHARS).to(DEVICE)
    trg = targetsTensor(trg_x, max_len, OUT_CHARS).to(DEVICE)
    names = [''] * batch_sz

    for i in range(src.shape[0]):
        probs = transformer(src, trg[:i + 1])
        loss += criterion(probs, trg[i])

    loss.backward()
    optimizer.step()

    return names, loss.item()
</code></pre>

<p>As you can see in the train code. I am training it ""sequentially"" by inputting the first letter of the data then computing the loss with the output then inputting the first and second character and doing the same thing, so on and so forth.</p>

<p>This doesn’t seem to be training properly though as the denoising is totally off. I thought maybe there’s something wrong with my code or you can’t train Transformers this way.</p>

<p>I'm taking first name data then noising it then training the Transformer to denoise it, but the output to the Transformers doesn't look remotely like the denoised version or even the noised version of the name. I built a denoising autoencoder using LSTMs and it did way better, but I feel like BART should be way out performing LSTMs cause it's supposedly state of the art NLP neural network model.</p>
","natural-language-processing"
"18759","What are pros and cons of Bi-LSTM as compared to LSTM?","2020-03-23 07:41:11","","6","2892","<natural-language-processing><comparison><long-short-term-memory><language-model><bidirectional-lstm>","<p>What are the pros and cons of <strong>LSTM</strong> vs <strong>Bi-LSTM</strong> in language modelling? What was the need to introduce Bi-LSTM?</p>
","natural-language-processing"
"18715","Which NLP applications are based on recurrent neural networks?","2020-03-19 05:52:24","","0","128","<natural-language-processing><recurrent-neural-networks><applications>","<p>Some of the NLP applications taken from this link <a href=""https://towardsdatascience.com/natural-language-processing-nlp-top-10-applications-to-know-b2c80bd428cb"" rel=""nofollow noreferrer"">NLP Applications</a>:</p>

<ul>
<li>Machine Translation</li>
<li>Speech Recognition</li>
<li>Sentiment Analysis</li>
<li>Question Answering</li>
<li>Automatic Summarization</li>
<li>Chatbots</li>
<li>Market Intelligence</li>
<li>Text Classification</li>
<li>Character Recognition</li>
<li>Spell Check</li>
</ul>

<p>Which are the NLP applications that supports recurrent neural network?</p>
","natural-language-processing"
"18671","Is there any resource that describes in detail a naive example-based machine translation algorithm?","2020-03-16 15:09:51","18788","5","171","<natural-language-processing><reference-request><resource-request><machine-translation>","<p>I'm looking to develop a machine translation tool for a constructed language. I think that the example-based approach is the most suitable because the said language is very regular and I can have a sufficient amount of parallel translations.</p>
<p>I already know the overall idea behind the example-based machine translation (EBMT) approach, but I can't find any resource that describes a naive EBMT algorithm (or model) that would allow me to easily implement it.</p>
<p>So, I'm looking for either:</p>
<ul>
<li>a detailed description,</li>
<li>pseudocode or</li>
<li>a sufficiently clear open-source project (maybe a GitHub one)</li>
</ul>
<p>of a naive EBMT algorithm. So, I'm not looking for a software library that implements this, but I'm looking for a resource that explains/describes in detail a naive/simple EBMT algorithm, so that I am able to implement it.</p>
<p>Note that there are probably dozens of variations of EBMT algorithms. I'm only looking for the most naive/simple one.</p>
<p>I have already looked at the project <a href=""https://github.com/proycon/pbmbmt"" rel=""nofollow noreferrer"">Phrase-based Memory-based Machine Translator</a>, but, unfortunately, it is not purely based on examples but also statistical, i.e. it needs an alignment file generated by, for example, Giza++ or Moses.</p>
","natural-language-processing"
"18634","What are the main differences between skip-gram and continuous bag of words?","2020-03-14 06:52:53","","20","20059","<natural-language-processing><comparison><word2vec><cbow><skip-gram>","<p>The skip-gram and continuous bag of words (CBOW) are two different types of word2vec models.</p>
<p>What are the main differences between them? What are the pros and cons of both methods?</p>
","natural-language-processing"
"18613","What are the advantages and disadvantages of extrinsic and perplexity model evaluation in NLP?","2020-03-13 13:30:02","","2","258","<natural-language-processing><comparison><models>","<p>In the video <a href=""https://www.youtube.com/watch?v=b6nwdc_fGfA&amp;list=PLQiyVNMpDLKnZYBTUOlSI9mi9wAErFtFm&amp;index=14"" rel=""nofollow noreferrer"">Evaluation and Perplexity</a> by Dan Jurafsky, the author talks about extrinsic and perplexity evaluation in the context of natural language processing (NLP).</p>

<p>What are the advantages and disadvantages of extrinsic and perplexity model evaluation in NLP? Which evaluation method is preferred usually, and why?</p>
","natural-language-processing"
"18606","Why is dialogue a hard problem in natural language processing?","2020-03-13 09:10:30","18644","4","273","<machine-learning><natural-language-processing>","<p>I've just started learning natural language processing from <a href=""https://www.youtube.com/watch?v=3Dt_yh1mf_U&amp;list=PLQiyVNMpDLKnZYBTUOlSI9mi9wAErFtFm"" rel=""nofollow noreferrer"">Dan Jurafsky's videos lectures</a>. In that video, minute 4:56, he is stating that dialogue is a hard problem in natural language processing (NLP). Why?</p>
","natural-language-processing"
"18605","What is the current state-of-the-art in unsupervised cross-lingual representation learning?","2020-03-13 08:42:19","18676","2","76","<natural-language-processing><reference-request><models><state-of-the-art>","<p>What is the current state-of-the-art in unsupervised cross-lingual representation learning?</p>
","natural-language-processing"
"18550","What algorithm to use for finding artists/bands in text and differentiating between artists that share the same name","2020-03-10 18:36:57","","1","31","<machine-learning><natural-language-processing><python><algorithm>","<p>Here's the data I have:  </p>

<ol>
<li><p>Text from articles from various music blogs &amp; music news sites (title, summary, full content, and sometimes tags).   </p></li>
<li><p>I used a couple different NLP/NER tools (nltk, spacy, and stanford NER) to determine the proper nouns in the text, and gave each proper noun a score based on how many times it appeared, and how many NLP tools recognized it as a proper noun. None of these tools are very accurate by themselves for my data</p></li>
<li><p>For each proper noun I queried <a href=""https://musicbrainz.org/"" rel=""nofollow noreferrer"">musicbrainz</a> to find artists with that name. (musicbrainz has a lot of data that may be helpful: aliases, discography, associations with other artists)</p></li>
<li><p>Any links in the article to Spotify, YouTube etc. and the song name &amp; artist for that link  </p></li>
</ol>

<p>I have three goals:    </p>

<ol>
<li>Determine which proper nouns are artists  </li>
<li>For artists that share the same name, determine which one the text is referring to (based on musicbrainz data)  </li>
<li>Determine if the artist is important to the article, or if they were just briefly mentioned</li>
</ol>

<p>I have manually tagged some of the data with the correct output for the above 3 goals.    </p>

<p>How would you go about this? Which algorithms do you think would be best for these goals?<br>
Is there any semi-supervised learning I can do to reduce the amount of tagging I need to do?</p>
","natural-language-processing"
"18527","Owner Search for given Server SNO","2020-03-10 07:22:42","","2","54","<machine-learning><natural-language-processing><python>","<p>I am newbie to NLP.
I have a excel sheet with following columns: 
    Server_SNo, 
    Owner, 
    Hosting Dept, 
    Bus owner, 
    Applications hosted, 
    Functionality,
    comments</p>

<p>a. Except the Server_SNo, other columns may or may not have data.<br>
b. For some records there is no data except Server_SNo which is the first column.
c. One business owner can own more than 1 Server.</p>

<p>So, out of 4000 records, about 50% of data contain direct mapping for a server with owner.  Remaining 50% of data have combination of other columns (Owner, Hosting Dept, Bus owner, Applications hosted, Functionality and comments)</p>

<p>Here is my problem, I need to find the owner for the given Server_Sno for 50% of data which have combination of other columns (Owner, Hosting Dept, Bus owner, Applications hosted, Functionality and comments).</p>

<p>I have just started to build the code using Python and NLTK.</p>

<p>Is this an NLP problem? Am I going in right direction using Python and NLTK for NLP?</p>

<p>Any insights is appreciated.</p>

<p>-Mani</p>
","natural-language-processing"
"18489","How do I turn this formula of the average degree of a graph into Python code?","2020-03-07 21:32:06","19917","1","489","<natural-language-processing><python><graph-theory>","<p>I am working through the textbook &quot;Graph-Based Natural Language Processing and Information Retrieval&quot;, where I've got a question on implementation of this first Latex looking formula/algorithm.</p>
<p>Can you help me turn the formula under 1.2 Graph Properties into python code? Yes, I know there are many other languages, but python is more user-friendly so I'm starting there, and will eventually rewrite it into C.</p>
<p>As I read the above node example, sorry the D and E nodes were cut off.
Node A has two outflowing arrows notating it as their head node, and it is the one tail node.</p>
<p>This first sentence references the Graphs:
To traverse from A to B, If A to B value is sufficient (above Nx), go to B. If A to B value is below Nx, go A to C to D to A to B total cost is 5.2+7+1+8 = 21.20 traverse cost, this makes sense.</p>
<p><a href=""https://i.sstatic.net/F8TeG.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/F8TeG.png"" alt=""enter image description here"" /></a></p>
<p>This sentence refers to the Latex formula in the book.
Then to start the formula calculation, the average degree of a graph &quot;a&quot; is equal to the sum of, one over N, times the sum of the in-degree of vertices? Asserting that the sum is a non zero integer between 1 and N?</p>
<p>Ok, I only loaded one page and hope that's not a TOS violation or causes issue, it's a challenge to find people who understand graph theory.</p>
<p>Let me know what questions you have, but I'm just wanting to get clarification if my understanding is what this page is saying.</p>
","natural-language-processing"
"18458","Use cases for AI inside the software company","2020-03-06 04:06:48","","1","67","<natural-language-processing><ai-design><philosophy><applications>","<p>This question is a bit philosophic and is about making new use cases for software companies. Let me describe what exist for now, why it is not enough, and what is needed.</p>

<p>I know that there are a lot of <a href=""https://github.com/src-d/awesome-machine-learning-on-source-code"" rel=""nofollow noreferrer"">existing researches</a> in applying ML for software (please don't simply point to this one!), but none of them consider the application of ML for <strong>software company</strong>, not the software alone.</p>

<p>Existent approaches that apply AI for software engineering tasks consider it as follows:</p>

<pre><code>human1 -&gt; software (big code) &lt;- human2
</code></pre>

<p>That means that <code>human1</code> makes some part of <code>software</code> (that is a part of <code>big code</code>), and <code>human2</code> reuses some knowledge from it. It may be a bugfix pattern (as e.g. <a href=""https://www.deepcode.ai/"" rel=""nofollow noreferrer"">DeepCode</a> does), API usage pattern, repair of code, summarization of code, code search, or whatever else. I think the main reason for this is the original <em>hypothesis of naturalness</em>:</p>

<blockquote>
  <p><strong>The naturalness hypothesis</strong>. Software is a form of human communication; software corpora have similar statistical properties to natural language corpora, and these properties can be exploited to build better software engineering tools.</p>
</blockquote>

<p>(from <a href=""https://arxiv.org/pdf/1709.06182.pdf"" rel=""nofollow noreferrer"">Allamanis et al</a>, page 3)</p>

<p>But imagine one software company. It has:</p>

<ul>
<li>Some number of engineers,</li>
<li>Some number of managers,</li>
<li>The software product,</li>
<li>Information related to the software product (documentation, bug/task tracking system, code review),</li>
<li>Some number of formal management processes (waterfall, scrum or whatever else),</li>
<li>Some number of informal processes</li>
</ul>

<p>But none of these models consider the software as a product itself. I mean that we should consider the model as follows:</p>

<pre><code>company -&gt; software product -&gt; customers
              |
              v
           big code
</code></pre>

<p>or even</p>

<pre><code>engineer1 -&gt; |
    |
engineer2 -&gt; |
    |
...          | ----&gt; software product ----&gt; customers
    |                   |
engineerN -&gt; |          |
    |                   |
manager  --&gt; |          |
                        v
                     big code
</code></pre>

<p>So my questions are:</p>

<ol>
<li>Are there any cases of investigation of such models? </li>
<li>Are there any similar cases in related fields, say in general companies (not specifically software ones)?</li>
<li>Are there any analogies (not specifically from software-related domains) where some knowledge can be transferred from a bigger object (<code>big code</code> in our case) to a smaller one (<code>software product</code>)?</li>
</ol>

<p>Any ideas are welcome.</p>
","natural-language-processing"
"18449","Is it possible to do token classification using a model such as GPT-2?","2020-03-05 21:26:11","","1","251","<natural-language-processing><classification><pytorch><transformer>","<p>I am trying to use <a href=""https://github.com/huggingface/transformers"" rel=""nofollow noreferrer"">PyTorch's transformers</a> as a part of a research project to do sentiment analysis of several types of review data (laptop and restaurant). </p>

<p>To do this, my team is taking a token-based approach and we are using models that can perform token analysis.</p>

<p>One problem we have encountered is that many of the models in <a href=""https://github.com/huggingface/transformers"" rel=""nofollow noreferrer"">PyTorch's transformers</a> do not support token classification, but do support sequence classification. One such model we wanted to test is GPT-2.</p>

<p>In order to overcome this, we proposed using sequence classifiers on single tokens which should work in theory, but possibly at reduced accuracy.</p>

<p>This raises the following questions:</p>

<ul>
<li><p>Is it possible to do token classification using a model such as GPT-2 using <a href=""https://github.com/huggingface/transformers"" rel=""nofollow noreferrer"">PyTorch's transformers</a>?</p></li>
<li><p>How do sequence classifiers perform on single token sequences?</p></li>
</ul>
","natural-language-processing"
"18437","How does positional encoding work in the transformer model?","2020-03-05 11:54:02","","2","168","<deep-learning><natural-language-processing><transformer><attention><positional-encoding>","<p>In the transformer model, to incorporate positional information of texts, the researchers have added a positional encoding to the model. <em>How does positional encoding work? How does the positional encoding system learn the positions when varying lengths and types of text are passed at different time intervals?</em></p>
<p>To be more concrete, let's take these two sentences.</p>
<ol>
<li>&quot;She is my queen&quot;</li>
<li>&quot;Elizabeth is the queen of England&quot;</li>
</ol>
<p>How would these sentences be passed to the transformer? What would happen to them during the positional encoding part?</p>
<p>Please explain with less math and with more intuition behind it.</p>
","natural-language-processing"
"18413","Is it recommended to remove stop words before named entity recognition?","2020-03-04 14:59:59","","2","1275","<natural-language-processing><data-preprocessing>","<p>Removing stop words can significantly speed up named entity recognition (NER) modeling by reducing the number of tokens in a document.</p>

<p>Are stop words critical to get correct NER performance?</p>
","natural-language-processing"
"18381","Why is the sample size of stochastic gradient descent a power of 2?","2020-03-03 06:08:33","","1","96","<deep-learning><natural-language-processing><stochastic-gradient-descent>","<p>I watched the video lecture of cs224: <a href=""https://www.youtube.com/watch?v=kEMJRjEdNzM&amp;list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z&amp;index=2"" rel=""nofollow noreferrer"">Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 2 – Word Vectors and Word Senses</a>.</p>
<p>They take the sample size of the window to be <span class=""math-container"">$2^5 = 32$</span> or <span class=""math-container"">$2^6 = 64$</span>. Why is the sample size of stochastic gradient descent a power of 2? Why not we can take 42 or 53 as the sample window size?</p>
<p>Btw, how do I identify the best minimum window sample size?</p>
","natural-language-processing"
"18369","Why I have a different number of terms in word2vec and TFIDF? How I can fix it?","2020-03-02 21:12:55","18385","1","53","<natural-language-processing><python><word-embedding><word2vec><weights>","<p>I need multiply the weigths of terms in TFIDF matrix by the word-embeddings of word2vec matrix but I can't do it because each matrix have a different number of terms. <strong>I am using the same corpus for get both matrix, I don't know why each matrix have a different number of terms
.</strong></p>

<p>My problem is that I have a matrix TFIDF with the shape <code>(56096, 15500)</code> (corresponding to: number of terms, number of documents) and matrix Word2vec with the shape <code>(300, 56184)</code> (corresponding to : number of word-embeddings, number of terms).<br>
And I need the same numbers of terms in both matrix. </p>

<p>I use this code for get the matrix of word-embeddings Word2vec: </p>

<pre><code>def w2vec_gensim(norm_corpus):
    wpt = nltk.WordPunctTokenizer()
    tokenized_corpus = [wpt.tokenize(document) for document in norm_corpus]
    # Set values for various parameters
    feature_size = 300
    # Word vector dimensionality
    window_context = 10
    # Context window size
    min_word_count = 1
    # Minimum word count
    sample = 1e-3
    # Downsample setting for frequent words
    w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size, window=window_context, min_count =  min_word_count, sample=sample, iter=100)
    words = list(w2v_model.wv.vocab)
    vectors=[]
    for w in words:
        vectors.append(w2v_model[w].tolist())
    embedding_matrix= np.array(vectors)
    embedding_matrix= embedding_matrix.T
    print(embedding_matrix.shape)

    return embedding_matrix
</code></pre>

<p>And this code for get the TFIDF matrix: </p>

<pre><code>tv = TfidfVectorizer(min_df=0., max_df=1., norm='l2', use_idf=True, smooth_idf=True)


def matriz_tf_idf(datos, tv):
    tv_matrix = tv.fit_transform(datos)
    tv_matrix = tv_matrix.toarray()
    tv_matrix = tv_matrix.T
    return tv_matrix
</code></pre>

<p>And I need the same number of terms in each matrix. For example, if I have 56096 terms in TFIDF, I need the same number in embeddings matrix, I mean matrix TFIDF with the shape <code>(56096, 1550)</code> and matrix of embeddings Word2vec with the shape <code>(300, 56096)</code>. How I can get the same number of terms in both matrix? 
Because I can't delete without more data, due to I need the multiplication to make sense because my goal is to get the embeddings from the documents. </p>

<p>Thank you very much in advance.</p>
","natural-language-processing"
"18253","Is it possible to derive meaning from text by providing multiple ways of saying the same thing to a neural network?","2020-02-25 23:40:13","","1","123","<neural-networks><natural-language-processing><classification><text-classification>","<p>Let's say I feed a neural network with multiple string sentences that mean roughly the same thing but are formulated differently. Will the neural network be able to derive patterns of meaning in the same way that it is being done with images. Is this an approach currently used in Natural Language Processing? </p>

<p>With images of dogs the neural network will get the underlying patterns that define a dog. Could it be the same thing with sentences? </p>
","natural-language-processing"
"18234","Why is my loss (binary cross entropy) converging on ~0.6? (Task: Natural Language Inference)","2020-02-25 08:46:47","18243","2","3239","<deep-learning><natural-language-processing><tensorflow><training><bert>","<p>I’m trying to debug my neural network (BERT fine-tuning) trained for natural language inference with binary classification of either entailment or contradiction. I've trained it for 80 epochs and its converging on ~0.68. Why isn't it getting any lower?</p>

<p>Thanks in advance!</p>

<hr>

<p>Neural Network Architecture:</p>

<p><a href=""https://i.sstatic.net/3VAyw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/3VAyw.jpg"" alt=""Architecture""></a></p>

<p>Training details:</p>

<ul>
<li>Loss function: Binary cross entropy</li>
<li>Batch size: 8</li>
<li>Optimizer: Adam (learning rate = 0.001)</li>
<li>Framework: Tensorflow 2.0.1</li>
<li>Pooled embeddings used from BERT output.</li>
<li>BERT parameters are not frozen.</li>
</ul>

<p>Dataset:</p>

<ul>
<li>10,000 samples</li>
<li>balanced dataset (5k each for entailment and contradiction)</li>
<li>dataset is a subset of data mined from wikipedia.</li>
<li>Claim example: <em>""'History of art includes architecture, dance, sculpture, music, painting, poetry literature, theatre, narrative, film, photography and graphic arts.'""</em></li>
<li>Evidence example: <em>""The subsequent expansion of the list of principal arts in the 20th century reached to nine : architecture , dance , sculpture , music , painting , poetry -LRB- described broadly as a form of literature with aesthetic purpose or function , which also includes the distinct genres of theatre and narrative -RRB- , film , photography and graphic arts .""</em></li>
</ul>

<p>Dataset preprocessing: </p>

<ul>
<li>Used [SEP] to separate the two sentences instead of using separate embeddings via 2 BERT layers. (Hence, segment ids are computed as such)</li>
<li>BERT's <a href=""https://github.com/google-research/bert/blob/master/tokenization.py"" rel=""nofollow noreferrer"">FullTokenizer</a> for tokenization.</li>
<li>Truncated to a maximum sequence length of 64.</li>
</ul>

<p>See below for a graph of the training history. (Red = train_loss, Blue = val_loss)</p>

<p><a href=""https://i.sstatic.net/h8Hlr.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/h8Hlr.png"" alt=""0.68 convergence""></a></p>
","natural-language-processing"
"18147","Are POS tagging, Chunking, Disambiguation, etc. subtasks of annotation?","2020-02-20 11:09:19","","0","62","<machine-learning><natural-language-processing>","<p>I wonder about the legitimacy of using the terms ""POS tagging"", ""Chunking"", ""Disambiguation"" and ""Categorization"" to describe an activity that doesn't include writing code and database queries, or interacting with the NLP algorithm and database directly.</p>

<p>More specifically, let's suppose I use the following tools:</p>

<ol>
<li><p>an ""Annotator"" for analyzing the input text (e.g. sentences copypasted from online newspapers) and choose and save proper values as regards to ""POS"" of tokens and words, ""Words""(entities and collocations) and ""Chunk"". Tokens are already detected by default. I have to decide which words are entities and/or collocations or not and their typology, though. May the performed tasks be called ""POS tagging"", ""Chunking"" and ""support to categorization""?</p></li>
<li><p>A knowledge base, for searching and choosing the proper synsets of the lemmas and assigning them to the words analyzed in the previous Annotation tool. May such a task be called ""Disambiguation""?</p></li>
<li><p>A graphical user interface which shows how the NLP analyzes by default the input texts as regards to Lemmas, POS, Chunks, Senses, entities, domains, main concepts, dependency tree, in order to make analyses consistent with it.</p></li>
</ol>

<p>If I want to define these activities in a few words, ""Machine Learning annotation"" may be the most correct. </p>

<p>But what if I want to be more specific? I don't know whether or not the terms ""POS tagging"", ""Chunking"", ""Disambiguation"" and ""Support to categorization"" may be appropriate for they generally come within ""programming contexts"", as far as I know. In other terms, do they involve writing algorithms and programming or are they / may they be referred to the ""less-technical"" activities described above?</p>
","natural-language-processing"
"18130","Simple sequential model with LSTM which doesn't converge","2020-02-19 18:14:16","","1","211","<natural-language-processing><tensorflow><recurrent-neural-networks><long-short-term-memory>","<p>I'm actually trying to create a sequential neural network in order to translate a ""human"" sentence in a ""machine"" sentence understandable by an algorithm. Like It didn't work, I've try to create a NN that understands whether the input is a unit or not.</p>

<p>Even this NN doesn't work and I don't understand Why. I tried with different optimize/loss/metrics/with Rnn/with LSTM.</p>

<p>So there is one array of unit and one array with lambda words.
I send to the NN :</p>

<p>input -> word in OneHotEncoding where each char is a vector</p>

<p>output -> a vector with a 1 at the relative position of the unit in the array, ex : [0,0,0,1,0]. If It's not a unit, the vector is composed of 0.</p>

<p>I'm actually using LSTM layers and sigmoid activation because I will need it for my ""big"" NN. </p>



<pre><code>model = tf.keras.Sequential()
model.add(tf.keras.Input(shape=(13,vocab_size),batch_size=80))
model.add(tf.keras.layers.LSTM(32, return_sequences=True)) 
model.add(tf.keras.layers.LSTM(6, return_sequences=False))
model.add(tf.keras.layers.Dense(6, activation=""sigmoid""))
model.reset_states()
model.summary()
model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
model.fit(encoded_word, my_targets, batch_size=80, epochs=100, validation_data=(encoded_word, my_targets))



Model: ""sequential_38""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_57 (LSTM)               (80, 13, 32)              6400      
_________________________________________________________________
lstm_58 (LSTM)               (80, 6)                   936       
_________________________________________________________________
dense_32 (Dense)             (80, 6)                   42        
=================================================================
Total params: 7,378
Trainable params: 7,378
Non-trainable params: 0


Epoch 1/100
10000/10000 [==============================] - 6s 619us/sample - loss: 0.7441 - categorical_accuracy: 0.2898 - val_loss: 0.6181 - val_categorical_accuracy: 0.3388
Epoch 2/100
10000/10000 [==============================] - 2s 233us/sample - loss: 0.5768 - categorical_accuracy: 0.3388 - val_loss: 0.5382 - val_categorical_accuracy: 0.3388
Epoch 3/100
10000/10000 [==============================] - 2s 229us/sample - loss: 0.5039 - categorical_accuracy: 0.3979 - val_loss: 0.4640 - val_categorical_accuracy: 0.5084
Epoch 4/100
10000/10000 [==============================] - 2s 229us/sample - loss: 0.4207 - categorical_accuracy: 0.4759 - val_loss: 0.3709 - val_categorical_accuracy: 0.5041
</code></pre>

<p>My NN is converging towards 0.5 all the time.</p>

<p>Thank you in advance for your answers !</p>
","natural-language-processing"
"18098","Using word embedding to extend words for searching POI names","2020-02-18 13:10:24","","1","109","<natural-language-processing><word-embedding>","<p>I am developing my own mobile app related to digital map. One of the functions is searching POIs (points of interest) in the map according to relevance between user query and POI name.</p>

<p>Besides the POIs whose names contain exact words in the query, the app also needs to return those whose names are semantically related. For example, searching 'flower' should return POI names that contain 'flower' as well as those that contain 'florist'. Likewise, searching 'animal' should return 'animal' as well as 'veterinary'.</p>

<p>That said, I need to extend words in the query semantically. For example, 'flower' has to be extended to ['flower', 'florist']. I have tried to use word embeddings: using the words corresponding to most similar vectors as extensions. Due to the fact I don't have user review data right now and most of the POI names are very short, I used trained word2vec model published by <a href=""https://code.google.com/archive/p/word2vec/"" rel=""nofollow noreferrer"">Google</a>. But the results turn out to be not what I expect: most similar words of 'flower' given by word2vec are words like 'roses'and 'orchid', and 'florist' is not even in the top 100 most similar list. Likewise, 'animal' gives 'dog', 'pets', 'cats' etc. Not very useful for my use case.</p>

<p>I think simply using word embedding similarity may not be enough. I may need to build some advanced model based on word embedding. Do you have any suggestions?</p>
","natural-language-processing"
"18097","When is it time to switch to deep neural networks from simple networks in text classification problems?","2020-02-18 12:59:46","","3","96","<natural-language-processing><classification><text-classification>","<p>I did an out of domain detection task (as a binary classification problem) and tried LR and Naive Bayes and BERT but the deep neural network didn't perform better than LR and NB. For the LR I just used BOW and it beats the 12-layer BERT. </p>

<p>In a lecture, <a href=""https://www.youtube.com/watch?v=HfM8UIohGE0"" rel=""nofollow noreferrer"">Andrew Ng</a> suggests ""Build First System Quickly, Then Iterate"", but it turns out that sometimes we don't need to iterate the model into a deep neural network and most of the time traditional shallow neural networks are good/competitive enough and much simpler for training. </p>

<p>As <a href=""https://twitter.com/dirk_hovy/status/1222902471246278657"" rel=""nofollow noreferrer"">this tweet (and its replies)</a> indicate, together with various papers [<a href=""https://arxiv.org/pdf/1503.00693.pdf"" rel=""nofollow noreferrer"">1</a>, <a href=""https://www.aclweb.org/anthology/S18-1003.pdf"" rel=""nofollow noreferrer"">2</a>, <a href=""https://www.aclweb.org/anthology/S18-1004.pdf"" rel=""nofollow noreferrer"">3</a>, <a href=""https://paperswithcode.com/sota/sentiment-analysis-on-imdb"" rel=""nofollow noreferrer"">4</a> etc], traditional SVM, LR, and Naive Bayes can beat RNN and some complicated neural networks. </p>

<p>Then my two questions are: </p>

<ol>
<li><p>When should we switch to complicated neural networks like RNN, CNN, and transformer and etc? How can we see that from the data set or the results (by doing error analysis) of the simple neural networks?       </p></li>
<li><p>The aforementioned experiments may be caused by the simple test set, then (how) is it possible for us to design a test set that can fail the traditional models? </p></li>
</ol>
","natural-language-processing"
"18082","How to produce documents like factset blackline?","2020-02-18 02:01:57","","0","134","<natural-language-processing><recurrent-neural-networks>","<p>Factset blackline reports essentially can compare two <a href=""https://www.investopedia.com/terms/1/10q.asp"" rel=""nofollow noreferrer"">10-Q SEC filings</a> and show you the difference between the two documents. It highlights added items in green and removed items in red + strikethrough (essentially, it's a document difference, but longer-term I would like to run algorithms on the differences).</p>
<p>I don't care to change colors, but what I would like to do is to produce similar extracts that summarize addition and deletions.</p>
<p>Which AI/ML algorithm could do the same?</p>
","natural-language-processing"
"17946","Sign Language to Speech conversion","2020-02-10 11:19:09","","2","22","<neural-networks><natural-language-processing>","<p>Is there any solution about sign language to speech conversion for mobiles? Can anyone suggest me the flow and tools so that I may implement the solution for mobiles?</p>
","natural-language-processing"
"17930","Can we use GPT-2 to smooth out / correct text?","2020-02-09 10:01:44","","2","323","<neural-networks><natural-language-processing><gpt>","<p>Are we able to use models like GPT-2 to smooth out/correct text? For instance if I have two paragraphs that need some text to make the transition easier to read, could this text be generated? And, could it find inconsistencies between the paragraphs and fix them?</p>
<p>As an example, imagine we're reordering some text so that we can apply the <a href=""https://medium.com/lessons-from-mckinsey/the-pyramid-principle-f0885dd3c5c7"" rel=""nofollow noreferrer"">pyramid principle</a>. What I'd like to do is reorder the sentences/paragraphs and still have a coherant story. The following three sentences for instance, start with a statement and then have some facts to support it. What's missing is the story that joins them together, right now they're three independent sentences.</p>
<blockquote>
<p>The strawberry is the best fruit based on its flavor profile, its coloring and texture and the nutritional profile.</p>
<p>Strawberries are very rich in antioxidants and plant compounds, which may have benefits for heart health and blood sugar control.</p>
<p>Strawberries have a long history and have been enjoyed since the Roman times.</p>
</blockquote>
<p>Feel free to point me at things to read, I have not been able to find anything like this in my searches.</p>
","natural-language-processing"
"17913","Creating a noising model for NLP that models human noising","2020-02-07 21:42:32","","1","19","<natural-language-processing>","<p>I'm trying to create a noising model that accurately reflects how people would noise name data. I was thinking of randomly switching out characters and creating a probability over which character gets switched in based on keyboard closeness and how similar anatomically another character looks to it. For example, ""l"" has a higher prob of being switched in with ""|"" and ""k"" cause ""k"" is close by on the keyboard and ""|"" looks like ""l"", but that requires a lot of hard coding and reward for that seemed low because that's not the only 2 ways people can noise things. I also had the same idea above except use template matching of every character to every other character but itself and that would give it a similarity score then divide that by the sum over all chars to get the probs. Any other suggestions? My goal is the maximize closeness to actual human noising.</p>
","natural-language-processing"
"17763","How to tell if two hotel reviews addressing the same thing","2020-01-30 15:08:07","","2","24","<natural-language-processing><text-generation>","<p>I am playing with a large dataset of hotel reviews, which contains both positive and negative reviews (the reviews are labeled). I want to use this dataset to perform textual style transfer - given a positive review, output a negative review which address the same thing. For example, if the positive review mentioned how spacious the rooms are, I want the output to be a review that complains about the small and claustrophobic rooms.</p>

<p>However, I don't have positive review-negative review pairs for the training. I was thinking that maybe I could create those pairs myself, but I'm not sure what is the best way to do that. Simple heuristics like jaccard index and such didn't give the desired results. </p>
","natural-language-processing"
"17636","What is ""Computational Linguistics""?","2020-01-23 12:10:05","17725","5","333","<machine-learning><natural-language-processing><terminology>","<p>It's not clear to me whether or not someone whose work aims to <strong>improve an NLP system</strong> may be called a ""<em>Computational Linguist</em>"" even when she/he <strong>doesn't modify the algorithm directly</strong> by coding.</p>

<p>Let's consider the following activities:</p>

<p>Annotation for Machine Learning: 
analysis of Morphology, Syntax, POS tagging
Annotation, analysis, and annotation of entities (NER) and collocations; supporting content categorization; chunking; word sense disambiguation.
Recording of technical issues of the annotation tool to improve its reliability.
Recording of linguistic and logical particular rules adopted by the research team who develops the NLP algorithm to improve consistency between annotation and criteria previously adopted to train the NLP.</p>

<p>May be these activities considered ""Computational Linguistics""? If not, which is their professional category and how should they be included in the resume in a word which synthesizes them?</p>
","natural-language-processing"
"17576","Can Bert be used to extract embedding for large categorical features?","2020-01-19 00:25:42","","3","568","<neural-networks><machine-learning><deep-learning><natural-language-processing><bert>","<p>I've lot of training data points (i.e in millions) and I've around few features but the issue with that is all the features are categorical data with 1 million+ categories in each.</p>

<p>So, I couldn't use one hot encoding because it's not efficient so I went with the other option which is embedding of fixed length. I've just used neural nets to compute embedding.</p>

<p>My question is can we use advanced NLP models like bert to extract embeddings for categorical data from my corpus? Is it possible? I've only asked it because I've only heard that bert is good for sentence embeddings.</p>

<p>Thank you.</p>
","natural-language-processing"
"17474","How much knowledge of the world is learnt through words?","2020-01-13 05:27:30","","1","69","<natural-language-processing><semantics>","<p>We know a lot of common sense about the world. Things like ""to buy something you need money"".</p>

<p>I wonder how much of this common sense comes about through actual someone explicitly telling you the instructions ""You need money to buy things"". Which we store in our brains as a sort of rule. As opposed to just intutively understanding things and picking it up. </p>

<p>I am imagining children playing at shop-keeping and saying things like ""I give you this and you give me that"". And other children not quite understanding the concept of buying things until being told by a teacher.</p>

<p>If so, giving a computer a list of common sense rules likes these is no different to teaching a child. So I am wondering why this area of AI research (semantic webs etc.) has been frowned upon in the last decade in favour of trying to learn everything through experience like deep neural networks?</p>
","natural-language-processing"
"17466","Is Sanskrit still relevant for NLP/AI?","2020-01-12 11:13:16","","7","740","<natural-language-processing>","<p>I came across a news article from 2018 where the president of India was saying that Sanskrit is the best language for ML/AI. I have no idea regarding his qualification on either AI or Sanskrit to say this but this idea has been floated earlier in the context of NLP. Specifically, Rick Briggs <a href=""http://vedicsciences.net/articles/sanskrit-nasa.html"" rel=""noreferrer"">had said so</a> in 1985.</p>

<p>I know elementary Sanskrit and I know NLP. I can understand the point that as a strongly declined language Sanskrit is less ambiguous than say English as the position of words in a sentence are not important. Add to it the fact that words are also declined (that's not the technical term for verbs and I am not sure what is) so that verb gender and number help identify which entity they refer to.</p>

<p>However, that point was valid in 1985. My question is that post the Deep Learning revolution of the last couple of years is it still relevant? Especially given the fact that humans still have to first learn Sanskrit in case NLP is done in Sanskrit.</p>

<p>Of course, as can be guessed from the tone of the question, I am of the opinion that Sanskrit is not relevant for AI now but I wanted to know if someone who works in AI thinks otherwise and if so what is their reason so think so.</p>
","natural-language-processing"
"17439","Training an RNN to answer simple quesitons","2020-01-09 23:11:58","","4","67","<natural-language-processing><recurrent-neural-networks><long-short-term-memory>","<p>I would like to train an RNN to follow the sentences:</p>

<p>""Would you like some cheese""? with ""Yes, I would like some cheese.""</p>

<p>So whenever the template ""Would you like some ____?"" appears then RNN produces the sequence above. And it should even work on sentences which are new like ""Would you like some blumf?""</p>

<p>I have thought of various ways of doing this. Such as, as well as having 26 outputs for letters of the alphabet have about 20 more for ""repeat the character that is 14 characters to the left"" and so on.</p>

<p>Has this been done before or is there a better way?</p>
","natural-language-processing"
"17426","Extract product information from email receipt HTML","2020-01-09 07:33:04","","0","112","<neural-networks><natural-language-processing><feature-extraction>","<p>I am trying to extract product information from email receipts HTML.  Most services I have found focus on OCR from paper receipts or PDFs.  I would imagine that extraction of product information would be easier from structured HTML.  What type of AI approach would be used to support this?</p>
","natural-language-processing"
"17418","How can I extract the reason of the legal compensation from a court report?","2020-01-08 17:02:46","","2","40","<neural-networks><deep-learning><natural-language-processing>","<p>I'm working on a project (court-related). At a certain point, I have to extract the reason of the legal compensation. For instance, let's take these sentences (from a court report)</p>

<blockquote>
  <p>Order mister X to pay EUR 5000 for compensation for unpaid wages </p>
</blockquote>

<p>and</p>

<blockquote>
  <p>To cover damages, mister X must pay EUR 4000 to mister Y </p>
</blockquote>

<p>I want to make an algorithm that is able from this sentence to extract the motive of legal compensation. For the first sentence </p>

<blockquote>
  <p>Order mister X to pay EUR 5000 for compensation for unpaid wages </p>
</blockquote>

<p>the algorithm's output must be ""compensation for unpaid wages"" or ""compensation unpaid wages "". </p>

<p>For the second sentence, the algorithm's output must be ""cover damages"". Output can be a string or a list of string, it doesn't matter.</p>

<p>As I'm not an NLP expert (but I have already worked on a project on sentiment analysis, so I know some stuff about NLP), and there are so many articles, I don't know where to start.</p>

<p>I'm working on French texts, but I can get away with working on English texts.</p>
","natural-language-processing"
"17403","Does summing up word vectors destroy their meaning?","2020-01-07 15:32:09","","4","145","<deep-learning><natural-language-processing><word-embedding><text-classification><binary-classification>","<p>For example, I have a paragraph that I want to classify in a binary manner. But because the inputs have to have a fixed length, I need to ensure that every paragraph is represented by a uniform quantity.</p>
<p>One thing I've done is taken every word in the paragraph, vectorized it using GloVe word2vec, and then summed up all of the vectors to create a &quot;paragraph&quot; vector, which I've then fed in as an input for my model. In doing so, have I destroyed any meaning the words might have possessed?</p>
<p>Considering these two sentences would have the same vector:</p>
<blockquote>
<p>My dog bit Dave</p>
</blockquote>
<blockquote>
<p>Dave bit my dog</p>
</blockquote>
<p>How do I get around this? Am I approaching this wrong?</p>
<p>What other way can I train my model? If I take every word and feed that into my model, how do I know how many words I should take? How do I input these words? In the form of a 2D array, where each word vector is a column?</p>
<p>I want to be able to train a model that can classify text accurately.
Surprisingly, I'm getting a high (&gt;90%) for a relatively simple model like RandomForestClassifier just by using this summing up method. Any insights?</p>
","natural-language-processing"
"17394","Creating an AI than can learn to give instructions","2020-01-06 19:03:49","","3","185","<natural-language-processing><generative-model><geometric-deep-learning>","<p>So we think a computer is dumb because it can only follow instructions. Therefor I am trying to create an AI that can <em>give</em> instructions.</p>

<p>The idea is this: Create a geometric scene (A) then make a change in scene such as turning a square red or moving a circle right one unit. This becomes the new scene B. Then the computer compares the scenes A and B and it's goal is to give the shortest possible instruction that will change scene A to scene B. Examples might be:</p>

<pre><code>""Turn the green square red"".
</code></pre>

<p>or</p>

<pre><code>""Move the yellow square down"".
</code></pre>

<p>Or when we get more advanced we might have:</p>

<pre><code>""Move the green square below the leftmost purple square down.""
</code></pre>

<p>Equally, this task could be seen as finding a description of the change. e.g. ""The green square has turned red"".</p>

<p>The way it would work is that there'd be a simplified English parser, and the computer would generate a number of phrases and check whether these achieved the desired result.</p>

<p>I would probably give it some prior knowledge of things like colours, shape-names, and so on. Or it could learn these by example.</p>

<p>Eventally I would hope it to generate more complicated loop type expressions such as ""Move the square left <strong>until</strong> it reaches the purple circle."" And these would essentially be little algorithms the AI has generated in words.</p>

<p>I've got some ideas how to do this. But do you know any similar projects that I could look at? If you were implementing this, how would you go about it?</p>

<p>[In other words we have an English parser that is interpreted to change a scene A into a scene B. But we want the AI to learn, given scenes A and B, how to generate instructions.]</p>
","natural-language-processing"
"17352","Is there any classifier that works best in general for NLP based projects?","2020-01-03 16:51:50","","4","108","<machine-learning><deep-learning><natural-language-processing><classification><text-classification>","<p>I've written a program to analyse a given piece of text from a website and make conclusary classifications as to its validity. The code basically vectorizes the description (taken from the HTML of a given webpage in real time) and takes in a few inputs from that as features to make its decisions. There are some more features like the domain of the website and some keywords I've explicitly counted.</p>

<p>The highest accuracy I've been able to achieve is with a RandomForestClassifier, (>90%). I'm not sure what I can do to make this accuracy better except incorporating a more sophisticated model. I tried using an MLP but for no set of hyperparameters does it seem to exceed the previous accuracy. I have around 2000 datapoints available for training.</p>

<p>Is there any classifier that works best for such projects? Does anyone have any suggestions as to how I can bring about improvements? (If anything needs to be elaborated, I'll do so.)</p>

<p>Any suggestions on how I can improve on this project in general? Should I include the text on a webpage as well? How should I do so? I tried going through a few sites, but the next doesn't seem to be contained in any specific element whereas the description is easy to obtain from the HTML. Any help?</p>

<p>What else can I take as features? If anyone could suggest any creative ideas, I'd really appreciate it.</p>
","natural-language-processing"
"17333","How to use AI for language recognition?","2020-01-02 16:08:58","","2","522","<machine-learning><natural-language-processing><audio-processing><speech-recognition>","<p>Given an audio track, I'm trying to find a way to recognize the audio language. Only within a small set (e.g. English vs Spanish). Is there a simple solution to detect the language in a speech?</p>
","natural-language-processing"
"17332","Is NLP likely to be sufficiently solved in the next few years?","2020-01-02 15:09:29","","2","108","<natural-language-processing>","<p>The reason I am asking this question is because I am about to start a PhD in NLP. So I am wondering if there would be as much job opportunities in research in industry as oppose to in academia in the future (~ 5 to 10 years) or would it be mostly a matter of using a library off the shelf. I have done some research and it seems NLP is AI-complete, which means it's probably a problem that will be ""solved"" only when AGI is solved , but still I would appreciate any input.</p>
","natural-language-processing"
"17331","What role do distractors play in natural language processing?","2020-01-02 13:27:14","","2","47","<natural-language-processing><terminology>","<p>I’m doing research on natural language processing (NLP). I’d like to put together my own model. However, I'm running into a concept I am not familiar with, namely, distractors. A google search does not reveal much.</p>

<p>I've been reading this article specifically: <a href=""https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313"" rel=""nofollow noreferrer"">https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313</a></p>

<p>In the section under ""Multi-Tasks Losses"" it reads:</p>

<blockquote>
  <p>Next-sentence prediction: we pass the hidden-state of the last token
  (the end-of-sequence token) through a linear layer to get a score and
  apply a cross-entropy loss to classify correctly a gold answer among
  distractors.</p>
</blockquote>

<p>I understand how transformers and coss-entropy works, however I'm not sure what a distractor or a ""gold answer"" is for that matter. </p>

<p>In this context, what does the author mean by distractor?</p>
","natural-language-processing"
"17176","How would an AI learn the concept of the words ""repeat twice""?","2019-12-20 03:43:15","","1","142","<machine-learning><natural-language-processing><learning-algorithms><human-computer-interaction>","<p>In a hypothetical conversation:</p>

<pre><code>Person A - ""Repeat the word 'cat' twice"".
Person B - ""cat cat"".
</code></pre>

<p>I'm thinking about how a human or AI can learn the concept of ""repeat twice"". In reinforcment learning it would require that after the first sentence the AI would go through every random sentence until it got it right and hence got a reward. </p>

<p>Another way might be the AI or human overhearing the conversation. Then on hearing a repetition or a word it may trigger some neurons in the brain related to detecting repetition. Thus by pavlovian learning associate the word ""repeat"" or ""twice"" with these neurons. When given the stimulus of the word ""repeat"" these neurons may get triggered making the brain do some repetition algorithm. (This is my favorite theory).</p>

<p>I suppose a third way might be as follows:</p>

<pre><code>Person A - ""Hello! Hello!""
Person B - ""Stop repeating yourself"".
</code></pre>

<p>It might learn to associate repeating with the word ""repeating"" in this way. </p>

<p>I think either way the brain must have some neurons dedicated to detecting repetitions and possibly inacting them. (I don't think any standard RNN has this capability).</p>

<p>What do you think is the most likely way?</p>
","natural-language-processing"
"17132","Giving an AI a purpose to talk","2019-12-16 18:41:13","","2","71","<natural-language-processing><algorithm><generative-model>","<p>I am trying to teach my AI to talk. The problem is I'm struggling to find a good scenario in which it needs to.</p>

<p>Some ideas I had were:
""Describe a geometric scene"" - Then together with a parser we could see how close the generated instructions came to the official geometric language.</p>

<p>""Give another AI instructions of where to find some food"" e.g. ""Go straight on passed the box then turn left until you get to the tree. Look under the rock.""</p>

<p>Another one might be ""Find out more information about a scene by asking questions of another AI in order to navigate a scene blindfolded"". This is quite an extreme example!</p>

<p>I need it to talk in formal English sentences (not some kind of made up secret langauge.) </p>

<p>Basically instead of just interpreting a language and following instructions, I want my AI to generate instructions.</p>

<p>So the things I want to teach it are the following:</p>

<ul>
<li>Ability to ask questions + ability to use the information gathered</li>
<li>Ability to give instructions</li>
</ul>

<p>Do you know of any projects like this?</p>
","natural-language-processing"
"17130","Are there any approaches other than deep learning to deal with unexpected questions in a question answering system?","2019-12-16 17:23:42","","2","49","<deep-learning><natural-language-processing><chat-bots><question-answering>","<p>I'm working on a question answering bot as my graduation project. The main concept is having a text file with many sentences, and building a question answering bot which answers a user's question based on the text file in hand.</p>
<p>Until now, I used <a href=""https://en.wikipedia.org/wiki/Tf%E2%80%93idf"" rel=""nofollow noreferrer"">tf-idf</a> and <a href=""https://en.wikipedia.org/wiki/Cosine_similarity"" rel=""nofollow noreferrer"">cosine similarity</a> and the results are somewhat satisfactory. The main problem is, if the user was to ask a question that doesn't have a word that is in the text file, my bot can't deduce what to bring back as an answer. For example, if I have a sentence in my text file that says &quot;I have a headache because my heart rate is low&quot;, if the user was to ask &quot;Why do you have a headache?&quot;, my bot chooses the correct sentence, but if he asked &quot;What's wrong with you?&quot; my bot doesn't know what to do.</p>
<p>All I've seen on the web until now are deep learning methods and neural networks, such as LSTM and such. I was wondering if there are any <strong>pure NLP</strong> approaches to go with my requirements.</p>
","natural-language-processing"
"17102","How to use BERT as a multi-purpose conversational AI?","2019-12-14 13:55:05","","7","1355","<natural-language-processing><classification><bert><language-model>","<p>I'm looking to make an NLP model that can achieve a dual purpose. One purpose is that it can hold interesting conversations (conversational AI), and another being that it can do <em>intent classification</em> and even accomplish the classified task. </p>

<p>To accomplish this, would I need to use multimodal machine learning, where you combine the signal from two models into one? Or can it be done with a single model?</p>

<p>In my internet searches, I found <a href=""https://github.com/google-research/bert"" rel=""nofollow noreferrer"">BERT</a>, developed by Google engineers (although apparently not a Google product), which is an NLP model trained in an unsupervised fashion on 3.3 billion words or more and seems very capable. </p>

<p>How can I leverage BERT to make my own conversational AI that can also carry out tasks? Is it as simple as copying the weights from BERT to your own model?</p>

<p>Any guidance is appreciated.</p>
","natural-language-processing"
"17061","Can a character-level Seq2Seq setup learn to perfectly reconstruct structured data like name strings?","2019-12-12 07:21:09","","1","39","<natural-language-processing><recurrent-neural-networks><sequence-modeling>","<p>If not perfect, how well can they do? For example, if I give the Seq2Seq setup a name it did not see in the training process, can it output the same name without error?</p>

<p>Example</p>



<pre><code>name = ""Will Smith""
output = DecoderRNN(EncoderRNN(name))
can_this_be_true = name == output
</code></pre>
","natural-language-processing"
"17031","How does a transformer leverage the GPU to be trained faster than RNNs?","2019-12-10 22:05:26","","4","862","<natural-language-processing><training><transformer><attention><gpu>","<p>How does a transformer leverage the GPU to be trained faster than RNNs?</p>
<p>I understand the parameter space of the transformer might be significantly larger than that of the RNN. But why does the transformer structure can leverage multiple GPUs, and why does that accelerate its training?</p>
","natural-language-processing"
"16996","What is the most accurate pretrained sentiment analysis model by 2019?","2019-12-09 04:49:08","","1","4113","<natural-language-processing><sentiment-analysis><text-classification>","<p>I've been using OpenAI's 2017 Sentiment Neuron implementation (<a href=""https://github.com/openai/generating-reviews-discovering-sentiment"" rel=""nofollow noreferrer"">https://github.com/openai/generating-reviews-discovering-sentiment</a>) for a while, because it was easy to set up and was the most accurate on benchmarks. What is the most accurate alternative now that I should use?</p>
","natural-language-processing"
"16978","Need examples for the following definitions","2019-12-07 18:03:11","","0","64","<machine-learning><natural-language-processing>","<p>I am currently reading the paper ""Similarity of Narratives"" by Loizos Michael (link below) and I am having a hard time figuring out the definitions listed (p.107 - p.109).</p>

<p>Could someone please give me a practical example for each of the definitions?</p>

<p>Article: <a href=""http://narrative.csail.mit.edu/cmn12/proceedings.pdf"" rel=""nofollow noreferrer"">http://narrative.csail.mit.edu/cmn12/proceedings.pdf</a> </p>
","natural-language-processing"
"16959","How to detect any native language when written in Latin characters?","2019-12-06 05:12:48","","1","356","<machine-learning><deep-learning><natural-language-processing>","<p>Assume somebody knows only to write in Latin characters. If they write words of any other language (example: Hindi, French, Latin)  using the Latin alphabet, how can I detect that language?</p>

<p>Example: If they write Hindi language word using the Latin alphabet) </p>

<blockquote>
  <blockquote>
    <p>kya kar raha hai</p>
  </blockquote>
</blockquote>

<pre><code>     &gt;&gt; the output is Hindi language
</code></pre>
","natural-language-processing"
"16899","What are the current big challenges in natural language processing and understanding?","2019-12-02 20:01:38","","8","1438","<natural-language-processing><natural-language-understanding>","<p>I'm doing a paper for a class on the topic of big problems that are still prevalent in AI, specifically in the area of natural language processing and understanding. From what I understand, the areas:</p>

<ul>
<li>Text classification</li>
<li>Entity recognition </li>
<li>Translation</li>
<li>POS tagging</li>
</ul>

<p>are for the most part solved or perform at a high level currently, but areas such as:</p>

<ul>
<li>Text summarization</li>
<li>Conversational systems</li>
<li>Contextual systems (relying on the previous context that will impact current prediction)</li>
</ul>

<p>are still relatively unsolved or are a big area of research (although this could very well change soon with the releases of big transformer models from what I've read).</p>

<p>For people who have experience in the field, what are areas that are still big challenges in NLP and NLU? Why are these areas (doesn't have to be ones I've listed) so tough to figure out?</p>
","natural-language-processing"
"16814","How can I feed any word into a neural network?","2019-11-27 12:38:50","","2","78","<neural-networks><natural-language-processing><word-embedding>","<p>I am working on an Intent detection problem for a chatbot in Java.
So I need to convert words from String to a double[] format.
I tried using wordToVec(deeplearning4j), but it does not return a vector for words not present in the training data.</p>

<p>e.g. My dataset for wordToVec.train() does not contain the word ""morning"". So wordToVec.getWordVector(""morning"") returns a null value.</p>

<p>There is no need to find the coorelation between two words(like in word2vec), but it should be able to give me some sort of vector representation for any word.</p>

<p>Here are some things I thought of-</p>

<ol>
<li>I could use a fixed length hash function and convert resulatant hash into vector.(Will Hash Collision be strong enough to be an issue in this case?)</li>
<li>I could initialize for each word a vector of huge length as zero, and set its elements as the ASCII value-64.
e.g. Keeping Maximum vector length as 10, AND would be represented as-
[1,14,4,0,0,0,0,0,0,0], and normalize this.
Is there a better solution to this problem?</li>
</ol>

<p>Here is the code I used to train the model-</p>



<pre><code>public static void trainModel() throws IOException
    {
        //These lines simply generate the dataset into a format readable by wordToVec
        utilities.GenRawSentences.genRaw();

        dataLocalPath = ""./TrainingData/"";
        String filePath = new File(dataLocalPath, ""raw_sentences.txt"").getAbsolutePath();
        //Data Generation ends   

        SentenceIterator iter = new BasicLineIterator(filePath);
        TokenizerFactory t = new DefaultTokenizerFactory();
        t.setTokenPreProcessor(new CommonPreprocessor());

        VocabCache&lt;VocabWord&gt; cache = new AbstractCache&lt;&gt;();
        WeightLookupTable&lt;VocabWord&gt; table = new InMemoryLookupTable.Builder&lt;VocabWord&gt;()
                .vectorLength(64)
                .useAdaGrad(false)
                .cache(cache).build();

        Word2Vec vec = new Word2Vec.Builder()
                .minWordFrequency(1)
                .iterations(5)
                .epochs(1)
                .layerSize(64)
                .seed(42)
                .windowSize(5)
                .iterate(iter)
                .tokenizerFactory(t)
                .lookupTable(table)
                .vocabCache(cache)
                .build();

        vec.fit();

        //Saves the model for use in other programs
        WordVectorSerializer.writeWord2VecModel(vec, ""./Models/WordToVecModel.txt"");

</code></pre>
","natural-language-processing"
"16674","NLP annotation tool online and other tools to compare performances of different NLP algorithms","2019-11-20 19:21:18","","2","42","<natural-language-processing><chat-bots><benchmarks>","<p>I do text annotations (POS tagging, NER, chunking, synset) by using a specific annotation tool for Natural Language Processing. I would like to make the same annotations on different tools to compare the performances of both.</p>

<p>Furthermore, for I found several logical and linguistic errors in the way the algorithm was previously trained, I would like to measure the way such anomalies affect the intelligence of the chatbot (that's to say its ability to understand questions and answers made by the customers as regard to sentences which have been structured in a certain way), by comparing results with those performed by other NLP engines.
In other terms, I would like to collect some ""benchmark"" to have an idea of which level the NLP algorithm developed by the company I work with works at.</p>

<p>Is there any tool (open source annotation tools based on other NLP algorithms, tools to collect benchmark, etc.) which might help me to perform such a task? </p>
","natural-language-processing"
"16553","Why embedding layer is used in the character-level Natural Language Processing models","2019-11-16 10:36:31","","3","39","<natural-language-processing><word-embedding>","<p><strong>Problem Background</strong></p>

<p>I am working with a problem, which requires a character-level, deep learning model. Previously I was working with word-level deep NLP (Natural Language Processing) models, and in these models almost always embedding encoding was used to represent given word in a lower-dimensional vector form. Furthermore, such embedding encoding allowed for putting similar words near themselves in the new lower-dimensional vector representation (i.e. man and woman vectors were near themselves in the vector space) which improved learning. Nevertheless, I often see that people use embedding encoding in character level NLP models. Even if the character-level one-hot encoding vectors are quite small in comparison to word-level one-hot encoding vectors (about 36 to 32k rows). Furthermore, there is no much correlation between characters, there is no something like ""similar characters"" in comparison to similar words, therefore some characters in comparison to other shouldn't be put near themselves. </p>

<p><strong>Question</strong>
Why embedding encoding is used in the character-level NLP models?</p>
","natural-language-processing"
"16516","Is the Mask Needed for Masked Self-Attention During Inference with GPT-2","2019-11-14 11:41:12","","6","2893","<natural-language-processing><attention><transformer><gpt><inference>","<p>My understanding is that masked self-attention is necessary during training of GPT-2, as otherwise it would be able to directly see the correct next output at each iteration. My question is whether the attention mask is necessary, or even possible, during inference. As GPT-2 will only be producing one token at a time, it doesn't make sense to mask out future tokens that haven't been inferred yet.</p>
","natural-language-processing"
"16380","Is there a detailed description or implementation of an end-to-end speech recognition system?","2019-11-09 18:51:26","","2","32","<neural-networks><natural-language-processing><research><reference-request><speech-recognition>","<p>I am currently trying to implement an <em>end-to-end speech recognition</em> system from scratch, that is, without using any of the existing frameworks (like TensorFlow, Keras, etc.). I am building my own library, where I am trying to do a polynomial approximation of functions (like exponential, log, sigmoid, ReLU, etc). I would like to have access to a nice description of the neural networks involved in an end-to-end speech recognition system, where the architecture (the layers, activation functions, etc.) is clearly laid out, so that I can implement it.</p>

<p>I find most of the academic or industry papers citing various previous works, toolkits or papers, making it tedious for me. I am new to the field, so I am having more difficulty, so looking for some help here. </p>
","natural-language-processing"
"16364","Deep audio fingerprinting for word search","2019-11-08 17:50:47","","1","91","<machine-learning><deep-learning><natural-language-processing><voice-recognition><audio-processing>","<p>Simply speaking, I'm trying to somehow search an audio clip for a list of words, and if found, I mark the time stamps. My use-case is profanity check with a list of pre-defined profane words.</p>

<p>Is there any successfull approaches, samples, tools or APIs, possibly through deep learning, to perform this? I'm new to audio processing.</p>
","natural-language-processing"
"16353","Are embeddings in multi-lingual language models comparable across languages?","2019-11-08 09:39:43","","4","352","<deep-learning><natural-language-processing><transformer><language-model>","<p>Facebook has <a href=""https://arxiv.org/pdf/1911.02116.pdf"" rel=""nofollow noreferrer"">just pushed out</a> a bigger version of their multi-lingual language model XLM, called XLM-R. My question is: do these kind of multi-lingual models imply, or even ensure, that their embeddings are comparable between languages? That is, are semantically related words close together in the vector space across languages?</p>

<p>Perhaps the most interesting citation from the paper that is relevant to my question (p. 3):</p>

<blockquote>
  <p>Unlike Lample and Conneau (2019), we do not use language embeddings,
  which allows our model to better deal with code-switching.</p>
</blockquote>

<p>Because they do not seem to make a distinction between languages, and there's just one vocabulary for all trained data, I fail to see how this can be truly representative of semantics anymore. The move away from semantics is increased further by the use of BPE, since morphological features (or just plain, statistical <em>word chunks</em>) of one language might often not be semantically related to the same chunk in another language - this can be true for tokens themselves, but especially so for subword information.</p>

<p>So, in short: how well can the embeddings in multi-lingual language models be used for semantically comparing input (e.g. a word or sentence) of two different languages?</p>
","natural-language-processing"
"16346","What happens when the output length in the brevity penalty is zero?","2019-11-08 02:22:40","16359","2","228","<natural-language-processing><machine-translation><bleu>","<p>The brevity penalty is defined as</p>

<p><span class=""math-container"">$$bp = e^{(1- r/c)},$$</span></p>

<p>where <span class=""math-container"">$r$</span> is the reference length and <span class=""math-container"">$c$</span> is the output length.</p>

<p>But what happens if the output length gets zero? Is there any standard way of coping with that issue?</p>
","natural-language-processing"
"16328","How do you build a language model to predict the contextual similarity between two documents?","2019-11-07 07:28:37","","2","88","<natural-language-processing><language-model>","<p>How do you build a language model to predict the contextual similarity between two documents?</p>
","natural-language-processing"
"16191","How to use TPU for real-time low-latency inference?","2019-11-01 01:08:15","","3","469","<natural-language-processing><tensorflow><transformer><google><inference>","<p>I use Google's Cloud TPU hardware extensively using Tensorflow for training models and inference, however, when I run inference I do it in large batches. The TPU takes about 3 minutes to warm up before it runs the inference. But when I read the <a href=""https://cloud.google.com/tpu/docs/faq"" rel=""nofollow noreferrer"">official TPU FAQ</a>, it says that we can do real-time inference using TPU. It says the latency is 10ms which for me is fast enough but I cannot figure out how to write code that does this, since every time I want to pass something for inference I have to start the TPU again.</p>

<p>My goal is to run large Transformer-based Language Models in real-time on TPUs. I guessed that TPUs would be ideal for this problem. Even Google seems to <a href=""https://www.blog.google/products/search/search-language-understanding-bert/"" rel=""nofollow noreferrer"">already do this</a>.</p>

<p>Quote from the <a href=""https://cloud.google.com/tpu/docs/faq"" rel=""nofollow noreferrer"">official TPU FAQ</a>:</p>

<blockquote>
  <p>Executing inference on a single batch of input and waiting for the
  result currently has an overhead of at least 10 ms, which can be
  problematic for low-latency serving.</p>
</blockquote>
","natural-language-processing"
"16076","How to Extract Information from the Image","2019-10-25 11:55:48","","2","541","<machine-learning><deep-learning><natural-language-processing><python><image-processing>","<p>I'm trying to extract some particular information from the image(png).</p>

<p>I tried to extract the text using the below code</p>

<pre><code>import cv2
import pytesseract
import os
from PIL import Image
import sys

def get_string(img_path):
    # Read image with opencv
    img = cv2.imread(img_path)

    # Convert to gray
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Apply dilation and erosion to remove some noise
    kernel = np.ones((1, 1), np.uint8)
    img = cv2.dilate(img, kernel, iterations=1)
    img = cv2.erode(img, kernel, iterations=1)

    # Write the image after apply opencv to do some ...
    cv2.imwrite(""thres.png"", img)
    # Recognize text with tesseract for python
    result = pytesseract.image_to_string(Image.open(""invoice.png""))
    os.remove(""invoice.png"")

    return result

if __name__ == '__main__':
    from sys import argv

    if len(argv)&lt;2:
        print(""Usage: python image-to-text.py relative-filepath"")
    else:
        print('--- Start recognize text from image ---')
        for i in range(1,len(argv)):
            print(argv[i])
            print(get_string(argv[i]))
            print()
            print()

        print('------ Done -------')
</code></pre>

<p>But I want to extract data from particular fields.</p>

<p>Such as</p>

<blockquote>
<pre><code> a) INVOICE NO.
 b) CUSTOMER NO.
 c) SUBTOTAL
 d) TOTAL
 e) DATE
</code></pre>
</blockquote>

<p><strong>How can I extract the required information from the below image ""invoice""?</strong></p>

<p>PFB</p>

<p><a href=""https://i.sstatic.net/RarrU.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/RarrU.png"" alt=""enter image description here""></a></p>
","natural-language-processing"
"16033","Is there a tool to convert from the brat standoff format to CoNLL-U format?","2019-10-22 15:08:58","","1","1338","<natural-language-processing><resource-request>","<p>I've been searching for a tool to convert from the <a href=""https://brat.nlplab.org/standoff.html"" rel=""nofollow noreferrer"">brat standoff format</a> to the <a href=""https://universaldependencies.org/format.html"" rel=""nofollow noreferrer"">CoNLL-U format</a>, so that to use it as a parsing corpus model to the <a href=""https://spacy.io"" rel=""nofollow noreferrer"">spaCy</a> library.</p>
<p>Can you help me?</p>
","natural-language-processing"
"16006","What is the underlying model of IBM Watson Assistant and Microsoft LUIS?","2019-10-21 16:25:22","","2","68","<machine-learning><deep-learning><natural-language-processing><chat-bots>","<p>As I stated in my question, I would like to know the underlying pipeline and machine learning models that are used to classify intents and identify entities in IBM Watson Assistant and Microsoft LUIS services.</p>

<p>I searched on different websites and the documentations of those services, but I did not find anything. However, there are some blogs mentioned that IBM Watson is trained using one billion words from Wikipedia but there is no reference to support that claim.</p>

<p>I highly appreciate if anyone could refer me to a doc/blog that answers my question.</p>

<p>Thanks in advance :)</p>
","natural-language-processing"
"15965","Is it possible to use the GPT-2 model for time-series data prediction?","2019-10-18 15:16:44","","1","2079","<natural-language-processing><prediction><time-series><gpt>","<p>Is it possible and how trivial (or not) might it be (if possible) to retrain GPT-2 on time-series data instead of text?</p>
","natural-language-processing"
"15951","How can neural networks be used to generate rather than classify?","2019-10-17 16:19:22","15963","2","155","<neural-networks><deep-learning><natural-language-processing><recurrent-neural-networks>","<p>In my experience with Neural Nets, I have only used them to take input vectors and return binary output.</p>

<p>But, here in a video, <a href=""https://youtu.be/ajGgd9Ld-Wc?t=214"" rel=""nofollow noreferrer"">https://youtu.be/ajGgd9Ld-Wc?t=214</a>, Kai Fu Lee, renowned AI Expert shows a deep net which takes thousands of samples of Trump's speeches and <strong>generates output in the Chinese Language.</strong></p>

<p>In short, how can deep nets/neural nets be used to <strong>generate</strong> output rather than giving answer <strong>yes or no</strong>? Additionally, how are these nets being trained? Can anyone here provide me a simple design to nets that are capable of doing that?</p>
","natural-language-processing"
"15914","Finetuning GPT-2 twice for particular style of writing on a particular topic","2019-10-15 07:14:42","","1","91","<natural-language-processing><training>","<p>Sorry if this is a stupid question. I'm just starting out in ML and am working with gpt-2 for text generation.</p>

<p>My situation is that I have to generate text in a particular field for eg. family businesses, which pretrained gpt-2 is unlikely to have much ""training"" with. Besides the topic, I also need to generate the text in the style of one particular writer (for eg. incorporating their turns of phrase etc) This particular writer hasn't written much about the family business topic unfortunately, but has written about other topics.</p>

<p>It occurred to me that I can take gpt-2, finetune it on a large corpus of material on family businesses, and then finetune the new model on the written material of the particular writer.</p>

<p>Would this be the right way to achieve my objective of creating content on family businesses in the style of this particular writer?</p>

<p>Any suggestions on what sort of stuff I should keep in mind while doing this?</p>

<p>Any help is much appreciated.</p>
","natural-language-processing"
"15882","Why hasn't deep learning been used for word level alignment?","2019-10-12 17:12:37","","1","26","<deep-learning><natural-language-processing>","<p>I've been exploring word-level alignments tools such as MGIZA and it seems to me that there hasn't been any new tool for this problem. Are neural networks not suitable to solve this problem or simply no interest in the area to build new tools?</p>
","natural-language-processing"
"15711","Does it matter if it's a bot or a human generating text? Doesn't it come down to the content?","2019-10-04 01:50:09","","1","49","<natural-language-processing><philosophy><semantics>","<p>It was noted today that automated text generation is advancing at a rapid pace, potentially accelerating.</p>

<p>As bots become more and more capable of passing turing tests, especially in single iterations, such as social media posts or news blurbs, I have to ask: </p>

<ul>
<li>Does it matter where a text originates, if the content is strong?</li>
</ul>

<p>Strength here is used in the sense of meaning.  To elucidate my argument I'll present an example.  (It helps to know the <a href=""https://en.wikipedia.org/wiki/The_Library_of_Babel"" rel=""nofollow noreferrer"">Library of Babel</a>, an infinite memory array where every possible combination of characters exists.)</p>

<blockquote>
  <p>An algorithm is set up to produce <a href=""https://en.wikipedia.org/wiki/Aphorism"" rel=""nofollow noreferrer"">aphorisms</a>. The overwhelming majority of the output is gibberish, but among the junk is an incredibly profound observation emerges that changes the way people think about a subject or issue.</p>
</blockquote>

<p>Where the bot just spams social media, the aphorism in question is identified because it recieves a high number of reposts by humans, who, in this scenario, provide the mechanism for finding the needle (the profound aphorism) in the haystack (the junk output).</p>

<p>Does the value of the insight depend on the cognitive quality of the generator, in the sense of having to understand the statement?</p>

<p>A real world example would be <a href=""https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol#Game_2"" rel=""nofollow noreferrer"">Game 2, Move 37</a> in the AlphaGo vs. Lee Sedol match.</p>
","natural-language-processing"
"15707","How to train a transformer text-to-text model on counterexamples?","2019-10-03 16:14:22","","2","29","<neural-networks><natural-language-processing><generative-adversarial-networks><transformer>","<p>Is it possible to update the weights of a vanilla transformer model using counterexamples alongside examples?</p>

<p>For example, from the <a href=""https://github.com/google-research-datasets/paws"" rel=""nofollow noreferrer"">PAWS</a> data set, given the phrases ""Although interchangeable, the body pieces on the 2 cars are not similar."" and ""Although similar, the body parts are not interchangeable on the 2 cars."" we have the label 0 because it is a counterexample, whereas for the phrases ""Katz was born in Sweden in 1947 and moved to New York City at the age of 1."" and ""Katz was born in 1947 in Sweden and moved to New York at the age of one."" we have the label 1 because it is a positive example of a valid paraphrase.</p>

<p>My goal is to use the transformer model to generate paraphrases, and I am attempting to build a GAN but could not find any references for updating the transformer text-to-text model using counterexamples.</p>
","natural-language-processing"
"15676","Why is embedding important in NLP, and how does autoencoder work?","2019-10-01 02:59:58","15689","1","417","<deep-learning><natural-language-processing><tensorflow><word-embedding><hidden-layers>","<p>People say <strong>embedding</strong> is necessary in NLP because if using just the word indices, the <strong>efficiency is not high</strong> as <strong>similar words are supposed to be related to each other</strong>. However, I still don't truly get it why.</p>

<p>The <strong>subword-based embedding</strong> (aka syllable-based embedding) is understandable, for example:</p>

<pre><code>biology   --&gt; bio-lo-gy
biologist --&gt; bio-lo-gist
</code></pre>

<p>For the 2 words above, when turning them into syllable-based embeddings, it's good because the 2 words will be related to each other due to the sharing syllables: <code>bio</code>, and <code>lo</code>.</p>

<p>However, it's hard to understand the <code>autoencoder</code>, it turns an index value into vector, then feed these vectors to DNN. Autoencoder can turn vectors back to words too.</p>

<p><strong>How does autoencoder make words related to each other?</strong></p>
","natural-language-processing"
"15562","How to change this RNN text classification code to become text generation code?","2019-09-20 15:57:15","15602","0","47","<natural-language-processing><classification><tensorflow><recurrent-neural-networks><generative-model>","<p>I can do text classification with RNN, in which the last output of RNN (rnn_outputs[-1]) is used to matmul with output layer weight and plus bias. That is getting a word (class name) after the last T in the time dimension of RNN.</p>

<p>The matter is for text generation, I need <strong>a word somewhere in the middle of time dimension</strong>, eg.:</p>

<pre><code>t0  t1    t2  t3
The brown fox jumps
</code></pre>

<p>For this example, I have the first 2 words: <code>The</code>, <code>brown</code>.</p>

<p>How to get the next word ie. ""<code>fox</code>"" using RNN (LSTM)? How to convert the following text classification code to text generating code?</p>

<p>Source code (text classification):</p>

<pre><code>import tensorflow as tf;
tf.reset_default_graph();

#data
'''
t0      t1      t2
british gray    is =&gt; cat (y=0)
0       1       2
white   samoyed is =&gt; dog (y=1)
3       4       2 
'''
Bsize = 2;
Times = 3;
Max_X = 4;
Max_Y = 1;

X = [[[0],[1],[2]], [[3],[4],[2]]];
Y = [[0],           [1]          ];

#normalise
for I in range(len(X)):
  for J in range(len(X[I])):
    X[I][J][0] /= Max_X;

for I in range(len(Y)):
  Y[I][0] /= Max_Y;

#model
Inputs   = tf.placeholder(tf.float32, [Bsize,Times,1]);
Expected = tf.placeholder(tf.float32, [Bsize,      1]);

#single LSTM layer
#'''
Layer1   = tf.keras.layers.LSTM(20);
Hidden1  = Layer1(Inputs);
#'''

#multi LSTM layers
'''
Layers = tf.keras.layers.RNN([
  tf.keras.layers.LSTMCell(30), #hidden 1
  tf.keras.layers.LSTMCell(20)  #hidden 2
]);
Hidden2 = Layers(Inputs);
'''

Weight3  = tf.Variable(tf.random_uniform([20,1], -1,1));
Bias3    = tf.Variable(tf.random_uniform([   1], -1,1));
Output   = tf.sigmoid(tf.matmul(Hidden1,Weight3) + Bias3);

Loss     = tf.reduce_sum(tf.square(Expected-Output));
Optim    = tf.train.GradientDescentOptimizer(1e-1);
Training = Optim.minimize(Loss);

#train
Sess = tf.Session();
Init = tf.global_variables_initializer();
Sess.run(Init);

Feed = {Inputs:X, Expected:Y};
for I in range(1000): #number of feeds, 1 feed = 1 batch
  if I%100==0: 
    Lossvalue = Sess.run(Loss,Feed);
    print(""Loss:"",Lossvalue);
  #end if

  Sess.run(Training,Feed);
#end for

Lastloss = Sess.run(Loss,Feed);
print(""Loss:"",Lastloss,""(Last)"");

#eval
Results = Sess.run(Output,Feed);
print(""\nEval:"");
print(Results);

print(""\nDone."");
#eof
</code></pre>
","natural-language-processing"
"15504","What is the best way to find the similarities between two text documents?","2019-09-18 11:23:55","","4","509","<natural-language-processing><classification><recommender-system>","<p>I would like to develop a platform in which people will write text and upload images. I am going to use Google API to classify the text and extract from the image all kinds of metadata. In the end, I am going to have a lot of text which describes the content (text and images). Later, I would like to show my users related posts (that is, similar posts, from the content point of view).</p>

<p>What is the most ppropriate way of doing this? I am not an AI expert and the best approach from my prescriptive it to have some tools, like google API or Apache Lucene search engine, which can hide the details of how this is done.</p>
","natural-language-processing"
"15501","What is the State-of-the-Art open source Voice Cloning tool right now?","2019-09-18 09:04:56","","2","409","<natural-language-processing><speech-synthesis>","<p>I would like to clone a voice as precisely as possible. Lately, impressive models have been released that only need about 10 s of voice input (cf. <a href=""https://github.com/CorentinJ/Real-Time-Voice-Cloning"" rel=""nofollow noreferrer"">https://github.com/CorentinJ/Real-Time-Voice-Cloning</a>), but I would like to go beyond that and clone a voice even more precisely (with subsequent text-to-speech using that voice). It doesn't matter if I have to provide minutes or hours of voice inputs.</p>
","natural-language-processing"
"15490","Doubt on formulating cost function for GloVe","2019-09-17 16:00:12","","2","30","<natural-language-processing><word-embedding><glove>","<p>I'm reading the notes <a href=""https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes02-wordvecs2.pdf"" rel=""nofollow noreferrer"">here</a> and have a doubt on page 2 (""Least squares objective"" section). The probability of a word <span class=""math-container"">$j$</span> occurring in the context of word <span class=""math-container"">$i$</span> is <span class=""math-container"">$$Q_{ij}=\frac{\exp(u_j^Tv_i)}{\sum_{w=1}^W\exp(u_w^Tv_i)}$$</span></p>

<p>The notes read:</p>

<blockquote>
  <p>Training proceeds in an on-line, stochastic fashion, but the implied global cross-entropy loss can be calculated as <span class=""math-container"">$$J=-\sum_{i\in corpus}\sum_{j\in context(i)}\log Q_{ij}$$</span>
  As the same words <span class=""math-container"">$i$</span> and <span class=""math-container"">$j$</span> can occur multiple times in the corpus, it is more efficient to first group together the same values for <span class=""math-container"">$i$</span> and <span class=""math-container"">$j$</span>:
  <span class=""math-container"">$$J=-\sum_{i=1}^W\sum_{j=1}^WX_{ij}\log(Q_{ij})$$</span></p>
</blockquote>

<p>where <span class=""math-container"">$X_{ij}$</span> is the total number of times <span class=""math-container"">$j$</span> occurs in the context of <span class=""math-container"">$i$</span> and the value of co-occuring frequency is given by the co-occurence matrix <span class=""math-container"">$X$</span>. This much is clear. But then the author states that the denominator of <span class=""math-container"">$Q_{ij}$</span> is too expensive to compute, so the cross entropy loss won't work.</p>

<blockquote>
  <p>Instead, we use a least square objective in which the normalization factors in <span class=""math-container"">$P$</span> and <span class=""math-container"">$Q$</span> are discarded:
  <span class=""math-container"">$$\hat J=\sum_{i=1}^W\sum_{j=1}^WX_i(\hat P_{ij}-\hat Q_{ij})^2$$</span>
  where <span class=""math-container"">$\hat P_{ij}=X_{ij}$</span> and <span class=""math-container"">$\hat Q_{ij}=\exp(u_j^Tv_i)$</span> are the unnormalized distributions.</p>
</blockquote>

<p><span class=""math-container"">$X_i=\sum_kX_{ik}$</span> is the number of times any word appears in the context of <span class=""math-container"">$i$</span>. I don't understand this part. <em>Why have we introduced <span class=""math-container"">$X_i$</span> out of nowhere? How is <span class=""math-container"">$\hat P_{ij}$</span> ""unnormalized""? Is there a tradeoff in switching from softmax to MSE?</em> </p>

<p>(As far as I know, softmax made total sense in skip gram because we were calculating scores corresponding to different words (discrete possibilities) and matching the predicted output to the actual word - similar to a classification problem, so softmax makes sense.)</p>
","natural-language-processing"
"14254","Why do you need to retrain GPT-2?","2019-09-02 12:44:54","","2","627","<natural-language-processing>","<p>I'm following <a href=""https://medium.com/@ngwaifoong92/beginners-guide-to-retrain-gpt-2-117m-to-generate-custom-text-content-8bb5363d8b7f"" rel=""nofollow noreferrer"">this</a> tutorial, and I wonder why is there a train-step - why is it necessary? I thought the whole idea of GPT-2 is that you do not need to train it on specific text domain, as it's already pre-trained on a large amount of data.</p>
","natural-language-processing"
"14243","How would an AI learn idiomatic phrases in a natural language?","2019-09-01 17:39:13","14298","7","1215","<machine-learning><natural-language-processing>","<p>After an AI goes through the process described in <a href=""https://ai.stackexchange.com/questions/1970/how-would-an-ai-learn-language"">How would an AI learn language?</a>, an AI knows the grammar of a language through the process of grammar induction. They can speak the language, but they have learned <em>formal grammar</em>. But most conversations today, even formal ones, use idiomatic phrases. Would it be possible for an AI to be given a set of idioms, for example, </p>

<blockquote>
  <p>Immer mit der Ruhe</p>
</blockquote>

<p>Which, in German, means 'take it easy' but an AI of grammar induction, if told to translate 'take it easy' to German, would not think of this. And if asked to translate this, it would output</p>

<blockquote>
  <p>Always with the quiet</p>
</blockquote>

<p>So, it is possible to teach an AI to use idiomatic phrases to keep up with the culture of humans?</p>
","natural-language-processing"
"14020","Which NLP techniques can be used to transform sentences (e.g. from passive to active voice) without affecting their meaning?","2019-08-17 08:34:08","14036","4","367","<natural-language-processing><reference-request><computational-linguistics>","<p>I'm looking for NLP techniques to transform sentences without affecting their meaning.</p>
<p>For example, techniques that could transform active voice into passive voice, such as</p>
<blockquote>
<p>The cat was chasing the mouse.</p>
</blockquote>
<p>to</p>
<blockquote>
<p>The mouse was being chased by the cat.</p>
</blockquote>
<p>I can think of a number of heuristics one could implement to make this happen for specific cases, but would assume that there is existing research on this in the field of linguistics or NLP. My searches for &quot;sentence transformation&quot; and similar terms didn't bring up anything though, and I'm wondering if I simply have the wrong search terms.</p>
<p>Related to this, I'm also looking for measures of text consistency, e.g., an approach that could detect that most sentences in a corpus are written in active voice and detect outliers written in passive voice. I'm using active vs. passive voice as an example here and would be interested in more general approaches.</p>
","natural-language-processing"
"14007","What are the advantages of Machine Learning compared to traditional programming for developing a chatbot?","2019-08-16 11:06:07","","3","135","<machine-learning><natural-language-processing><comparison><chat-bots><question-answering>","<p>I am currently building a chatbot. What I have done so far is, collected possible questions/training data/files and create a model out of it using Apache OpenNLP; the model is able to predict all the questions that are in the training data and fails to predict for new questions.</p>
<p>Instead of doing all the above, I can write a program that matches the question/words against training data and predict the answer — what is the advantage of using Machine Learning algorithms?</p>
<p>I have searched extensively about this and all I got was, in Machine Learning there is no need to change the algorithm and the only change would be in the training data, but that is the case with programming too: the change will be in training data.</p>
","natural-language-processing"
"13988","How does Continuous Bag of Words ensure that similar words are encoded as similar embeddings?","2019-08-15 11:44:55","13990","3","187","<natural-language-processing><word-embedding><word2vec>","<p>This is related to <a href=""https://ai.stackexchange.com/questions/13947/understanding-how-continuous-bag-of-words-method-learns-embedded-representations"">my earlier question</a>, which I'm trying to break down into parts (this being the first). I'm reading notes on word vectors <a href=""https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf"" rel=""nofollow noreferrer"">here</a>. Specifically, I'm referring to section 4.2 on page 7. First, regarding points 1 to 6 - here's my understanding:</p>

<p>If we have a vocabulary <span class=""math-container"">$V$</span>, the naive way to represent words in it would be via one-hot-encoding, or in other words, as basis vectors of <span class=""math-container"">$R^{|V|}$</span> - say <span class=""math-container"">$e_1, e_2,\ldots,e_{|V|}$</span>. We want to map these to <span class=""math-container"">$\mathbb{R}^n$</span>, via some linear transformation such that the images of similar words (more precisely, the images of basis vectors corresponding to similar words) have higher inner products. Assuming the matrix representation of the linear transformation given the standard basis of <span class=""math-container"">$\mathbb{R}^{|V|}$</span> is denoted by <span class=""math-container"">$\mathcal{V}$</span>, then the ""embedding"" of the <span class=""math-container"">$i$</span>-th vocab word (i.e. the image of the corresponding basis vector <span class=""math-container"">$e_i$</span> of <span class=""math-container"">$V$</span>) is given by <span class=""math-container"">$\mathcal{V}e_i$</span>.</p>

<p>Now suppose we have a context ""The cat ____ over a"", CBoW seeks to find a word that would fit into this context. Let the words ""the"", ""cat"", ""over"", ""a"" be denoted (in the space <span class=""math-container"">$V$</span>) by <span class=""math-container"">$x_{i_1},x_{i_2},x_{i_3},x_{i_4}$</span> respectively. We take the image of their linear combination (in particular, their average):
<span class=""math-container"">$$\hat v=\mathcal{V}\bigg(\frac{x_{i_1}+x_{i_2}+x_{i_3}+x_{i_4}}{4}\bigg)$$</span></p>

<p>We then map <span class=""math-container"">$\hat v$</span> back from <span class=""math-container"">$\mathbb{R}^n$</span> to <span class=""math-container"">$\mathbb{R}^{|V|}$</span> via <em>another</em> linear mapping whose matrix representation is <span class=""math-container"">$\mathcal{U}$</span>: <span class=""math-container"">$$z=\mathcal{U}\hat v$$</span></p>

<p>Then we turn this <em>score vector</em> <span class=""math-container"">$z$</span> into softmax probabilities <span class=""math-container"">$\hat y=softmax(z)$</span> and compare it to the basis vector corresponding to the actual word, say <span class=""math-container"">$e_c$</span>. For example, <span class=""math-container"">$e_c$</span> could be the basis vector corresponding to ""jumped"". </p>

<p>Here's my interpretation of what this procedure is trying to do: given a context, we're trying to learn maps <span class=""math-container"">$\mathcal{U}$</span> and <span class=""math-container"">$\mathcal{V}$</span> such that given a context like ""the cat ____ over a"", the model should give a high score to words like ""jumped"" or ""leaped"", etc. Not just that - but ""similar"" contexts should also give rise to high scores for ""jumped"", ""leaped"", etc. For example, given a context ""that dog ____ above this"" wherein ""that"", ""dog"", ""above"", ""this"" are represented by <span class=""math-container"">$x_{j_1},x_{j_2},x_{j_3},x_{j_4}$</span>, let the image of their average be</p>

<p><span class=""math-container"">$$\hat w=\mathcal{V}\bigg(\frac{x_{j_1}+x_{j_2}+x_{j_3}+x_{j_4}}{4}\bigg)$$</span></p>

<p>This gets mapped to a score vector <span class=""math-container"">$z'=\mathcal{U}\hat w$</span>. Ideally, both score vectors <span class=""math-container"">$z$</span> and <span class=""math-container"">$z'$</span> should have similarly high magnitudes in their components corresponding to similar words ""jumped"" and ""leaped"".</p>

<p>Is my above understanding correct? Consider the following quote from the lectures:</p>

<blockquote>
  <p>We create two matrices, <span class=""math-container"">$\mathcal{V} \in \mathbb{R}^{n\times |V|}$</span> and <span class=""math-container"">$\mathcal{U} \in \mathbb{R}^{|V|\times n}$</span>, where <span class=""math-container"">$n$</span> is an arbitrary size which defines the size of our embedding space. <span class=""math-container"">$\mathcal{V}$</span> is the input word matrix such that the <span class=""math-container"">$i$</span>-th column of <span class=""math-container"">$\mathcal{V}$</span> is the <span class=""math-container"">$n$</span>-dimensional embedded vector for word <span class=""math-container"">$w_i$</span> when it is an input to this model. We denote this <span class=""math-container"">$n\times 1$</span> vector as <span class=""math-container"">$v_i$</span>. Similarly, <span class=""math-container"">$\mathcal{U}$</span> is the output word matrix. The <span class=""math-container"">$j$</span>-th row of <span class=""math-container"">$\mathcal{U}$</span> is an <span class=""math-container"">$n$</span>-dimensional embedded vector for word <span class=""math-container"">$w_j$</span> when it is an output of the model. We denote this row of <span class=""math-container"">$\mathcal{U}$</span> as <span class=""math-container"">$u_j$</span>.</p>
</blockquote>

<p><strong>It's not obvious to me why <span class=""math-container"">$v_i=\mathcal{V}e_i$</span> should be the same as or even similar to <span class=""math-container"">$u_i$</span>. How does the whole backpropagation procedure above ensure that?</strong></p>

<p><strong>Also, how does the procedure ensure that basis vectors corresponding to similar words <span class=""math-container"">$e_i$</span> and <span class=""math-container"">$e_j$</span> are mapped to vectors in <span class=""math-container"">$\mathbb{R}^n$</span> that have high inner product?</strong> (In other words, how is it ensured that if words no. <span class=""math-container"">$i_1$</span> and <span class=""math-container"">$i_2$</span> are similar, then <span class=""math-container"">$\langle v_{i_1}, v_{i_2}\rangle$</span> and <span class=""math-container"">$\langle u_{i_1}, u_{i_2}\rangle$</span> have high values?)</p>
","natural-language-processing"
"13947","Understanding how continuous bag of words method learns embedded representations","2019-08-13 15:23:07","","0","33","<natural-language-processing><word-embedding><word2vec>","<p>I'm reading notes on word vectors <a href=""https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf"" rel=""nofollow noreferrer"">here</a>. Specifically, I'm referring to section 4.2 on page 7. First, regarding points 1 to 6 - here's my understanding:</p>
<p>If we have a vocabulary <span class=""math-container"">$V$</span>, the naive way to represent words in it would be via one-hot-encoding, or in other words, as basis vectors of <span class=""math-container"">$R^{|V|}$</span> - say <span class=""math-container"">$e_1, e_2,\ldots,e_{|V|}$</span>. We want to map these to <span class=""math-container"">$\mathbb{R}^n$</span>, via some linear transformation such that the images of similar words (more precisely, the images of basis vectors corresponding to similar words) have higher inner products. Assuming the matrix representation of the linear transformation given the standard basis of <span class=""math-container"">$\mathbb{R}^{|V|}$</span> is denoted by <span class=""math-container"">$\mathcal{V}$</span>, then the &quot;embedding&quot; of the <span class=""math-container"">$i$</span>-th vocab word (i.e. the image of the corresponding basis vector <span class=""math-container"">$e_i$</span> of <span class=""math-container"">$V$</span>) is given by <span class=""math-container"">$\mathcal{V}e_i$</span>.</p>
<p>Now suppose we have a context &quot;The cat ____ over a&quot;, CBoW seeks to find a word that would fit into this context. Let the words &quot;the&quot;, &quot;cat&quot;, &quot;over&quot;, &quot;a&quot; be denoted (in the space <span class=""math-container"">$V$</span>) by <span class=""math-container"">$x_{i_1},x_{i_2},x_{i_3},x_{i_4}$</span> respectively. We take the image of their linear combination (in particular, their average):
<span class=""math-container"">$$\hat v=\mathcal{V}\bigg(\frac{x_{i_1}+x_{i_2}+x_{i_3}+x_{i_4}}{4}\bigg)$$</span></p>
<p>We then map <span class=""math-container"">$\hat v$</span> back from <span class=""math-container"">$\mathbb{R}^n$</span> to <span class=""math-container"">$\mathbb{R}^{|V|}$</span> via <em>another</em> linear mapping whose matrix representation is <span class=""math-container"">$\mathcal{U}$</span>: <span class=""math-container"">$$z=\mathcal{U}\hat v$$</span></p>
<p>Then we turn this <em>score vector</em> <span class=""math-container"">$z$</span> into softmax probabilities <span class=""math-container"">$\hat y=softmax(z)$</span> and compare it to the basis vector corresponding to the actual word, say <span class=""math-container"">$e_c$</span>. For example, <span class=""math-container"">$e_c$</span> could be the basis vector corresponding to &quot;jumped&quot;.</p>
<p>Here's my interpretation of what this procedure is trying to do: given a context, we're trying to learn maps <span class=""math-container"">$\mathcal{U}$</span> and <span class=""math-container"">$\mathcal{V}$</span> such that given a context like &quot;the cat ____ over a&quot;, the model should give a high score to words like &quot;jumped&quot; or &quot;leaped&quot;, etc. Not just that - but &quot;similar&quot; contexts should also give rise to high scores for &quot;jumped&quot;, &quot;leaped&quot;, etc. For example, given a context &quot;that dog ____ above this&quot; wherein &quot;that&quot;, &quot;dog&quot;, &quot;above&quot;, &quot;this&quot; are represented by <span class=""math-container"">$x_{j_1},x_{j_2},x_{j_3},x_{j_4}$</span>, let the image of their average be</p>
<p><span class=""math-container"">$$\hat w=\mathcal{V}\bigg(\frac{x_{j_1}+x_{j_2}+x_{j_3}+x_{j_4}}{4}\bigg)$$</span></p>
<p>This gets mapped to a score vector <span class=""math-container"">$z'=\mathcal{U}\hat w$</span>. Ideally, both score vectors <span class=""math-container"">$z$</span> and <span class=""math-container"">$z'$</span> should have similarly high magnitudes in their components corresponding to similar words &quot;jumped&quot; and &quot;leaped&quot;.</p>
<p>Now to the questions:</p>
<blockquote>
<p>We create two matrices, <span class=""math-container"">$\mathcal{V} \in \mathbb{R}^{n\times |V|}$</span> and <span class=""math-container"">$\mathcal{U} \in \mathbb{R}^{|V|\times n}$</span>, where <span class=""math-container"">$n$</span> is an arbitrary size which defines the size of our embedding space. <span class=""math-container"">$\mathcal{V}$</span> is the input word matrix such that the <span class=""math-container"">$i$</span>-th column of <span class=""math-container"">$\mathcal{V}$</span> is the <span class=""math-container"">$n$</span>-dimensional embedded vector for word <span class=""math-container"">$w_i$</span> when it is an input to this model. We denote this <span class=""math-container"">$n\times 1$</span> vector as <span class=""math-container"">$v_i$</span>. Similarly, <span class=""math-container"">$\mathcal{U}$</span> is the output word matrix. The <span class=""math-container"">$j$</span>-th row of <span class=""math-container"">$\mathcal{U}$</span> is an <span class=""math-container"">$n$</span>-dimensional embedded vector for word <span class=""math-container"">$w_j$</span> when it is an output of the model. We denote this row of <span class=""math-container"">$\mathcal{U}$</span> as <span class=""math-container"">$u_j$</span>.</p>
</blockquote>
<ol>
<li><p>How does minimizing the cross-entropy loss between <span class=""math-container"">$e_c$</span> and <span class=""math-container"">$\hat y$</span> ensure that basis vectors corresponding to similar words <span class=""math-container"">$e_i$</span> and <span class=""math-container"">$e_j$</span> are mapped to vectors in <span class=""math-container"">$\mathbb{R}^n$</span> that have high inner product? I'm not sure of the mechanism how the above procedure ensures that. In other words, how is it ensured that if words no. <span class=""math-container"">$i_1$</span> and <span class=""math-container"">$i_2$</span> are similar, then <span class=""math-container"">$\langle v_{i_1}, v_{i_2}\rangle$</span> and <span class=""math-container"">$\langle u_{i_1}, u_{i_2}\rangle$</span> have high values?</p>
</li>
<li><p>How does the above procedure ensure that linear combinations of words in similar contexts are mapped to &quot;similar&quot; images? Does that even happen? In the above description for example, do <span class=""math-container"">$\hat v$</span> and <span class=""math-container"">$\hat w$</span> corresponding to similar contexts also have a high inner product? If so, how is that ensured?</p>
</li>
<li><p>Maybe my linear algebra is rusty and this is a silly question, but from what I gather, the columns of <span class=""math-container"">$\mathcal{V}$</span> represent the images of OHE vectors (standard basis of <span class=""math-container"">$V$</span>) in the standard basis of <span class=""math-container"">$\mathbb{R}^n$</span> - i.e. the embedded representation of vocab words. Also, the rows of <span class=""math-container"">$\mathcal{U}$</span> also somehow represent the embedded representation of vocab words in <span class=""math-container"">$\mathbb{R}^n$</span>. It's not obvious to me why <span class=""math-container"">$v_i=\mathcal{V}e_i$</span> should be the same as or even similar to <span class=""math-container"">$u_i$</span>. Again, how does the above procedure ensure that?</p>
</li>
</ol>
","natural-language-processing"
"13926","Can ELMO embeddings be used to find the n most similar sentences?","2019-08-12 19:58:00","","3","1263","<natural-language-processing><word-embedding>","<p>Assume I have a list of sentences, which is just a list of strings. I need a way of comparing some input string against those sentences to find the most similar. Can <a href=""https://allennlp.org/elmo"" rel=""nofollow noreferrer"">ELMO embeddings</a> be used to train a model that can give you the <span class=""math-container"">$n$</span> most similar sentences to an input string?</p>

<p>For reference, gensim provides a <a href=""https://radimrehurek.com/gensim/models/doc2vec.html"" rel=""nofollow noreferrer"">doc2vec</a> model that can be trained on a list of strings, then you can use the trained model to infer a vector from some input string. That inferred vector can then be used to find the <span class=""math-container"">$n$</span> most similar vectors.</p>

<p>Could something similar be done, but using ELMO embedding instead?</p>

<p>Any guidance would be greatly appreciated. </p>
","natural-language-processing"
"13917","How to use pretrained checkpoints of BERT model on semantic text similarity task?","2019-08-12 13:38:44","","1","230","<natural-language-processing><bert>","<p>I am unaware to use the derived checkpoints from pre-trained BERT model for the task of semantic text similarity.</p>

<pre><code>!python create_pretraining_data.py \
          --input_file=/input_path/input_file.txt \
          --output_file=/tf_path/tf_examples.tfrecord \
          --vocab_file=/vocab_path/uncased_L-12_H-768_A-12/vocab.txt \
          --do_lower_case=True \
          --max_seq_length=128 \
          --max_predictions_per_seq=20 \
          --masked_lm_prob=0.15 \
          --random_seed=12345 \
          --dupe_factor=5

!python run_pretraining.py \
      --input_file=/tf_path/tf_examples.tfrecord \
      --output_dir=pretraining_output \
      --do_train=True \
      --do_eval=True \
      --bert_config_file=/bert_path/uncased_L-12_H-768_A-12/bert_config.json \
      --init_checkpoint=/bert_path/uncased_L-12_H-768_A-12/bert_model.ckpt\
      --train_batch_size=32 \
      --max_seq_length=128 \
      --max_predictions_per_seq=20 \
      --num_train_steps=20 \
      --num_warmup_steps=10 \
      --learning_rate=2e-5
</code></pre>

<p>I have run a pre-trained BERT model with some domain of corpora from scratch. I have got the checkpoints and graph.pbtxt file from the code above. But I am unaware on how to use those files for evaluating semantic text similarity test file.</p>
","natural-language-processing"
"13830","What is ""Word Sense Disambiguation""?","2019-08-06 17:39:17","13833","1","180","<natural-language-processing><terminology>","<p>I recently came across this <a href=""https://www.analyticsindiamag.com/iisc-bangalores-ai-team-comes-up-with-a-solution-to-an-old-nlp-problem/"" rel=""nofollow noreferrer"">article</a> which cites a <a href=""https://malllabiisc.github.io/publications/papers/EWISE_ACL19.pdf"" rel=""nofollow noreferrer"">paper</a>, which apparently won the outstanding paper award in ACL 2019. The theme is that it solved a longstanding problem called <strong>Word Sense Disambiguation</strong>.</p>
<p>What is <em>Word Sense Disambiguation</em>? How does it affect NLP?</p>
<p>(Moreover, how does the proposed method solve this problem?)</p>
","natural-language-processing"
"13654","Grouped Text classification","2019-07-29 14:02:26","","2","61","<machine-learning><deep-learning><natural-language-processing><classification><python>","<p>I have thousands groups of paragraphs and I need to classify these paragraphs. The problem is that I need to classify each paragraph based on other paragraphs in the group! For example, a paragraph individually maybe belongs to class A but according to other paragraph in the group it belongs to class B.</p>

<p>I have tested lots of traditional and deep approaches( in fields like text classification, IR, text understanding, sentiment classification and so on) but those couldn't classify correctly.</p>

<p>I was wondering if anybody has worked in this area and could give me some suggestion. Any suggestions are appreciated. Thank you.</p>

<p><strong>Update 1:</strong></p>

<p>Actually we are looking for manual sentences/paragraph for some fields, so we first need to recognize if a sentence/paragraph is a manual or not second we need to classify it to it's fields and we can recognize its field only based on previous or next sentences/paragraphs.</p>

<p>To classify the paragraphs to manual/no-manual we have developed some promising approaches but the problem come up when we should recognize the field according to previous or next sentences/paragraphs, but which one?? we don't know the answer would be in any other sentences!!.</p>

<p><strong>Update 2:</strong></p>

<p>We can not use whole text of group as input because those are too big (sometimes tens of thousands of words) and contain some other classes and machine can't learn properly which lead to  the drop the accuracy sharply.</p>

<p>Here is a picture that maybe help to better understanding the problem:
<a href=""https://i.sstatic.net/HC2mj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/HC2mj.png"" alt=""enter image description here""></a></p>
","natural-language-processing"
"13600","Why do language models place less importance on punctuation?","2019-07-26 10:51:32","","2","1187","<natural-language-processing>","<p>I have a very outdated idea about how NLP tasks are carried out by normal RNN's, LSTM's/GRU's, word2vec, etc to basically generate some hidden form of the sentence understood by the machine.</p>
<p>One of the things I have noticed is that, in general, researchers are interested in generating the context of the sentence, but oftentimes ignore punctuation marks which are one of the most important aspects for generating context. For example:</p>
<blockquote>
<p>“Most of the time, travellers worry about their luggage.”</p>
<p>“Most of the time travellers worry about their luggage”</p>
</blockquote>
<p><a href=""https://cybertext.wordpress.com/2012/11/22/a-light-hearted-look-at-how-punctuation-can-change-meaning/"" rel=""nofollow noreferrer"">Source</a></p>
<p>Like this there exists probably 4 important punctuation marks <code>.,?</code> and <code>!</code>. Yet, I have not seen any significant tutorials/blogs on them. It is also interesting to note that punctuation marks don't have a meaning (quite important, since most language models try to map word to a numerical value/meaning), they are more of a 'delimiter'. So what is the current theory or perspective on this? And why is it ignored?</p>
","natural-language-processing"
"13576","How can we use Dependency Parsers for Negation detection","2019-07-25 14:05:01","","1","11","<natural-language-processing>","<p>I am building a negation detection system. How to use dependency parsers for the same. I am using SPACY for dependency parser</p>
","natural-language-processing"
"13518","Language Model from missing data","2019-07-22 23:54:19","","1","29","<deep-learning><natural-language-processing><sequence-modeling>","<p>I want to learn how a set of operations (my vocabulary) are composed in a dataset of algorithms (corpus). </p>

<p>The algorithms are a sequence of higher level operations which have varying low-level implementations. I am able to map raw code to my vocabulary, but not all of it.</p>

<p>e.g. I observe a lossy description of an algorithm that does something:</p>

<p><code>X: missing data
Algo 1: BIND3 EXTEND2 X X ROTATE360 X PUSH
Algo 2: X X EXTEND2 ROTATE360
</code></p>

<p>The underlying rotate operation could have very different raw code, but effectively the same function and so it gets mapped to the same operation. </p>

<p>I want to infer what the next operation will be given a sequence of (potentially missing) operations (regions of code I could not map). </p>

<p>i.e. I want a probability distribution over my operations vocabulary.</p>

<p>Any ideas on the best approach here? The standard thing seems to throw out  missing data, but I can still learn in these scenarios. Also, the gaps in the code are non-homogenous--some could do many things, The alternative is to contract the sequences and lose the meaning of the gaps, or to learn an imputation.</p>
","natural-language-processing"
"13498","Machine learning methods to identify the recipient of a document?","2019-07-22 05:14:52","","2","67","<natural-language-processing>","<p>I need some advice on what AI methods would be suited to the identification of a recipient of a document, where the format of the documents may vary. </p>
","natural-language-processing"
"13397","Can computers recognise ""grouping"" from voice tonality?","2019-07-16 17:23:35","","3","31","<natural-language-processing><voice-recognition><speech-synthesis>","<p>In human communication, tonality or tonal language play many complex information, including emotions and motives. But excluding such complex aspects, tonality serves some a very basic purpose of ""grouping"" or ""taking common"" functions such as: </p>

<ol>
<li>The sweet, (pause), bread-and-drink. </li>
</ol>

<p>It means ""The sweet bread and the sweet drink"". However</p>

<ol start=""2"">
<li>The sweet-bread, (pause) and drink. </li>
</ol>

<p>It means only the bread is sweet but the drink isn't necessarily sweet, or the drink's sweetness property isn't assigned. </p>

<p>Can computers recognise these differences of meaning based on tonality?</p>
","natural-language-processing"
"13382","Can a computer identify the philosophical concept on which a given story is based?","2019-07-16 04:49:48","","4","172","<natural-language-processing><philosophy><natural-language-understanding>","<p>Say you have to enter a story to a computer. Now, the computer has to identify the philosophical concept on which the story is based, say:</p>
<ol>
<li><p>Was it a &quot;self-fulfilling prophecy&quot;?</p>
</li>
<li><p>Was it an example of &quot;Deadlock&quot; or &quot;Pinocchio paradox situation&quot;?</p>
</li>
<li><p>Was it an example of how rumours magnify? or something similar to a chain reaction process?</p>
</li>
<li><p>Was it an example of &quot;cognitive dissonance&quot; of a person?</p>
</li>
<li><p>Was it a story about &quot;altruism&quot;?</p>
</li>
<li><p>Was it a story about a &quot;misunderstanding&quot; when a person did something &quot;innovative&quot; but it accidentally was innovated earlier so the person was &quot;falsely accused&quot; of &quot;plagiarising&quot;?</p>
</li>
</ol>
<p>And so on.</p>
<p>Given that the story is <strong>not only</strong> a heavy rephrase of the pre-existing story; <strong>not only</strong> character names and identities are totally changed, <em><strong>but</strong></em> the context completely changed, the exact tasks they were doing are changed.</p>
<p>Can computers identify such &quot;concepts&quot; from stories? If yes, then what mechanism do they use?</p>
","natural-language-processing"
"13362","What is a conditional random field?","2019-07-14 10:29:59","","2","257","<machine-learning><natural-language-processing><definitions><probabilistic-graphical-models><conditional-random-field>","<p>I new in machine learning, especially in Conditional Random Fields (CRF).</p>

<p>I have read several articles and papers and in there is always associated with HMM and sequences classification. I don't really understand mathematics, especially in the annoying formula. So I can't understand the process. Where I need to start to understand CRFs??</p>

<p>I want to make an information extraction application using CRF Named Entity Recognition (NER).</p>

<p>I got some tutorial for that: <a href=""https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html#training-data"" rel=""nofollow noreferrer"">https://eli5.readthedocs.io/en/latest/tutorials/sklearn_crfsuite.html#training-data</a> </p>

<p><strong>But</strong> I don't know the proses each step, like training proses, evaluation, and testing</p>

<p>I use this code :</p>

<pre><code>  data_frame = eli5.format_as_dataframes(
            eli5.explain_weights_sklearn_crfsuite(self.crf))
</code></pre>

<p><strong>Targets</strong>
<a href=""https://i.sstatic.net/bCHpg.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bCHpg.png"" alt=""enter image description here""></a></p>

<p><strong>Transition Features</strong>
<a href=""https://i.sstatic.net/jqlGi.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/jqlGi.png"" alt=""enter image description here""></a></p>

<p>How to get that number ?</p>

<p>and 1 more thing makes me confused:</p>

<pre><code>crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=0.1,
    c2=0.1,
    max_iterations=20,
    all_possible_transitions=False,
)
</code></pre>

<p>What is the algorithm <code>lbfgs</code>? Is the CRF not an algorithm? Why do I need <code>lbfgs</code>? What is exactly a conditional random field?</p>
","natural-language-processing"
"13278","Models to extract Causal Relationship between entities in a document using Natural Language Processing techniques","2019-07-09 11:26:14","","2","47","<machine-learning><natural-language-processing><causation>","<p>I am looking to extract causal relations between entities like Drug and Adverse Effect in a document. Are there any proven NLP or AI techniques to handle the same.  Also are there ways to handle cases where the 2 entities may not necessarily co-occur in the same sentence. </p>
","natural-language-processing"
"13043","How do I classify strings with possibly no meaning?","2019-06-25 02:30:55","","1","157","<machine-learning><natural-language-processing><classification><word2vec>","<p>I am quite new to text classification. </p>

<p>Using EAST text detection model, I get multiple strings that aren't words and most often have no meaning. For example, IDs, brand names, etc. I would like to classify them into two groups. Which models work the best and how should I preprocess the strings?  I wanted to use Word2Vec, but I think it only works with real words and not with arbitrary strings.</p>
","natural-language-processing"
"12965","Is there any way to classify Document Image without OCR?","2019-06-21 06:31:16","","0","262","<neural-networks><machine-learning><natural-language-processing><classification><optical-character-recognition>","<p>I have multiple invoices images which need to classify invoice types such as fright, utility, goods, etc. Is there any way to classify without OCR?</p>
","natural-language-processing"
"12815","How can I build an AI with NLP that read stories","2019-06-12 15:31:33","","3","167","<machine-learning><deep-learning><natural-language-processing>","<p>I want to do an NLP project but I don't know if it's doable or not as I have no experience or knowledge in NLP or ML yet.</p>

<p>The idea is as follows: Let's say we have a story (in the text) that has 10 characters. Can we define them, their characteristics, whole sentences they said, and then analyze emotions within those sentences.</p>

<p>After that, is it possible to generate an audio version of the story where: the text, in general, is narrated by one voice, each individual character's sentences are read in a different voice generated specifically for that character. Finally is it possible to make the tones of the characters voices change depending on the emotions detected in their sentences?</p>
","natural-language-processing"
"12810","Do I need to use a pre-processed dataset to classify comments?","2019-06-12 12:04:21","","1","63","<neural-networks><natural-language-processing><classification><tensorflow><data-preprocessing>","<p>I want to use Machine Learning for text classification, more precisely, I want to determine whether a text (or comment) is positive or negative. I can download a dataset with 120 million comments. I read the TensorFlow <a href=""https://www.tensorflow.org/tutorials/keras/basic_text_classification"" rel=""nofollow noreferrer"">tutorial</a> and they also have a text dataset. This dataset is already pre-processed, like the words are converted to integers and the most used words are in the top 10000. </p>

<p>Do I also have to use a pre-processed dataset like them? If yes, does it have to be like the dataset from TensorFlow? And which pages could help me to implement that kind of program? </p>

<p>My steps would be:</p>

<ol>
<li>find datasets</li>
<li>preprocess them if needed</li>
<li>feed them in the neural network</li>
</ol>
","natural-language-processing"
"12777","Is there a way to break a piece of dialogue into components?","2019-06-10 14:17:46","","1","30","<natural-language-processing><reference-request><dialogue-systems>","<p>In many chatbots, I've seen a lot of hardcoded responses, but nothing that allows an AI to break a piece of dialogue into components (say that the speaker sounds happy or is trying to be manipulative) and model a response based on this.</p>
<p>I envision a coding scheme for different core components of conversation. This would allow an AI to be more dynamic in its responses, and would be closer to actually being able to hold a conversation.</p>
<p>I'm <em>not</em> looking for AI-generated text, at least not in the sense of some NN or the like being fed a diet of literature and seeing what it spits out - there's nothing dynamic about that.</p>
","natural-language-processing"
"12727","How to distinguish between proper nouns and other words in NLP?","2019-06-06 20:10:35","","1","318","<natural-language-processing>","<p>If an NLP system processes a text containing proper nouns like names, trade marks, etc. without knowing anything about the language (ie no lexicon), is it possible to recognise them?</p>
","natural-language-processing"
"12659","What is the actual quality of machine translations?","2019-06-03 14:34:41","","30","6739","<natural-language-processing><natural-language-understanding><machine-translation><google-translate>","<p>As an AI layman, till today I am confused by the promised and achieved improvements of automated translation.</p>
<p>My impression is: <strong>there is still a very, very far way to go.</strong> Or are there other explanations why the automated translations (offered and provided e.g. by Google) of quite simple Wikipedia articles still read and sound mainly silly, are hardly readable, and only very partially helpful and useful?</p>
<p>It may depend on personal preferences (concerning readability, helpfulness, and usefulness), but <strong>my personal expectations</strong> are disappointed sorely.</p>
<p>The other way around: Are Google's translations nevertheless readable, helpful, and useful <strong>for a majority of users</strong>?</p>
<p>Or does Google have reasons to <strong>retain its achievements</strong> (and not to show to the users the best they can show)?</p>
","natural-language-processing"
"12656","Will BERT embedding be always same for a given document when used as a feature extractor","2019-06-03 10:45:37","","5","722","<machine-learning><natural-language-processing><word-embedding><bert>","<p>When we use BERT embeddings for a classification task, would we get different embeddings every time we pass the same text through the BERT architecture? If yes, is it the right way to use the embeddings as features? Ideally, while using any feature extraction technique, features values should be consistent. How do I handle this if we want BERT to be used as a feature extractor?</p>
","natural-language-processing"
"12655","Generate QA dataset from large text corpus","2019-06-03 09:39:45","","2","496","<natural-language-processing><python><datasets>","<p>I have a corpus of a domain data in form of 10-15 books pdf and some articles and my end-goal is to make a question-answering system particular to that domain.
For that, I would need a dataset on Q/A which I can use on top of something like SQuAD(<strong>S</strong>tanford <strong>Qu</strong>estion <strong>A</strong>nswering <strong>D</strong>ataset) for domain-specific knowledge</p>

<p>My stuck point is <em>how to convert this corpus into a usable question-answering dataset</em>.</p>

<p>My current strategy is something <strong>AllenAI</strong> has been working with. A list of their research papers on it can be found <a href=""https://allenai.org/aristo/"" rel=""nofollow noreferrer"">here</a></p>

<p>As I understand they use a combination of <em>Knowledge Extraction</em>, <em>Natural Language Understanding</em>, and <em>Inference</em> to get the job done. But I cannot find any good practical implementation. </p>

<p>Where can I find a good resource?</p>
","natural-language-processing"
"12654","How do I identify a monologue or dialogue in a conversation?","2019-06-03 08:33:06","","4","179","<machine-learning><natural-language-processing><machine-translation>","<p>How do I identify monologues and dialogues in a conversation (or transcript) using natural language processing? How do I distinguish between the two?</p>
","natural-language-processing"
"12647","Does the human brain use beam search for text generation?","2019-06-02 19:47:24","","2","181","<natural-language-processing><brain>","<p>As far as I understand, <a href=""https://www.youtube.com/watch?v=RLWuzLLSIgw"" rel=""nofollow noreferrer"">beam search</a> is the most widely used algorithm for text generation in NLP. So I was wondering: does the human brain also use beam search for text generation? If not, then what?</p>
","natural-language-processing"
"12600","How can I implement a GAN network for text (review) generation?","2019-05-30 18:10:08","","0","241","<deep-learning><natural-language-processing><generative-adversarial-networks><software-evaluation>","<p>How can I implement a GAN network for text (review) generation?</p>

<p>Please, can someone guide me to resource (code) to help in text generation? </p>
","natural-language-processing"
"12579","Why can we approximate the joint probability distribution using the output vector of an LSTM?","2019-05-29 10:08:39","12598","2","698","<machine-learning><natural-language-processing><long-short-term-memory><probability-distribution><sequence-modeling>","<p>In the paper, <a href=""https://www.aclweb.org/anthology/C18-1139"" rel=""nofollow noreferrer"">Contextual String Embeddings for Sequence Labeling</a>, the authors state that</p>

<p><span class=""math-container"">\begin{equation}
P(x_{0:T}) = \prod_{t=0}^T P(x_t|x_{0:t-1})
\end{equation}</span></p>

<p>They also state that, in the LSTM architecture, the conditional probability <span class=""math-container"">$P(x_{t}|x_{0:t})$</span> is approximately a function of the network output <span class=""math-container"">$h_t$</span>.</p>

<p><span class=""math-container"">\begin{equation}
P(x_{t}|x_{0:t}) \approx \prod_{t=0}^{T} P(x_t|h_t;\theta)
\end{equation}</span></p>

<p>Why is this equation true?</p>
","natural-language-processing"
"12527","Bert super easy implementation","2019-05-25 13:44:26","","2","105","<natural-language-processing><python>","<p>I myself am not new to NLP, but for some reason I am unable to grasp purity of BERT. I have seen a ton of blogs, github repos, but none could clarify BERT usage to me.</p>

<p>It would be helpful if you could provide two things :</p>

<ol>
<li>A clear implementation of BERT, preferably in ipython notebook.</li>
<li>Some papers on BERT excluding the original paper by google.</li>
</ol>
","natural-language-processing"
"12240","Convolutional Sequence to Sequence Learning kernel parameters","2019-05-10 13:22:04","","1","88","<convolutional-neural-networks><natural-language-processing><machine-translation>","<p>I am reading the paper Convolutional Sequence to Sequence Learning by Facebook AI researchers and having trouble to understand how the dimensions of convolutional filters work here. Please take a look at the relevant part of the paper below. </p>

<p><a href=""https://i.sstatic.net/1xSku.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/1xSku.png"" alt=""enter image description here""></a></p>

<p>Let's say the input to the kernel X is k*d (say k=5 words of d=300 embedding dimenisonality). Therefore the input is 5*300. In a computer vision task a kernel would slide over parts of the image, in NLP you usually see kernel taking up the whole width of the input matrix. So I would expect kernel to be m*d (e.g. 3*300 - slide over 3 words and look at their whole embeddiings).</p>

<p>However, the kernel here is of dimensionality 2d x kd which in our hypothetical example would be 600*1500. I don't understand how this massive kernel would slide over an input that is by far lower dimensional (5*300). In computer vision you could zero-pad the input, but here zero-padding would basically turn the input matrix into mostly zeros with only a handful of meaningful numbers.</p>

<p>Thanks for shedding some light on it!</p>
","natural-language-processing"
"12115","What data formats/pipelining are best to store and wrangle data which contains both text and float vectors?","2019-05-02 19:49:34","12119","1","48","<natural-language-processing><datasets><data-science><structured-data><data-mining>","<p>Often in NLP project the data points contain both text and float embeddings, and it's very tricky to deal with. CSVs take up a ton of memory and are slow to load. But most the other data formats seem to be meant for either pure text or pure numerical data.</p>

<p>There are those that can handle data with the dual data types, but those are generally not flexible for wrangling. For example, for pickle you have to load the entire thing into memory if you want to wrangle anything. You can just append directly to the disk like you can with hdf5, which can be very helpful for huge datasets which can not be all loaded into memory?</p>

<p>Also, any alternatives to Pandas for wrangling Huge datasets? Sometimes you can't load all the data into Pandas without causing a memory crash.</p>
","natural-language-processing"
"11900","Understanding how the loss was calculated for the SQuAD task in BERT paper","2019-04-20 01:13:46","11947","3","2035","<natural-language-processing><objective-functions><papers><bert>","<p>In the <a href=""https://arxiv.org/pdf/1810.04805.pdf"" rel=""nofollow noreferrer"">BERT paper</a>, section 4.2 covers the SQuAD training. </p>

<p>From my understanding, there are two extra parameters trained, they are two vectors with the same dimension as the hidden size, so the same dimensions as the contextualized embeddings in BERT. They are S (for start) and E (for End). For each, a softmax is taken with S and each of the final contextualized embeddings to get a score for the correct Start position. And the same thing is done for E and the correct end position.</p>

<p>I get up to this part. But I am having trouble figuring out how the did the labeling and final loss calculations, which is described in this paragraph</p>

<blockquote>
  <p>and the maximum scoring span is used as the prediction. The training objective is the loglikelihood of the correct start and end positions.</p>
</blockquote>

<p>What do they mean by ""maximum scoring span is used as the prediction""?</p>

<p>Furthermore, how does that play into </p>

<blockquote>
  <p>The training objective is the loglikelihood of the correct start and end positions</p>
</blockquote>

<p>From this source: <a href=""https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/"" rel=""nofollow noreferrer"">https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/</a></p>

<p>It says the log-likelihood is only applied to the correct classes. So, we are only calculating the softmax for the correct positions only, not any of the incorrect positions.</p>

<p>If this interpretation is correct, then the loss will be</p>

<pre><code>Loss = -Log( Softmax(S*T(predictedStart) / Sum(S*Ti) ) -Log( Softmax(E*T(predictedEnd) / Sum(S*Ti) )
</code></pre>
","natural-language-processing"
"11833","Do we have cross-language vector space for word embedding?","2019-04-15 14:35:28","","2","181","<natural-language-processing><word-embedding>","<p>Do we have cross-language vector space for word embedding?</p>

<p>When measure similarity for apple/Pomme/mela/Lacus/苹果/りんご, they should be the same</p>

<p>If would be great if there's available internet service of neuron network which already be trained by multiple language</p>
","natural-language-processing"
"11825","How can we create a vector space where word spelling and pronunciation can be easily compared?","2019-04-15 09:42:09","","1","144","<natural-language-processing><word-embedding>","<p>In natural language processing, we can convert words to vectors (or word embeddings). In this vector space, we can measure the similarity between these word embeddings.</p>

<p>How can we create a vector space where word spelling and pronunciation can be easily compared? For example, ""apple"" and ""ape"", ""start"" and ""startle"" are very similar, so they should also be similar in this new vector space.</p>

<p>I am eventually looking for a library that can do this out of the box. I would like to avoid implementing this myself.</p>
","natural-language-processing"
"11824","How do I create syntactically correct sentences given several words?","2019-04-15 08:33:47","","1","208","<machine-learning><natural-language-processing>","<p>Is there an AI application that can produce syntactically (and semantically) correct sentences given a bag of words? For example, suppose I am given the words ""cat"", ""fish"", and ""lake"", then one possible sentence could be ""cat eats fish by the lake"".</p>
","natural-language-processing"
"11822","Can AI help summarize article or abstract sentence keyword?","2019-04-15 07:47:20","","1","392","<natural-language-processing><artificial-neuron>","<p>I'm wondering if AI now can help us abstract summary or general idea of long article, for example novel or historical stories, or abstract most important keyword from sentence;</p>

<p>Would you please tell me if any of this kind of project is done?</p>

<p>I wish I can improve my reading speed and effectiveness with AI help.</p>
","natural-language-processing"
"11755","How does bidirectional encoding allow the predicted word to indirectly ""see itself""?","2019-04-10 10:02:36","","3","269","<deep-learning><natural-language-processing><recurrent-neural-networks><bert>","<p>Before the release of BERT, we used to say that it is not possible to train bidirectional models by simply conditioning each word on its previous and next words, since this would allow the word that's being predicted to indirectly ""see itself"" in a multi-layer model. How does this happen? </p>
","natural-language-processing"
"11748","How to make meaningful sentences from a set of words?","2019-04-10 05:11:27","","2","2278","<machine-learning><natural-language-processing>","<p>I have set of topics generated using LDA and  like {code, language, test , write, function}, {class, public, method, string, int} etc and I want to make meaningful sentence/sentences from these words using  api or libraries.  How do I implement this with NLTK and(or) Machine Learning? Any suggestions as to how I should go about this?</p>
","natural-language-processing"
"11678","Which algorithm should I use to map an input sentence to an output sentence?","2019-04-05 16:13:24","","1","944","<machine-learning><natural-language-processing><recurrent-neural-networks>","<p>I am new to NLP realm. If you have an input text ""The price of orange has increased"" and output text ""Increase the production of orange"". Can we make our RNN model to predict the output text? Or what algorithm should I use?</p>
","natural-language-processing"
"11621","How can I generate a document from a single word using GPT or BERT?","2019-04-03 13:15:15","","2","80","<natural-language-processing><bert><language-model><gpt>","<p>I have a dataset of 100000 documents each labelled with a topic to it. I want to create a model such that, given a topic, the model can generate a document from it. </p>

<p>I came across language models <a href=""https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf"" rel=""nofollow noreferrer"">GPT</a>, GPT-2 and <a href=""https://arxiv.org/pdf/1810.04805.pdf"" rel=""nofollow noreferrer"">BERT</a>. I learned that they can be used for generation purposes. But I did not find anywhere whether they can generate sentences given only a word.</p>

<p>I am inclined to use GPT for my task, but I am not sure how to proceed with it. I wanted to know whether it is possible or not? It would be helpful if anyone can help me give a start in the right direction.</p>
","natural-language-processing"
"11575","Cold start collaborative filtering with NLP","2019-04-01 04:53:30","","5","156","<natural-language-processing><recommender-system>","<p>I’m looking to match two pieces of text - e.g. IMDb movie descriptions and each person’s description of the type of movies they like. I have an existing set of ~5000 matches between the two. I particularly want to overcome the cold-start problem: what movies to recommend to a new user? When a new movie comes out, to which users should it be recommended? I see two options:</p>

<ol>
<li>Run each description of a person through an LSTM; do the same for each movie description; concatenate the results for some subset of possible combinations of people and movies, and attach to a dense net to then predict whether it’s a match or not</li>
<li>Attempt to augment collaborative filtering with the output from running the movie description and person description through a text learner.</li>
</ol>

<p>Are these tractable approaches?</p>
","natural-language-processing"
"11574","Multi-field text input for LSTM","2019-04-01 03:39:55","","2","52","<natural-language-processing><long-short-term-memory><hidden-layers><architecture>","<p>I'm using LSTM to categorize medium-sized pieces of text. Each item to be categorized has several free-form text fields, in addition to several categorical fields. What is the best approach to using all this information for categorization?  I see two options:</p>

<ul>
<li>Concatenate the text from all fields, preceding each field content with a special token. Run concatenated text through LSTM.</li>
<li>Train one model per field. Concatenate output from each model in a hidden layer and pass into subsequent layers.</li>
</ul>

<p>What are the benefits of each of the approaches? Is there an alternative I'm missing?</p>
","natural-language-processing"
"11511","Why does all of NLP literature use noise contrastive estimation loss for negative sampling instead of sampled softmax loss?","2019-03-29 00:44:19","","4","36","<natural-language-processing><word2vec><word-embedding>","<p>A sampled softmax function is like a regular softmax but randomly selects a given number of 'negative' samples.</p>

<p>This is difference than NCE Loss, which doesn't use a softmax at all, it uses a logistic binary classifier for the context/labels. In NLP, 'Negative Sampling' basically refers to the NCE-based approach.</p>

<p>More details here: <a href=""https://www.tensorflow.org/extras/candidate_sampling.pdf"" rel=""nofollow noreferrer"">https://www.tensorflow.org/extras/candidate_sampling.pdf</a>.</p>

<p>I have tested both and they both give pretty much the same results. But in word embedding literature, they always use NCE loss, and never sampled softmax.</p>

<p>Is there any reason why this is? The sampled softmax seems like the more obvious solution to prevent applying a softmax to all the classes, so I imagine there must be some good reason for the NCE loss.</p>
","natural-language-processing"
"11438","Is it a good idea to use BERT to answer a FAQ with semantic similarity?","2019-03-25 09:55:07","","2","728","<deep-learning><natural-language-processing><ai-design><applications><bert>","<p>I have been looking for BERT for many tasks. I would like to compare the performance to answer an FAQ, using BERT semantic similarity and BERT Q/A. 
However, I'm not sure it is a good idea to use semantic similarity for this task. If it is, do you think it is possible to find a dataset to fine-tune my algorithm? </p>
","natural-language-processing"
"11394","How can I make meaningful English sentences from given set of words?","2019-03-23 06:26:44","","2","1547","<machine-learning><natural-language-processing>","<p>I have a set of topics and each topic consists of a set of words. I want to make meaningful English sentences from these words. Each topic consist of 5 to 10 words and these words are relevant to each other, like <code>{code, language, test, write and function}</code> and <code>{class, public, method, string, int}</code> are two sets. I want to generate a sentence from these set of words using API.</p>
","natural-language-processing"
"11366","Algorithms and strategies to help judges rule cases","2019-03-22 01:38:14","","1","39","<natural-language-processing><text-summarization>","<p>I'm a Rails developer with a lot of web experience, but none (still) in AI.</p>

<p>I'm working in a web text editor that judges use to writing their sentences.</p>

<p>The goal is to start to use AI to help the judge rule the case, either based on his own previous rulings, either based on his colleagues rulings.</p>

<p>The judge would provide the text for the plaintiffs and defendants petitions, and based on these two inputs the system would recommend previous rulings that apply for the case. </p>

<p>I already have a considerable dataset of judges rulings inside the database, and they can be easily attached to the plaintiffs and defendants petitions for training (so this plaintiff petition + this defendant petition = this ruling). </p>

<p>This is specially challenging because the complaints can contain different subjects combined into the same petition; but the fact is that many offices use the same standardized petitions, as the defendants do as well, so I think the system can have a great chance of prediction success.</p>

<p>What algorithms or strategies should I start studying to tackle this problem? </p>

<p>Any similar articles, white papers or repositories that could help in my goal?</p>
","natural-language-processing"
"11328","Skip-Gram Model Training","2019-03-19 19:25:00","","1","116","<natural-language-processing><word2vec><word-embedding>","<p>Suppose we want to predict context words <span class=""math-container"">$w_{i-h}, \dots, w_{i+h}$</span> given a target word <span class=""math-container"">$w_i$</span> for a window size <span class=""math-container"">$h$</span> around the target word <span class=""math-container"">$w_i$</span>. We can represent this as: <span class=""math-container"">$$p(w_{i-h}, \dots, w_{i+h}|w_i) = \prod_{-h \leq k \leq h, \ k \neq 0} p(w_{i+k}|w_i)$$</span> where we model the probabilities of a word <span class=""math-container"">$u$</span> given another word <span class=""math-container"">$v$</span> as <span class=""math-container"">$$p(u|v) = \frac{\exp(\left&lt;\phi_u, \theta_v \right&gt;)}{\sum_{u' \in W} \exp(\left&lt;\phi_{u'}, \theta_v \right&gt;)}$$</span> where <span class=""math-container"">$\phi_u, \theta_v$</span> are some vector representations for words <span class=""math-container"">$u$</span> and <span class=""math-container"">$v$</span> respectively and <span class=""math-container"">$\left&lt;\phi_u, \theta_v \right&gt;$</span> is the dot product between these vector representations (which represents some sort of similarity between the words) and <span class=""math-container"">$W$</span> is a matrix of all the words.</p>

<p>In Skip-Gram Negative Sampling, we want to learn the embeddings <span class=""math-container"">$\phi_u, \theta_v$</span> that maximize the following: <span class=""math-container"">$$\sum_{u \in W} \sum_{v \in W} n_{uv} \log \sigma(\left&lt;\phi_u, \theta_v \right&gt;) +k \mathbb{E}_{\bar{v}} \log \sigma(-\left&lt;\phi_u, \theta_{\bar{v}} \right&gt;)$$</span></p>

<blockquote>
  <p><strong>Question.</strong> How exactly does this work? For example, suppose <span class=""math-container"">$k=5$</span>, the target word <span class=""math-container"">$w_i$</span> is <span class=""math-container"">$\text{apple}$</span> and we want to find
  <span class=""math-container"">$p(\text{pie}| \text{apple})$</span>. Let <span class=""math-container"">$n_{uv} = 10$</span> (number of times pie
  co-occurs with apple). Then we sample <span class=""math-container"">$5$</span> random words <span class=""math-container"">$\bar{v}$</span> that
  did not occur with <span class=""math-container"">$\text{apple}$</span> and whichever term in the sum is
  bigger is the one we predict? For example, if the first term in the
  sum is larger than the second term then we would predict that
  <span class=""math-container"">$p(\text{pie}| \text{apple}) \approx 1$</span>? Otherwise we predict that
  <span class=""math-container"">$p(\text{pie}| \text{apple}) \approx 0$</span>? Is this the correct
  intuition?</p>
</blockquote>

<p><strong>Source.</strong> <a href=""https://www.coursera.org/learn/language-processing/lecture/A4eQD/explicit-and-implicit-matrix-factorization"" rel=""nofollow noreferrer"">Here</a> at around the 10:05 mark.</p>
","natural-language-processing"
"11277","Is Reinforcement Learning the future of Natural Language Processing?","2019-03-16 22:24:45","","2","190","<reinforcement-learning><natural-language-processing>","<p>I was reading about the <a href=""https://en.wikipedia.org/wiki/Symbol_grounding_problem"" rel=""nofollow noreferrer"">grounding problem</a> after seeing it mentioned in another answer today. The article states that, in order to avoid the ""infinite regress"" of defining all words with other words, we must ground the meaning of some words in the ""sensorimotor."" </p>

<blockquote>
  <p>To be grounded, the symbol system would have to be augmented with nonsymbolic, sensorimotor capacities—the capacity to interact autonomously with that world of objects, events, actions, properties and states that its symbols are systematically interpretable (by us) as referring to.</p>
</blockquote>

<p>Obviously, this made me think of Reinforcement Learning. But I'm not exactly sure what counts as ""interaction."" Would this necessarily imply an MDP-like formulation with rewards, state transitions, etc? Or could some form of grounding be accomplished with supervised learning?</p>

<p>This seems like a pretty fundamental problem of AI. Does anyone know of research being done on grounding words/symbols within an RL agent?</p>
","natural-language-processing"
"11261","Which matrix represents the similarity between words when using SVD?","2019-03-15 17:44:50","11263","2","985","<machine-learning><natural-language-processing><math>","<p>Two words can be similar if they co-occur ""a lot"" together. They can also be similar if they have similar vectors. This similarity can be captured using cosine similarity. Let <span class=""math-container"">$A$</span> be a <span class=""math-container"">$n \times n$</span> matrix counting how often <span class=""math-container"">$w_i$</span> occurs with <span class=""math-container"">$w_k$</span> for <span class=""math-container"">$i,k = 1, \dots, n$</span>. Since computing the cosine similarity between <span class=""math-container"">$w_i$</span> and <span class=""math-container"">$w_k$</span> might be expensive, we approximate <span class=""math-container"">$A$</span> using truncated SVD with <span class=""math-container"">$k$</span> components as: <span class=""math-container"">$$A \approx W_k \Sigma W^{T}_{k} = CD$$</span></p>

<p>where <span class=""math-container"">$$C = W_{k} \Sigma \\ D = W^{T}_{k}$$</span></p>

<p>Where are the cosine similarities between the words <span class=""math-container"">$w_i$</span> and <span class=""math-container"">$w_k$</span> captured? In the <span class=""math-container"">$C$</span> matrix or the <span class=""math-container"">$D$</span> matrix?</p>
","natural-language-processing"
"11236","Why would adding all the possible embeddings be ""worse"" than using 1D-convolutions?","2019-03-14 14:43:58","","0","157","<natural-language-processing><word-embedding><word2vec><1d-convolution><n-gram>","<p>Suppose we are using word2vec and have embeddings of individual words <span class=""math-container"">$w_1, \dots, w_{10}$</span>. Let's say we wanted to analyze <span class=""math-container"">$2$</span> grams or <span class=""math-container"">$3$</span> grams.</p>
<p>Why would adding all the possible embeddings, <span class=""math-container"">$\binom{10}{2}$</span> or <span class=""math-container"">$\binom{10}{3}$</span>, be &quot;worse&quot; than using 1D-convolutions?</p>
","natural-language-processing"
"11235","Why does the BERT encoder have an intermediate layer between the attention and neural network layers with a bigger output?","2019-03-14 14:15:54","","4","1418","<deep-learning><natural-language-processing><papers><attention><bert>","<p>I am reading the BERT paper <a href=""https://arxiv.org/pdf/1810.04805.pdf"" rel=""nofollow noreferrer"">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>.</p>

<p>As I look at the attention mechanism, I don't understand why in the BERT encoder we have an intermediate layer between the attention and neural network layers with a bigger output (<span class=""math-container"">$4*H$</span>, where <span class=""math-container"">$H$</span> is the hidden size).
Perhaps it is the layer normalization, but, by looking at the code, I'm not certain. </p>
","natural-language-processing"
"11234","How to perform unsupervised anomaly detection from log file with mostly textual data?","2019-03-14 13:03:06","","2","170","<neural-networks><machine-learning><natural-language-processing><word2vec><anomaly-detection>","<p>I have a log file of the format,</p>

<blockquote>
  <p>Index, Date, Timestamp, Module, App, Context, Session, Verbosity level, Description</p>
</blockquote>

<p>The log file can be considered as a master log, which consists of individual logs from several modules constituting a distributed system. The individual log can be identified using the corresponding Module+App+Context tags. The verbosity level(Info, Warn, Error, …) and the descriptions(system generated + print statements added by developers) contain further information on the log events necessary for debugging. I need to perform an <strong>unsupervised anomaly detection</strong> with the log file as input. The output should be the functionality and timestamp of the identified anomalies. </p>

<p>Since the log is mostly textual, I plan to use NLP algorithm (Bag of words/TF-IDF) to convert the data into word vectors and then perform a generative learning method to identify the normal pattern. Can someone suggest if my approach in the right direction? Which headers of the log file would be relevant for the word-vector representation and further analysis?</p>
","natural-language-processing"
"11202","How many parameter would there be in a logistic regression model used to classify reviews into ""good"" or ""bad""?","2019-03-13 18:03:26","","1","166","<natural-language-processing><weights><logistic-regression><binary-classification><bag-of-words>","<p>Suppose we want to classify a review as good (<span class=""math-container"">$1$</span>) or bad (<span class=""math-container"">$0$</span>). We have a training data set of <span class=""math-container"">$10,000$</span> reviews. Also, suppose we have a vocabulary of <span class=""math-container"">$100,000$</span> words <span class=""math-container"">$w_1, \dots, w_{100,000}$</span>. So the data is a matrix of dimension <span class=""math-container"">$100,000 \times 10,000$</span>. Let's represent each of the words in the reviews using a bag-of-words approach over tf-idf values. Also, we normalize the rows such that they sum to <span class=""math-container"">$1$</span>.</p>
<p>In a logistic regression approach, would we have <span class=""math-container"">$10,000$</span> different logistic regression models as follows:</p>
<p><span class=""math-container"">$$ \log \left(\frac{p}{1-p} \right)_{1} = \beta_{0_{1}} + \beta_{1_{1}}w_{11} + \dots + \beta_{100,000_{1}}w_{100,000} \\ \vdots \\ \log \left(\frac{p}{1-p} \right)_{10,000} = \beta_{0_{10,000}} + \beta_{1_{10,000}}w_{11} + \dots + \beta_{100,000_{10,000}}w_{100,000}$$</span></p>
<p>So are we estimating <span class=""math-container"">$100,000 \times 10,000$</span> coefficients?</p>
","natural-language-processing"
"11178","What do the vectors of the center and outside word look like in word2vec?","2019-03-12 17:10:04","","2","396","<natural-language-processing><word2vec><word-embedding>","<p>In <a href=""https://en.wikipedia.org/wiki/Word2vec"" rel=""nofollow noreferrer"">word2vec</a>, the task is to learn to predict which words are most likely to be near each other in some long corpus of text. For each word <span class=""math-container"">$c$</span> in the corpus, the model outputs the probability distribution <span class=""math-container"">$P(O=o|C=c)$</span> of how likely each other word <span class=""math-container"">$o$</span> in the vocabulary is to be within a certain number of words away from <span class=""math-container"">$c$</span>. We call <span class=""math-container"">$c$</span> the ""center word"" and <span class=""math-container"">$o$</span> the ""outside word"".</p>

<p>We choose the softmax distribution as the output of our model: <span class=""math-container"">$$P(O=o|C=c) = \frac{\exp(\textbf{u}_{0}^{T} \textbf{v}_{c})}{\sum_{w \in \text{Vocab}} \exp(\textbf{u}_{w}^{T} \textbf{v}_c)}$$</span></p>

<p>where <span class=""math-container"">$\textbf{u}_0$</span> and <span class=""math-container"">$\textbf{v}_c$</span> are vectors that represent the outside and center words respectively. </p>

<blockquote>
  <p><strong>Question.</strong> What do the vectors  <span class=""math-container"">$\textbf{u}_0$</span> and <span class=""math-container"">$\textbf{v}_c$</span> look like? Are they just one-hot-encodings? Do we need to learn them
  too? Why is this useful?</p>
</blockquote>
","natural-language-processing"
"11144","Extract personal information about a person from a list of documents and summarize it","2019-03-11 07:31:54","","1","43","<natural-language-processing>","<p>I need to extract personal information about a person from a list of documents and summarize it to the user. If there are 2 people with the same name, the correct person should be identified. If the person has a nickname, that also needs to be identified. The input to the program can be the name of the person, address, organization name etc.
I have extracted named entities like person, org, location etc from the text using NLTK library. 
The output after extracting the named entities is mentioned below,</p>

<p>[('Michael', 'NNP', 'B-PERSON'), ('Joseph', 'NNP', 'B-PERSON'), ('Jackson', 'NNP', 'I-PERSON'), ('was', 'VBD', 'O'), ('born', 'VBN', 'O'), ('in', 'IN', 'O'), ('Gary', 'NNP', 'B-GPE'), (',', ',', 'O'), ('Indiana', 'NNP', 'B-GPE')....</p>

<p>Now, I want to extract relationships between those entities.</p>
","natural-language-processing"
"11128","How would an AI visualize a story written in natural language?","2019-03-09 16:38:17","","3","44","<natural-language-processing><image-generation>","<p>Can AI transform natural language text describing real scenarios to visual images and videos ? How does as AI interprets say a Harry Potter story if it has to reproduce it in form of videos ? Would be useful if anyone can help me with the required literature for understanding text to image transformation by AI </p>
","natural-language-processing"
"11116","How much the dialects recognition and speech recognition are relevant?","2019-03-09 03:05:14","11804","3","56","<deep-learning><natural-language-processing><classification><voice-recognition>","<p>In <a href=""https://www.tensorflow.org/tutorials/sequences/audio_recognition"" rel=""nofollow noreferrer"">this</a> tutorial, they build a speech recognition model to classify a one-second audio clip as one of ten predefined words. Suppose that we modified this problem as the following: Given an Arabic dataset, we aim to build a <em>dialects</em> recognition model to classify a <em>two</em>-second audio clip as one of <span class=""math-container"">$n$</span> local dialects using ten predefined <em>sentences</em>. I.e. for each of these ten sentences, there are <span class=""math-container"">$x$</span> different phrases and idioms which refer to the same meaning<span class=""math-container"">$^*$</span>. Now how can I take advantage of the mentioned tutorial to solve the modified problem?</p>

<p><span class=""math-container"">$*$</span> The <span class=""math-container"">$x$</span> different phrases and idioms for each sentence are not predefined.</p>
","natural-language-processing"
"11099","Translate product names with AI","2019-03-08 11:57:23","","2","119","<natural-language-processing><machine-translation>","<p>I frequently need to translate product names for hundreds of similar products -- and I have a list of past product names. Is it possible to train AI to review past translations and translate? It doesn't have any special grammar, simply the name (with some industry-specific usage that a general machine translator can't do.) What would I need to do to get started?</p>
","natural-language-processing"
"11092","Dialects classification using deep learning","2019-03-07 22:28:01","","1","85","<deep-learning><natural-language-processing><classification><applications><voice-recognition>","<p>Dialects differ a lot between cities in my country, Syria. People sometimes express themselves using different local phrases and idioms which refer to the same topic. So, I came up with the idea of creating an Android application shows a limited set of sentences or expressions while asking you to express them in the local dialect of your region <strong>orally</strong>, after that this application tries to figure out what your dialect is. For a short period of time, I'm going to launch an Android application in order to collect the needed dataset which will be a new contribution. First of all, I need some helpful answers to my questions:</p>

<ol>
<li>In general, is a period of 6 months enough for such a project to be done by only one student who is a <strong>beginner in this field</strong> or it is harder than it seems?</li>
<li>Are the libraries and tools needed to do this project available for free?</li>
<li>I know that more training data leads to more accurate results. In order to obtain good results, what is the estimated minimum number of training data needed for this model?</li>
<li>How do you advise me to begin?</li>
<li>How much is my suggested project relevant to the project attached in this <a href=""https://www.tensorflow.org/tutorials/sequences/audio_recognition"" rel=""nofollow noreferrer"">link</a>?</li>
</ol>

<p>kindly write down your suggested edits and recommendations if any.</p>

<p><strong>Edit</strong> for the 5th question: also see <a href=""https://arxiv.org/ftp/arxiv/papers/1707/1707.09917.pdf"" rel=""nofollow noreferrer"">this</a> paper.</p>
","natural-language-processing"
"11047","Isolate the speech of two people in an audio record with two people only","2019-03-06 08:57:54","","1","176","<machine-learning><natural-language-processing><python><audio-processing>","<p>I would like to find a way to isolate the speech of each of the people in an audio record so I can create a file of that form :</p>

<pre><code>[
   {
       ""voice_fingerprint"": ""701066EDD3A0A40A2F53F61EAFD0E6AB"",
       ""sentences"": {
           {
               ""sentence"": ""do you like red apples"",
               ""position"": 1.39 // Seconds. Time position in the audio record
           },
           {
               ""sentence"": ""and how do you feel about time shifts"",
               ""position"": 7.21
           }
       }
   },
   {
       ""voice_fingerprint"": ""8FFEA051AF3E3FB9A80A51A98FE05896"",
       ""sentences"": {
           {
               ""sentence"": ""yes I do like them"",
               ""position"": 4.54
           },
           {
               ""sentence"": ""i feel well about traveling"",
               ""position"": 10.18
           }
       }
   }
]
</code></pre>

<p>This may be an interview record.</p>

<p>The problem <strong>IS NOT</strong> the Speech to Text, but to <strong>isolate the two people's sentences</strong>. Preferably in Python.</p>

<p>Have you ever worked on this ? Do you have any hints ?</p>
","natural-language-processing"
"10989","How do the sine and cosine functions encode position in the transformer?","2019-03-03 19:41:22","","2","265","<deep-learning><natural-language-processing><transformer><attention><positional-encoding>","<p>After going through both the ""<a href=""http://jalammar.github.io/illustrated-transformer/"" rel=""nofollow noreferrer"">Illustrated Transformer</a>"" and ""<a href=""http://nlp.seas.harvard.edu/2018/04/03/attention.html"" rel=""nofollow noreferrer"">Annotated Transformer</a>"" blog posts, I still don't understand how the sinusoidal encodings are representing the position of elements in the input sequence. </p>

<p>Is it the fact that since each row (input token) in a matrix (entire input sequence) has a unique waveform as its encoding, each of which can be expressed as a linear function of any other element in the input sequence, then the transformer can learn relations between these rows via linear functions? </p>
","natural-language-processing"
"10987","How can/should I use AI to populate a game (in the game theory sense) from text input","2019-03-03 18:32:27","","1","51","<deep-learning><natural-language-processing><game-theory>","<p>I'm wanting to conduct game theoretic analyses of ongoing conflict situations (e.g. the US/North Korea negotiations; Syrian conflict; etc)  as reported in the news media. I believe that AI may help me do this by helping me to pick out from the text: the parties involved; the issues over which they are in conflict; the choices they have; their preferences.  However I'm not sure whether to approach this using 'modern' 'deep learning' approaches or to try something along the lines of the classic work by Schank, deJong etc. who used the notion of scripts (and sketchy scripts) in their work with conceptual dependency approaches.  Does anyone have comments, suggestions that may guide my work please?</p>
","natural-language-processing"
"10958","Can a sentence have different parse trees?","2019-03-02 06:02:53","10964","4","1554","<natural-language-processing>","<p>I just read about the concept of a <a href=""https://en.wikipedia.org/wiki/Parse_tree"" rel=""nofollow noreferrer"">parse tree</a>.</p>
<p>In my understanding, a valid parse tree of a sentence needs to be validated by a linguistic expert. So, I concluded, a sentence only has one parse tree.</p>
<p>But, is that correct? Is it possible a sentence has more than one valid parse tree (e.g. constituency-based)?</p>
","natural-language-processing"
"10895","How to make chatbot using NLP like Dialogflow?","2019-02-26 14:01:34","","1","266","<chat-bots><natural-language-processing>","<p>I want to apply the concept that exists in the <a href=""https://dialogflow.com/"" rel=""nofollow noreferrer"">Dialogflow</a> API in my e-commerce website.</p>

<p>I get some references in this regard :</p>

<ol>
<li>Tokenization</li>
<li>Part Of Speech</li>
<li>Named Entity Recognition</li>
<li>Rule based </li>
</ol>

<p>I just saw that I just didn't understand how to implement it on the website. 
so I still don't know how the truth is.</p>

<p>please give me a method or explanation that can help me create a chatbot for ecommerce that can give action when a user asks for a product and wants to place an order or something else.</p>

<p>Please give me some explanation or method or references :(</p>
","natural-language-processing"
"10869","How do we know if GPT-2 is a better language model?","2019-02-25 09:51:23","","7","735","<natural-language-processing><transformer><gpt>","<p>You may have heard of GPT2, a new language model. It has recently attracted attention from the general public as the foundation that published the paper, <a href=""https://blog.openai.com/better-language-models/"" rel=""nofollow noreferrer"">OpenAI</a>, ironically refused to share the whole model fearing dangerous implications. Along the paper, they also published a manifesto to justify their choice: &quot;Better Language Models and Their Implications&quot;. And soon a lot of media were publishing articles discussing the choice and its effectiveness to actually prevent bad implications. I am not here to discuss the ethical components of this choice but the actual performance of the model.</p>
<p>The model got my attention too and I downloaded the small model to play with. To be honest I am far from impressed by the results. Some times the first paragraph of the produced text appears to make sense, but nine times out of ten it is giberish by the first or the second sentence. Exemples given in the paper seems to be &quot;Lucky&quot; outputs, cherry picked by human hands. Overall, the paper may suffer from a very strong publication bias.</p>
<p>However, most article we can read on the internet seems to take its powerfulness for granted. <a href=""https://www.technologyreview.com/s/612975/ai-natural-language-processing-explained/"" rel=""nofollow noreferrer"">The MIT technology review</a> wrote:</p>
<blockquote>
<p>The language model can write like a human</p>
</blockquote>
<p><a href=""https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction"" rel=""nofollow noreferrer"">The Guardian</a> wrote</p>
<blockquote>
<p>When used to simply generate new text, GPT2 is capable of writing plausible passages that match what it is given in both style and subject. It rarely shows any of the quirks that mark out previous AI systems, such as forgetting what it is writing about midway through a paragraph, or mangling the syntax of long sentences.</p>
</blockquote>
<p>The model appears generally qualified as a &quot;breakthrough&quot;. These writings do not match my personal experimentation as produced texts are rarely consistent / syntactically correct.</p>
<p>My question is: without the release of the whole model for ethical reasons, how do we know if the model is really that powerful?</p>
","natural-language-processing"
"10855","Anomaly Detection in distributed system using generated log file","2019-02-24 15:56:06","","2","270","<neural-networks><machine-learning><natural-language-processing><pattern-recognition>","<p>I am developing an AI tool for <strong>anomaly detection in a distributed system</strong>.  The system supports an interface that combines several individual logs into a single log file generating approx. 7000 entries/min. The logs entries are partially system generated (d-Bus, IPC, ….)  and human written statements (Status not received, initialized successfully, ….). The developers use the generated log for debugging. The entries have been configured to have a similar format depending on the generated system (timestamp, ids, component, context, verbosity level, description, ….). </p>

<p><em>Background:</em><br>
1. The history of the identified anomalies is minimal and not archived.<br>
2. Not many similar event templates in log files.<br>
3. Software execution rules are not clearly documented.<br>
4. The log events are co-related.  </p>

<p>What are the recommended algorithms (Statistical, NLP, ML, Neural networks) that can be used to efficiently perform pattern extraction on the entries and identify existing and new anomalous behavior?</p>
","natural-language-processing"
"10842","What is the motivation for row-wise convolution and folding in Kalchbrenner et al. (2014)?","2019-02-23 17:01:19","","4","61","<machine-learning><deep-learning><natural-language-processing>","<p>I was reading the paper by Kalchbrenner et al. titled <a href=""https://arxiv.org/pdf/1404.2188.pdf"" rel=""nofollow noreferrer"">A Convolutional Neural Network for Modelling Sentences</a> and I am struggling to understand their definition of convolutional layer.</p>
<p>First, let's take a step back and describe what I'd expect the 1D convolution to look like, just as defined in <a href=""https://arxiv.org/pdf/1408.5882.pdf"" rel=""nofollow noreferrer"">Yoon Kim (2014)</a>.</p>
<blockquote>
<p>sentence. A sentence of length n (padded where necessary) is represented as</p>
<p><span class=""math-container"">$x_{1:n} = x_1 \oplus  x_2 \oplus \dots ⊕ x_n,$</span> (1)</p>
<p>where <span class=""math-container"">$\oplus$</span> is the concatenation operator. In general, let <span class=""math-container"">$x_{i:i+j}$</span> refer to the concatenation of words <span class=""math-container"">$x_i, x_{i+1}, \dots, x_{i+j}$</span>. A convolution operation involves a filter <span class=""math-container"">$w \in \mathbb{R}^{hk}$</span>, which is applied to a window of h words to produce a new feature. For example, a feature ci is generated from a window of words <span class=""math-container"">$x_{i:i+h−1}$</span> by</p>
<p><span class=""math-container"">$c_i = f(w \cdot x_{i:i+h−1} + b)$</span> (2).</p>
<p>Here <span class=""math-container"">$b \in \mathbb{R}$</span> is a bias term and <span class=""math-container"">$f$</span> is a non-linear function such as the hyperbolic tangent. This filter is applied to each possible window of words in the sentence <span class=""math-container"">$\{x_{1:h}, x_{2:h+1}, \dots, x_{n−h+1:n}\}$</span> to produce a feature map</p>
<p><span class=""math-container"">$c = [c_1, c_2, \dots, c_{n−h+1}]$</span>, (3)</p>
<p>with <span class=""math-container"">$c \in \mathbb{R}^{n−h+1}$</span>.</p>
</blockquote>
<p>Meaning a single feature detector transforms every window from the input sequence to a single number, resulting in <span class=""math-container"">$n-h+1$</span> activations.</p>
<p>Whereas in Kalchbrenner's paper, the convolution is described as follows:</p>
<blockquote>
<p>If we temporarily ignore the pooling layer, we may state how one computes each d-dimensional column a in the matrix a resulting after the convolutional and non-linear layers. Define <span class=""math-container"">$M$</span> to be the matrix of diagonals:</p>
<p><span class=""math-container"">$M = [diag(m:,1), \dots, diag(m:,m)]$</span> (5)</p>
<p>where <span class=""math-container"">$m$</span> are the weights of the d filters of the wide convolution. Then after the first pair of a convolutional and a non-linear layer, each column <span class=""math-container"">$a$</span> in the matrix <strong>a</strong> is obtained as follows, for some index <span class=""math-container"">$j$</span>:</p>
<p><a href=""https://i.sstatic.net/7EwxO.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/7EwxO.png"" alt=""enter image description here"" /></a></p>
<p>Here <span class=""math-container"">$a$</span> is a column of first order features. Second order features are similarly obtained by applying Eq. 6 to a sequence of first order features <span class=""math-container"">$a_j, \dots, a_{j+m'−1}$</span> with another weight matrix <span class=""math-container"">$M'$</span>. Barring pooling, Eq. 6 represents a core aspect of the feature extraction function and has a rather general form that we return to below. Together with pooling, the feature function induces position invariance and makes the range of higher-order features variable.</p>
</blockquote>
<p>As described in <a href=""https://stats.stackexchange.com/questions/345977/what-does-the-matrix-m-diagm-1-ldots-diagm-m-look-like"">this question</a>, the matrix <span class=""math-container"">$M$</span> has dimensionalty of <span class=""math-container"">$d$</span> by <span class=""math-container"">$d * m$</span> and the vector of concatenated <span class=""math-container"">$w$</span>'s has dimensionality <span class=""math-container"">$d * m$</span>. Thus the multiplication produces a vector of dimensionality d (for a single convolution of a single window!).</p>
<p>Architecture visualization from the paper seems to confirm this understanding:</p>
<p><a href=""https://i.sstatic.net/3iHN7.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/3iHN7.png"" alt=""enter image description here"" /></a></p>
<p>The two matrices in the second layer represent two feature maps. Each feature map has dimensionality <span class=""math-container"">$(s + m - 1) \times d$</span>, and not <span class=""math-container"">$(s + m - 1)$</span> as I would expect.</p>
<p>Authors refer to a &quot;conventional&quot; model where feature maps have only one dimension as Max-TDNN and differentiate it from their own.</p>
<p>As the authors point out, feature detectors in different rows are fully independent from each other until the top layer. Thus they introduce the Folding layer, which merges each pair of rows in the penultimate layer (by summation), reducing their number in half (from <span class=""math-container"">$d$</span> to <span class=""math-container"">$d/2$</span>).</p>
<p><a href=""https://i.sstatic.net/e1Dyn.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/e1Dyn.png"" alt=""architecture"" /></a></p>
<p>Sorry for the prolonged introduction, here are my two main questions:</p>
<ol>
<li><p>What is the possible motivation for this definition of convolution (as opposed to Max-TDNN or e.g. Yoon Kim's model)</p>
</li>
<li><p>In the Folding layer, why is it satisfying to only have dependence between pairs of corresponding rows? I don't understand the gain over no dependence at all.</p>
</li>
</ol>
","natural-language-processing"
"10823","How can I train a neural network to grade the user's answers to a questionnaire?","2019-02-22 16:51:21","","3","217","<neural-networks><machine-learning><natural-language-processing><classification>","<p>I have a questionnaire consisting of over 10 questions. The questionnaire is being answered by a lot of people, which I have manually graded. Each question can give the user up to 10 points depending on how they have answered. </p>

<p>Let's say that my dataset is big enough, how would I go about using a neural network to automatically grade these questions for me?</p>

<p>I have used a convolutional neural network before for image classification, but, when dealing with text classification, where should I start? Is there some sort of tutorial out there that covers this with a similar example?</p>
","natural-language-processing"
"10810","Detect named entities inside words using spaCy","2019-02-22 09:02:25","","1","75","<natural-language-processing><chat-bots>","<p>I am using rasa nlu for training an NLU system to detect intents and slots. Now, some languages have word endings with their nouns (like Finnish, e.g. ""in Berlin"" -> ""Berliinissä""). I have tried to annotate the characters in the training data as entities, but then I run the model, it doesn't detect the characters inside the word. When those characters are a separate word, only then they're detected. I am unable to think of an implementation to effectively detect named entities within a word. Suggestions needed.</p>
","natural-language-processing"
"10617","Do I need an encoder-decoder architecture to predict the next item of a sequence?","2019-02-16 16:09:31","10619","1","472","<deep-learning><natural-language-processing><recurrent-neural-networks><machine-translation>","<p>I am trying to understand how RNNs are used for sequence modelling.</p>

<p>On a <a href=""https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"" rel=""nofollow noreferrer"">tutorial here</a>, it mentions that if you want to translate say a sentence from English to French you can use an encoder-decoder set-up as they described.</p>

<p>However what if you want to do a sequence to sequence modelling where your inputs and outputs are of the same domain but you just want to predict the next output of a sequence.</p>

<p>For example if I want to use sequence modelling to learn the sine function. So say I have 20 y-coordinates from <span class=""math-container"">$y = sin(x)$</span> from 20 evenly spaced out x-coordinates and I want to predict the next 10 or so y-coordinates. Would I use an encoder-decoder setup here? </p>
","natural-language-processing"
"10540","Is there a way to understand the type of a sentence?","2019-02-12 19:22:41","","3","735","<natural-language-processing><classification><computational-linguistics><semantics>","<p>I am a beginner, just started studying around NLP, specifically various language models. So far, my understanding is that -  the goal is to understand/produce natural language.</p>

<p>So far the methods I have studied speak about correlation of words, using correct combination to make a meaningful sentence. I also have the sense that the language modeling does not really care about the punctuation marks (or did I miss it?)</p>

<p>Thus I am curious is there a way they can classify sentence types such as Declarative, Imperative, Interrogative or Exclamatory?</p>
","natural-language-processing"
"10508","What is the difference between automatic transcription and automatic speech recognition?","2019-02-11 10:38:55","","3","183","<natural-language-processing><comparison><speech-synthesis>","<p>What is the difference between automatic transcription and automatic speech recognition? Are they the same?</p>

<p>Is my following interpretation correct?</p>

<p><em>Automatic transcription</em>: it converts the speech to text by looking at the whole spoken input </p>

<p><em>Automatic speech recognition</em>: it converts the speech to text by looking into word by word choices</p>
","natural-language-processing"
"10496","How to train chat bot on infinite non-stationary data?","2019-02-10 18:39:19","","1","32","<deep-learning><reinforcement-learning><natural-language-processing><long-short-term-memory>","<p>I have continual simulated data of million sentences of two simulated persons talking to each other in a room and I want to model one of the persons speech. Now, during this period things in the room can change. Let's say, one of them says ""Where is the book?"" The other one responds ""I placed the book on the bookshelf"". Now during time, the position of the book changes, so the question Where is the book? does not have stationary answer i.e the answer changes during time. However, in general the answer has to be ""The book is at some_location"" and not something else. Also, the mentioning that the book is placed on the bookshelf can be sometimes 10, 100 or 1000 sentences before the question ""Where is the book?""</p>

<p>How do you approach this kind of problem? Since the window can be too large I can not split data into training samples of 10, 100 or 1000 sentences. My guess is that I should use BPTT + LSTM and train in one shot without shuffling the data. I am not sure this is feasible, so I will greatly appreciate your help! I have also my doubts what if ""Where is the book?"" appears 20 sentences after (instead of 10,100 and 1000) in the test set (which is not same as the training set)? Also, should I use Reinforcement Learning (since I can generate the data) or Supervised learning?</p>

<p>Thanks a lot!</p>
","natural-language-processing"
"10446","Is a dataset of roughly 700 sentences of an average length of 15 words enough for text classification?","2019-02-07 22:33:01","10455","2","376","<natural-language-processing><classification><datasets><chat-bots><text-classification>","<p>I'm building a customer assistant chatbot in Python. So, I am modelling this problem as a text classification task. I have available more or less 7 hundred sentences of an average length of 15 words (unbalanced class).</p>

<p>What do you think, knowing that I have to do an oversampling, is this dataset large enough?</p>
","natural-language-processing"
"10259","Is it possible to recognise a person based on what they have written?","2019-01-28 04:52:15","10260","5","141","<natural-language-processing><reference-request><computational-linguistics>","<p>I needed to make a system for recognizing people based on hundreds of texts by finding similarities in their written text grammatically or similarities between words they choose for writing. I don't want it so accurate, but I wanted to know if it is possible.</p>
<p>For example, finding one person with two accounts or more on a forum or something in that case (texts already gathered). I'm just wondering if it's possible and what field should I research for.</p>
","natural-language-processing"
"10133","What are the segment embeddings and position embeddings in BERT?","2019-01-22 11:01:17","10630","11","13027","<machine-learning><deep-learning><natural-language-processing><bert>","<p><a href=""https://i.sstatic.net/thmqC.png"" rel=""noreferrer""><img src=""https://i.sstatic.net/thmqC.png"" alt=""enter image description here""></a></p>

<p>They only reference in the paper that the position embeddings are learned, which is different from what was done in ELMo.</p>

<p>ELMo paper - <a href=""https://arxiv.org/pdf/1802.05365.pdf"" rel=""noreferrer"">https://arxiv.org/pdf/1802.05365.pdf</a></p>

<p>BERT paper - <a href=""https://arxiv.org/pdf/1810.04805.pdf"" rel=""noreferrer"">https://arxiv.org/pdf/1810.04805.pdf</a></p>
","natural-language-processing"
"10114","What's the commercial usage of ""image captioning""?","2019-01-21 13:54:08","10116","1","1395","<deep-learning><natural-language-processing><image-recognition>","<p>If ""image captioning"" is utilized to make a commercial product, what application fields will need this technique? And what is the level of required performance for this technique to be usable?</p>
","natural-language-processing"
"10102","Natural language recommendation system: to pre-classify inputs or not?","2019-01-21 03:38:23","","3","37","<classification><natural-language-processing>","<p>Does it help to &quot;pre-classify&quot; natural language inputs using labeled input fields? E.g., &quot;Who,&quot; &quot;What,&quot; &quot;Where,&quot; &quot;When,&quot; &quot;Why,&quot; &quot;How,&quot; and &quot;How much?&quot; Or is a single, monolithic, free-form, long-text input field equally effective and efficient for model training purposes?</p>
Scenario 1: Without input labels
<blockquote>
<p>We are three research fellows, Alice, Bob and Charlie at the University of Copenhagen. We want to understand the development of the human visual system. This knowledge will help in the prevention and treatment of certain vision problems in children. Further, the rules that guide development in the visual system can be applied to other systems within the brain. Our work, therefore, has wide application to other developmental disorders affecting the nervous system. We will conduct this research in 2019 under a budget of $15,000.</p>
</blockquote>
Scenario 2: With input lables
<blockquote>
<p><strong>Who:</strong> We are three research fellows, Alice, Bob and Charlie.</p>
<p><strong>What:</strong> We want to understand the development of the human visual system.</p>
<p><strong>Where:</strong> At the University of Copenhagen.</p>
<p><strong>When:</strong> During the calendar year of 2019.</p>
<p><strong>Why:</strong> This knowledge will help in the prevention and treatment of certain vision problems in children.</p>
<p><strong>How:</strong> Further, the rules that guide development in the visual system can be applied to other systems within the brain.</p>
<p><strong>How Much:</strong> The research will cost $15,000.</p>
</blockquote>
<p>Use Case:</p>
<p>I am building an AI/ML recommendation system. Users subscribe to the system to get recommendations of research projects they might like to participate in or fund. There will be many projects from all over the globe. Far too many for a human to sort through and filter. So AI will sort and filter automatically.</p>
<p>Will pre-classifying input fields using labels help the training algorithm be more efficient or effective?</p>
","natural-language-processing"
"9982","How to recognise metaphors in texts using NLP/NLU?","2019-01-14 11:59:12","9986","7","2890","<machine-learning><natural-language-processing><natural-language-understanding><computational-linguistics>","<p>What are the current NLP/NLU techniques that can extract metaphors from texts?</p>
<p>For example</p>
<blockquote>
<p>His words cut deeper than a knife.</p>
</blockquote>
<p>Or a simpler form like:</p>
<blockquote>
<p>Life is a journey that must be travelled no matter how bad the roads and accommodations.</p>
</blockquote>
","natural-language-processing"
"9824","How do I create chatbots without machine learning?","2019-01-04 09:28:17","","0","403","<natural-language-processing><chat-bots>","<p>I am looking for an non-ML method for two chat bots to communicate to each other about a specific topic. I am looking for an ""explainable AI"" method, as opposed to a ""black-box"" one (like a neural network).</p>
","natural-language-processing"
"9813","Handling emotion in informal text (Hi vs HIIIIII!!!!)?","2019-01-03 17:45:03","","4","1202","<neural-networks><machine-learning><natural-language-processing>","<p>This is a question related to <a href=""https://ai.stackexchange.com/questions/9725/neural-network-to-detect-spam"">Neural network to detect &quot;spam&quot;?</a>. 
I'm wondering how it would be possible to handle the emotion conveyed in text. In informal writing, especially among a juvenile audience, it's usual to find emotion expressed as repetition of characters. For example, ""Hi"" doesn't mean the same as ""Hiiiiiiiiiiiiiii"" but ""hiiiiii"", ""hiiiiiiiii"", and ""hiiiiiiiiii"" do. </p>

<p>A naive solution would be to preprocess the input and remove the repeating characters after a certain threshold, say, 4. This would probably reduce most long ""hiiiii"" to 4 ""hiiii"", giving a separate meaning (weight in a context?) to ""hi"" vs ""long hi"".</p>

<p>The naivete of this solution appears when there are combinations. For example,
haha vs hahahahaha or lol vs lololololol. Again, we could write a regex to reduce lolol[ol]+ to lolol. But then we run into the issue of hahahaahhaaha where a typo broke the sequence.</p>

<p>There is also the whole issue of Emoji. Emoji may seem daunting at first since they are special characters. But once understood, emoji may actually become helpful in this situation. For example, 😂 may mean a very different thing than 😂😂😂😂😂, but 😂😂😂😂😂 may mean the same as 😂😂😂😂 and 😂😂😂😂😂😂. </p>

<p>The trick with emojis, to me, is that they might actually be easier to parse. Simply add spaces between 😂 to convert 😂😂😂😂 to 😂 😂 😂 😂 in the text analysis. I would guess that repetition would play a role in training, but unlike ""hi"", and ""hiiii"", Word2Vec won't try to categorize 😂 and 😂😂 as different words (as I've now forced to be separate words, relying in frequency to detect the emotion of the phrase). </p>

<p>Even more, this would help the detection of ""playful"" language such as 😠😂😂😂, where the 😠 emoji might imply there is anger, but alongside 😂 and especially when repeating 😂 multiple times, it would be easier for a neural network to understand that the person isn't really angry.</p>

<p>Does any of this make sense or I'm going in the wrong direction?</p>
","natural-language-processing"
"9756","LSTM language model not working","2018-12-30 15:45:51","9762","1","961","<neural-networks><natural-language-processing><recurrent-neural-networks><keras><long-short-term-memory>","<p>I am trying to use a Keras LSTM neural network for character level language modelling. As the input, I give it the last 50 characters and it has to output the next one. It has 3 layers of 400 neurons each. For the training data, I am using 'War of The Worlds' by H.G. Wells which adds up to 269639 training samples and 67410 validation samples.</p>

<p>After 7 epochs the validation accuracy has reached 35.1% and the validation loss has reached 2.31. However, after being fed the first sentence of war of the worlds to start it outputs:</p>

<blockquote>
  <p>the the the the the the the the the the the the the the the the...</p>
</blockquote>

<p>I'm not sure where I'm going wrong; I don't want it to overfit and output passages straight from the training data but I also don't want it to just output 'the' repeatedly. I'm really at a loss as to what I should do to improve it.</p>

<p>Any help would be greatly appreciated. Thanks!</p>
","natural-language-processing"
"9660","What AI designs are suited for producing title replacements?","2018-12-23 06:20:11","","1","73","<machine-learning><ai-design><natural-language-processing>","<p>Problem: ""For a given news article, generate another title for the article if the article is to be published under a different Publication.""</p>

<p>Which algorithm will be well suited for this? Should I use naive Bayesian or any NLP algorithm? </p>
","natural-language-processing"
"9557","Is there bidirection sequence-to-sequence neural machine translation?","2018-12-16 21:30:00","","1","52","<neural-networks><machine-learning><natural-language-processing><long-short-term-memory>","<p>I have heard about bidirectional RNN LSTM units (endcoders-decoders), but my question is - is there bidirectional neural machine translation, that uses A->B weights for the translation in the opposite direction B->A? If not, then what are the obstacles to such system?</p>
","natural-language-processing"
"9494","Grouping products and naming groups","2018-12-12 14:33:00","9499","0","198","<natural-language-processing><applications>","<p>I'm working on a home tool that will help create a shopping list from a list of recipes chosen for a coming week.</p>

<p>This boils down to:</p>

<ol>
<li>Extracting ingredients and their quantities from recipes.</li>
<li>Grouping similar ingredients together.</li>
<li>Summing up quantities for similar ingredients.</li>
<li>Naming groups of similar products in a shopping list.</li>
</ol>

<p>The tasks seem non-trivial for a few reasons.</p>

<ul>
<li><p><strong>Similar ingredients are described differently</strong>, depending on the recipe book/portal, e.g.:</p>

<blockquote>
  <ul>
  <li>5 lemons</li>
  <li>5 lemons (to be squeezed)</li>
  <li>5 fresh lemons</li>
  <li>5 big yellow lemons</li>
  </ul>
</blockquote></li>
<li><p><strong>Recipes lists alternatives for ingredients</strong> (e.g., <em>""3 lemons or 5 limes""</em>), leaving decision up to a user. </p></li>
<li><p><strong>Recipes involve some information about product-preprocessing</strong>. For instance, one has to buy lemons instead of lemon juice when the recipe says:</p>

<blockquote>
  <ul>
  <li>100ml lemon juice</li>
  <li>100ml freshly squeezed lemon juice</li>
  </ul>
</blockquote></li>
<li><p><strong>My language has a complex inflection</strong>. For instance, there can be multiple plural forms of a noun and the form of an adjective must be agreed with a form of noun. Adapting NLP algorithms designed for English language might be not straightforward and require some lemmatizing/stemming but not for single words, but whole phrases.</p></li>
<li><p><strong>Naming products group is hard</strong>. Once fresh lemons and big yellow lemons are group together and their quantities summed up, one need to decide how to name this group in a shopping list, e.g.: <em>""10 lemons""</em> or <em>""10 fresh lemons""</em>.</p></li>
</ul>

<p>Is there any research paper that would cover those challenges?</p>

<p>Especially applied in the same domain? </p>
","natural-language-processing"
"9397","In speech recognition, what kind of signal is used?","2018-12-08 06:25:30","9402","1","523","<natural-language-processing>","<p>Speech is a major primary mechanism of communication between humans. With respect to artificial intelligence, which signal is used to identify the sequence of words in speech?</p>
","natural-language-processing"
"9372","Can Machine Learning be applied to decipher the script of lost ancient languages?","2018-12-06 18:34:22","","6","1274","<machine-learning><natural-language-processing><applications>","<p>Can Machine Learning be applied to decipher the script of <strong>lost</strong> ancient languages (namely, languages that were being used many years ago, but currently are not used in human societies and have been forgotten, e.g. <a href=""https://en.wikipedia.org/wiki/Avestan"" rel=""nofollow noreferrer"">Avestan language</a>)?</p>

<p>If yes, is there already any successful experiment to decipher the script of unknown ancient languages using Machine Learning?   </p>
","natural-language-processing"
"9358","How can I evaluate the performance of a system that generates text?","2018-12-06 06:44:42","","1","44","<natural-language-processing><software-evaluation><data-science>","<p>I am preparing to perform research comparing the performance of two different systems that probabilistically generate the next word of an input sentence.</p>

<p>For example, given the word 'the', a system might output 'car', or any other word. Given the input 'the round yellow', a system might output 'sun', or it might output something that doesn't make sense.</p>

<p>My question is, how can I quantitatively evaluate the performance of the two different systems performing this task? Of course if I tested each system manually I could qualitatively determine how often each system responded in a way that makes sense, and compare how often each system responds correctly, but I'd really like a meaningful quantitative method of evaluation that I could preferably automate.</p>

<p>Precision and recall don't seem like they would work here, seeing as for each given input there are many potentially acceptable outputs. Any suggestions?</p>
","natural-language-processing"
"9179","Does an advanced Dialogue state tracking eliminate the need of intent classifier and slot filling models in dialogue systems/ chatbots?","2018-11-26 13:12:13","","2","136","<neural-networks><machine-learning><natural-language-processing><recurrent-neural-networks><chat-bots>","<p>I am learning to create a dialogue system. The various parts of such a system are Intent classifier, slot filling, Dialogue state tracking (DST), dialogue policy optimization and NLG.</p>

<p>While reading <a href=""https://storage.googleapis.com/pub-tools-public-publication-data/pdf/44018.pdf"" rel=""nofollow noreferrer"">this</a> paper on DST, I found out that a discriminative  sequence model of DST can identify goal constraints, fill slots and maintain state of the conversation. </p>

<p>Does this mean that now I dont need to create an intent classifier and slot filling models separately as the tasks are already being done by this DST? Or I am misunderstanding both the things and they are separate?</p>
","natural-language-processing"
"9169","Neural network architecture for comparison","2018-11-26 01:39:10","9175","2","200","<neural-networks><natural-language-processing><models><architecture>","<p>When someone wants to compare 2 inputs, the most widespread idea is to use a Siamese architecture. Siamese architecture is a very high level idea, and can be customized based on the problem we are required to solve.</p>

<p><strong>Is there any other architecture type to compare 2 inputs ?</strong> </p>

<hr>

<h3>Background</h3>

<p>I want to use a neural network for comparing 2 documents (semantic textual similarity). Siamese network is one approach, I was wondering if there is more.</p>
","natural-language-processing"
"9141","Can BERT be used for sentence generating tasks?","2018-11-24 13:44:39","10628","32","43109","<neural-networks><deep-learning><natural-language-processing><bert><text-generation>","<p>I am a new learner in NLP. I am interested in the sentence generating task. As far as I am concerned, one state-of-the-art method is the <a href=""https://github.com/karpathy/char-rnn"" rel=""noreferrer"">CharRNN</a>, which uses RNN to generate a sequence of words.</p>

<p>However, <a href=""https://arxiv.org/abs/1810.04805"" rel=""noreferrer"">BERT</a> has come out several weeks ago and is very powerful. Therefore, I am wondering whether this task can also be done with the help of BERT? I am a new learner in this field, and thank you for any advice!</p>
","natural-language-processing"
"8999","How to know which kind of adverb in NLP Parts of Speech (POS) tagging?","2018-11-16 11:47:11","","0","312","<natural-language-processing>","<p>There are 4 kinds of adverbs :</p>

<ul>
<li>Adverbs of Manner. For example, slowly, quietly</li>
<li>Adverbs of Place. For example, there, far</li>
<li>Adverbs of Frequency. For example, everyday, often</li>
<li>Adverbs of Time. For example, now, first, early</li>
</ul>

<p>nltk, spacy and textblob only tag a token as an adverb without specifying which kind it is.</p>

<p>Are there any libraries which tag including the type of adverb?</p>
","natural-language-processing"
"8958","Possible to translate generic English-language document into higher-order logic?","2018-11-13 17:22:08","","-1","75","<natural-language-processing><logic>","<h3>(Un-original) idea:</h3>
<p>Wouldn't it be cool if we could fact-check using an algorithm that could understand a whole bunch of documents (e.g. scientific papers) as higher-order logic?</p>
<h3>Question:</h3>
<p>What work has been done on this to date?</p>
<h3>What I've got so far:</h3>
<p>(1) I seem to recall there being prior work to create a subset of English (I think intended for use in scientific writing) that could be easily interpreted by an algorithm. This doesn't quite get us to the algorithm described above (as it's restricted to a subset of English) - but seems pertinent.</p>
<p>(2) Once parsed, I guess a resolution algorithm like that in <a href=""https://en.wikipedia.org/wiki/Prolog"" rel=""nofollow noreferrer"">Prolog</a> could be used to check wether a fact (presumably also inputted as a logical statement) contradicts the logic of the documents?</p>
","natural-language-processing"
"8578","Which model should I use to determine the similarity between predefined sentences and new sentences?","2018-10-22 09:31:20","","4","170","<machine-learning><natural-language-processing><tensorflow>","<p>The Levenshtein algorithm and some ratio and proportion may handle this use case.</p>

<blockquote>
  <p>Based on the pre-defined sequence of statements, such as ""I have a dog"", ""I own a car"" and many more, I must determine if an another input statement such as ""I have a cat"" is the same or how much percentage does the input statement is most likely equal to the pre-defined statements.</p>
</blockquote>

<p>For Example:</p>

<blockquote>
  <p>Predefined statements: ""I have a dog"", ""I own a car"", ""You think you are smart""</p>
</blockquote>

<p>Input statements and results:</p>

<blockquote>
  <p>I have a dog - 100% (because it has exact match), I have a cat - ~75% (because it was almost the same except for the animal, think - ~10% (because it was just a small part of the third statement), bottle - 0% (because it has no match at all)</p>
</blockquote>

<p>The requirement is that TensorFlow be used rather than Java, which is the language I know, so any help with what to look at to get started would be helpful.</p>

<p>My plan was to use the predefined statements as the train_data, and to output only the accuracy during the prediction, but I don't know what model to use. Please, guide me with the architecture and I will try to implement it.</p>
","natural-language-processing"
"8487","How to understand marginal loglikelihood objective function as loss function (explanation of an article)?","2018-10-17 20:16:58","","0","192","<neural-networks><natural-language-processing><long-short-term-memory><objective-functions>","<p>I am reading article <a href=""https://allenai.org/paper-appendix/emnlp2017-wt/"" rel=""nofollow noreferrer"">https://allenai.org/paper-appendix/emnlp2017-wt/</a> <a href=""http://ai2-website.s3.amazonaws.com/publications/wikitables.pdf"" rel=""nofollow noreferrer"">http://ai2-website.s3.amazonaws.com/publications/wikitables.pdf</a> about training neural network and the loss function is mentioned on page 6 chapter 3.4 - this loss function <code>O(theta)</code> is expressed as marginal loglikelihood objective function. I simply does not understand this. The neural network generates logical expression (query) from some question in natural language. The network is trained using question-answer pairs. One could expect that simple sum of correct-1/incorrect=0 result could be good loss function. But there is strange expression that involves <code>P(l|qi, Ti; theta)</code> that is not mentioned in the article. What is meant by this <code>P</code> function? As I understand, then many logical forms <code>l</code> are generated externally for some question <code>qi</code>. But further I can not understand this. The mentioned article largely builds on other article <a href=""http://www.aclweb.org/anthology/P16-1003"" rel=""nofollow noreferrer"">http://www.aclweb.org/anthology/P16-1003</a> from which it borrows some terms and ideas.</p>

<p>It is said that <code>l</code> is treated as latent variable and <code>P</code> seems to be some kind of probability. Of course, we should assign the greated probability to the right logical form <code>l</code>, but where can I find this assignment. Does training/supervision data should contain this probability function for training/supervision data?</p>
","natural-language-processing"
"8480","How could I use machine learning to detect text and non-text regions in scanned documents?","2018-10-17 10:54:29","","3","1187","<machine-learning><natural-language-processing><pattern-recognition><optical-character-recognition>","<p>I have a collection of scanned documents (which come from newspapers, books, and magazines) with complex alignments for the text, i.e. the text could be at any angle w.r.t. the page. I can do a lot of processing for different features extraction. However, I want to know some robust methods that do not need many features.</p>
<p>Can machine learning be helpful for this purpose? How could I use machine learning to detect text and non-text regions in these scanned documents?</p>
","natural-language-processing"
"8367","How to find the category of a technical text on a surface-semantic-level","2018-10-12 06:04:40","","2","158","<machine-learning><deep-learning><natural-language-processing><python><semantics>","<p>There are some predefined categories( Overview, Data Architecture, Technical Details, Applications, etc). The requirement is to classify the input text of paragraphs into their resp. category. I can't use any pre-trained word embeddings (Word2Vec, Glove) because the data entered is not in general English ( talking about dogs, environment, etc) but pure technical (How does a particular program orks, steps to download anaconda, etc). Don't have any data available on the internet to train as well. Anything that understands semantic-surface-level of a sentence will work</p>
","natural-language-processing"
"8335","Pre priming a network for white space","2018-10-09 23:56:19","","1","42","<neural-networks><machine-learning><natural-language-processing>","<p>When a human looks at a page. He notices the sets of letters are grouped together separated by white space. If the white space was replaced by another character say z, it would be harder to distinguish words.</p>

<p>For a neural network, spaces are ""just another character"". How can we set up an RNN so it gives special importance to the difference between certain characters like white spaces and letters so that it will train faster? Assume the input is just a sequence of ASCII characters.</p>
","natural-language-processing"
"8126","What is the name of the NLP technique that determines ""who did what to whom"" given a sentence?","2018-09-24 21:35:10","8134","1","77","<natural-language-processing><reference-request><computational-linguistics>","<p>Within a piece of text, I'm trying to detect who did what to whom.</p>
<p>For instance, in the following sentences:</p>
<blockquote>
<p>CV hit IV. CV was hit by IV.</p>
</blockquote>
<p>I'd like to know who hit whom.</p>
<p>I can't remember what this technique is called.</p>
","natural-language-processing"
"8013","Calculation of GPU memory consumption on softmax layer doesn't match with the empirical result","2018-09-17 04:44:46","8020","1","367","<neural-networks><natural-language-processing>","<p>I'm training a language model with <code>5000</code> vocabularies using a single <code>M60 GPU</code> (w/ actually usable memory about 7.5G). 
<br>The number of tokens per batch is about <code>8000</code>, and the hidden dimension to the softmax layer is <code>512</code>. So, if I understand correctly, fully-connected (softmax) layer theoretically consumes <code>5000*8000*512*4=81.92GB</code> for a forward pass (4 is for float32).
<br>But the GPU performed the forward and backward passes without any problem, and it says the GPU memory usage is less than <code>7GB</code> in total. </p>

<p>I used PyTorch. What's causing this? </p>

<p>EDIT: To be clearer, the input to the final fc layer (256x5000 matrix) is of size [256, 32, 256]. </p>
","natural-language-processing"
"7977","Can I develop a chatbot to carry on a natural conversation with a human using NLP and neural networks?","2018-09-14 14:44:09","7978","2","446","<neural-networks><natural-language-processing><chat-bots>","<p>I would like to develop a chatbot that is able to pass the Turing test, i.e. a chatbot that is able to carry on a natural conversation with a human.</p>

<p>Can natural language processing (NLP) be used to do that? What if I combine NLP with neural networks?</p>
","natural-language-processing"
"7899","How to build a commercial image captioning system?","2018-09-09 22:20:04","7931","1","120","<deep-learning><image-recognition><natural-language-processing>","<p>Image Captioning is a hot research topic in the AI community. There are considerable image captioning models for research usage such as NIC, Neural Talk 2 etc. But can these research models be used for commercial purpose? Or we should build much more complex structured ones for commercial usage? Or if we can make some improvements based these models to meet the business applications situation? If so, what improvements should we take? Are there any existing commercial Image Captioning applications can be referenced?</p>
","natural-language-processing"
"7880","How to parse conjunctions in natural language processing?","2018-09-07 22:39:06","7883","4","1193","<natural-language-processing><python><computational-linguistics>","<p>Is there an accepted way in NLP to parse conjunctions (and/or) in a sentence?</p>

<p>By following the example below, how would I parse</p>

<blockquote>
  <p>I drink orange juice if its the weekend or if it's late and I'm tired.</p>
</blockquote>

<p>into</p>

<blockquote>
  <p>it's the weekend</p>
</blockquote>

<p>and </p>

<blockquote>
  <p>it's late</p>
</blockquote>

<p>and </p>

<blockquote>
  <p>I'm tired</p>
</blockquote>

<p>?</p>

<p>Implying an action will be taken when one of the above elements at the 1st level of depth is true.</p>

<p>I know when I hear the sentence that it means ""its the weekend"" OR (""it's late"" AND ""I'm tired""), but how could this be determined computationally?</p>

<p>Can an existing python/other library do this?</p>
","natural-language-processing"
"7747","How does the ""Lorem Ipsum"" generator work?","2018-08-28 23:10:23","7752","4","1234","<natural-language-processing><text-summarization>","<p>I've seen many <a href=""https://en.wikipedia.org/wiki/Lorem_ipsum"" rel=""nofollow noreferrer"">Lorem Ipsum</a> generators on the web, but not only, there is also ""bacon ispum"", ""space ispum"", etc. So, how do these generators generate the text? Are they powered by an AI?</p>
","natural-language-processing"
"7684","Where can I find pre-trained language models in English and German?","2018-08-23 07:17:27","7754","5","1948","<neural-networks><natural-language-processing><bert><gpt><language-model>","<p>Where can I find (more) pre-trained <a href=""https://en.wikipedia.org/wiki/Language_model"" rel=""nofollow noreferrer"">language models</a>? I am especially interested in <strong>neural network-based</strong> models for <strong>English and German</strong>.</p>

<p>I am aware only of <a href=""https://github.com/tensorflow/models/tree/master/research/lm_1b"" rel=""nofollow noreferrer"">Language Model on One Billion Word Benchmark</a> and <a href=""https://github.com/lverwimp/tf-lm"" rel=""nofollow noreferrer"">TF-LM: TensorFlow-based Language Modeling Toolkit</a>.</p>

<p>I am surprised not to find a greater wealth of models for different frameworks and languages.</p>
","natural-language-processing"
"7675","Is there a machine learning system that is able to understand mathematical problems given in a textual description?","2018-08-22 09:28:40","","4","151","<natural-language-processing><natural-language-understanding><automated-reasoning><question-answering>","<p>Is there a machine learning system that is able to &quot;understand&quot; mathematical problems given in a textual description, such as</p>
<blockquote>
<p>A big cat needs 4 days to catch all the mice and a small cat needs 12 days. How many days need both, if they catch mice together?</p>
</blockquote>
<p>?</p>
","natural-language-processing"
"7655","Sequence to sequence machine learning / NMT - converting numbers into words","2018-08-20 21:31:23","","1","36","<natural-language-processing><tensorflow><keras>","<p>I want to do some sequence to sequence modelling on source data that looks like this:</p>

<pre><code>/-0.013428/-0.124969/-0.13435/0.008087/-0.269241/-0.36849/
</code></pre>

<p>with target data that looks like this:</p>

<pre><code>Dont be angry with the process youre going through right now
</code></pre>

<p>Both are of indeterminate lengths, and the lengths of target and source data aren't the same. What I'd like to do is have a prediction model where I can input similar numbers and have it generate texts based on the target training data.</p>

<p>I started off doing character level s2s, but the output of the model is too nonsensical even at 2-5k epochs. So I've been looking into word level s2s and NMT, but the tutorials always assume strings of text as the target and source, and I keep running into roadblocks trying to preprocess the text, when all the tutorials assume a certain syntax/set of characters. This is my first try at ML, and some of the tutorials really throw me out with the text preprocessing requirements.</p>

<p>Am I going down the right avenue looking at word level/NMT stuff? And is there a tutorial I've missed for something like what I'm trying to build?</p>
","natural-language-processing"
"7602","How can I train model to extract custom entities from text?","2018-08-16 15:07:36","","4","200","<machine-learning><deep-learning><natural-language-processing>","<p>I have a 100-150 words text and I want to extract particular information like location, product type, dates, specifications and price.</p>

<p>Suppose if I arrange a training data which has a text as input and location/product/dates/specs/price as a output value. So I want to train the model for these specific output only.</p>

<p>I have tried Spacy and NLTK for entity extraction but that doesn't suffice above requirements.</p>

<p>Sample text:</p>

<blockquote>
  <p>Supply of Steel Fabrication Items. 
  General Item . 
  Construction Material . 
  Hardware Stores and Tool . 
  Construction of Security Fence. - Angle Iron 65x65x6mm for fencing post of height 3.5, Angle Iron 65x65x6mm for fencing post of height 3.5, MS Flat 50 x 5mm of 2.60m height, Angle Iron 50x50x6mm for Strut post of height 3.10mtr, Angle Iron 50x50x6mm for fencing post of height 1.83, Angle Iron 50x50x6mm for fencing post of height 1.37, Barbed wire made out of GI wire of size 2.24mm dia, Chain link fence dia 4 mm and size of mesh 50mm x, Concertina Coil 600mm extentable up to 6 mtr, Concertina Coil 900mm extentable up to 15 to 20 mtr, Binding wire 0.9mm dia., 12 mm dia 50mm long bolts wih nuts &amp; 02 x washers, Cement in polythene bags 50 kgs each grade 43 OPC, Sand Coarse confiming to IS - 383-970, 2nd revision, Crushed Stone Aggregate 20 mm graded, TMT Bar 12mm dia with 50mm U bend, Lime 1st quality, Commercial plywood 6' x 3' x 12 mm., Nails all Type 1"" 2""3"" 4"" 5"" and 6""., Primer Red Oxide, Synthetic enamel paint, colour black/white Ist quality . 
  Angle Iron 65x65x6mm for fencing post of height 3.5, Angle Iron 65x65x6mm for fencing post of height 3.5 mtr, MS Flat 50 x 5mm of 2.60m height, Angle Iron 50x50x6mm for Strut post of height 3.10mtr, Barbed wire made out of GI wire of size 2.24mm dia, Chain link fence dia 4 mm and size of mesh 50mm x, Concertina Coil 600mm extentable up to 6 mtr, Binding wire 0.9mm dia., 12 mm dia 50mm long bolts with nuts &amp; 02 x washers, Cement in polythene bags 50 kgs each grade 43 OPC, Sand Coarse confiming to IS - 383-970, 2nd revision, Crushed Stone Aggregate 20 mm graded, TMT Bar 12mm dia with 50mm U bend, Lime 1st quality, Commercial plywood 6' x 3' x 12 mm., Nails all Type 1"" 2""3"" 4"" 5"" and 6""., Primer Red Oxide, Synthetic enamel paint, colour black/white Ist quality., Cutting Plier 160mm long, Leather Hand Gloves/Knitted industrial, Ring Spanner of 16mm x 17mm, 14 x 16mm, Crowbar hexagonal 1200mm long x 40mm, Plumb bob steel, Bucket steel 15 ltr capacity (as per, Plastic water tank 500 ltrs Make - Sintex, Water level pipe 30 Mtr, Brick Hammer 250 Gms with handle, Hack saw Blade double side, Welding Rod, Cutting rod for making holes, HDPE Sheet 5' x 8', Plastic Measuring tape 30 Mtr, Steel Measuring tape 5 Mtr, Wooden Gurmala 6""x3"", Steel Pan Mortar of 18""dia (As, Showel GS with wooden handle, Phawarah with wooden handle (As per, Digital Vernier Caliper, Digital Weighing Machine cap 500 Kgs, Portable Welding Machine, Concrete mixer machine of 8 CFT . 
  Angle Iron 65x65x6mm for fencing post of height 3.5, Angle Iron 65x65x6mm for fencing post of height 3.5, MS Flat 50 x 5mm of 2.60m height, Angle Iron 50x50x6mm for Strut post of height 3.10mtr, Barbed wire made out of GI wire of size 2.24mm dia, Chain link fence dia 4 mm and size of mesh 50mm, Concertina Coil 600mm extentable up to 6 mtr, Binding wire 0.9mm dia., 12 mm dia 50mm long bolts with nuts &amp; 02 x washers, Cement in polythene bags 50 kgs each grade 43, Sand Coarse confiming to IS - 383-970, 2nd revision, Crushed Stone Aggregate 20 mm graded, TMT Bar 12mm dia with 50mm U bend, Lime 1st quality, Commercial plywood 6' x 3' x 12 mm., Nails all Type 1"" 2""3"" 4"" 5"" and 6""., Primer Red Oxide, Synthetic enamel paint, colour black/white Ist quality., Cutting Plier 160mm long, Leather Hand Gloves/Knitted industrial, Ring Spanner of 16mm x 17mm, 14 x 16mm, Crowbar hexagonal 1200mm long x 40mm, Plumb bob steel, Bucket steel 15 ltr capacity (as per, Plastic water tank 500 ltrs Make - Sintex, Water level pipe 30 Mtr, Brick Hammer 250 Gms with handle, Hack saw Blade double side, Welding Rod, Cutting rod for making holes, HDPE Sheet 5' x 8', Plastic Measuring tape 30 Mtr, Steel Measuring tape 5 Mtr, Wooden Gurmala 6""x3"", Steel Pan Mortar of 18""dia (As per, Showel GS with wooden handle, Phawarah with wooden handle (As per, Digital Vernier Caliper)</p>
</blockquote>
","natural-language-processing"
"7601","Can we teach an artificial intelligence through sentences?","2018-08-16 14:57:13","","6","159","<neural-networks><machine-learning><natural-language-processing><computational-learning-theory>","<p>Could we teach an AI with sentences such as ""ants are small"" and ""the sky is blue""? Is there any research work that attempts to do this?</p>
","natural-language-processing"
"7453","How can I create a chatbot application where the user can create its own bot?","2018-08-07 09:44:19","","1","98","<natural-language-processing><ai-design><chat-bots>","<p>I am trying to create a chatbot application where the user can create its own bot, like <a href=""https://www.botengine.ai/"" rel=""nofollow noreferrer"">Botengine</a>. After going through google, I saw I need some NLP API to process the user's query. As per wit.ai <a href=""https://wit.ai/docs/quickstart"" rel=""nofollow noreferrer"">basic example</a>, I can set and get data. How I am going to create a bot engine?</p>

<p>So, as far I understand the flow, here is an example for pizza delivery</p>

<ol>
<li><p>The user will enter a welcome message, i.e - Hi or Hello</p></li>
<li><p>The welcome reply will be saved by bot owner in my database</p></li>
<li><p>The user will enter some query, then I will hit wit.ai API to process that query. Example: The user's query is ""What kind of pizza's available in your store"" and wit.ai will respond with the details of intent ""pizza_type""</p></li>
<li><p>Then I will search for the intent returned by wit in my database.</p></li>
</ol>

<p>So, is that the right flow to create a chatbot? Am I in the right direction? Could anyone give me some link or some example so I can go through it? I want to create this application using Node.js. I have also found some example in <a href=""https://github.com/wit-ai/node-wit"" rel=""nofollow noreferrer"">node-wit</a>, but can't find how I will implement this.</p>
","natural-language-processing"
"7286","Why are documents kept separated when training a text classifier?","2018-07-24 23:03:29","","8","196","<natural-language-processing><text-classification><tf-idf><bag-of-words>","<p>Most of the literature considers text classification as the classification of documents. When using the bag-of-words and Bayesian classification, they usually use the statistic TF-IDF, where TF normalizes the word count with the number of words per document, and IDF focuses on ignoring widely used and thus useless words for this task.</p>
<p>My question is, why they keep the documents separated and create that statistic, if it is possible to merge all documents of the same class? This would have two advantages:</p>
<ul>
<li><p>You can just use word counts instead of frequencies, as the documents per class label is 1.</p>
</li>
<li><p>Instead of using IDF, you just select features with enough standard deviation between classes.</p>
</li>
</ul>
","natural-language-processing"
"7235","Sentence classification and named identity detection with automatic retraining","2018-07-21 09:02:49","","2","71","<training><natural-language-processing><getting-started>","<p>I am learning AI and trying out my first real-life AI application.
What I am trying to do is taking as an input various sentences, and then classifying the sentences into one of X number of categories based on keywords, and 'action' in the sentence. </p>

<p>The keywords are, for example, Merger, Acquisition, Award, product launch, etc. so in essence, I am trying to detect if the sentence in question talks about a merger between two organizations, or an acquisition by an organization, a person or an organization winning an award, or launching of a new product, etc.</p>

<p>To do this, I have made custom models based on the basic NLTK package model, for each keyword, and trying to improve the classification by dynamically tagging/updating the models with related keywords, synonyms, etc to improve the detection capability. Also, given a set of sentences, I am presenting the user with the detected categorization and asking whether it is correct or wrong, and if wrong, what is the correct categorization, and also identify the entities (company names, person names, product names, etc).</p>

<p>So the object is to first classify the sentence into a category, and additionally, detect the named entities in the sentence, based on the category.</p>

<p>The idea is, to be able to automatically re-train the models based on this feedback to improve its performance over time and to be able to retrain with as little manual intervention as possible. For the sake of this project, we can assume that user feedback would be accurate.</p>

<p>The problem I am facing is that NLK is allowing fixed-length entities while training, so for example a two-word award is being detected as two awards. </p>

<p>What should be my approach to solve this problem? Is there a better NLU (even a commercial one) that can address this problem? It seems to me that this would be a common AI problem, and I am missing something basic. I would love you guys to have any input on this.</p>
","natural-language-processing"
"7222","Is 'job title classification' rather a problem of NLP or machine learning?","2018-07-20 14:13:15","","6","2561","<neural-networks><machine-learning><natural-language-processing>","<p>first of all I want to specify the data available and what needs to be achieved: I have a huge amount of vacancies (in the millions). The information about the <strong>job title</strong> and the <strong>job description</strong> of each vacancy are stored separately. I also have a <strong>list of professions</strong> (around 3000), to which the vacancies shall be mapped.</p>

<p><strong>Example</strong>: <em>java-developer, java web engineer and java software developer</em> shall all be mapped to the profession <em>java engineer</em>.</p>

<p>Now about my current researches and problems: Since a lot of potential training data is present, I thought a machine learning approach could be useful. I have been reading about different algorithms and wanted to give neural networks a shot. </p>

<p>Very fast I faced the problem, that I couldn't find a satisfying way to <strong>transform text of variable length to numerical vectors of constant size</strong> (needed by neural networks). As discussed <a href=""https://stackoverflow.com/questions/14783431/processing-strings-of-text-for-neural-network-input"">here</a>, this seems to be a non trivial problem. </p>

<p>I dug deeper and came across <a href=""https://skymind.ai/wiki/bagofwords-tf-idf"" rel=""noreferrer"">Bag of Words (BOW) and Text Frequency - Inverse Document Frequency (TFIDF)</a>, which seemed suitable at first glance. But here I faced other problems: If I feed all the job titles to TFIDF, the resulting word-weight-vectors will probably be very large (in the tenth of thousands). The search term on the other hand will mostly consist of between 1 and 5 words (we currently match the job title only). Hence, the neural network must be able to reliably map an ultra sparse input vector to one of a few thousand basic jobs. This sounds very difficult for me and I doubt a good classification quality.</p>

<p>Another problem with BOW and TFIDF is, that they cannot handle typos and new words (I guess). They cannot be found in TFIDF's word list, which results in a vector filled with zeros. To sum it up: I was first excited to use TFIDF, but now think it doesn't work well for what I want to do.</p>

<p>Thinking more about it, I now have doubt if neural networks or other machine learning approaches are even good solutions for this task at all. Maybe there are much better algorithms in the field of natural language processing. 
This moment (before digging into NLP) I decided to first gather the opinions of some more experienced AI users, so I don't miss the best solution. </p>

<p>So <strong>what would be a useful approach to this in your opinion</strong> (best would be an approach that is capable of handling synonyms and typos)? Thanks in advance!</p>

<p>p. s.: I am currently thinking about <strong>feeding the whole job description</strong> into the TFIDF and also do matches for new incoming vacancies with the whole document (instead of job title only). This will expand the size of the word-weight-vector, but it will be less sparse. Does this seem logical to you?</p>
","natural-language-processing"
"7217","Would it make sense to use together capsule neural neworks and ""topic / narrative modeling""?","2018-07-20 10:19:25","","1","90","<natural-language-processing><capsule-neural-network><topic-model>","<p>This is actually something I have been researching a bit on my own.</p>

<p>Most movie scripts can be structurally analysed by using writing theory such as <a href=""http://dramatica.com/theory/book/theme"" rel=""nofollow noreferrer"">Dramatica</a>. Dramatica is based upon a hierarchy of concepts, which can be topic modeled. The hierarchy of topic models would seem to work very well with the capsule neural networks.</p>

<p>I have been working with computational creativity problems in a narrative generation. The state of the art methods use Partial Order Causal Link Planners, but they depend on propositional logic. Alonzo Church presented the <a href=""https://en.wikipedia.org/wiki/Extensional_context"" rel=""nofollow noreferrer"">Superman dilemma</a> (Louis Lane does not know that Clark Kent is Superman, but Superman knows, that he is Clark Kent) and invented Intensional Logic as a solution; the basic idea is, that if we do not know the context of the narrative, the meaning is always in superposition and can only be understood through entangled meanings from the background story. So, in a sense, propositional logic is limited by classic information theory constraints, while Church's logic can take a quantum information-theoretic approach. I do not believe that classic information theory can resolve narrative analysis problems. So, basically, the meaning of a narrative collapses (the superposition gets resolved) by using the hierarchical narrative structure and what we know beforehand.</p>

<p>So my intuition would be the following:</p>

<ul>
<li><p>We can use Dramatica and potentially other narrative theories (hierarchical metamemetics, reverse SCARF, etc.) to create a hierarchical network like ImageNet, but for narratives.</p></li>
<li><p>We can build conceptual topic models. Dramatica has a hierarchy of 4-16-64-64 concepts and annotated data exists already.</p></li>
<li><p>When using hundreds of topic models, there will be a lot of false positives. However, the superposition of the topic models can be collapsed by using the hierarchical levels and some other dramatic analytics.</p></li>
<li><p>By using the capsule neural networks, we might be able to build a system, which could determine a narrative interpretation of the full story, which would make the most sense by using the concept hierarchy.</p></li>
</ul>

<p>I tried to prove my intuition, but, unfortunately, Dramatica only has 300 movies analysed, and I was able to find scripts of only 10 of them; not enough data.</p>

<p>However, there are other hierarchical ontologies out there and other narrative structures; could the same intuition be used for political news for example?</p>
","natural-language-processing"
"7144","Extracting referenced documents","2018-07-13 18:17:09","","3","50","<natural-language-processing><automation>","<p>I'm looking to write an AI that will be able to extract in text references from standards documents to assist human research.</p>

<p>My use case is extracting the identifying numbers, for example, ""AR 25-2"", along with the title of the document ""Information Assurance"" so that a human can gather all the related research on a contract at once, instead of having to keep track of references while they're reading through the document.</p>

<p>I have a pretty good idea of where to gather the names of these documents for training, I'm planning on 'scraping' a few repositories for different categories of these documents. </p>

<p>What kind of model should I use to get the best results?</p>
","natural-language-processing"
"6965","Can AI solve jumbled words?","2018-06-30 17:37:49","","2","3756","<natural-language-processing><reference-request>","<p>Is there any general idea on how humans solve jumbled words? I know many people will say we match it against a commonly used words checklist mentally, but it is kind of vague. Is there any theory on this? And how might an AI learn to do the same?</p>
","natural-language-processing"
"6898","What algorithms does stackoverflow use for classifying duplicate questions?","2018-06-26 19:23:54","","5","539","<natural-language-processing>","<p>Can I get details about the algorithms used for classifying questions in stackoverflow (""Questions that may already have your answer""). Most of the suggestions I get are nowhere related to the question I have intended to ask.</p>
","natural-language-processing"
"6814","Question classification according to chapters","2018-06-20 01:42:58","6815","1","321","<machine-learning><deep-learning><classification><natural-language-processing>","<p>I have a corpus, say an instruction manual. The text in this manual is grouped into chapters and each chapter is split up into sections. For example, Chapter 1/Section 1, Chapter 1/Section 2 and so on.
Assume the corpus has C chapters and each chapter has S sections. My goal is, given a sentence or question, to classify this sentence/question. In other words I want to compute three most probable chapters to which this sentence or question belongs to. 
I tried MultinomialNB model using sklealrn, but it did not give me the desired result. I want to try another approach, for example using a Neural Network and compare it with the MultinomialNB model. I have Googled and found Doc2Vec but haven't tried yet. </p>

<p>Can anyone suggest a better or another possible approach so that I could try and compare? What is the standard approach to such kind of problem? </p>
","natural-language-processing"
"6571","How should the output layer of an LSTM be when the output are word embeddings?","2018-05-30 09:12:50","","3","279","<natural-language-processing><long-short-term-memory><word-embedding><word2vec>","<p>I'm having trouble grasping how to output word embeddings from an LSTM model. I'm seeing many examples using a softmax activation function on the output, but for that I would need to output one hot vectors as long as the vocabulary (which is too long). So, should I use a linear activation function on the output to get the word embeddings directly (and then find the closest word) or is there something I'm missing here?</p>
","natural-language-processing"
"6524","How can I build an AI with NLP that reads and understands documents?","2018-05-27 15:47:36","6566","2","347","<natural-language-processing>","<p>I have to read a lot of papers, and I thought that I can use an A.I. to read them and summarize them. Maybe find one that can understand what the papers are talking about it seems a lot to ask.</p>

<p>I think I can use natural language processing. Is it the right choice?</p>

<p>I'm sorry, but I'm new in A.I. and I don't know much about it.</p>
","natural-language-processing"
"6414","Are there any references of NLP/text mining techniques for identifying the theme of news headlines?","2018-05-14 20:43:22","6458","3","153","<machine-learning><deep-learning><natural-language-processing><reference-request>","<p>I am looking to extract the central theme from a given news headline using NLP or text mining. Is there any reference that goes in this direction?</p>
<p>Here's an example. Let's say that I have the following news headline.</p>
<blockquote>
<p>BRIEF-Dynasil Corporation Of America Reports Q2 EPS Of $0.08</p>
</blockquote>
<p>Then the algorithm should produce</p>
<blockquote>
<p>Reports</p>
</blockquote>
<p>Here's another example. The input is</p>
<blockquote>
<p>China's night-owl retail investors leverage up to dominate oil futures trade</p>
</blockquote>
<p>And the output would e.g. be</p>
<blockquote>
<p>oil futures</p>
</blockquote>
","natural-language-processing"
"6402","How can I create my own Google duplex?","2018-05-14 05:53:45","6409","-1","786","<deep-learning><natural-language-processing><reference-request>","<p>I am trying to create my own variant of Google duplex however, it won't make calls but just have a real-time conversation.</p>
<p>My question is, where and how to start?</p>
<p>How do I train my model with real conversation and how do I make speech sound almost human-like? Where do I incorporate RNN and how can I make my model understand nuances?</p>
<p><a href=""https://youtu.be/p3PfKf0ndik"" rel=""nofollow noreferrer"">https://youtu.be/p3PfKf0ndik</a> trying to create something like this.</p>
","natural-language-processing"
"6297","How can we compare, in terms of similarity, two pieces of text?","2018-05-07 16:40:26","6405","2","5041","<neural-networks><natural-language-processing><metric><similarity>","<p>How can we compare, in terms of similarity (and/or meaning), two pieces of text (or documents)?</p>
<p>For example, let's say that I want to determine whether a document is a plagiarized version of another document. Which approach should I use? Could I use neural networks to do this? Or are there other more suitable approaches?</p>
","natural-language-processing"
"6216","Recommended Modelling Technique for Influencer Marketing Scenario","2018-04-30 23:58:24","6221","2","78","<training><natural-language-processing><sentiment-analysis>","<p>I have an approximately 90,000 row dataset that has information of social media profiles which has columns for biography, follower count, language spoken, name, username and the <strong>label (to identify whether the profile is that of an influencer, brand or news and media)</strong>.</p>

<p>Task: I have to train a model that predicts the label. I then need to produce a confidence interval for each prediction.</p>

<p>As I have never come across a problem like this, I am just after some suggestions of what models I should be using for a situation like this? I am thinking Natural Language Processing (NLP), but not sure. </p>

<p>Also, for NLP (if a suitable method), any codes or advice to help me implement for the first time on Python would be greatly appreciated! Thanks in advanced</p>
","natural-language-processing"
"6164","How to add contextual follow up like Google Assistant","2018-04-25 03:05:35","6190","0","126","<natural-language-processing><reference-request><ai-design><algorithm-request><intelligent-personal-assistants>","<p>I am developing PDA like Google assistant on Android. So far, so good.
But now, I want to add contextual follow up like Google assistant so it can keep the train of thought.
As demonstrated here- <a href=""https://www.youtube.com/watch?v=xYRENGuwwCA"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=xYRENGuwwCA</a></p>
<p>Can anyone guide me or hint how to design the algorithm?</p>
","natural-language-processing"
"6144","Do individual dimensions in vector space have meaning?","2018-04-23 18:58:09","","4","71","<natural-language-processing><word2vec><word-embedding>","<p>Word2vec assigns an N-dimensional vector to given words (which can be considered a form of dimensionality reduction). </p>

<p>It turns out that, at least with a number of canonical examples, vector arithmetic seems to work intuitively. For example ""<em>king + woman - man = queen</em>"".</p>

<p>These terms are all N-dimensional vectors. Now, suppose, for simplicity, that <span class=""math-container"">$N=3$</span>, <span class=""math-container"">$\text{king} = [0, 1, 2], \text{woman} = [1, 1, 0], \text{man} = [2, 2, 2], \text{queen} = [-1, 0, 0]$</span>, then the expression above can be written as <span class=""math-container"">$[0, 1, 2] +  [1, 1, 0] - [2, 2, 2] = [-1, 0, 0]$</span>.</p>

<p>In this (contrived) example, the last dimension (king/man=2, queen/woman=0) suggests a semantic concept of gender. Aside from semantics, a given dimension could ""mean"" a part of speech, first letter, or really any feature or set of features that the algorithm might have latched onto. However, any perceived ""meaning"" of a single dimension might well just be a simple coincidence.</p>

<p>If we picked out only a single dimension, does that dimension itself convey some predictable or determinable information? Or is this purely a ""random"" artefact of the algorithm, with only the full N-dimensional vector distances mattering?</p>
","natural-language-processing"
"5874","Can we detect the emotions (or feelings) of a human through conversations with an AI?","2018-04-03 16:33:54","","4","236","<natural-language-processing><emotional-intelligence><sentiment-analysis>","<p>Can we detect the emotions (or feelings) of a human through conversations with an AI?</p>
<p>Something like a &quot;confessional&quot;, disregarding human possibilities to lie.</p>
<p>Below, I have the categories joyful, sadness, anger, fear and affection. For each category, there are several words that can be in the texts that refer to it.</p>
<ul>
<li><p><strong>Joy:</strong> <strong>(</strong> cheerful, happy, confident, happy, satisfied, excited, interested, dazzled, optimistic, relieved, euphoric, drunk, witty, good <strong>)</strong></p>
</li>
<li><p><strong>Sadness:</strong> <strong>(</strong> sad, desperate, displeased, depressed, bored, lonely, hurt, desolate, meditative, defrauded, withdrawn, pitying, concentrated, depressed, melancholic, nostalgic <strong>)</strong></p>
</li>
<li><p><strong>Anger:</strong> <strong>(</strong> aggressive, critical, angry, hysterical, envious, grumpy, disappointed, shocked, exasperated, frustrated, arrogant, jealous, agonized, hostile, vengeful <strong>)</strong></p>
</li>
<li><p><strong>Fear:</strong> <strong>(</strong> shy, frightened, fearful, horrified, suspicious, disbelieving, embarrassed, embarrassed, shaken, surprised, guilty, anxious, cautious, indecisive, embarrassed, modest <strong>)</strong></p>
</li>
<li><p><strong>Affection:</strong> <strong>(</strong> loving, passionate, supportive, malicious, dazzled, glazed, homesick, embarrassed, indifferent, curious, tender, moved, hopeful <strong>)</strong></p>
</li>
</ul>
<p><strong>Flow Example</strong></p>
<p><strong>Phrase 1:</strong> &quot;I'm very happy! It concludes college.&quot;</p>
<p><strong>Categorization 1:</strong>
 - Joy <strong>(+1)</strong></p>
<ul>
<li>Sadness <strong>(-1)</strong></li>
</ul>
<hr />
<p><strong>Phrase 2:</strong> &quot;I'm sad, my mother passed away.&quot;</p>
<p><strong>Categorization 2:</strong>
 - Sadness <strong>(+1)</strong></p>
<ul>
<li>Joy <strong>(-1)</strong></li>
</ul>
<hr />
<p><strong>Phrase 3:</strong> &quot;I met a girl, but I was ashamed.&quot;</p>
<p><strong>Categorization 3:</strong>
 - Fear <strong>(+1)</strong></p>
<p>Is this a clever way to follow and / or improve, or am I completely out of the way?</p>
<p>I see that there is a Google product that creates parsing according to the phrases. I do not know how it works, because I like to recreate the way I think it would work.</p>
<p>Remembering that this would not be the only way to categorize the phrase. This would be the first phase of the analysis. I can also identify the subject of the sentence, so we would know if the sadness is from the creator of the message or from a third party, in most cases.</p>
<ul>
<li><a href=""http://www.nltk.org/book/ch08.html"" rel=""nofollow noreferrer"">NLTK</a></li>
<li><a href=""https://github.com/text-machine-lab/sentimental"" rel=""nofollow noreferrer"">Sentiment Analysis Python Example</a></li>
</ul>
","natural-language-processing"
"5782","Did Turing foresee the required capabilities to pass the Turing test?","2018-03-23 16:38:40","","7","2001","<machine-learning><natural-language-processing><knowledge-representation><turing-test><automated-reasoning>","<p>In Section 1.1 of <em>Artificial Intelligence: A Modern Approach</em>, it is stated that a computer which passes the Turing Test would need 4 capabilities, and that these 4 capabilities comprise most of the field of Artificial Intelligence:</p>

<ol>
<li><p>natural language processing: to enable it to communicate successfully in English</p></li>
<li><p>knowledge representation: to store what it knows and hears</p></li>
<li><p>automated reasoning: to use the stored information to answer questions and to draw new conclusions</p></li>
<li><p>machine learning: to adapt to new circumstances and to detect and extrapolate patterns</p></li>
</ol>

<p>Did Alan Turing discern the requirements for the field of artificial intelligence (the necessary subfields) and purposefully design a test around these requirements, or did he simply design a test that is so general that the subfields which developed within artificial intelligence happen to be what is required to solve it? That is, was he prescient or lucky? Are these Turing's subdivisions, or Peter Norvig's and Stuart Russell's?</p>

<p>If Turing did foresee these 4 requirements, what did he base them on? What principles of intelligence allowed him to predict the requirements for the field?</p>
","natural-language-processing"
"5652","NLP proved against US legal texts","2018-03-12 18:50:49","","3","116","<neural-networks><ai-design><natural-language-processing><legal>","<p>I'm new to AI development and am looking for a quality algorithm (potentially nlp?) implementation proved against US legal texts.</p>

<p>Obviously some training would need to be done, but I've found little to no online references to go on when it comes to running assessment against US legal documents.</p>

<p>My goal is to use an algorithm to discover potential issues in long and complex legal texts, or associated (groups) of legal texts which bind one or more related entities (people or corporations) to potentially conflicting clauses.</p>

<p>Just a pointer in some kind of direction would be helpful.</p>
","natural-language-processing"
"5536","Seq2Seq dialogs predicts only most common words like `you` after couple of epoches","2018-03-06 10:35:34","7554","3","1790","<neural-networks><natural-language-processing><tensorflow><recurrent-neural-networks><long-short-term-memory>","<p>I'm training Seq2Seq model on OpenSubtitles dialogs - <a href=""http://www.cs.cornell.edu/%7Ecristian/Cornell_Movie-Dialogs_Corpus.html"" rel=""nofollow noreferrer"">Cornell-Movie-Dialogs-Corpus</a>.</p>
<p>My work based on the following papers (but currently I'm not implemented Attention yet):</p>
<ul>
<li><a href=""https://arxiv.org/abs/1409.3215"" rel=""nofollow noreferrer""><em>Sequence to Sequence Learning with Neural Networks, Sutskever et al. 2014</em></a></li>
<li><a href=""https://arxiv.org/abs/1506.05869"" rel=""nofollow noreferrer""><em>A Neural Conversational Model, Vinyals, Le, 2015</em></a></li>
</ul>
<p>The <code>loss</code> I received is quite high and sucked in variation <code>~6.4</code> after 3 epoches. The model predicts the most common words with some times other not significant words (but 99.99% is just 'you'):</p>
<ul>
<li>I’ve experimented with 128 - 2048 hidden units and with 1 or 2 or 3 LSTM layers per <code>encoder</code> and <code>decoder</code>. The outcomes are more or less the same.</li>
</ul>
<blockquote>
<p>SEQ1: yeah man it means love respect community and the dollars too the package the unk end</p>
<p>SEQ2: but how did you get unk 82 end</p>
<p>PREDICTION: promoting 16th dashboard be of the the the you you you you you you you you you you you you you you you you you you you you you you you you</p>
</blockquote>
<p>I'm using here <code>greedy</code> prediction, meaning - after I receive <code>logit</code> I do <code>argmax(..)</code> on all its value for first-3 mini-batch-elements (here I present only first element). For convenient - <code>SEQ1</code> and <code>SEQ2</code> are also printed - to know the actual dialog which was presented to the model.</p>
<p>The pseudo-code of my architecture looks like this (I'm using Tensorflow 1.5):</p>
<pre><code>seq1 = tf.placeholder(...)
seq2 = tf.placeholder(...)

embeddings = tf.Variable(tf.random_uniform([vocab_size, 100],-1,1))

seq1_emb = tf.nn.embedding_lookup(embeddings, seq1)
seq2_emb = tf.nn.embedding_lookup(embeddings, seq1)

encoder_out, state1 = tf.nn.static_rnn(BasicLSTMCell(), seq1_emb)
decoder_out, state2 = tf.nn.static_rnn(BasicLSTMCell(), seq2_emb,
                                                        initial_state=state_1)
logit = Dense(decoder_out, use_bias=False)

crossent = tf.nn.saparse_softmax_cross_entropy_with_logits(logits=logit, 
                                                         labels=target)
crossent = mask_padded_zeros(crossent)
loss = tf.reduce_sum(crossent) / number_of_words_in_batch

train = tf.train.AdamOptimizer(learning_rate=0.00002).minimize(loss) 
</code></pre>
<p>I'm also wonder if I pass well <code>state1</code> to <code>decoder</code>, which in general looks like this:</p>
<pre><code># reshape in pseudocode: state1 = state[1:]
new_state1 = []
for lstm in state1:
    new_lstm = []
    for gate in lstm:
        new_lstm.append(gate[1:])
    new_state1.append(tuple(new_lstm))
state1 = tuple(new_state1)
</code></pre>
<ul>
<li>Should I use some projection layer between states of <code>encoder</code> and <code>decoder</code> ?</li>
</ul>
<p>So if <code>seq1</code> has 32 words, <code>seq2</code> has 31 (since we will not predict nothing after the last word, which is the tag <code>&lt;END&gt;</code>).</p>
","natural-language-processing"
"5517","Two chatbots - One teaches another","2018-03-04 22:39:31","","3","449","<natural-language-processing><reference-request><chat-bots>","<p>I am seeking the information for this kind of chatbot architecture : There are two chatbots. One plays the role of teacher, and another is a student who is learning. The goal is to test the student's quality, and to improve the student's ability.</p>
<p>I didn't find much reference. There are :</p>
<p><a href=""http://Bottester:%20Testing%20Conversational%20Systems%20with%20Simulated%20Users"" rel=""nofollow noreferrer"">Bottester: Testing Conversational Systems with Simulated Users</a></p>
<p>And the <a href=""http://parl.ai/static/docs/basic_tutorial.html#"" rel=""nofollow noreferrer"">ParlAI</a>, a python-based platform for enabling dialog AI research has the notion of &quot;Teacher agent&quot;, which seems to be what I am looking for.</p>
<p>Of course, we also have deep reinforcement learning which might be related.</p>
<p>I prefer to have some classical references for this approach to chatbots.
Currently, reinforcement learning is not in my consideration.</p>
<p>Constructing two chatbots talking to each other, like what Facebook did, is not what I want. Because in this case, both of them are student agents.</p>
","natural-language-processing"
"5422","What is easier or more efficient to summarize voice or text? [DP/RN]","2018-02-24 21:55:33","5424","2","143","<neural-networks><deep-learning><natural-language-processing><voice-recognition><text-summarization>","<p>If possible consider the relationship between implementation difficulty and accuracy in voice examples or simply chat conversations.</p>

<p>And currently, what are the directions on algorithms like Deep Learning or others to solve this.</p>
","natural-language-processing"
"5408","What is the intuition behind how word embeddings bring information to a neural network?","2018-02-23 10:25:50","","5","234","<neural-networks><machine-learning><natural-language-processing><word-embedding><embeddings>","<p>How is it that a word embedding layer (say word2vec) brings more insights to the neural network compared to a simple one-hot encoded layer?</p>
<p>I understand how the word embedding carries some semantic meaning, but it seems that this information would get &quot;squashed&quot; by the activation function, leaving only a scalar value and as many different vectors could yield the same result, I would guess that the information is more or less lost.</p>
<p>Could anyone bring me insights as to why a neural network may utilize the information contained in a word embedding?</p>
","natural-language-processing"
"5333","Methods to tell if a question can be answered from a paragraph","2018-02-16 05:39:17","","5","663","<neural-networks><machine-learning><classification><natural-language-processing>","<p>I'm working on a project related to machine Q&amp;A, using the SQuAD dataset. I've implemented a neural-net solution for finding answers in the provided context paragraph, but the system (obviously) struggles when given questions that are unanswerable from the context. It usually produces answers that are nonsensical and of the wrong entity type.</p>

<p>Is there any existing research in telling whether or not a question is answerable using the info in a context paragraph? Or whether a generated answer is valid? I considered textual entailment but it doesn't seem to be exactly what I'm looking for (though maybe I'm wrong about that?)</p>
","natural-language-processing"
"5317","How to find the subject in a text?","2018-02-15 03:54:17","","1","1793","<algorithm><natural-language-processing><ai-basics><getting-started>","<p>I often develop bots and I need to understand what some people are saying.</p>

<p>Examples:<br>
- I want an apple<br>
- I want an a p p l e</p>

<p>How do I find the object (<em>apple</em>)? I honestly don't know where to start looking. Is there an API that I can send the text to which returns the object? Or perhaps I should manually code something that analyses the grammar?</p>
","natural-language-processing"
"5285","How is the word embedding represented in the paper ""Recurrent neural network based language model""?","2018-02-12 13:05:53","5293","1","273","<natural-language-processing><recurrent-neural-networks><word-embedding><papers>","<p>I'm reading <em>""<a href=""http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf"" rel=""nofollow noreferrer"">Recurrent neural network based language model</a>""</em> of Mikolov et al. (2010). Although the article is straight forward, I'm not sure how word embedding <span class=""math-container"">$w(t)$</span> is obtained:</p>

<p><a href=""https://i.sstatic.net/6i54I.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/6i54I.png"" alt=""enter image description here""></a></p>

<p>The reason I wonder is that in the classic ""<em><a href=""http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"" rel=""nofollow noreferrer"">A Neural Probabilistic Language Model</a></em>"" Bengio et al. (2003) - they used separate embedding vector for representing each word and it was somehow ""semi-layer"", meaning - it haven't contains non-linearity, but they did update word embeddings during the back-propagation.</p>

<p>In Mikolov approach though, I assume they used simple one-hot vector, where each feature represent presence of each word. If we represent that's way single word input (like was in the Mikolov's paper) - that vector become all-zeros except single one.</p>

<p>Is that correct?</p>
","natural-language-processing"
"5266","Existing programs that find out words with same meanings","2018-02-10 03:28:13","5273","1","192","<machine-learning><natural-language-processing>","<p>I'm wondering if these 2 specific programs already exist and if not how hard would it be to write them:</p>

<ol>
<li><p>A program that would figure out (by only ""reading"" large amounts of texts in human language 1 and 2) which words in second language have the same meaning as a word in first language.  You would give for input texts in both languages and for output you would get for every word in first language a list of words in second language that are most similar to it with a probability that they mean the same thing. </p></li>
<li><p>A program that would figure out which words have the most similar meaning by analyzing large amounts of texts in one human language.</p></li>
</ol>

<p>I'm planning on writing these two programs and it would be nice if I could get existing programs that do this so that I could compare results of my program to those of existing programs.</p>
","natural-language-processing"
"5167","How could a chat bot learn synonyms?","2018-01-28 02:59:24","","2","1564","<natural-language-processing><chat-bots>","<p>I have started to make a chatbot. It has a list of greetings that it understands and responds to with its own list of greetings.</p>

<p>How could a bot learn a new greeting or a synonym for a word it already knows?</p>
","natural-language-processing"
"5138","How can I improve this word-prediction AI?","2018-01-26 20:20:16","5154","2","231","<natural-language-processing><probability>","<p>I'm relatively new to AI, and I've tried to create one that ""speaks"". Here's how it works:<br><br>
1. Get training data e.g 'Jim ran to the shop to buy candy'<br>
2. The data gets split into overlapping 'chains' of three e.g ['Jim ran to', 'ran to the', 'to the shop', 'the shop to'...]<br>
3. User enters two words<br>
4. Looks through the chains to find if the two words have been seen before.<br>
5. If they have, finds out which word followed it and how many times.<br>
6. Work out the probability e.g: if 'or' followed the two words 3 times, 'because' followed the two words 1 time and 'but' followed it 1 time it would be 0.6, 0.2 and 0.2<br>
7. Generate a random decimal<br>
8. If the random decimal is in the range of the first word (0 - 0.6) pick that one or if it's in the range of the second word (0.6 - 0.8) pick that word or if it's in the range of the third (0.8 - 1) pick that word<br>
9. Output the word picked<br>
10. Repeat from 4 but with the new last two words e.g if the last words had been 'to be' and it picked 'or' the new last two words would be 'be or'.</p>

<p>It does work, but it doesn't stick to a particular topic. For example, after training with 800 random Wikipedia articles:</p>

<blockquote>
  <p>In the early 1990s the frequency had a plastic pickguard and separate hardtail bridge with the council hoped that the bullet one replaced with the goal of educating the next orders could revert to the north island or string of islands in a new urban zone close to the west.</p>
</blockquote>

<p>As you can see the topic changes many times mid-sentence. I thought of increasing the number of words it considered from two to three or four, but I thought it might start simply quoting the articles. If I'm wrong please tell me.</p>

<p>Any help is greatly appreciated. If I haven't explained clearly enough or you have any questions please ask.</p>
","natural-language-processing"
"5115","How to figure out which words have the same meaning in two different languages?","2018-01-24 21:38:41","5178","4","222","<natural-language-processing><statistical-ai>","<p>Imagine two languages that have only these words:</p>

<pre><code>Man = 1,
deer = 2, 
eat = 3,
grass = 4 
</code></pre>

<p>And you would form all sentences possible from these words:</p>

<pre><code>Man eats deer.
Deer eats grass.
Man eats.
Deer eats.
</code></pre>

<p>German:</p>

<pre><code>Mensch = 5,
Gras = 6, 
isst = 7, 
Hirsch = 8
</code></pre>

<p>Possible german sentences:</p>

<pre><code>Mensch isst Hirsch.
Hirsch isst Gras.
Mensch isst.
Hirsch isst.
</code></pre>

<p>How would you write a program that would figure out which words have the same meaning in English and German?</p>

<p>It is possible.</p>

<p>All words get their meaning from the information in which sentences they can be used. The connection with other words defines their meaning.</p>

<p>We need to write a program that would recognize that a word is connected to other words in the same way in both languages. Then it would know those two words must have the same meaning.</p>

<p>If we take the word ""deer"" (2) it has this structure in English</p>

<pre><code>1-3-2
2-3-4
</code></pre>

<p>In german (8):</p>

<pre><code>5-6-8
8-6-7
</code></pre>

<p>We get the same structure (pattern) in both languages: both 8 and 2 lie in first and last position, and the middle word is the same in both languages, the other word is different in both languages. So we can conclude that 8=2 because both elements are connected with other elements the same way.</p>

<p>Maybe we just need to write a very good program for recognizing analogies and we will be on the right track to creating AI?</p>
","natural-language-processing"
"5110","Is there an AI system that automatically generates classes and methods by giving it voice commands?","2018-01-23 22:19:57","","3","502","<natural-language-processing><reference-request><chat-bots>","<p>I want to develop (in Java) a voice plugin for Eclipse on a Mac that helps me jot down high-level classes and stub methods. For example, I would like to command it to create a class that inherits from <code>X</code> and add a method that returns <code>String</code>.</p>

<p>Could somebody help me point out the right material to learn to achieve that?</p>

<p>I don't mind using an existing solution if it exists. As far as I understand, I would have to use some Siri interface and use nltk to convert the natural text into commands. Maybe there's some chatbot library that saves me some boilerpate NLP code to directly jump on to writing grammar or selecting sentence patterns.</p>
","natural-language-processing"
"4991","Why does Google Translate produce two different translations for the same Chinese text?","2018-01-13 20:13:58","4995","0","2516","<machine-learning><natural-language-processing><natural-language-understanding><machine-translation><google-translate>","<p>I don't understand why Google Translate translates the same text in different ways.</p>
<p><a href=""https://en.wikipedia.org/wiki/Enter_the_Dragon"" rel=""nofollow noreferrer"">Here is the Wikipedia page of the 1973 film &quot;Enter the Dragon&quot;</a>. You can see that its traditional Chinese title is: 龍爭虎鬥. <a href=""https://translate.google.com"" rel=""nofollow noreferrer"">Google translates</a> this as &quot;Dragons fight&quot;.</p>
<p>Then, if we go to <a href=""https://zh-yue.wikipedia.org/wiki/%E9%BE%8D%E7%88%AD%E8%99%8E%E9%AC%A5_(%E9%9B%BB%E5%BD%B1)"" rel=""nofollow noreferrer"">Chinese Wikipedia page of this film</a>, and search for 龍爭虎鬥 using Ctrl-F, it will be found on several places:</p>
<p><a href=""https://i.sstatic.net/cezxH.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/cezxH.png"" alt=""enter image description here"" /></a></p>
<p>But if we try to copy the hyperlink of Chinese page into Google translate, it will be the word &quot;tiger&quot; from somewhere:</p>
<p><a href=""https://i.sstatic.net/bsf5G.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/bsf5G.png"" alt=""enter image description here"" /></a></p>
<p>Even more, if we try to translate Chinese page into English using build-in Chrome translate, it will be sometimes translated as &quot;Enter the Dragon&quot;, in English manner:</p>
<p><a href=""https://i.sstatic.net/JIRQY.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/JIRQY.png"" alt=""enter image description here"" /></a></p>
<p>Why it gives different translations for the same Chinese text here?</p>
","natural-language-processing"
"4965","How do I compute the structural similarity between sentences?","2018-01-10 16:52:52","6418","14","18087","<natural-language-processing><python><similarity>","<p>I am working on a problem where I need to determine whether two sentences are similar or not.  I implemented a solution using BM25 algorithm and wordnet synsets for determining syntactic &amp; semantic similarity.  The solution is working adequately, and even if the word order in the sentences is jumbled, it is measuring that two sentences are similar. For example</p>

<ol>
<li>Python is a good language.</li>
<li>Language a good python is.</li>
</ol>

<p>My problem is to determine that these two sentences are similar.  </p>

<ul>
<li>What could be the possible solution for structural similarity? </li>
<li>How will I maintain the structure of sentences?</li>
</ul>
","natural-language-processing"